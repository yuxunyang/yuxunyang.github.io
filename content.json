{"posts":[{"title":"0 | Netty：简略梳理IO模型","text":"这是一篇对IO模式知识点的简要笔记，后续会根据知识的积累与理解继续做更新。 几种常见的IO名称最早接触的是BIO，在Java的网络编程中，有一个ServerSocket，会调用accept()方法，监听某个端口，直到有新的连接进来，代码才会继续往后执行；再到后面是NIO，一说是New IO，又说是Non-blocking IO，到底怎么叫感觉并不重要，重要的是它可以不阻塞代码的执行，但是这里有个很关键的点：不阻塞代码的情况下，如何执行相应的处理逻辑（对这个问题会在后续的Reactor相关笔记中进行阐述）？ 另外，目前还没有接触过AIO，待后续补充。 BIO完整流程示意图： 采用的开发模式为：Thread-Per-Connection，顾名思义，也就是每来一个请求，都会开一个线程，在子线程中进行逻辑处理。 阻塞同步方式 jdk1.4之前 NIO完整流程示意图： 采用的开发模式为：Reactor，简单说就是：各个业务先说清楚自己关心什么事件，然后当这个事件发生的时候，会执行该业务的逻辑。 非阻塞同步方式 Since jdk1.4 AIO非阻塞异步方式 阻塞与非阻塞阻塞和非阻塞指的是不能立刻得到结果之前，会不会阻塞当前线程。 阻塞：当前线程会被挂起，直到结果返回； 非阻塞：指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回（会导致线程切换的增加）。 线程是否需要阻塞以等待数据准备好，同理写操作也会直接返回。 同步与异步描述的是用户线程与内核的交互方式，与消息的通知机制有关： 同步：当一个同步调用发出后，需要等待返回消息（用户线程不断去询问），才能继续进行； 异步：当一个异步调用发出后，调用者不能立即得到返回消息，完成后会通过状态、通知和回调来通知调用者。 简单来说就是： 同步：同步等待消息通知，消息返回才能继续进行； 异步：异步等待消息通知，完成后被调系统通过回调等来通过调用者。 再简而言之：数据准备好了谁来读取。 同步：数据传好了之后应用程序自己去读； 异步：OS读好然后通过回调通知应用程序； 参考：极客时间-Netty源码剖析与实战Java 5种IO模型","link":"/2020/02/01/652f972433d5.html"},{"title":"0 | Spring：源代码下载、导入与Hello World","text":"最近确实受到一些打击，开始思考人生、也开始思考自己到底缺的是什么。决定从spring源代码开始学习，是我在思考后，作出的决定。但是同时我也不会放弃netty，等稍微有点时间了，我会继续开始netty相关的学习。 说起来很是惭愧，因为项目中每天都在用这个框架，也觉得自己大致懂spring是干什么的，除了偶尔看看SpringMVC的代码外，很少看过spring以及SpringBoot相关的源码，以致于连SpringBoot的自动配置也只是知道个大概。最近几天看了看SpringBoot的自动配置源码，算是从代码上有了一个了解，但是同时感觉自己对每天都在用到的Spring还所知盛少。所以，在这样的基础上，还去看netty，有一种眼高手低、“起房子我只要顶楼”的感觉。所以还是从头开始吧，毕竟这个框架，在毕业前就一致被问来问去，到现在都还没说太清楚，确实很是惭愧。 源代码的克隆从 https://github.com/spring-projects/spring-framework 克隆源代码到本地，然后导入到idea中。 如果从github上面克隆比较慢，可以先在github上面fork一份源代码到自己的账号上； 然后在gitee上，导入绑定的github账号下的项目，这个速度比较快； 最后直接从gitee上面克隆。 1git clone git@gitee.com:sasurai/spring-framework.git 这样操作的话，速度比较快。 源代码的导入看多了网上的各种教程，包括书上面的，都没有官方导入说明来得直接。 The following has been tested against IntelliJ IDEA 2016.2.2 StepsWithin your locally cloned spring-framework working directory: Precompile spring-oxm with ./gradlew :spring-oxm:compileTestJava Import into IntelliJ (File -&gt; New -&gt; Project from Existing Sources -&gt; Navigate to directory -&gt; Select build.gradle) When prompted exclude the spring-aspects module (or after the import via File-&gt; Project Structure -&gt; Modules) Code away Known issues spring-core and spring-oxm should be pre-compiled due to repackaged dependencies.See *RepackJar tasks in the build and https://youtrack.jetbrains.com/issue/IDEA-160605). spring-aspects does not compile due to references to aspect types unknown toIntelliJ IDEA. See https://youtrack.jetbrains.com/issue/IDEA-64446 for details. In the meantime, the‘spring-aspects’ can be excluded from the project to avoid compilation errors. While JUnit tests pass from the command line with Gradle, some may fail when run fromIntelliJ IDEA. Resolving this is a work in progress. If attempting to run all JUnit tests from withinIntelliJ IDEA, you will likely need to set the following VM options to avoid out of memory errors: -XX:MaxPermSize=2048m -Xmx2048m -XX:MaxHeapSize=2048m If you invoke “Rebuild Project” in the IDE, you’ll have to generate some testresources of the spring-oxm module again (./gradlew :spring-oxm:compileTestJava) TipsIn any case, please do not check in your own generated .iml, .ipr, or .iws files.You’ll notice these files are already intentionally in .gitignore. The same policy goes for eclipse metadata. FAQQ. What about IntelliJ IDEA’s own Gradle support? A. Keep an eye on https://youtrack.jetbrains.com/issue/IDEA-53476 与maven类似，import之后会使用gradle构建整个项目，这个过程中会下载依赖，默认的依赖下载网址是国外的，很慢，所以构建需要很长时间，甚至出现构建失败。 多试几次 使用阿里镜像 在用户目录下的.gradle中，新建init.gradle文件：vim ~/.gradle/init.gradle 内容是从网上抄过来的，内容如下： 123456789101112131415161718192021222324allprojects { repositories { def ALIYUN_REPOSITORY_URL = 'http://maven.aliyun.com/nexus/content/groups/public' def ALIYUN_JCENTER_URL = 'http://maven.aliyun.com/nexus/content/repositories/jcenter' all { ArtifactRepository repo -&gt; if (repo instanceof MavenArtifactRepository) { def url = repo.url.toString() if (url.startsWith('https://repo1.maven.org/maven2')) { project.logger.lifecycle &quot;Repository ${repo.url} replaced by $ALIYUN_REPOSITORY_URL.&quot; remove repo } if (url.startsWith('https://jcenter.bintray.com/')) { project.logger.lifecycle &quot;Repository ${repo.url} replaced by $ALIYUN_JCENTER_URL.&quot; remove repo } } } maven { url ALIYUN_REPOSITORY_URL url ALIYUN_JCENTER_URL } }} 架个梯子（尝试了，但是想过不太理想，可能是梯子本身太慢） 构建完成后，各个模块能够突出显示出来，与用maven构建后的效果类似。 来一个基于源码的Hello World新建一个module，然后在新建module的build.gradle中，加入对spring-framework中子模块的依赖 123456dependencies { testCompile group: 'junit', name: 'junit', version: '4.12' compile project(&quot;:spring-core&quot;) compile project(&quot;:spring-beans&quot;) compile project(&quot;:spring-context&quot;)} 只要注意这个写法就行了，与maven中加入依赖的效果是类似的，然后新建一个bean类 1234567891011121314151617181920package main.beans;public class TestBean { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;TestBean{&quot; + &quot;name='&quot; + name + '\\'' + '}'; }} xml配置文件。这段是从书上敲过来的，太坑了，连大小写都还要再改，搞得一脸懵逼。 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;testBean&quot; class=&quot;main.beans.TestBean&quot;/&gt;&lt;/beans&gt; 测试类 123456789101112package main;import main.beans.TestBean;import org.springframework.context.support.ClassPathXmlApplicationContext;public class TestMainApplication { public static void main(String[] args) { ClassPathXmlApplicationContext beanFactory = new ClassPathXmlApplicationContext(&quot;beanFactoryTest.xml&quot;); TestBean testBean = beanFactory.getBean(TestBean.class); System.out.println(testBean); }} 启动测试类，输出如下： 愉快地开始spring吧！","link":"/2020/03/23/3709269a7e44.html"},{"title":"0 | Spinnaker 官网笔记","text":"Spinnaker官网 ConceptsApplication management to view and manage your cloud resources Spinnaker 中的三个概念：Applications、 clusters、 server groups 暴露服务给用户：Load balancers 、firewall 架构图： ApplicationApplication 由多个 Cluster 组成、Cluster 由 Server Groups 组成。 Application 即所要部署的 Service。 ClusterServer Group 的逻辑组合。 Server Group可以理解成 VM images、docker image、source location 实体、配置信息的组合。 通常配备负载均衡、防火墙。 Load Balanceringress 协议+端口范围 可选开启健康检查 Firewall对某IP（段）的端口段的特定通信协议，进行流量控制。 Application deploymentPipeline由多个 Stage 组成。pipeline 可以手动/由事件触发，及对 pipeline 运行状态进行反馈。 Stage简单理解，pipeline 的组成部分。有很多种 stage，像有很多个函数一样。 部署策略Red/black(Blue/green) 绿色为新版本，蓝色为当前的稳定版本。当进行更新时，直接切到绿色的服务，如果服务不行，那么将请求全部转发到蓝色版本。 Rolling red/black通过逐个替换为最新实例来完成部署。 Canary 在小范围内使用最新版本，发现异常立即回退到就版本；如果无异常情况，那么继续扩大新版本。 a/b testing存在多个版本，通过统计，选出最优的版本。 Spinnaker架构各服务简介 Deck : 用 typescript 写的前端页面。 Gate : API 网关。Deck 只通过 Gate 来获取服务。类似 nginx 做转发。 Orca : spinnaker 的控制中枢。执行定义好的具体事件，控制 stage、task 以及协调其他 spinnaker 服务。 Clouddriver : 为 spinnaker 提供与云厂商，如 AWS, GCE, CloudFoundry, Azure，的集成服务。 Front50 : 存储 spinnaker 各种数据，如 application, pipeline, projects, notification。在内存中进行缓存。 Rosco : 创建容器、镜像。 Igor : 为 spinnaker 提供与 CI 和 SCM 集成服务。即通过 CI jobs 来触发 pipeline。 Echo : 事件中心。在 pipeline 的某个阶段发送通知。 Fiat : 用户鉴权。 Kayenta : 自动化金丝雀分析。 Halyard : 配置服务。掌管上述服务的生命周期，但是只在 spinnaker 启动、更新、回滚时，与上面的服务进行交互。 服务间依赖是不是最优的启动序列应该是这样： Fiat Rosco, Clouddriver, Front50, Keyenta Orca Echo Igor Gate Deck 涂色块表示：该列所表示的服务 依赖 该行所表示的服务。如：Deck 依赖 Gate。 服务端口 Service Port Clouddriver 7002 Deck 9000 Echo 8089 Fiat 7003 Front50 8080 Gate 8084 Halyard 8064 Igor 8088 Kayenta 8090 Orca 8083 Rosco 8087 Spinnaker执行时序Deploy 时序 SetupHalyard 是一个工具集，会帮助拉取 spinnaker 各代码的源代码、启动脚本、日志目录、pid 文件等。 Kubernetes网络策略默认接受所有到该pod的流量。","link":"/2020/11/02/5dbc8073506f.html"},{"title":"1 | Dubbo：探讨标签路由的实现","text":"项目需要，对 Dubbo 进行了一次功能调研，主要集中在服务治理中的标签路由。这部分的内容不难，但是能够对 Dubbo 的实现有一定的了解。 环境搭建需要 ZooKeeper、Java Application Based on Dubbo。 ZooKeeper 的搭建通过 CODING CD，在腾讯云的弹性伸缩组上（有兴趣可到 CODING CD 中详细了解），部署的一个实例，需要先安装 java 依赖，如下： 1java-1.8.0-openjdk-devel.x86_64 其主要的配置是一个脚本，如下： 12345678910111213141516wget http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.6.1/apache-zookeeper-3.6.1-bin.tar.gztar -xzvf apache-zookeeper-3.6.1-bin.tar.gzmv apache-zookeeper-3.6.1-bin zkmv zk/conf/zoo_sample.cfg zk/conf/zoo.cfgecho '''[Unit]Description=ZooKeeper for Dubbo After=network.target[Service]Type=forkingExecStart=/bin/sh /root/zk/bin/zkServer.sh startExecStop=/bin/sh /root/zk/bin/zkServer.sh stopUser=root[Install]WantedBy=multi-user.target ''' &gt; /usr/lib/systemd/system/zk-for-dubbo.servicesystemctl enable zk-for-dubbo 在安全组中确保端口 2181 开放。此时： 公网 IP 为 49.233.238.170 内网 IP 为 172.21.0.34 Java Application Based on DubboA 模块在调用 B 模块前，设置了一个 TAG_KEY，表示选择带有 TAG_KEY 的 B 服务： 1234567@Referenceprivate DoSomeThingService doSomeThingService;public String sayHello() { RpcContext.getContext().setAttachment(CommonConstants.TAG_KEY, &quot;tag1&quot;); return doSomeThingService.sayHello();} 应用的部署还是采用 CODING CD 部署在腾讯云的弹性伸缩组上。主要的配置如下： A 模块启动： 1java -jar -Ddubbo.registry.address=zookeeper://172.21.0.34:2181 /root/a.jar 2&gt;&amp;1 &amp; B 模块启动： 1java -jar -Ddubbo.registry.address=zookeeper://172.21.0.34:2181 /root/b.jar 2&gt;&amp;1 &amp; Dubbo admin 安装与配置dubbo-admin 使用的 github 中 develop 的最新版，按照相应的提示进行构建即可。 启动 dubbo-admin 的前端，此时的目录为 dubbo-admin/dubbo-admin-ui 1npm run dev 启动 dubbo-admin 的后端，此时的目录为 dubbo-admin/dubbo-admin-server 修改 dubbo-admin/dubbo-admin-server/src/main/resources/application.properties 文件，改成正确的 zookeeper 地址。 123admin.registry.address=zookeeper://49.233.238.170:2181admin.config-center=zookeeper://49.233.238.170:2181admin.metadata-report.address=zookeeper://49.233.238.170:2181 编译并启动 123mvn clean package -DskipTests=truecd targetjava -jar dubbo-admin-server-0.2.0-SNAPSHOT.jar 打开 dubbo-admin，找到标签路由，配置如下，应用名填写 moduleb： 123456789enabled: trueforce: trueruntime: truetags: - name: tag1 addresses: - '172.21.0.40:20880' - name: tag2 addresses: null TIPS如果有遇到在 Dubbo Admin 中修改不生效的情况，考虑一下 Dubbo Admin 与 Dubbo 版本间的差异。在此踩到一个坑如下： Dubbo Admin 管理页面是用 docker 跑起来的，它里面的源代码比较旧，路由设置到 zk 中的路径与 dubbo 读取 zk 的路径不一样。ISSUE 可见：https://github.com/apache/dubbo-admin/issues/577 效果展示请求流向：LB -&gt; A -&gt; B A 中设置的 TAG_KEY 为： 1234public String sayHello() { RpcContext.getContext().setAttachment(CommonConstants.TAG_KEY, &quot;tag1&quot;); return doSomeThingService.sayHello();} 此时 B 模块服务有两个，即一个新、一个旧。 如果要只返回最新版本，可在 dubbo-admin 控制台的服务治理中，添加标签路由，新的实例在 tag1 下，旧的实例在 tag2 下，如下： 12345678910enabled: trueforce: trueruntime: truetags: - name: tag1 addresses: - '172.21.0.21:20880' - name: tag2 addresses: - '172.21.0.40:20880' 此时的返回如下： 如果只使用旧版本实例，可在将上面 tag1 和 tag2 下面的内容调换即可，此时返回如下： 如果要同时能够访问到新旧实例的内容，将上述配置中所有的 IP 全部填写到 tag1 下即可，此时的返回如下： Dubbo 标签路由的实现原理总共分三个大的方面，分别是配置的存储、配置同步、如何解析配置。 标签路由配置的存储URL: /api/dev/rules/route/tag/modulebRequest Method: PUT 在 dubbo-admin-server 中它的实现在文件 TagRoutesController.java 中，最终是将配置保存到 ZooKeeper 中，保存的路径为： 即：/dubbo/config/dubbo/moduleb.tag-router 在 ZooKeeper 中可以在相应的路径下看到相关的配置，如下： 配置变更同步在 TagRouter.java 中实现了 ConfigurationListener 接口，当配置变更时，会更新 tagRouterRule。 123456789101112131415161718@Overridepublic synchronized void process(ConfigChangedEvent event) { if (logger.isDebugEnabled()) { logger.debug(&quot;Notification of tag rule, change type is: &quot; + event.getChangeType() + &quot;, raw rule is:\\n &quot; + event.getContent()); } try { if (event.getChangeType().equals(ConfigChangeType.DELETED)) { this.tagRouterRule = null; } else { this.tagRouterRule = TagRuleParser.parse(event.getContent()); } } catch (Exception e) { logger.error(&quot;Failed to parse the raw tag router rule and it will not take effect, please check if the &quot; + &quot;rule matches with the template, the raw rule is:\\n &quot;, e); }} 配置解析源码位于 dubbo 中的 TagRouter.java 结语在上面的示例中，我们需要手动在 dubbo-admin 界面中，新增标签路由的配置，但经过对该配置的新增过程的简要分析，发现只是在 ZooKeeper 中新增一条记录。","link":"/2020/07/30/3f3a2e801ffb.html"},{"title":"0 | kubernetes：学习路线导览与记录","text":"在之前的后端开发中，多多少少接触过一些 kubernetes 的内容，但是并未深入了解，在接触到 golang 编程以及 CD 发布系统的情形下，知道了 kubernetes 的强大之后，便开始找机会系统了解 kubernetes，因此了解 kubernetes 是一种不可多得的提升自我的方式，不论是从工作上、还是自我提升。 本文路线主要参照此教程给出的建议，记录遇到的问题以及对 kubernetes 的认识。 https://kubernetes.io/ 8月第一周本周目标 Kubernetes 的背景 安装 Kubernetes 环境 Kubernetes 基本概念和使用方法 为什么会出现 kubernetes学习任何系统的之前，了解其出现的背景和意义都是必不可少的，为什么会出现 Kubernetes？它解决了什么问题？有没有其他类似的系统？这里推荐阅读才云科技 CEO 张鑫在 2017 年文章《从风口浪尖到十字路口，写在 Kubernetes 两周年之际》。 以简易方式安装 kubernetes推荐使用 minikube 或 kind 部署一个本地环境，然后开始部署一个”真实”的应用（minikube 安装需要使用科学上网，或使用“国内版” minikube）。如果想一开始就挑战更高难度的安装方式（不推荐），可以使用 kubeadm 或者手动部署所有组件。关于安装，可以参考文档 lab1-installation。 kubernetes 资源与概念推荐熟练使用以下常用资源和概念：Pod、Node、Label、Event、Service、Configmap &amp; Secret、Deployment、Namespace。相关学习可以参考文档 lab2-application-and-service。 （可选）仅完成上述内容可能还不足以让我们非常熟悉 Kubernetes 的基本概念，下面列出其他可以参考的资料，大家也可以按照自己的方式去搜索相关的资料： 官方 Tutorial：Learn Kubernetes Basics 官方 Guestbook 样例：Guestbook Example 预期达到效果 反复加深对上面资源的操作熟练度。如果你是第一次接触 Kubernetes，或者仅了解过一点 Kubernetes 的知识，那么基（ken）本（ding）是不明白 Kubernetes 底层到底发生了什么。请不要心急，姑且把它当成一个黑盒工具即可 ?。 你可能会在网上看到更多的概念，如 PVC、Ingress、Priority 等。炼气阶段，请不要尝试学习过多的资源类型。Kubernetes 有非常多的概念和类似的资源，我们这里熟悉最核心的概念即可，否则易走火入魔 ?，切记。当我们打通任督二脉之时，所有的新概念都不过尔尔。","link":"/2020/08/02/d33b9db7e790.html"},{"title":"1 | Golang：基础数据结构","text":"三个常用的数据类型的大致实现，有点绕，但是很有收获！ 切片 Slice数据结构在64位架构的机器上，一个切片需要24字节的内存：指针字段需要8字节，长度和容量字段分别需要8字节。 var slice []int 创建的数据结构如下： 使用对新切片的长度与容量的计算规则如下： 对底层数组容量是k的切片slice[i:j]来说 长度: j - i 容量: k - i 1234567891011func showSliceLenAndCap() { //创建一个整型切片 //其长度和容量都是5个元素 slice := []int{10, 20, 30, 40, 50} fmt.Println(&quot;capacity: &quot;, cap(slice), &quot; length: &quot;, len(slice)) //创建一个新切片 //其长度为2个元素，容量为4个元素 newSlice := slice[1:3] fmt.Println(&quot;capacity: &quot;, cap(newSlice), &quot; length: &quot;, len(newSlice))} 运行结果为： 其实也很好理解，对slice[i:j] 来说，i 为新切片的第一个元素，在就切片中的数组下标，k 是原数组最大的容量，所以新切片的容量为 k - i；对 j 来说，可以视为一个前闭后开区间，即 [i, j)，也就是不包含原数组中的第 j 位，所以长度为 j - i。 当多个切片基于同一个数组时，修改共享部分的数据，在其他切片中也能看见改变。 1234567891011func showSharedArrayBySlice() { slice := []int{10, 20, 30, 40, 50} slice1 := slice[0:3] slice2 := slice[1:4] slice1[1] = 666 fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;slice1: &quot;, slice1) fmt.Println(&quot;slice2: &quot;, slice2) fmt.Println(slice2[0])} 运行结果为： 扩容 切片扩容使用 append，长度一定改变，但容量未必改变。 append 可能会导致底层数组的值被覆盖，表现为别的共享此底层数组的切片，发现内容被改变。（不一定会发生，前置条件为必须是共享的底层数组） 如何创建一个不共享底层数组的切片？ 让新产生的切片的长度、容量相同，第一次 append 的时候，发现容量不够，会进行自动扩容，使用新的底层数组，这样新增的元素，就不会影响其他共享了数组的切片 length 在 1000 以下，扩容时 x2；以上则 x1.25。 下面是上述小点的代码表述： 12345678910111213141516171819func showSliceAppend() { slice := []int{10, 20, 30, 40, 50} slice1 := slice[1:2:2] slice2 := slice[0:3] showSliceLenAndCapValue(slice1) showSliceLenAndCapValue(slice2) slice1 = append(slice1, 66) slice2 = append(slice2, 77) fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;slice1: &quot;, slice1) fmt.Println(&quot;slice2: &quot;, slice2)}func showSliceLenAndCapValue(slice []int) { fmt.Println(&quot;capacity: &quot;, cap(slice), &quot; length: &quot;, len(slice))} 运行结果如下： 迭代range 获取到的是一个元素副本。也就是说，range 的两个返回值中的 value 的地址在内存中只有一个。 映射 Map关于 Golang 中 map 的实现，有篇非常透彻的文章。与 Java 中的 HashMap 实现类似，都采用拉链法，但一个很大的不同之处在于，一个桶只能放8个键值对，超过8个，会放入溢出桶。 在Go语言里，通过键来索引映射时，即便这个键不存在也总会返回一个值。在这种情况下，返回的是该值对应的类型的零值。 在函数间传递映射并不会制造出该映射的一个副本。实际上，当传递映射给一个函数，并对这个映射做了修改时，所有对这个映射的引用都会察觉到这个修改。","link":"/2020/09/23/fb0ee74ab711.html"},{"title":"1 | Redis 基础数据结构 SDS","text":"在 redis 中，保存基础的字符串的数据结构为 Simple Dynamic String(SDS)，它是一个对 C 语言中字符串的包装结构。在 C 语言中，用 char[] str 来声明一个字符串，且每个字符串都以 \\0 结尾，一些字符串操作函数，都以 \\0 作为字符串的结束标识符。而 SDS 则作为一个结构体，包含了长度(len)、空闲(free)以及字符串(char[])。 定义比 C 字符串多含有 len、free 字段的结构体。 12345678struct sdshdr { // buf 中已占用空间的长度 int len; // buf 中剩余可用空间的长度 int free; // 数据空间 char buf[];}; 实际长度：len + free + 1 可用长度：free 字符串长度：len，不包括空字符 \\0 与C字符串的区别主要操作API","link":"/2020/11/08/5adefc0a1796.html"},{"title":"1 | Spinnaker: Agent 缓存云厂商各项数据流程分析","text":"在 clouddriver 中缓存云厂商的各项数据，是由这些 agent 所来完成。本文主要聚焦于何时执行、如何存储、以及存储后如何使用这三点上。 Agent 从哪里来创建 agent为每个云账号的每个区域创建10个不同类型的 agent 安排启动ProviderUtils.rescheduleAgents()上面的 agentScheduler 的实现类为 com.netflix.spinnaker.cats.redis.cluster.ClusteredAgentScheduler，具体操作就是将待添加的 100 个 agents 全部放到其中的 map 中，并以 accountName+region+className 作为 key。到此时，已经把新增的 agents 全部安排好了。 为什么加入到 agents 这个 map 中，agent 就能跑起来首先，ClusteredAgentScheduler 实现类 Runnable 并且，在其实现的 run 方法中，会将所有的 agents 封装成一个 Runnable，然后丢到 agentExecutionPool 中执行。 123456789101112131415@Overridepublic void run() { try { runAgents(); }//....}private void runAgents() { Map&lt;String, NextAttempt&gt; thisRun = acquire(); activeAgents.putAll(thisRun); for (final Map.Entry&lt;String, NextAttempt&gt; toRun : thisRun.entrySet()) { final AgentExecutionAction exec = agents.get(toRun.getKey()); agentExecutionPool.submit(new AgentJob(toRun.getValue(), exec, this)); }} ClusteredAgentScheduler 的 run 方法何时调用首先 ClusteredAgentScheduler 作为一个 Runnable，被加入到一个 ScheduledExecutor 中，并且它的执行周期为 30s。 123456Executors.newSingleThreadScheduledExecutor( new NamedThreadFactory(ClusteredAgentScheduler.class.getSimpleName())),// ...Integer lockInterval = agentLockAcquisitionIntervalSeconds == null ? 1 : agentLockAcquisitionIntervalSeconds;lockPollingScheduler.scheduleAtFixedRate(this, 0, lockInterval, TimeUnit.SECONDS); agentLockAcquisitionIntervalSeconds 最终来源为 yaml 文件中的配置数值即： 如何执行到 agent 的拉取逻辑上面的描述，并不是特别直观，执行到 agent 拉取逻辑的调用链路不是特别明显，它的调用链路如下： 将 agent 以及 agent 中所产生的 AgentExecution 封装到 AgentExecutionAction 中，也就是前面所述的，将 agent 加入到某个 map 中，只是做了包装。12345agentScheduler.schedule(agent, agent.getAgentExecution(catsModule.providerRegistry), catsModule.executionInstrumentation)// ...// 其中 agentExecution 最终来自 agent，也就是抽象类 CachingAgent 中的内部类。AgentExecutionAction agentExecutionAction = new AgentExecutionAction(agent, agentExecution, executionInstrumentation); 将 AgentExecutionAction 包装到 AgentJob，即一个 Runnable 中，并提交到线程池中12final AgentExecutionAction exec = agents.get(toRun.getKey());agentExecutionPool.submit(new AgentJob(toRun.getValue(), exec, this)); 在 AgentJob 的 run 方法中，执行 AgentExecutionAction 的 execute() 方法1234567891011private final AgentExecutionAction action;@Overridepublic void run() { Status status = Status.FAILURE; try { status = action.execute(); } finally { scheduler.agentCompleted( action.getAgent().getAgentType(), lockReleaseTime.getNextTime(status)); }} 在 AgentExecutionAction 中执行 agentExecution 的 executeAgent(agent) 方法12345678910111213Status execute() { try { executionInstrumentation.executionStarted(agent); long startTime = System.nanoTime(); agentExecution.executeAgent(agent); executionInstrumentation.executionCompleted( agent, TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)); return Status.SUCCESS; } catch (Throwable cause) { executionInstrumentation.executionFailed(agent, cause); return Status.FAILURE; }} executeAgent 方法来到 CachingAgent 中，此时的调用栈就相对较清晰，如下12345678910111213@Overridepublic void executeAgent(Agent agent) { AgentIntrospection introspection = new DefaultAgentIntrospection(agent); CacheResult result = executeAgentWithoutStore(agent); // 此处进入 agent 拉取逻辑 introspection.finish(result); CacheIntrospectionStore.getStore().recordAgent(introspection); storeAgentResult(agent, result);}public CacheResult executeAgentWithoutStore(Agent agent) { CachingAgent cachingAgent = (CachingAgent) agent; ProviderCache cache = providerRegistry.getProviderCache(cachingAgent.getProviderName()); return cachingAgent.loadData(cache); // 调用 agent 的拉取逻辑} 获取数据获取数据的入口是函数 loadData()，只负责从云账号拉取信息，并将信息按照一定的形式组装后返回，交给后续的逻辑处理模板进行处理。此处获取数据及组织数据的逻辑，根据 agent 类型的不同，有很大的出入，但是他们的共同点在于，组装所需返回的数据的形式。 以 TencentImageCachingAgent 为例，它有一个函数，实现了某个接口，如下： 这里有两个问题： 函数 getProvidedDataTypes() 何时调用？用于什么场景？在存储数据时进行调用，用来获取哪些数据项是可以覆盖更新的。 什么是 AgentDataType？有什么用处？首先它有两个属性，分别为 String typeName 和 Authority authority，在此处 typeName 就是 NAMESPACE 中所对应的云主机所拥有的信息类型，而 authority 有两个值，一个是 AUTHORITATIVE 表示此数据是资源数据，一个是 INFORMATIVE 表示此数据为关联数据（起关联作用）。typeName 的作用为对应后面存储操作时所需要操作的表等；authority 的作用则如上所述。 最后，loadData() 函数返回的数据，就是以上述 AgentDataType 所包含的值作为 key 的 map。 存储数据在这一部分的代码中，逻辑非常多且略带抽象，因为这一部分代码，是所有 agent 拉完数据后，进行存储的统一模板代码，有部分代码处理个别 agent 数据的情况出现。但是化繁为简，它的目的就是做存储，并且此时的存储方式，有两种，资源对应 AUTHORITATIVE；关联数据对应 INFORMATIVE。抛开 agent 的差异，专注到存储的逻辑中，它的逻辑其实也很明了。存储数据的位置在：CacheingAgent.java 的内部类 CacheExecution 的 executeAgent() 的最后一行，如下： 准备工作从 storeAgentResult(agent, result) 出发。准备工作其实主要是确定 agent 拉回的数据，哪些是需要存储的，以及用什么样的方式进行存储。 进入 SqlProviderCache.kt 的 putCacheResult 方法。它的代码很长，但是主要根据 agent 数据类型的不同，最终调用两个方法，即： 12345private fun cacheDataType(type: String, agent: String, items: Collection&lt;CacheData&gt;, authoritative: Boolean, cleanup: Boolean)private fun cacheDataType(type: String, agent: String, items: Collection&lt;CacheData&gt;, authoritative: Boolean) { cacheDataType(type, agent, items, authoritative, cleanup = true)} 本质上是调用同一个方法，也就是第一个方法，只是入参会有所不同。所以 putCacheResult 的主要逻辑可归纳如下： 根据 agent 返回数据不同，在 authoritativeTypes 中加入对应类型为资源的数据的 key。 如果 agent 返回数据的 key 中含有以 ON_DEMAND.ns，该 key 也加入到 authoritativeTypes 中，也属于资源数据。 此时分三种情况： 如果 agentType 中含有 ON_DEMAND，那么拉取结果中的 ON_DEMAND.ns 对应的 key 将被视为属于资源数据。 如果 authoritativeTypes 不为空，那么拉取结果中，key 为 AUTHORITATIVE 类型的数据，将被视为属于资源数据。 非上述两种情况，对拉取结果中所有的数据，直接覆盖更新。 对于非 AUTHORITATIVE 类型的数据，将视为属于关联数据。 有需要删除的项目，直接删除。 上面便是对此函数的抽象概括，接下来进入实际的存储操作中。按照上面的分析，实际 db 操作包括两种，即增、删。 删除删除相对比较简单。 1234567891011121314151617181920212223override fun evictDeletedItems(type: String, ids: Collection&lt;String&gt;) { // ... backingStore.evictAll(type, ids) // ...}override fun evictAll(type: String, ids: Collection&lt;String&gt;) { // ... var deletedCount = 0 var opCount = 0 try { ids.chunked(dynamicConfigService.getConfig(Int::class.java, &quot;sql.cache.read-batch-size&quot;, 500)) { chunk -&gt; withRetry(RetryCategory.WRITE) { jooq.deleteFrom(table(resourceTableName(type))) .where(&quot;id in (${chunk.joinToString(&quot;,&quot;) { &quot;'$it'&quot; }})&quot;) .execute() } deletedCount += chunk.size opCount += 1 } } //...} 增加增加的逻辑在 cacheDataType 方法中，处理逻辑比较多，比较绕。其中包括了覆盖更新、追加更新两种。从 SqlProviderCache.kt 的 cacheDataType() 进入 SqlCache.kt 的 mergeAll() 方法，便开始了新增逻辑。 创建表。如果存在就忽略。 判断是否运用那种存储方式。12345val storeResult = if (authoritative) { storeAuthoritative(type, agent, items, cleanup)} else { storeInformative(type, items, cleanup)} AUTHORITATIVE 和 INFORMATIVE 的区别： AUTHORITATIVE：操作资源表。它在更新表前，获取表名的方法为：resourceTableName(type)。 INFORMATIVE：操作 *_rel 表。它在更新表前，获取表名的方法为：relTableName(type)。 它们通过 type 来获取表名的函数的实现分别为： 12345private fun resourceTableName(type: String): String = checkTableName(&quot;cats_v${schemaVersion}_&quot;, sanitizeType(type), &quot;&quot;)private fun relTableName(type: String): String = checkTableName(&quot;cats_v${schemaVersion}_&quot;, sanitizeType(type), &quot;_rel&quot;) 另外它们两，还有一个特性上的区别，如下(来自：AgentDataType.java)： If an agent is an Authoritative source of data, then it’s resulting data set will be considered the current complete set for that data source. If an agent is an Informative source of data, its results will contribute to the data set for that type, but is never considered the complete set of data, so will not result in deletions when elements are no longer present. 资源更新-AUTHORITATIVEAUTHORITATIVE 的更新资源的逻辑如下： 12345678910111213141516171819202122// 从表中取出已经存在的信息，包括 body_hash 和 idval existingHashIds = getHashIds(type, agent)// 找出已存在信息的 idval existingIds = existingHashIds .asSequence() .map { it.id } .toSet()// 插入新的信息// 代码过长，省略// 根据 id 删除已存在的信息if (!cleanup) { return result}val toDelete = existingIds .asSequence() .filter { !currentIds.contains(it) } .toSet()evictAll(type, toDelete) 可以看出来，cleanup 为 true 的时候，才会删除之前的信息，即 cleanup 为 true 才覆盖更新。 关联资源更新-INFORMATIVE此类型的 db 相关代码逻辑较绕，即函数 storeInformative(type, items, cleanup) 中，引入了很多变量，但通过命名揣测相应含义并不太可行，需要先行知晓一些概念。用到此类型的腾讯云 agent 如下：外加一个 TencentLoadBalancerInstanceStateCachingAgent，它所实现的接口 HealthProvidingCachingAgent 引用了 INFORMATIVE，即：此处仅以 TencentLoadBalancerInstanceStateCachingAgent 为例，此 Agent 返回一个 AUTHORITATIVE 类型的 health，还有一个 INFORMATIVE 类型的 instances。health 不看，只看 instances，且直接到 storeInformative(type, items, cleanup)。 Agent 返回的数据 究竟干了啥 操作了两张表，cats_v1_instances_rel 和 cats_v1_health_rel。 其中的数据分为两类，一类是 fwd 系，另外一类是 rev 系。可能是 forward 和 reverse 的缩写。在此处，fwd 系的数据全部来自 cats_v1_instances_rel；rev 系的数据全部来自 cats_v1_health_rel。代码如下：fwdrev它们调用的方法实现如下： 由于操作了两张表，且对两张表的操作基本一致，所以对流程而言，可以只分析某一张表的操作逻辑。 其中对 fwd 系数据的操作如下： 从 agent 返回的数据中挑选出新增的数据 插入新增数据 删除失效数据（失效的定义：表中存在，但 agent 返回的数据中不存在） 与 AUTHORITATIVE 相比，cleanup 仍然是决定是否删除先前数据的一个开关，但是可以看出： AUTHORITATIVE 是将 agent 返回的所有数据，全部插入表中，且在 cleanup 开关打开后，将之前所有的数据（即上一批插入的数据）删除。 INFORMATIVE 只将 agent 返回的新增数据（即之前表中不存在的数据）插入表中，且在 cleanup 开关打开后，将之前已失效的数据删除。","link":"/2020/07/30/20d4d0eeb1ae.html"},{"title":"1 | SpringBoot：配置文件的加载顺序","text":"SpringBoot 官方文档说明","link":"/2020/08/03/1ccace6d1c44.html"},{"title":"1 | SpringCloud：nacos从入门到出门","text":"nacos可提供动态服务发现、服务配置、服务元数据及流量管理。 nacos集群搭建 下载nacos：https://github.com/alibaba/nacos/releases/download/1.2.0/nacos-server-1.2.0.zip 解压 修改startup.cmd中的MODE为cluster，只要不为standalone就行。 复制bin/startup.cmd，分别为bin/startup-8858.cmd，bin/startup-8868，这样会得到3份启动脚本，然后在复制出来的脚本中，分别加入所需要绑定的端口，如下： 1234// bin/startup-8858.cmdset &quot;JAVA_OPT=%JAVA_OPT% -Dserver.port=8858&quot;// bin/startup-8868.cmdset &quot;JAVA_OPT=%JAVA_OPT% -Dserver.port=8868&quot; 注意位置，放在读取默认配置代码的后面，会导致端口修改不生效。最保险的是放在这个变量最开始地方的前面。可参考下面的修改： 重命名cluster.conf.example为cluster.conf，然后加入其它实例信息： 123192.168.137.1:8848192.168.137.1:8858192.168.137.1:8868 在docker环境中创建一个mysql容器，root密码为root，如下： 1docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:5.7 登录进MySQL，新增一个nacos数据库，然后运行conf/nacos-mysql.sql，导入nacos需要的表结构： 修改application.properties中数据库相关的配置 依次点击startup.cmd、startup-8858.cmd、startup-8868.cmd 然后随便打开一个实例的url，这里选了8848的实例，如下： 后面还可以考虑做一个nginx，对三个nacos做一下负载均衡，docker运行指令如下： 1docker run --name nginx -v /d/projects/nginx:/etc/nginx -p 80:80 -d nginx nginx的配置信息如下： 12345678910111213141516171819202122232425user www-data; ## 配置 worker 进程的用户和组worker_processes auto; ## 配置 worker 进程启动的数量，建议配置为 CPU 核心数error_log logs/error.log; ## 全局错误日志pid /run/nginx.pid; ## 设置记录主进程 ID 的文件worker_rlimit_nofile 8192; ## 配置一个工作进程能够接受并发连接的最大数events { }http{ upstream nacos { server 192.168.137.1:8848; server 192.168.137.1:8858; server 192.168.137.1:8868; } server { listen 80; server_name localhost; location /nacos/ { proxy_pass http://nacos/nacos/; } }} 还试了一下，删掉leader，过段时间会重新选举出来新的leader。 如何在代码中使用nacos还是继续分成两种类型，一种是配置相关，另一种是服务注册与发现。 配置信息可通过web端访问localhost/nacos来进行管理，也可以通过命令行进行简单的查询、管理： 1234// 发布配置curl -X POST &quot;http://localhost/nacos/v1/cs/configs?dataId=module-01.yml&amp;group=DEFAULT_GROUP&amp;content=hellonacos&quot;// 获取配置curl -X GET &quot;http://localhost/nacos/v1/cs/configs?dataId=module-01.yml&amp;group=DEFAULT_GROUP&quot; 在代码中使用nacos的配置使用时，以Spring Cloud为例（也可参考官方文档demo）： ①pom文件需要特别注意版本问题，用官方的实例都有问题，主要体现在配置发布了之后不能刷新。 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba.cloud/spring-cloud-starter-alibaba-nacos-config --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 出问题的原因主要是版本不一致。主要是看Spring Boot的版本，这里的Spring Boot版本是v2.2.5.RELEASE，根据官网版本说明wiki可以看出： 所以这里选2.2.0.RELEASE版本的spring-cloud-starter-alibaba-nacos-config。按照官网example的例子，选0.2.1.RELEASE配置更新后，并不会刷新。 ②resources下面新建bootstrap.yaml，并在nacos上面创建好module-01.yaml。 12345678910spring: application: name: module-01 cloud: nacos: config: refresh: enabled: true server-addr: localhost file-extension: yaml module-01.yaml的内容如下： ③创建启动类。与普通Spring Boot应用无区别。 123456789101112package com.example.springloud.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); }} ④创建获取配置信息的接口。需要加上@RefreshScope，以使自动刷新生效。 12345678910111213141516171819package com.example.springloud.demo.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(&quot;config&quot;)@RefreshScopepublic class GetDynamicValueController { @Value(value = &quot;${hello}&quot;) private String dynamicValueStr; @RequestMapping(&quot;get&quot;) public String getStr() { return dynamicValueStr; }} ⑤修改配置，看能否自动刷新。如果加了@RefreshScope注解，但还是不能自动刷新，可考虑检查Spring Boot与spring-cloud-starter-alibaba-nacos-config版本是否一致。 服务注册与发现在开始之前，还是要注意一下版本问题。 ①pom文件导入spring-cloud-starter-alibaba-nacos-discovery。版本选的2.2.0.RELEASE，原因同上所述。如果不能运行了，那么再参看官网wiki上面的版本对应表进行修改。 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; ②bootstrap.yaml文件中加入服务发现相关的配置： 12345678910spring: application: name: module-01 cloud: nacos: discovery: server-addr: localhost config: server-addr: localhost file-extension: yaml ③创建RestTemplate实例，然后加上@LoadBalanced注解，开启 @LoadBalanced 与 Ribbon 的集成。 12345678910111213141516package com.example.springloud.demo.beans;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class LoadBalancedTemplate { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); }} ④在Controller中注入restTemplate，然后新建一个新的接口config/remote-get，通过nacos，调用注册在其上的config/get接口，作为返回。 123456789101112131415161718192021222324252627282930package com.example.springloud.demo.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestController@RequestMapping(&quot;config&quot;)@RefreshScopepublic class GetDynamicValueController { @Value(value = &quot;${hello}&quot;) private String dynamicValueStr; @Autowired private RestTemplate restTemplate; @RequestMapping(&quot;get&quot;) public String getStr() { return dynamicValueStr; } @RequestMapping(&quot;remote-get&quot;) public String getStrViaNacos() { return restTemplate.postForObject(&quot;http://module-01/config/get&quot;, null, String.class); }} 此时的demo整体架构为： ⑤运行代码，可以观察到nacos上面的服务列表中出现了module-01： 调用config/remote-get接口，正常返回config/get接口的数据：","link":"/2020/03/12/4c4e3782503c.html"},{"title":"1 | Spring：基础注解使用及场景概述","text":"本来是打算按照书上面的内容，跟着看一看spring的实现。它是从XML中读取bean配置，感觉现在不怎么用XML来配置了，虽然可以跳过bean的读取，直接看bean的生命周期，但是毕竟现在基本上用注解，所以从网上找了一个直接基于注解讲解spring源码的视频。 视频内容讲解spring的AOP感觉很好，至少第一遍的时候，看懂了一个大概。这篇博客在看第一遍的时候，记录了大概的内容，可以算是一个笔记；第二遍是在第一遍笔记的基础上，自己写代码进行实现、测试，并将代码和当时的想法再记录上来，有问题了再看视频。 概览 组件添加类注解 先看看比较基础的注解的用法。这个里面比较重要的注解有@Import，后面讲AOP经常用到，特别是在@Import中传ImportBeanDefinitionRegistrar的用法。因为AOP的入口点就是利用了这个注解。 @Configuration + @Bean这是一个很常用的组合，在项目中也经常用到过。但是有一个地方需要注意，被@Bean修改的函数的函数名，默认情况下，会是返回bean的名字。要改名可以通过设置@Bean的name属性。 123456789101112public class BasicMain { public static void main(String[] args) { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(BasicConfig.class);// System.out.println(applicationContext.getBean(Person.class)); for (String definitionName : applicationContext.getBeanDefinitionNames()) { System.out.println(definitionName); } }} 结果是： 这里有一个问题：为什么可以生成3个BeanDefinition，但是获取的时候，会报错失败？。先留给后面吧。 @Scopespring默认情况下，bean是单例。可设置为多实例：prototype。如下： 1234567891011121314151617181920@Configurationpublic class BasicAnnotationConfig { @Bean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public Person getPerson() { return new Person(&quot;萨日朗&quot;, 11); } @Bean @Scope(ConfigurableBeanFactory.SCOPE_SINGLETON) public Actor getActor() { return new Actor(); } @Bean public Programmer getProgrammer() { return new Programmer(); }} 然后创建IOC容器，然后对上面的3个bean都获取两次，比较两次获得的内容是否为同一对象。 123456789101112131415public static void main(String[] args) { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(BasicAnnotationConfig.class); Person person1 = applicationContext.getBean(Person.class); Person person2 = applicationContext.getBean(Person.class); System.out.println(&quot;Person: &quot; + (person1 == person2)); Actor actor1 = applicationContext.getBean(Actor.class); Actor actor2 = applicationContext.getBean(Actor.class); System.out.println(&quot;Actor: &quot; + (actor1 == actor2)); Programmer programmer1 = applicationContext.getBean(Programmer.class); Programmer programmer2 = applicationContext.getBean(Programmer.class); System.out.println(&quot;Programmer: &quot; + (programmer1 == programmer2));} 结果为： @ComponentScan自动扫描包下的bean。 12345678public class ComponentScanMain { public static void main(String[] args) { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ComponentScanConfig.class); for (String definitionName : applicationContext.getBeanDefinitionNames()) { System.out.println(definitionName); } }} 包、类的情况如下，其中dao和services下面的类，都是空类，没有任何其他数据，只有@Service和@Repository注解。 12345678910111213test-spring/src/main/java/└── run └── oxffff └── spring ├── apps │ └── ComponentScanMain.java ├── configs │ └── ComponentScanConfig.java ├── dao │ └── PersonDao.java └── services ├── SpeakService.java └── TalkService.java 结果 @ComponentScan还可以指定exclude和include属性，分别表示要排除的内容、扫描的内容。使用一个项目中用到的示例，效果就不演示了： 12345@ComponentScan(excludeFilters = {@ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, value = {com.***.service.AlgoProducer.AlgoProducerConfig.class, com.***.service.WsProducer.WsProducerConfig.class})}) type还有好几种，分别是： FilterType.ANNOTATION。注解类型 FilterType.ASSIGNABLE_TYPE。给定的类型 FilterType.ASPECTJ。AspectJ表达式 FilterType.REGEX。正则表达式 FilterType.CUSTOM。自定义过滤规则 如果指定的是自定义过滤规则，那么后面value表示的类，需要实现TypeFilter的match方法。 @Lazy懒加载bean @Conditional条件加载bean。其中的value是一个数组类型，数组中的元素必须实现了Condition接口。 123456@Target({ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Conditional { Class&lt;? extends Condition&gt;[] value();} Condition接口只有一个match方法，实现即可。 123public interface Condition { boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);} matches方法的两个参数，可以用来做什么？简单理解，Spring Boot中有一个@ConditionalOnBean，基于Conditional，它的作用就是当容器中已经某些特定的bean时，加载某些bean。 另外，在Spring Boot中有很多基于@ConditionalXXXXX的注解，都是基于此注解。以@ConditionalOnProperty为例，项目中曾用到过此注解，解决一些关于不同环境的配置问题。 1234@Conditional(OnPropertyCondition.class)public @interface ConditionalOnProperty { // ...} 所以这个OnPropertyCondition一定是一个实现了Condition的类，可以从下面的继承继承结构中看出来： @Import快速导入bean，id默认是全类名。这个注解很重要，理解这个注解，对后面AOP的理解有很大的帮助。 普通类 不是很确定能不能导入，特地测试了一下，是可以import到IOC容器中的。 被@Configuration注解的类 实现了ImportSelector的类。此项返回的是一个类全名数组。 实现了ImportBeanDefinitionRegistrar的类。 手动注册Bean到IOC容器。 主要测试一次实现了ImportBeanDefinitionRegistrar接口的value值，后面用到的比较多。这里先实现一个如下： 123456public class MyInportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { registry.registerBeanDefinition(&quot;programmer&quot;, new RootBeanDefinition(Programmer.class)); }} 配置信息，主要是验证导入普通类、实现了ImportBeanDefinitionRegistrar的类。 1234@Configuration@Import({Actor.class, MyInportBeanDefinitionRegistrar.class})public class ImportConfig {} 启动类为，主要功能是打印容器中的bean name： 12345678public class ImportMain { public static void main(String[] args) { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ImportConfig.class); for (String definitionName : applicationContext.getBeanDefinitionNames()) { System.out.println(definitionName); } }} 结果导入了两个bean，如下： 可以看出来，import普通类时，默认的名称是类全名。 FactoryBean的使用实现FactoryBean的类，然后用@Bean注解一个返回实现了该类的对象。 定义一个Actor的FactoryBean，并实现相应的方法。 12345678910111213141516public class ActorFactoryBean implements FactoryBean&lt;Actor&gt; { @Override public Actor getObject() throws Exception { return new Actor(); } @Override public Class&lt;?&gt; getObjectType() { return Actor.class; } @Override public boolean isSingleton() { return true; }} 在配置类中，生成相应的bean配置。 1234567@Configurationpublic class FactoryBeanConfig { @Bean public ActorFactoryBean getActorFactoryBean() { return new ActorFactoryBean(); }} 通过ActorFactoryBean的bean名称，获取bean，看得到的bean类型是什么，然后再加一个&amp;符号，对比两次结果： 123456789101112131415public class ActorFactoryBeanMain { public static void main(String[] args) { ApplicationContext applicationContext = new AnnotationConfigApplicationContext(FactoryBeanConfig.class); for (String definitionName : applicationContext.getBeanDefinitionNames()) { System.out.println(definitionName); } Object obj1 = applicationContext.getBean(&quot;getActorFactoryBean&quot;); System.out.println(obj1.getClass()); Object obj2 = applicationContext.getBean(&quot;&amp;getActorFactoryBean&quot;); System.out.println(obj2.getClass()); }} 容器中存在的bean是getObject()方法返回的对象，加&amp;可获取factoryBean本身。 Bean的生命周期主要参考了这篇博客，总结得很好。 流程图 分类Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类： Bean自身的方法：这个包括了Bean本身调用的方法和通过配置文件中bean的init-method和destroy-method指定的方法。 Bean级生命周期接口方法：这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法。 容器级生命周期接口方法：这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。 工厂后处理器接口方法：这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 用法 通过@Bean的initMethod和destroyMethod分别指定初始化方法、销毁方法。 对象创建完成、并赋值好，才调用initMethod； 单例bean会执行销毁方法，多实例bean不会执行销毁方法； 单示例：在容器启动时创建对象；多实例：在每次获取时创建对象。 初始化方法都执行 通过让Bean实现InitializingBean、DisposableBean来实现参与初始化、销毁。 InitializingBean的afterPropertiesSet方法在initMethod方法之前执行； DisposableBean的destroy方法在destroyMethod之前执行。 通过@PostConstruct、@PreDestroy注解来指定 这两个是J2EE中的注解，需要导入javax.annotation-api依赖，如下： 12// https://mvnrepository.com/artifact/javax.annotation/javax.annotation-apicompile group: 'javax.annotation', name: 'javax.annotation-api', version: '1.3.2' @PostConstruct在bean的所有依赖都注入完成后，会调用。在InitializingBean的afterPropertiesSet方法之前执行（测试结果如此）。 @PreDestroy在DisposableBean的destroy方法之前执行（测试结果如此）。 通过实现BeanPostProcessor方法来 这个接口太厉害了，数据校验、@Autowire注入等等都是通过此接口来实现的。它有两个函数，他们的执行时机如下所示： 示例对上面4种情况，参考一些资料写了如下demo，验证其中的调用顺序。 测试bean 123456789101112131415161718192021222324252627282930313233343536373839404142public class LifeCycleTestBean implements InitializingBean, DisposableBean, BeanFactoryAware, BeanNameAware { public LifeCycleTestBean() { System.out.println(&quot;构造器执行...&quot;); } public void init1() { System.out.println(&quot;bean init method -&gt; init1...&quot;); } @PostConstruct public void init2() { System.out.println(&quot;PostConstruct...init2...&quot;); } @Override public void afterPropertiesSet() throws Exception { System.out.println(&quot;InitializingBean...afterPropertiesSet...&quot;); } @Override public void destroy() throws Exception { System.out.println(&quot;DisposableBean...destroy...&quot;); } @PreDestroy public void destroy2() throws Exception { System.out.println(&quot;PreDestroy...destroy...&quot;); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(&quot;BeanFactoryAware...setBeanFactory...&quot;); } @Override public void setBeanName(String name) { System.out.println(&quot;BeanNameAware...setBeanName...&quot;); }} bean后置处理器 12345678910111213public class MyBeanPostProcessor implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;Before 【&quot; + beanName + &quot;】 initialization&quot;); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(&quot;After 【&quot; + beanName + &quot;】 initialization&quot;); return bean; }} 配置类 1234567891011121314151617@Configurationpublic class LifeCycleConfig { @Bean(initMethod = &quot;init1&quot;, destroyMethod = &quot;destroy2&quot;) public LifeCycleTestBean getLifeCycleTestBean() { return new LifeCycleTestBean(); } @Bean public MyBeanPostProcessor getMyBeanPostProcessor() { return new MyBeanPostProcessor(); } @Bean public Actor getActor() { return new Actor(); }} 启动类 12345678public class LifeCycleMain { public static void main(String[] args) { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(LifeCycleConfig.class); System.out.println(&quot;容器创建完成...&quot;); LifeCycleTestBean lifeCycleBean = ac.getBean(LifeCycleTestBean.class); ac.close(); }} 结果。结论都写在上面了。 赋值 @Value 基本数值；@Value(&quot;洋芋&quot;) SpEL；@Value(&quot;#{20 - 2}&quot;) 配置文件取值。@Value(&quot;${server.port}&quot;)。可以用@PropertySource(&quot;classpath:/**.properties&quot;)指定外部配置文件 自动装配Spring利用依赖注入(DI)，完成对IOC容器中各个组件的依赖关系赋值。 @AutowiredSpring注解。 默认优先按类型去容器中找TestBean组件。 12@Autowiredprivate TestBean testBean1; 如果有多个TestBean，默认情况下，会再按照属性名testBean1去匹配。此时也可以用@Qualifier指定想要的beanName。如下会加载beanName为testBean的bean。 123@Qualifier(&quot;testBean&quot;)@Autowiredprivate TestBean testBean1; 默认情况下，如果IOC容器中没有相应的bean，会报初始化错误。可以通过@Autowired注解中的required属性来设置，默认为true。即： 12@Autowired(required = false)private TestBean testBean1; 还可以通过@Primary来设置首选bean。 @Autowired标注在不同地方的区别： set方法上。从IOC容器中取bean作为参数。 构造器上。从IOC容器中去bean作为参数；一个参数时，可省略@Autowired。 参数上。从IOC容器中去bean作为参数。 被@Bean注解的函数的参数，可用@Autowired注入，可省略。 @ResourceJava规范注解。 默认按照组件名称进行装配，可以通过name属性修改。不支持@Primary、没有required属性。 @InjectJava规范注解。 需要导入依赖javax.inject。与@Autowired类似，但是没有required属性。 环境相关@Profile它的作用是指定此Bean所对应的环境，不是该环境时，不加载此bean。环境可以通过spring.profiles.active属性来指定，也可以通过JVM参数：-Dspring.profiles.active=test来指定。 获取Spring容器底层组件 想要名为xxx的组件，实现xxxAware接口，最后交由xxxAwareProcessor。 例如：获取ApplicationContext需要实现ApplicationContextAware，而对它的处理是通过ApplicationContextAwareProcessor来处理，ApplicationContextAwareProcessor即实现了BeanPostProcessor，也就是前面所遇到的那个后置处理器。 Spring AOP基础概念 通知（Advice）具体做的工作。比如打印日志。 连接点（JoinPoint）可以进行扩展的一个时机。比如说调用方法时、修改一个字段时等，但spring只支持调用方法时。 切点（PointCut）通知所要织入的具体位置。以调用方法这个连接点为例，方法有很多，不可能为所有的方法都加入通知，那些被选中的方法就是切点。 切面（Aspect）切点与切面的集合。 织入（Weaving）将切面应用到目标对象并创建代理对象的过程。通俗理解，把目标对象装饰加强成加入通知的代理对象。有3种织入时期：编译期、类加载期、运行期（Spring AOP）。 使用步骤 导入aop模块，即spring-aspects依赖 1compile project(&quot;:spring-aspects&quot;) 定义业务逻辑类。 12345public class Divider { public int div(int x, int y) { return x / y; }} 定义切面类。 通知包括：①前置通知（@Before）、②后置通知（@After）、③返回通知（@AfterReturning）、④异常通知（@AfterThrowing）、⑤环绕通知（@Around），分别对应目标方法执行前、执行后、返回后、异常时。 123456789101112131415161718192021222324252627@Aspectpublic class DividerAspect { @Pointcut(&quot;execution(* run.oxffff.spring.beans.Divider.div(..))&quot;) public void pointcut() { } @Before(&quot;pointcut()&quot;) public void before() { System.out.println(&quot;Before div()&quot;); } @After(&quot;pointcut()&quot;) public void after() { System.out.println(&quot;After div()&quot;); } @AfterReturning(&quot;pointcut()&quot;) public void afterReturning() { System.out.println(&quot;After div() returning&quot;); } @AfterThrowing(&quot;pointcut()&quot;) public void afterThrowing() { System.out.println(&quot;After div() throwing&quot;); }} @Aspect一定要加，这个注解相当于一个开关，加上了才会进行织入操作。 在切面类的目标方法中标注何时在何处运行。 可使用@PointCut简化代码。切点的写法可参考： 将切面类、业务类都放入IOC容器，并且通过IOC容器获取业务类。 12345678910111213@Configuration@EnableAspectJAutoProxypublic class AopConfig { @Bean public Divider getDivider() { return new Divider(); } @Bean public DividerAspect getDividerAspect() { return new DividerAspect(); }} 必须使用@Aspect指明哪个bean将作为切面类。 在@Configuration注解标注的配置类中，开启注解@EnableAspectJAutoProxy。 启动类 12345678public class AopMain { public static void main(String[] args) { ApplicationContext ac = new AnnotationConfigApplicationContext(AopConfig.class); Divider divider = ac.getBean(Divider.class); System.out.println(divider.div(1, 2)); System.out.println(divider.div(1, 0)); }} 执行结果 注意：JoinPoint在切面方法中如果要注入，必须要放在第一个参数位上。为啥？深刻怀疑是用了args[0]，哈哈。","link":"/2020/03/25/5b62a62a88c2.html"},{"title":"1 | netty：粘包与拆包的处理","text":"TCP是个流协议，流是一串没有界限的数据。TCP会根据TCP缓冲区的实际情况对包进行划分。因此造成一个完整的业务包，会被TCP分成多个包、把多个包封装成一个大的包进行发送。 粘包与拆包现象 服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包； 服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包； 服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这被称为TCP拆包； 服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包。 产生原因 应用程序write写入的字节大小/大于套接口发送缓冲区大小； 进行MSS大小的TCP分段； 以太网帧的payload大于MTU进行IP分片。 对于Linux，发送缓冲区的默认值为：16384。可使用下面命令查看： 12345678910# 接收cat /proc/sys/net/ipv4/tcp_rmem# min default max# 4096 87380 6291456 (单位：byte)# 4K 85K 6M# 发送(单位：byte)cat /proc/sys/net/ipv4/tcp_wmem# min default max# 4096 16384 4194304 (单位：byte)# 4K 16K 4M 数据来自百度云的云服务器： 对于MacOS，可参考：sysctl net.inet.tcp，但是好像没找到与linux类似的参数。 如何解决 Netty如何解决 Netty中主要是在收到数据后，对数据进行处理解码处理时，根据不同的策略，进行了拆包操作，然后将得到的完整的业务数据包传递给下个处理逻辑。分割前后的逻辑主要在ByteToMessageDecoder这个类中。它的继承如下： 每次从TCP缓冲区读到数据都会调用其channelRead()方法。这个函数的处理逻辑是： 用累加器cumulator将新读入的数据(ByteBuf)存储到cumulation中； 调用解码器 累加器存在两个累加器，MERGE_CUMULATOR和COMPOSITE_CUMULATOR。默认的是前者，即:private Cumulator cumulator = MERGE_CUMULATOR;。 MERGE_CUMULATOR会先判断是否需要扩容，然后再将收到的msg拷贝到cumulation中。 12345678910111213141516171819202122232425/** * Cumulate {@link ByteBuf}s by merge them into one {@link ByteBuf}'s, using memory copies. */public static final Cumulator MERGE_CUMULATOR = new Cumulator() { @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) { try { final int required = in.readableBytes(); if (required &gt; cumulation.maxWritableBytes() || (required &gt; cumulation.maxFastWritableBytes() &amp;&amp; cumulation.refCnt() &gt; 1) || cumulation.isReadOnly()) { // Expand cumulation (by replacing it) under the following conditions: // - cumulation cannot be resized to accommodate the additional data // - cumulation can be expanded with a reallocation operation to accommodate but the buffer is // assumed to be shared (e.g. refCnt() &gt; 1) and the reallocation may not be safe. return expandCumulation(alloc, cumulation, in); } return cumulation.writeBytes(in); } finally { // We must release in in all cases as otherwise it may produce a leak if writeBytes(...) throw // for whatever release (for example because of OutOfMemoryError) in.release(); } }}; 扩容的过程是先得到一个能够容纳下原数据+当前数据的收集器，然后将原数据和当前数据依次拷贝进入收集器，最后释放旧的收集器里面的数据。 12345678910111213private static ByteBuf expandCumulation(ByteBufAllocator alloc, ByteBuf oldCumulation, ByteBuf in) { ByteBuf newCumulation = alloc.buffer(alloc.calculateNewCapacity( oldCumulation.readableBytes() + in.readableBytes(), MAX_VALUE)); ByteBuf toRelease = newCumulation; try { newCumulation.writeBytes(oldCumulation); newCumulation.writeBytes(in); toRelease = oldCumulation; return newCumulation; } finally { toRelease.release(); }} COMPOSITE_CUMULATOR是将每个新收到的消息，作为一个Component存储到收集器CompositeByteBuf中的components数组中。 12345678910111213141516171819202122232425262728293031323334353637/** * Cumulate {@link ByteBuf}s by add them to a {@link CompositeByteBuf} and so do no memory copy whenever possible. * Be aware that {@link CompositeByteBuf} use a more complex indexing implementation so depending on your use-case * and the decoder implementation this may be slower then just use the {@link #MERGE_CUMULATOR}. */public static final Cumulator COMPOSITE_CUMULATOR = new Cumulator() { @Override public ByteBuf cumulate(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf in) { try { if (cumulation.refCnt() &gt; 1) { // Expand cumulation (by replace it) when the refCnt is greater then 1 which may happen when the // user use slice().retain() or duplicate().retain(). // // See: // - https://github.com/netty/netty/issues/2327 // - https://github.com/netty/netty/issues/1764 return expandCumulation(alloc, cumulation, in); } final CompositeByteBuf composite; if (cumulation instanceof CompositeByteBuf) { composite = (CompositeByteBuf) cumulation; } else { composite = alloc.compositeBuffer(MAX_VALUE); composite.addComponent(true, cumulation); } composite.addComponent(true, in); in = null; return composite; } finally { if (in != null) { // We must release if the ownership was not transferred as otherwise it may produce a leak if // writeBytes(...) throw for whatever release (for example because of OutOfMemoryError). in.release(); } } }}; 拆包解码流程callDecode()方法中的decodeRemovalReentryProtection()将调用decode()方法，其中decode()是一个抽象方法，由子类去实现。主要的子类有： FixedLengthFrameDecoder里面有一个属性叫frameLength，用来表示消息的长度。 123456789A decoder that splits the received ByteBufs by the fixed number of bytes. For example, if you received the following four fragmented packets: +---+----+------+----+ | A | BC | DEFG | HI | +---+----+------+----+A FixedLengthFrameDecoder(3) will decode them into the following three packets with the fixed length: +-----+-----+-----+ | ABC | DEF | GHI | +-----+-----+-----+ 流程也比较简单，收集器里面的数据长度够frameLength，就从收集器中截取frameLengthbyte，然后返回一个新的ByteBuf。 123456789101112131415161718192021222324@Overrideprotected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception { Object decoded = decode(ctx, in); if (decoded != null) { out.add(decoded); }}/** * Create a frame out of the {@link ByteBuf} and return it. * * @param ctx the {@link ChannelHandlerContext} which this {@link ByteToMessageDecoder} belongs to * @param in the {@link ByteBuf} from which to read data * @return frame the {@link ByteBuf} which represent the frame or {@code null} if no frame could * be created. */protected Object decode( @SuppressWarnings(&quot;UnusedParameters&quot;) ChannelHandlerContext ctx, ByteBuf in) throws Exception { if (in.readableBytes() &lt; frameLength) { return null;// 长度不够，此次decode不产生消息 } else { return in.readRetainedSlice(frameLength); }} 有一个问题，如果一次收到的数据长度为2 * frameLength，且这个数据是最后一个数据，那么是否存在解码出现异常的情况？ 有一个循环 输入结束的时候再次调用解码 LineBasedFrameDecoder流程是先找到当前消息中的换行符，存在且没有超过最大长度，返回解释到的数据。 DelimiterBasedFrameDecoder根据特定的字符进行分割，其中如果分割符是行标志，会调用LineBasedFrameDecoder进行分割解码。 1234567891011// decode()方法中if (lineBasedDecoder != null) { return lineBasedDecoder.decode(ctx, buffer);}// lineBasedDecoder不为空的情况是分割字符是行分割字符// 构造方法中if (isLineBased(delimiters) &amp;&amp; !isSubclass()) { lineBasedDecoder = new LineBasedFrameDecoder(maxFrameLength, stripDelimiter, failFast); this.delimiters = null;} 判断分割符是否为行分割符的代码如下： 1234567891011121314private static boolean isLineBased(final ByteBuf[] delimiters) { if (delimiters.length != 2) { return false; } ByteBuf a = delimiters[0]; ByteBuf b = delimiters[1]; if (a.capacity() &lt; b.capacity()) { a = delimiters[1]; b = delimiters[0]; } return a.capacity() == 2 &amp;&amp; b.capacity() == 1 &amp;&amp; a.getByte(0) == '\\r' &amp;&amp; a.getByte(1) == '\\n' &amp;&amp; b.getByte(0) == '\\n';} 因为分割字符可能是多个，当数据中存在多个分割字符的情况下，会用分割后得到的数据最短的那个分割字符。如下： 12345678910// Try all delimiters and choose the delimiter which yields the shortest frame.int minFrameLength = Integer.MAX_VALUE;ByteBuf minDelim = null;for (ByteBuf delim: delimiters) { int frameLength = indexOf(buffer, delim); if (frameLength &gt;= 0 &amp;&amp; frameLength &lt; minFrameLength) { minFrameLength = frameLength; minDelim = delim; }} For example, if you have the following data in the buffer: +————–+ | ABC\\nDEF\\r\\n | +————–+ a DelimiterBasedFrameDecoder(Delimiters.lineDelimiter()) will choose ‘\\n’ as the first delimiter and produce two frames: +—–+—–+ | ABC | DEF | +—–+—–+ rather than incorrectly choosing ‘\\r\\n’ as the first delimiter: +———-+ | ABC\\nDEF | +———-+ LengthFieldBasedFrameDecoder简而言之，就是在数据的头部，放一个专门的长度位，根据长度位来读取后面信息的内容。 这个类比较有意思，注释差不多占了2/5。主要的处理逻辑是decode()，但是这个方法100行都不到。注释主要解释了这个类里面几个参数的不同配置，产生不同的处理情况。 情况对应于下表： lengthFieldOffset lengthFieldLength lengthAdjustment initialBytesToStrip 0x01 0 2 0 0 0x02 0 2 0 2 0x03 0 2 -2 0 0x04 2 3 0 0 0x05 0 3 2 0 0x06 1 2 1 3 0x07 1 2 -3 3 0x01lengthFieldLength = 2表示长度位占头部的2 bytes，剩下的都是消息占位，也就是0x000C(12) + 2 = 14。 0x02与0x01类似，只是多了initialBytesToStrip = 2，解码后的内容截取掉了头部的initialBytesToStrip位。也就是解码后的长度为14 - initialBytesToStrip = 12。 0x03这种情况下，长度位的值，表示整个包的长度，包括长度位本身的长度。lengthAdjustment = -2表示要将长度位的值加上lengthAdjustment,作为消息的长度。 0x04与0x01相比，多了个一个长度位的偏移量lengthFieldOffset。所以长度位的前面又可以放一些其他数据。也就是说，真正的消息是从lengthFieldOffset + lengthFieldLength后开始。 0x05与0x03对比，只是lengthAdjustment的正负不同，也就意味着真实的消息是在长度位后面是有偏移的，而偏移出来的空间，可以用作存放另外一种数据类型。 0x06在0x04、0x05的基础上，长度位多了偏移lengthFieldOffset，真实的消息的偏移又多加了一个lengthAdjustment，然后截掉了头部开始的initialBytesToStripbytes。 0x07在0x06的基础上，lengthAdjustment变成负数了，与0x03的情况类似。 整体代码的流程除去异常处理的情况，就是计算整个消息的长度，然后跳过要求跳过的字节数，再从ByteBuf中读取消息。如下： 参考： 《Netty权威指南》 netty源码分析之拆包器的奥秘","link":"/2020/01/01/735c928aff1c.html"},{"title":"2 | Golang： 笔记","text":"Go语言允许用户定义类型。当用户声明一个新类型时，这个声明就给编译器提供了一个框架，告知必要的内存大小和表示信息。声明后的类型与内置类型的运作方式类似。Go语言里声明用户定义的类型有两种方法。最常用的方法是使用关键字struct，它可以让用户创建一个结构类型。 零值：当声明变量时，这个变量对应的值总是会被初始化。这个值要么用指定的值初始化，要么用零值（即变量类型的默认值）做初始化。 对数值类型来说，零值是0； 对字符串来说，零值是空字符串； 对布尔类型，零值是false。 结构里每个字段都会用零值初始化。 任何时候，创建一个变量并初始化为其零值，习惯是使用关键字var。 123456type user struct{ name string email string ext int privileged bool} 方法：本质上还是函数，但是在 func 和 名称之间，多了一个括号，表示这个方法属于某个 struct。关键字func和函数名之间的参数被称作接收者，将函数与接收者的类型绑在一起。如果一个函数有接收者，这个函数就被称为方法。 两种类型的接收者：值接收者和指针接收者。如果使用值接收者声明方法，调用时会使用这个值的一个副本来执行。即：修改无效，当方法执行完之后，不会对接收者产生影响；指针接受者则相反。 类型的本质内置类型：数值类型、string和bool当把这些类型的值传递给方法或者函数时，传递对应值的副本。 引用类型：slice、map、channel、interface 和 func声明上述类型的变量时，创建的变量被称作标头（header）值。从技术细节上说，字符串也是一种引用类型。每个引用类型创建的标头值是包含一个指向底层数据结构的指针。每个引用类型还包含一组独特的字段，用于管理底层数据结构。因为标头值是为复制而设计的，所以永远不需要共享一个引用类型的值。标头值里包含一个指针，因此通过复制来传递一个引用类型的值的副本，本质上就是在共享底层数据结构。 Reference 威廉·肯尼迪（William Kennedy）,布赖恩·克特森（ian Ketelsen）,埃里克·圣马丁（BrErik St. Martin）. Go语言实战（异步图书） (Chinese Edition) (p. 84). 人民邮电出版社. Kindle 版本.","link":"/2020/09/28/622379f83330.html"},{"title":"1.1 |  kubernetes: 是什么和为什么","text":"WHAT of kubernetes 一套基于容器技术的分布式架构方案。 基于 Google 的 Borg（内部使用超过10年） 系统 实现资源管理的自动化、资源利用的最大化 使用 kubernetes 可以减少开发成本（如服务治理、服务监控、故障处理等），将精力投入到业务开发中。 开放平台，不限编程语言，模块间通过 TCP 通信协议进行交互。 Kubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建的智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时，Kubernetes提供了完善的管理工具，这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节。因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台。 WHY of kubernetes 少量人员的小团队即可开发复杂系统。 全面拥抱微服务架构。 Kubernetes 中含有微服务架构的基础设施。 随时迁移到公有云。GCE、CCE、ACK、TKE。 面对突发流量可利用服务弹性扩容机制进行扩容。 横向扩容提供产品的竞争力。","link":"/2020/08/16/6658589810ed.html"},{"title":"1.2 | Kubernetes：容器技术","text":"此文是一篇大杂烩，记录一些对我很有用处的新知识。主要包括容器相关概念、实现原理、相关标准等。最大的感触就是 Golang 才是云时代的语言，很多容器相关软件的开发语言是用的 Golang。 Let’s go! 什么是容器容器就是将软件打包成标准化单元，以用于开发、交付和部署。简单说就是：容器可以被当做一个盒子，盒子里面装了软件运行所需环境、软件包，我们拿到这个盒子就能把所需软件跑起来。 容器的实现原理https://segmentfault.com/a/1190000009732550 NamespaceCgroup容器与虚拟机对比 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动 。 虚拟机 (VM) 是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个 VM 在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此 占用大量空间 。而且 VM 启动也十分缓慢 。 虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而 Docker通常用于隔离不同的应用 ，例如前端，后端以及数据库。 容器与虚拟机 (VM) 总结 换言之，容器具有如下优势： 极其轻量：只打包了必要的Bin/Lib； 秒级部署：根据镜像的不同，容器的部署大概在毫秒与秒之间（比虚拟机强很多）； 易于移植：一次构建，随处部署； 弹性伸缩：Kubernetes、Swam、Mesos这类开源、方便、好使的容器管理平台有着非常强大的弹性管理能力。 容器的标准化2015年，由Google，Docker、CoreOS等厂商联合发起的OCI（Open Container Initiative）组织成立了，并于2016年4月推出了第一个开放容器标准。标准主要包括runtime运行时标准和image镜像标准。 标准的推出，有助于替成长中市场带来稳定性，让企业能放心采用容器技术，用户在打包、部署应用程序后，可以自由选择不同的容器Runtime；同时，镜像打包、建立、认证、部署、命名也都能按照统一的规范来做。 两种标准主要包含以下内容： 容器运行时标准 （runtime spec） creating：使用 create 命令创建容器，这个过程称为创建中 created：容器创建出来，但是还没有运行，表示镜像和配置没有错误，容器能够运行在当前平台 running：容器的运行状态，里面的进程处于 up 状态，正在执行用户设定的任务 stopped：容器运行完成，或者运行出错，或者 stop 命令之后，容器处于暂停状态。这个状态，容器还有很多信息保存在平台中，并没有完全被删除 容器镜像标准（image spec） 文件系统：以 layer 保存的文件系统，每个 layer 保存了和上层之间变化的部分，layer 应该保存哪些文件，怎么表示增加、修改和删除的文件等; config 文件：保存了文件系统的层级信息（每个层级的 hash 值，以及历史信息），以及容器运行时需要的一些信息（比如环境变量、工作目录、命令参数、mount 列表），指定了镜像在某个特定平台和系统的配置。比较接近我们使用 docker inspect 看到的内容; manifest 文件：镜像的 config 文件索引，有哪些 layer，额外的 annotation 信息，manifest 文件中保存了很多和当前平台有关的信息; index 文件：可选的文件，指向不同平台的 manifest 文件，这个文件能保证一个镜像可以跨平台使用，每个平台拥有不同的 manifest 文件，使用 index 作为索引。 容器与Docker容器就是 Docker，Docker 就是容器吗？答案很明显是否，还有很多其他的容器运行时。 以下3个容器引擎基本上基于 Go 语言开发 container-d cri-o kata 它们 2019 年的市场分额如下： 什么是 podman之前总是听有文章说，docker 快要被替代了，替代品是 podman。那 podman 又是一个什么东西呢？ What is Podman? Podman is a daemonless container engine for developing, managing, and running OCI Containers on your Linux System. Containers can either be run as root or in rootless mode. Simply put: alias docker=podman. podman 与 docker 的区别 docker 需要在我们的系统上运行一个守护进程(docker daemon)，而podman 不需要 启动容器的方式不同：docker cli 命令通过API跟 Docker Engine(引擎)交互告诉它我想创建一个container，然后docker Engine才会调用OCI container runtime(runc)来启动一个container。这代表container的process(进程)不会是Docker CLI的child process(子进程)，而是Docker Engine的child process。Podman是直接给OCI containner runtime(runc)进行交互来创建container的，所以container process直接是podman的child process。 因为docke有docker daemon，所以docker启动的容器支持–restart策略，但是podman不支持，如果在k8s中就不存在这个问题，我们可以设置pod的重启策略，在系统中我们可以采用编写systemd服务来完成自启动 docker需要使用root用户来创建容器，但是podman不需要 为什么不使用 docker daemon 模式？在Docker实践中，很多人应该都遇到过开机重启时，由于Docker守护程序在占用多核CPU使用100%C使用的情况，此时所有容器都无法正常工作，所有服务都不能用。很悲催的是这事儿虫虫也遇到了，之前虫虫利用Docker重构WP博客的新架构（ http://ijz.me ）。由于VPS机器不是很稳定，时常会重启，重启时候就会遇到这个事情，VPS负载很高，容器都没有起来，网站就无法访问了。解决唯一方法只能杀掉所有容器并重启守护进程，才能恢复。经过了解该问题是由于Docker守护进程引起，而且Docker守护进程是以root特权权限启动的，是一个安全问题。 为什么会有 podmanhttps://github.com/containers podman是OCI计划下的工具。还有另外两个工具，它们三者各司其职，配合完成Docker所有的功能和新扩展功能，并且对docker的问题进行了改良： 包括不需要守护程序或访问有root权限的组； 容器架构基于fork/exec模型创建容器，更加安全可靠； 所以是更先进、高效和安全的下一代容器容器工具。 BuildahBuildah是套件中的Build工具，用来构建OCI镜像。虽然Podman也可以用户构建Docker镜像，但是构建速度超慢，并且默认情况下使用vfs存储驱动程序会消耗大量磁盘空间。 而buildah bud（使用Dockerfile构建）非常快，并使用覆盖存储驱动程序，可以节约大量的空间。 SkopeoSkopeo是套件中镜像管理工具，允许我们通过推，拉和复制镜像来处理Docker和OC镜像。 Buildah构建容器，Podman运行容器，Skopeo传输容器镜像。这些通过在Github容器组织维护和开源。套件下的工具都无需运行守护进程，并且大多数情况下也不需要root访问权限。 Podman和Buildah之间的一个主要区别是他们的容器概念。 Podman可允许用户创建”传统容器”。Buildah容器作用是给容器添加一些特有的内容而构建容器，Buildah容器是过程容器，编译完成就消失，不能用来跑服务 。简而言之，buildah run命令模拟Dockerfile中的RUN命令，而podman run命令则模拟功能中的docker run命令。 总之，Buildah是创建OCI镜像的有效方式，而Podman允许我们使用熟悉的容器cli命令在生产环境中管理和维护这些镜像和容器。 CRI与OCI的区别Open Container Initiative，也就是常说的OCI，是由多家公司共同成立的项目，并由linux基金会进行管理，致力于container runtime的标准的制定和runc的开发等工作。所谓container runtime，主要负责的是容器的生命周期的管理。oci的runtime spec标准中对于容器的状态描述，以及对于容器的创建、删除、查看等操作进行了定义。 在k8s 1.5版本之后，kubernetes推出了自己的运行时接口api–CRI(container runtime interface)。cri接口的推出，隔离了各个容器引擎之间的差异，而通过统一的接口与各个容器引擎之间进行互动。 与oci不同，cri与kubernetes的概念更加贴合，并紧密绑定。cri不仅定义了容器的生命周期的管理，还引入了k8s中pod的概念，并定义了管理pod的生命周期。在kubernetes中，pod是由一组进行了资源限制的，在隔离环境中的容器组成。而这个隔离环境，称之为PodSandbox。在cri开始之初，主要是支持docker和rkt两种。其中kubelet是通过cri接口，调用docker-shim，并进一步调用docker api实现的。 后来，docker独立出来了containerd,kubernetes也顺应潮流，孵化了cri-containerd项目，用以将containerd接入到cri的标准中。 为了进一步与oci进行兼容，kubernetes还孵化了cri-o，成为了架设在cri和oci之间的一座桥梁。通过这种方式，可以方便更多符合oci标准的容器运行时，接入kubernetes进行集成使用。可以预见到，通过cri-o，kubernetes在使用的兼容性和广泛性上将会得到进一步加强 Reference 可能是把Docker的概念讲的最清楚的一篇文章 InfoQ - 容器相关产品的市场份额 podman与docker的区别 https://zhuanlan.zhihu.com/p/39155341 https://xuanwo.io/2019/08/06/oci-intro/ https://www.jianshu.com/p/62e71584d1cb","link":"/2020/08/16/b84b0ed4d8b2.html"},{"title":"2 | Netty：Reactor与Netty之间的关系","text":"今天是2020年2月2号，感觉是一个比较特殊的日子，今天就来一篇记录型的博客吧，哈哈 起初很好奇，到底什么叫Reactor模式，这个名词感觉特别高大上，然后看描述，虽然能看懂描述，但是却不是特别明白到底是什么意思。这个时候主要是没有形成一种直观的印象，直观的印象就是比如说苹果，再给你看个实物，你就能把苹果与关联起来。在学习netty的时候，也遇到了Reactor模式，于是有了机会来形成一种比较直观的印象。 什么是Reactor模式？定义看起来很抽象，但是其实很好理解。它是一种开发模式，模式的核心流程：注册感兴趣的事件 -&gt; 扫描是否有感兴趣的事件发生 -&gt; 事件发生后做出相应的处理。仅此而已。使用BIO开发的时候，每有一个新的请求过来了，都会新开一个线程，然后在新的线程里面进行业务处理，这种处理方式就是Thread-Per-Connection；所以对应起来，使用NIO开发的时候，也有一个模式去处理相应的请求与业务逻辑，叫做Reactor模式。至于具体怎么做，也就是前面提到的Reactor模式的核心流程。 Reactor模式的3种版本开始这个之前我有一个疑问：Thread-Per-Connection与Reactor单线程有什么关系？ Thread-Per-Connection模式示意图： 伪代码： Reactor单线程模式 从这张图里面看不懂其执行流是什么样的。待后续理解了再补上解读。 Reactor多线程模式 主从Reactor多线程模式对服务器开发来说，很重要的事情是接收连接，accept事件会被单独注册到另外一个reactor中。 在Netty中如何实现Reactor三种模式 其中单线程和非主从reactor多线程模式的差别只在于new的时候传入的线程数量，不传的话，会默认以CPU的核数为依据来确定最终的线程数。 Netty 如何支持主从 Reactor 模式以netty项目源代码（分支4.1）中netty-example模块的EchoServer为例。 保存它是一个主从reactor多线程模式，其中bossGroup负责accept事件，workerGroup负责逻辑处理。 在①中，分别将两个EventLoopGroup传入到ServerBootstrap中，并将这两个EventLoopGroup保存起来。 步骤②执行的保存逻辑如下： 步骤③即已保存完毕。保存起来之后，什么时候使用呢？ 将channel注册到parentGroup先看parentGroup的使用过程，找到使用了group这个变量的地方Ctrl + B： 进去之后，是一个类似于普通getter方法 只有一个地方调用，名称也叫group()，所以还可以继续往上看调用者 然后使用Ctrl + Alt + H查看该group()方法的调用者： 在initAndRegister()中可以找到将channel（即ServerSocketChannel）注册到该EventLoopGroup的代码，如下： 绑定完毕。 将channel注册到childGroup找到使用了childGroup这个变量的地方Ctrl + B： 只有个地方使用到了该childGroup，并改名成了currentChildGroup。 ①改名，②将childGroup作为一个变量，传入ServerBootstrapAcceptor中。ServerBootstrapAcceptor继承自ChannelInboundHandlerAdapter，其覆盖了父类的channelRead()方法，其中将新进来的channel注册到childGroup中。 也就是说，新进来的连接，即SocketChannel，都会被注册到childGroup中。 新连接建立进行哪些初始化回到上面的init()方法中提出的，它是何时被调用的这个问题中。 它是AbstractBootstrap抽象类中的一个抽象方法，有两个类继承自AbstractBootstrap，分别是Bootstrap和ServerBootstrap。调用init()方法的地方只有一个，即initAndRegister()中。 其中传入init()的channel为ServerSocketChannel，其大致过程： 当服务端即EchoServer启动的时候，会为ServerSocketChannel的pipeline添加一个ServerBootstrapAcceptor，所以每当有来自客户端的请求时，都会首先经过ServerBootstrapAcceptor，让它先处理，而它的处理内容就是将SocketChannel注册到childGroup中。 为什么说 Netty 的 main reactor 大多并不能用到一个线程组，只能线程组里面的一个？因为服务端只会启动一次，只有在启动过程中去绑定端口号时才会将ServerSocketChannel绑定到main reactor上。所以这时候要从initAndRegister的调用者逐级往上查看，如下； 12345678910111213141516171819202122232425262728public ChannelFuture bind(InetAddress inetHost, int inetPort) { return bind(new InetSocketAddress(inetHost, inetPort));}public ChannelFuture bind(SocketAddress localAddress) { validate(); return doBind(ObjectUtil.checkNotNull(localAddress, &quot;localAddress&quot;));}private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); ...}final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); // 设置新接入连接的SocketChannel注册到sub reactor init(channel); } catch (Throwable t) { ... } // 注册ServerSocketChannel到main reactor ChannelFuture regFuture = config().group().register(channel); ...} 所以一个ServerSocketChannel只会注册到一个group中。但还是个疑问，是与EventLoopGroup相关的，留待后续再来回答。这个问题的意思是说，只能用线程组里面的一个线程，为什么？为什么不能多个线程？下面这个问题可以回答这个疑问！ Netty 给 Channel 分配 NIO event loop 的规则是什么从initAndRegister()中的config().group().register(channel)代码出发，也就是ServerSocketChannel注册到main reactor中的那段代码（参见上面）。 12345678910111213141516171819202122232425262728293031323334353637// 从register方法进入ChannelFuture regFuture = config().group().register(channel);// 进入EventLoopGroup.java，它是一个接口。// NIO选MultithreadEventLoopGroup的实现ChannelFuture register(Channel channel);@Overridepublic ChannelFuture register(Channel channel) { return next().register(channel);}@Overridepublic EventLoop next() { return (EventLoop) super.next();}// 进入父类的next()实现中@Overridepublic EventExecutor next() { return chooser.next();}// 进入chooser的next()方法，发现这个chooser是一个接口类型private final EventExecutorChooserFactory.EventExecutorChooser chooser;public interface EventExecutorChooserFactory { EventExecutorChooser newChooser(EventExecutor[] executors); @UnstableApi interface EventExecutorChooser { EventExecutor next(); }}// chooser的初始化是根据传入的线程数决定的// 在MultithreadEventExecutorGroup的构造函数中children = new EventExecutor[nThreads];// 需要多少个线程，就有多少个EventExecutor，它初步与Thread等价chooser = chooserFactory.newChooser(children); 所以chooser.next()返回的是一个等价于Thread的对象，也就是说这个ServerSocketChannel只会在这个Thread中进行接收。其中的chooser就是根据线程数的个数，来选取一个线程分配给register进来的ServerSocketChannel。具体分配策略： 1234567891011121314151617181920212223242526272829303132333435363738394041// next()是一个抽象方法，它的具体实现有两种public EventExecutorChooser newChooser(EventExecutor[] executors) { if (isPowerOfTwo(executors.length)) { return new PowerOfTwoEventExecutorChooser(executors); } else { return new GenericEventExecutorChooser(executors); }}// 判断是否为2的幂的简便方法private static boolean isPowerOfTwo(int val) { return (val &amp; -val) == val;}private static final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; PowerOfTwoEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[idx.getAndIncrement() &amp; executors.length - 1]; }}private static final class GenericEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[Math.abs(idx.getAndIncrement() % executors.length)]; }} 至此，上面的那个疑问算是有了一个答案。","link":"/2020/02/02/8dae1f5a56e2.html"},{"title":"2 | Spinnaker orca 如何找到对应的 stage","text":"首先，我们定义的 Stage 都实现了 StageDefinitionBuilder 接口，例如： 1234567@Slf4j@Component@CompileStaticclass BakeStage implements StageDefinitionBuilder { public static final String PIPELINE_CONFIG_TYPE = &quot;bake&quot; // ...} 其次，看一个 bean StageResolver，它在初始化的时候，将所有的 StageDefinitionBuilder 作为集合传递进去。 123456789@Beanpublic StageResolver stageResolver( Collection&lt;StageDefinitionBuilder&gt; stageDefinitionBuilders, Optional&lt;Collection&lt;SimpleStage&gt;&gt; simpleStages, PluginManager pluginManager) { Collection&lt;SimpleStage&gt; stages = simpleStages.orElseGet(ArrayList::new); stages.addAll(pluginManager.getExtensions(SimpleStage.class)); return new StageResolver(stageDefinitionBuilders, stages);} 并将所有的 bean 存入一个 map 中 1234567891011121314151617public StageResolver( Collection&lt;StageDefinitionBuilder&gt; stageDefinitionBuilders, Collection&lt;SimpleStage&gt; simpleStages) { for (StageDefinitionBuilder stageDefinitionBuilder : stageDefinitionBuilders) { stageDefinitionBuilderByAlias.put(stageDefinitionBuilder.getType(), stageDefinitionBuilder); for (String alias : stageDefinitionBuilder.aliases()) { if (stageDefinitionBuilderByAlias.containsKey(alias)) { throw new DuplicateStageAliasException(&quot;xxxooo&quot;); } stageDefinitionBuilderByAlias.put(alias, stageDefinitionBuilder); } } simpleStages.forEach( s -&gt; stageDefinitionBuilderByAlias.put(s.getName(), new SimpleStageDefinitionBuilder(s)));} 其中 map 的 key 与对应的 stage 的关系如下： type -&gt; stage：stageDefinitionBuilderByAlias.put(stageDefinitionBuilder.getType(), stageDefinitionBuilder) alias -&gt; stage：stageDefinitionBuilderByAlias.put(alias, stageDefinitionBuilder) type 的默认实现是以 className 基础，将首字母小写后，去换掉结尾的 “Stage”、”StageDefinitionBuilder”，处理完成后做为 type。代码如下： 12345678910111213/** @return the stage type this builder handles. */default @Nonnull String getType() { return getType(this.getClass());}static String getType(Class&lt;? extends StageDefinitionBuilder&gt; clazz) { String className = clazz.getSimpleName(); return className.substring(0, 1).toLowerCase() + className .substring(1) .replaceFirst(&quot;StageDefinitionBuilder$&quot;, &quot;&quot;) .replaceFirst(&quot;Stage$&quot;, &quot;&quot;);} alias 的获取方式是通过在 stage 的类上的注解： 1234567default Collection&lt;String&gt; aliases() { if (getClass().isAnnotationPresent(Aliases.class)) { return Arrays.asList(getClass().getAnnotation(Aliases.class).value()); } return Collections.emptyList();} 最后，在 StartStageHandler 的 stage.plan() 方法中，会调用 StageResolver 的 getStageDefinitionBuilder() 方法。 12345@Overridepublic @Nonnull StageDefinitionBuilder builderFor(@Nonnull Stage stage) { return stageResolver.getStageDefinitionBuilder( stage.getType(), (String) stage.getContext().get(&quot;alias&quot;));} 在此方法中，会从 pipeline 相应的 stage 中，获取配置的 type 和 alias，并将它们作为 key，到 StageResolver 的 map stageDefinitionBuilderByAlias 中依次去 get。顺序是先用 type 去取，如果未取到，再用 alias 取到的 stage 对象。 123456789101112@Nonnullpublic StageDefinitionBuilder getStageDefinitionBuilder(@Nonnull String type, String typeAlias) { StageDefinitionBuilder stageDefinitionBuilder = stageDefinitionBuilderByAlias.getOrDefault( type, stageDefinitionBuilderByAlias.get(typeAlias)); if (stageDefinitionBuilder == null) { throw new NoSuchStageDefinitionBuilderException(type, stageDefinitionBuilderByAlias.keySet()); } return stageDefinitionBuilder;} 因此，在编写一个 Stage 类时，需要做完如下两个件事： 在 xxxStage 类中实现 getType() 方法以覆盖默认获取 type 的方法 依靠 xxxStage 类的名称（需要与前端沟通好相应的 type 字段和 alias 字段） 前者比较明显易懂，后者不是特别容易理解，但是 spinnaker 里面大多数是以后者的形式出现的。","link":"/2020/10/31/60b943d025b2.html"},{"title":"2 | SpringCloud：OpenFeign从入门到上天","text":"在前篇的基础上，对整个demo项目进行了重新的规划，包括模块名、包名的修改，以及对接口进行了调整，并将模块调用改成了OpenFeign，这个用起来更加方便，连RestTemplate都不需要使用即可完成调用。修改之后的demo项目整体架构如下： 123456789101112131415161718192021222324252627282930313233343536373839.├── module01│ ├── module01.iml│ ├── pom.xml│ └── src│ └── main│ ├── java│ │ └── com│ │ └── example│ │ └── springcloud│ │ └── demo│ │ ├── Module01Application.java│ │ ├── controller│ │ │ └── HelloController.java│ │ └── feign│ │ ├── MultiLanguageHelloFeignClient.java│ │ ├── custom│ │ │ └── MultiLanguageHelloClientConfiguration.java│ │ └── fallback│ │ └── MultiLanguageHelloFeignClientFallback.java│ └── resources│ └── bootstrap.yaml├── module02│ ├── module02.iml│ ├── pom.xml│ └── src│ └── main│ ├── java│ │ └── com│ │ └── example│ │ └── springcloud│ │ └── demo│ │ ├── Module02Application.java│ │ └── controller│ │ └── MultiLanguageHelloController.java│ └── resources│ └── bootstrap.yaml├── pom.xml└── spring-cloud-demo.iml Ribbon 是 Netflix开源的基于HTTP和TCP等协议负载均衡组件。可以用来做客户端负载均衡，调用注册中心的服务。如果单纯使用Ribbon，需要代码里手动调用目标服务，请参考官方示例。 Feign是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端，并且它内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。 不论怎么样，都要去官网上面瞄一瞄OpenFeign的README.md。 配置流程如果只是简单使用OpenFeign，它的步骤很简单，只需要引入依赖、开启FeignClient、新建接口、设置连接信息，然后调用即可完成。但如果需要进行一些定制化的话，就需要做一些额外的工作，比如自己创建相关的bean。 如果想对OpenFeign做更多的定制化，则需要仔细研究一下OpenFeign提供的README.md里面的样例。 这里贴出来它用到的注解： Annotation Interface Target Usage @RequestLine Method Defines the HttpMethod and UriTemplate for request. Expressions, values wrapped in curly-braces {expression} are resolved using their corresponding @Param annotated parameters. @Param Parameter Defines a template variable, whose value will be used to resolve the corresponding template Expression, by name. @Headers Method, Type Defines a HeaderTemplate; a variation on a UriTemplate. that uses @Param annotated values to resolve the corresponding Expressions. When used on a Type, the template will be applied to every request. When used on a Method, the template will apply only to the annotated method. @QueryMap Parameter Defines a Map of name-value pairs, or POJO, to expand into a query string. @HeaderMap Parameter Defines a Map of name-value pairs, to expand into Http Headers @Body Method Defines a Template, similar to a UriTemplate and HeaderTemplate, that uses @Param annotated values to resolve the corresponding Expressions. 接下来开始最简单的配置与使用，以对其有个基本的印象。 ①引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; ②开启FeignClient，即启动类上面加上@EnableFeignClients注解 123456789101112131415package com.example.springcloud.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class Module01Application { public static void main(String[] args) { SpringApplication.run(Module01Application.class, args); }} ③创建接口，即FeignClient，并初始化连接信息。name指定模块，@RequestMapping指定url。 12345678@Component@FeignClient(name = &quot;module02&quot;)public interface MultiLanguageHelloFeignClient { @RequestMapping(value = &quot;hello/cn&quot;) String getChineseHello();} 此处有个疑问，Feign貌似能够识别RequestMapping注解，不必使用前面提到的RequestLine，但是并没有看到文档上有什么说明。使用别人没有申明的东西，没有安全感。 ④注入MultiLanguageHelloFeignClient，调用getChineseHello()方法 1234567891011121314151617181920212223242526272829package com.example.springcloud.demo.controller;import com.example.springcloud.demo.feign.MultiLanguageHelloFeignClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.context.config.annotation.RefreshScope;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(&quot;hello&quot;)@RefreshScopepublic class HelloController { @Value(value = &quot;${server.port}&quot;) private String port; @Autowired private MultiLanguageHelloFeignClient multiLanguageHelloFeignClient; @RequestMapping(&quot;&quot;) public String getDefault() { return &quot;hi&quot; + &quot; -- from port: &quot; + port; } @RequestMapping(&quot;/cn&quot;) public String getStrViaNacos() { return multiLanguageHelloFeignClient.getChineseHello() + &quot; -- from port: &quot; + port; }} ⑤启动module01和module02，调用结果如下，可以看出配置生效 自定义配置 开启fallback fallback也就是当所调用的服务没有起来的时候，会执行该方法。不知道返回一个错误。 ①开启hystrix 123feign: hystrix: enabled: true ②实现MultiLanguageHelloFeignClient，编写fallback，作为失败时的返回结果 123456789101112package com.example.springcloud.demo.feign.fallback;import com.example.springcloud.demo.feign.MultiLanguageHelloFeignClient;import org.springframework.stereotype.Component;@Componentpublic class MultiLanguageHelloFeignClientFallback implements MultiLanguageHelloFeignClient { @Override public String getChineseHello() { return &quot;service down&quot;; }} ③指定fallback 123456@Component@FeignClient(name = &quot;module02&quot;, fallback = MultiLanguageHelloFeignClientFallback.class)public interface MultiLanguageHelloFeignClient { @RequestMapping(value = &quot;hello/cn&quot;) String getChineseHello();} 自定义HTTP客户端 首先，Feign默认的HTTP客户端是JDK自带的HTTP客户端：HttpURLConnection。有代码为证： 12345678910111213// Feign.java $ Builderprivate Client client = new Client.Default(null, null);// Client.javaclass Default implements Client { // ... @Override public Response execute(Request request, Options options) throws IOException { HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection, request); } // ...} 指定其他客户端、设置其他参数，如重试相关 123456789101112131415@Value(&quot;${retry.period:3000}&quot;)private int period;@Value(&quot;${retry.maxPeriod:30000}&quot;)private int maxPeriod;@Value(&quot;${retry.maxAttempts:5}&quot;)private int maxAttempts;@BeanAuthClient authClient() { return Feign.builder() .retryer(new Retryer.Default(period, maxPeriod, maxAttempts)) .target(AuthClient.class, baseServerUrl);} 总体而言，简易的配置完成了，并且也能工作。","link":"/2020/03/14/8f13ddc7a103.html"},{"title":"2 | Spring：BeanPostProcessor执行时机与实现原理","text":"这一篇主要学到了一种新的看源代码的方法。之前都是从最开始的代码开始，然后一步一步step into。这样会比较浪费时间，并且会因为代码多而容易搞混淆，抓不住重点。 这篇主要是看BeanPostProcessor的执行时机与相应的源代码，目前对于它是合适执行的，并不知道，但是可以明确的是我们继承的BeanPostProcessor一定会执行。因此可以完全将断点放在我们写的类MyBeanPostProcessor的函数里面。 看源码的另一种姿势打开调试，进入断点。如下图所示： 然后逐帧查看其调用栈，慢慢找到关键代码： 初始化流程主要的初始化流程包括：XXXAware方法执行、BeanPostProcessor.beforeXX()、InitilizingBean、initMethod、BeanPostProcessor.afterXX()。 执行AwareXX的顺序如下： 执行applyBeanPostProcessorsBeforeInitialization时，如果BeanPostProcessor返回的是null，那么将不会执行后续的BeanPostProcessor。 然后先执行InitializingBean，再调用自定义初始化方法initMethod。 最后执行BeanPostProcessor.afterXX()，与before的类似。 在Spring中的用途先看两个比较简单的，会直接调用BeanPostProcessor的两个方法，达到spring的相应功能。 ApplicationContextAwareProcessor在bean中，实现ApplicationContextAware接口，这个后置处理器会在bean初始化前，设置进ApplicationContext。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Override@Nullablepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if (!(bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)){ return bean; } AccessControlContext acc = null; if (System.getSecurityManager() != null) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; { invokeAwareInterfaces(bean); return null; }, acc); } else { invokeAwareInterfaces(bean); } return bean;}private void invokeAwareInterfaces(Object bean) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); }} BeanValidationPostProcessor此方法默认在初始化数据之前进行数据校验。 1234567891011121314151617181920212223242526272829303132333435363738private boolean afterInitialization = false;@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { if (!this.afterInitialization) { doValidate(bean); } return bean;}@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (this.afterInitialization) { doValidate(bean); } return bean;}protected void doValidate(Object bean) { Assert.state(this.validator != null, &quot;No Validator set&quot;); Object objectToValidate = AopProxyUtils.getSingletonTarget(bean); if (objectToValidate == null) { objectToValidate = bean; } Set&lt;ConstraintViolation&lt;Object&gt;&gt; result = this.validator.validate(objectToValidate); if (!result.isEmpty()) { StringBuilder sb = new StringBuilder(&quot;Bean state is invalid: &quot;); for (Iterator&lt;ConstraintViolation&lt;Object&gt;&gt; it = result.iterator(); it.hasNext();) { ConstraintViolation&lt;Object&gt; violation = it.next(); sb.append(violation.getPropertyPath()).append(&quot; - &quot;).append(violation.getMessage()); if (it.hasNext()) { sb.append(&quot;; &quot;); } } throw new BeanInitializationException(sb.toString()); }} InitDestroyAnnotationBeanPostProcessor执行被@PostConstruct和@PreDestroy注解的方法，参与生命周期。 初始化方法执行@PostConstruct执行过程比较直接，因为此类直接实现了BeanPostProcessor的初始化方法。 1234567891011121314151617181920@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass()); try { // 执行初始化方法 metadata.invokeInitMethods(bean, beanName); } catch (InvocationTargetException ex) { throw new BeanCreationException(beanName, &quot;Invocation of init method failed&quot;, ex.getTargetException()); } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Failed to invoke init method&quot;, ex); } return bean;}@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean;} 具体的初始化方法如下： 12345678910111213public void invokeInitMethods(Object target, String beanName) throws Throwable { Collection&lt;LifecycleElement&gt; checkedInitMethods = this.checkedInitMethods; Collection&lt;LifecycleElement&gt; initMethodsToIterate = (checkedInitMethods != null ? checkedInitMethods : this.initMethods); if (!initMethodsToIterate.isEmpty()) { for (LifecycleElement element : initMethodsToIterate) { if (logger.isTraceEnabled()) { logger.trace(&quot;Invoking init method on bean '&quot; + beanName + &quot;': &quot; + element.getMethod()); } element.invoke(target); } }} 寻找bean中初始化、销毁方法所有的checkedInitMethods来自对initMethods中函数的遍历。包括destroy方法也是类似的。 1234567891011121314151617181920212223242526public void checkConfigMembers(RootBeanDefinition beanDefinition) { Set&lt;LifecycleElement&gt; checkedInitMethods = new LinkedHashSet&lt;&gt;(this.initMethods.size()); for (LifecycleElement element : this.initMethods) { String methodIdentifier = element.getIdentifier(); if (!beanDefinition.isExternallyManagedInitMethod(methodIdentifier)) { beanDefinition.registerExternallyManagedInitMethod(methodIdentifier); checkedInitMethods.add(element); if (logger.isTraceEnabled()) { logger.trace(&quot;Registered init method on class [&quot; + this.targetClass.getName() + &quot;]: &quot; + element); } } } Set&lt;LifecycleElement&gt; checkedDestroyMethods = new LinkedHashSet&lt;&gt;(this.destroyMethods.size()); for (LifecycleElement element : this.destroyMethods) { String methodIdentifier = element.getIdentifier(); if (!beanDefinition.isExternallyManagedDestroyMethod(methodIdentifier)) { beanDefinition.registerExternallyManagedDestroyMethod(methodIdentifier); checkedDestroyMethods.add(element); if (logger.isTraceEnabled()) { logger.trace(&quot;Registered destroy method on class [&quot; + this.targetClass.getName() + &quot;]: &quot; + element); } } } this.checkedInitMethods = checkedInitMethods; this.checkedDestroyMethods = checkedDestroyMethods;} 只要是被@PostConstruct注解过的函数，都会被加入到initMethods中。destroy也类似。 123456789101112131415161718192021222324252627282930do { final List&lt;LifecycleElement&gt; currInitMethods = new ArrayList&lt;&gt;(); final List&lt;LifecycleElement&gt; currDestroyMethods = new ArrayList&lt;&gt;(); ReflectionUtils.doWithLocalMethods(targetClass, method -&gt; { // 被initAnnotationType注解 if (this.initAnnotationType != null &amp;&amp; method.isAnnotationPresent(this.initAnnotationType)) { LifecycleElement element = new LifecycleElement(method); currInitMethods.add(element); if (logger.isTraceEnabled()) { logger.trace(&quot;Found init method on class [&quot; + clazz.getName() + &quot;]: &quot; + method); } } // 被destroyAnnotationType注解 if (this.destroyAnnotationType != null &amp;&amp; method.isAnnotationPresent(this.destroyAnnotationType)) { currDestroyMethods.add(new LifecycleElement(method)); if (logger.isTraceEnabled()) { logger.trace(&quot;Found destroy method on class [&quot; + clazz.getName() + &quot;]: &quot; + method); } } }); initMethods.addAll(0, currInitMethods); destroyMethods.addAll(currDestroyMethods); targetClass = targetClass.getSuperclass();}while (targetClass != null &amp;&amp; targetClass != Object.class);return (initMethods.isEmpty() &amp;&amp; destroyMethods.isEmpty() ? this.emptyLifecycleMetadata : new LifecycleMetadata(clazz, initMethods, destroyMethods)); 具体的类型为： init destroy 销毁方法执行对@PreDestroy注解方法的执行，逻辑都放在了DisposableBeanAdapter中，它实现了DisposableBean， 并实现了destroy()方法，执行所有的DestructionAwareBeanPostProcessor方法。 进入InitDestroyAnnotationBeanPostProcessor的postProcessBeforeDestruction，它完成了对所有的销毁方法的调用。 具体的执行销毁方法的逻辑与初始化类似","link":"/2020/03/26/8928c5285ae3.html"},{"title":"2.0 | kubernetes: Docker Desktop 安装单节点 k8s 集群","text":"修改镜像配置： 1234567&quot;registry-mirrors&quot;: [ &quot;https://reg-mirror.qiniu.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://hub-mirror.c.163.com&quot;, &quot;https://registry.docker-cn.com&quot;] 运行下面脚本，从阿里云镜像源拉取镜像，然后重新打 tag 为 k8s.gcr.io/xxxx 12345678910111213141516171819202122232425262728to be continued...#!/bin/bashset -eKUBE_VERSION=v1.19.3KUBE_PAUSE_VERSION=3.2ETCD_VERSION=3.4.13-0COREDNS_VERSION=1.7.0GCR_URL=k8s.gcr.ioALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers# get imagesimages=(kube-proxy:${KUBE_VERSION} kube-scheduler:${KUBE_VERSION} kube-controller-manager:${KUBE_VERSION} kube-apiserver:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} etcd:${ETCD_VERSION} coredns:${COREDNS_VERSION})for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageNamedone# show imagesdocker images","link":"/2021/10/13/9877d33625fe.html"},{"title":"2.1 | kubernetes: 在裸机 Linux 上安装 k8s 集群","text":"在开始安装 k8s 必要的软件前，最理想的环境是能够自由访问外网，所以需要先准备好代理，这样在安装被墙软件、拉取被墙的镜像时方便很多，不用为这种意义不大的事情纠结。 基础系统： Ubuntu Server 22.04虚拟机软件：VMware Fusion宿主机系统：macOS 重命名系统名称12hostnamectl set-hostname k8s-masterecho &quot;127.0.0.1 $(hostname)&quot; &gt;&gt; /etc/hosts Ubuntu 22.04 必要软件安装设置软件源打开 /etc/apt/source.list，替换软件源为阿里云源，如下 123456789101112cat &lt;&lt; EOF | sudo tee /etc/apt/sources.list &gt;/dev/null &amp;&amp; sudo apt update deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverseEOF 更新软件源 1sudo apt update &amp;&amp; sudo apt upgrade -y zsh12345678sudo apt install -y zshsh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;# zsh-syntax-highlighting 命令是否正确git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting# zsh-autosuggestions 根据命令历史推荐git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 修改 zsh 配置文件 123sed -i '2s/# //g' ~/.zshrcsed -i 's/ZSH_THEME=.*/ZSH_THEME=ys/g' ~/.zshrcsed -i 's/plugins=(git)/plugins=(git zsh-syntax-highlighting zsh-autosuggestions)/' ~/.zshrc 基础软件常用小工具 1234sudo apt install -y \\ apt-transport-https gnupg2 curl vim \\ htop tree neofetch tldr tig make cmake \\ golang-go nodejs 网络工具 123sudo apt install -y \\ net-tools bridge-utils iputils-ping iproute2 \\ netcat telnet traceroute sudo 免输入密码12sudo update-alternatives --config editorsudo visudo 修改配置如下 1%sudo ALL=(ALL:ALL) NOPASSWD:ALL 或直接运行下面的命令 1sudo sed -i '50s/ALL$/NOPASSWD:ALL/g' /etc/sudoers Docker配置 Docker 软件源 12345678910sudo apt install -y \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-releasecurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpgecho \\ &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null 安装 Docker 及 containerd 12sudo apt updatesudo apt install -y docker-ce docker-ce-cli containerd.io 配置 Docker：/etc/docker/daemon.json 12345678910111213cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json &gt;/dev/null{ &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://hub-mirror.c.163.com&quot;, &quot;https://reg-mirror.qiniu.com&quot; ], &quot;exec-opts&quot;: [ &quot;native.cgroupdriver=systemd&quot; ]}EOF 普通用户使用 docker 命令 （可尝试 logout 后再 login） 1sudo usermod -aG docker $USER 开启 TCP 访问 12sudo sed -i '/^ExecStart=/s#$# -H tcp://0.0.0.0:2375#' /lib/systemd/system/docker.servicesudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker 关闭 swap 分区永久关闭 12#/swapfile none swap sw 0 0sudo vim /etc/fstab 暂时关闭，重启后失效 1sudo swapoff -a kubernetes 三件套 kubectl 文档 kubenetes 安装文档 下载 gpg 密钥 1curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo tee /etc/apt/trusted.gpg.d/kubernetes-aliyun.gpg &gt;/dev/null 添加 k8s 镜像源 123cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list &gt;/dev/nulldeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOF 更新源列表 1sudo apt update 下载 kubectl，kubeadm以及 kubelet 1sudo apt install -y kubelet kubeadm kubectl kubernetes-cni K8s 集群安装配置 containerd123456containerd config default | sudo tee /etc/containerd/config.toml &gt; /dev/null# 修改 /etc/etc/containerd/config.toml 默认镜像，改成国内或者私有镜像仓库地址sudo sed -i &quot;s/k8s.gcr.io/registry.aliyuncs.com\\/google_containers/g&quot; /etc/containerd/config.tomlsudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml# 重启 containerdsudo systemctl restart containerd 安装集群1234sudo kubeadm init \\--cri-socket /run/containerd/containerd.sock \\--pod-network-cidr=10.244.0.0/16 \\--image-repository=registry.aliyuncs.com/google_containers 10.244.0.0/16 的含义 对一个用 32 位二进制表示的 IP 地址，前 16 位位网络前缀，即不变的前缀，后面的 16 位是主机地址，是可变的。此处即 10.244 占 16 位，位网络前缀，不变。 --pod-network-cidr 指 pod 网络的 IP 地址范围 --service-cidr 指 svc 的虚拟 IP 地址范围，默认为 10.96.0.0/12 --apiserver-advertise-address 显式指定 apiserver 的 IP 地址 配置 kubectl此时还不能通过 kubectl 访问，需要将配置文件拷贝到 $HOME/.kube 目录下 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 加入集群在各个 Node 中执行 kubeadm join ...。 添加 Node 的语句如果堵塞，考虑验证 node 节点与 master 节点之间的连通性。 添加 Node 节点完成后，在 master 节点，如果发现 node 节点的状态为 NotReady，还可以考虑查看 master 与各个 node 节点之间的连通性。 安装 CNI 插件安装 CNI 插件，不然 NODE 会处于 NOT_READY 状态。 calico 1kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml flannel 12kubectl apply -f \\https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 这个 flannel 有坑，apply 之后，在 pod 中无法访问 k8s 的 api-server。原因可能是上面 apply 的 kube-flannel.yml 中的 flannel 子网段是 10.244.0.0/16。 后面确实在文档中找到相关的说明，需要在跑 kubeadm init 的时候，指定 --pod-network-cidr=10.244.0.0/16，也就是和 flannel 指定的网段保持一致。 123456789101112131415161718192021222324252627282930313233343536kind: ConfigMapapiVersion: v1metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flanneldata: cni-conf.json: | { &quot;name&quot;: &quot;cbr0&quot;, &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: { &quot;portMappings&quot;: true } } ] } net-conf.json: | { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } } 而 docker0 网桥的地址范围是 172.17.0.0/16 结果最终，可以在 master 节点通过 kubectl get nodes -o wide 来查看集群的组成信息，如下： 其他配置containerd 添加非 https 仓库打开 /etc/containerd/config.toml 文件，添加如下配置：12345[plugins] [plugins.cri.registry] [plugins.cri.registry.mirrors] [plugins.cri.registry.mirrors.&quot;127.0.0.1:5000&quot;] endpoint = [&quot;http://127.0.0.1:5000&quot;] 重启 containerd systemctl restart containerd CentOS关闭selinux 12sed -i 's/enforcing/disabled/' /etc/selinux/configsetenforce 0 关闭 swap 1sudo swapoff -a docker 安装文档 12345678910111213sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-enginesudo yum install -y yum-utilssudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.reposudo yum install docker-ce docker-ce-cli containerd.io 新增依赖 12345678910cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo &gt;/dev/null[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgexclude=kubelet kubeadm kubectlEOF 修改 docker 的 CgroupDriver。默认的是 cgroupfs，推荐的是 systemd。 1234567vim /etc/docker/daemon.json{ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]}systemctl daemon-reload &amp;&amp; systemctl restart docker 安装并开启 kubelet 自启动 12yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessystemctl enable --now kubelet 代理宿主机设置 v2ray 代理服务 模式选择 global，这里主要是因为没有设置 pac 规则 宿主机 IP：10.211.55.2 虚拟机 IP：10.211.55.3 curl 命令走代理在 .bashrc 中添加如下变量： 1export ALL_PROXY=http://10.211.55.2:8001 让变量生效 1source .bashrc 测试 1curl -v www.google.com apt 命令走代理1sudo apt -o Acquire::http::proxy=&quot;http://10.211.55.2:8001&quot; update 配置 Docker 代理1vim /lib/systemd/system/docker.service 在 [Service] 块下面增加一行 1Environment=&quot;HTTP_PROXY=http://10.211.55.2:8001&quot; &quot;HTTPS_PROXY=https://10.211.55.2:8001&quot; 再重新加载守护进程与重启 docker 12systemctl daemon-reloadsystemctl restart docker Referencehttps://www.xiebruce.top/796.htmlhttps://forum.ubuntu.org.cn/viewtopic.php?t=476834","link":"/2021/10/14/3c640a7f1fff.html"},{"title":"3 | Netty：源代码导入IDEA","text":"Netty源代码导入IDEA时需要注意的地方 操作系统64位 版本问题 官网上面说可以用64-bit OpenJDK 8 or above 。没有尝试OpenJDK，Oracle的JDK要1.8版本的。源码里面用到了Unsafe这个类，在jdk1.8之后的版本中被移除掉了。 IDEA的位数保持与操作系统位数相同 操作流程 最好先设置好maven的镜像，导入时需要拉取很多jar包。 打开IDEA，选择Import Project，选择好netty源码目录后再选择maven。 等待Import完成，找到EchoServer，跑main方法，这时会报错，按照如下方式操作即可。 如果用的不是jdk1.8以上的jdk，会报Unsafe找不到，这种情况只需要在Project Structure中将Project SDK设置成jdk1.8即可。 如果是io.netty.util.collection.LongObjectMap找不到之类的错误，可以在netty-common模块中执行mvn clean compile，可以按下图方式进行操作该指令。 操作完成 参考：https://netty.io/wiki/setting-up-development-environment.html","link":"/2020/02/11/96e6a8296171.html"},{"title":"2.3 | kubernetes: Linux 常用网络命令的使用","text":"ifconfig manual-1 manual-2 man ifconfig ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置，但是重启后会失效。 命令概览 -a：显示所有网络设备 -s：显示简要信息 &lt;interface&gt; &lt;operation&gt; &lt;parameters&gt;：操作对应网卡 up：启用网卡 down：关闭网卡 txqueuelen &lt;NN&gt;：设置网卡传输队列长度 mtu &lt;NN&gt;：设置网卡最大传输单元 add &lt;address&gt;[/&lt;prefixlen&gt;]：设置网卡地址 del &lt;address&gt;[/&lt;prefixlen&gt;]：删除网卡地址 netmask &lt;address&gt;：设置子网掩码 tunnel &lt;address&gt;：网卡建立到 address 的隧道 hw &lt;HW&gt; &lt;address&gt;：设置网卡 MAC 地址 输出信息示例 12345678910111213$ ifconfig ens33ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.214.5 netmask 255.255.255.0 broadcast 172.16.214.255 inet6 fe80::fd8f:e0f5:1f03:57ac prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:ee:fe:e0 txqueuelen 1000 (Ethernet) RX packets 76848 bytes 54358432 (54.3 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 72546 bytes 52701758 (52.7 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0$ ifconfig -s ens33Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgens33 1500 76956 0 0 0 72673 0 0 0 BMRU 字段解析 ens33：网卡名称，例 lo 为 loopback 的名称 flags： 4163 = 0x1043 = 0x1000 + 0x40 + 0x2 + 0x1 UP 0x1 RUNNING 0x40 BROADCAST 0x2 MULTICAST 0x1000 IPv4 inet IPv4 地址 netmask 子网掩码 broadcast 广播地址 IPv6 inet6 IPv6 地址 prefixlen scopeid ether：网卡硬件地址，即 MAC 地址 txqueuelen：传输数据的缓冲区的储存长度 RX &amp; TX 共有字段 packets 数据包数 bytes 总数据量 errors 数据包发生错误的数量 dropped 数据包由于有问题而遭丢弃的数量 overruns RX：数据包接收情况（由启动到目前为止） frame TX：数据包传送情况（由启动到目前为止） collisions 数据包碰撞的情况。太多次，表示网络状况不好 carrier routeroute 命令可以显示或设置 Linux 内核中的路由表，主要是静态路由。 对于局域网中的 Linux 主机，要想访问 Internet，需要将局域网的网关 IP 地址设置为这个主机的默认路由。 在命令行中通过 route 命令添加的路由在网卡重启或机器重启后失效。可以在 /etc/rc.local 中添加 route 命令来保证路由设置永久有效。 通过 route 命令查看 Linux 内核的路由表（等同于 netstat -r）： 1234567891011121314151617181920# feivxs @ k8s-node-3 in ~ [18:00:22]$ routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault _gateway 0.0.0.0 UG 100 0 0 ens33link-local 0.0.0.0 255.255.0.0 U 1000 0 0 ens33172.16.214.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0192.168.0.0 172.16.214.2 255.255.255.255 UGH 0 0 0 tunl0192.168.0.0 172.16.214.2 255.255.255.0 UG 0 0 0 tunl0192.168.1.0 - 255.255.255.0 ! 0 - 0 -192.168.2.0 - 255.255.255.0 ! 0 - 0 -192.168.3.0 - 255.255.255.0 ! 0 - 0 -192.168.76.128 0.0.0.0 255.255.255.192 U 0 0 0 *192.168.76.137 0.0.0.0 255.255.255.255 UH 0 0 0 calie2066d21eda192.168.76.138 0.0.0.0 255.255.255.255 UH 0 0 0 cali3ef2c7cdd89192.168.76.139 0.0.0.0 255.255.255.255 UH 0 0 0 calic440f455693192.168.109.64 172.16.214.3 255.255.255.192 UG 0 0 0 tunl0192.168.140.64 172.16.214.4 255.255.255.192 UG 0 0 0 tunl0192.168.235.192 172.16.214.2 255.255.255.192 UG 0 0 0 tunl0 字段含义 列 含义 Destination 目标网络或目标主机。Destination 为 default（0.0.0.0）时，表示这个是默认网关，所有数据都发到这个网关（这里是 10.139.128.1） Gateway 网关地址，0.0.0.0 表示当前记录对应的 Destination 跟本机在同一个网段，通信时不需要经过网关 Genmask Destination 字段的网络掩码，Destination 是主机时需要设置为 255.255.255.255，是默认路由时会设置为 0.0.0.0 Flags 标记，含义参考表格后面的解释 Metric 路由距离，到达指定网络所需的中转数，是大型局域网和广域网设置所必需的 （不在Linux内核中使用。） Ref 路由项引用次数 （不在Linux内核中使用。） Use 此路由项被路由软件查找的次数 Iface 网卡名字，例如 eth0 Flags 含义： U 路由是活动的 H 目标是个主机 G 需要经过网关 R 恢复动态路由产生的表项 D 由路由的后台程序动态地安装 M 由路由的后台程序修改 ! 拒绝路由 Linux 内核的路由种类 主机路由 路由表中指向单个 IP 地址或主机名的路由记录，其 Flags 字段为 H。下面示例中，对于 10.0.0.10 这个主机，通过网关 10.139.128.1 网关路由： 1234[root@VM_139_74_centos ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.0.0.10 10.139.128.1 255.255.255.255 UGH 0 0 0 eth0 网络路由 主机可以到达的网络。下面示例中，对于 10.0.0.0/24 这个网络，通过网关 10.139.128.1 网关路由： 1234[root@VM_139_74_centos ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.0.0.0 10.139.128.1 255.255.255.0 UG 0 0 0 eth0 默认路由 当目标主机的 IP 地址或网络不在路由表中时，数据包就被发送到默认路由（默认网关）上。默认路由的 Destination 是 default 或 0.0.0.0。 1234[root@VM_139_74_centos ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault gateway 0.0.0.0 UG 0 0 0 eth0 命令选项 -A：设置地址类型 -C：打印 Linux 内核的路由缓存 -v：显示详细信息 -n：不执行 DNS 反向查找，直接显示数字形式的 IP 地址 -e：netstat 格式显示路由表 -net：到一个网络的路由表 -host：到一个主机的路由表 命令参数 add：增加路由记录 del：删除路由记录 target：目的网络或目的主机 gw：设置默认网关 mss：设置TCP的最大区块长度（MSS），单位MB window：指定通过路由表的TCP连接的TCP窗口大小 dev：路由记录所表示的网络接口 ipip 几乎可以替代 route 和 ifconfig 命令，输出内容也比较类似。 ip address/ip a 12345678910111213# feivxs @ k8s-node-3 in ~ [21:21:23] C:255$ ip -s -h address show ens332: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:ee:fe:e0 brd ff:ff:ff:ff:ff:ff altname enp2s1 inet 172.16.214.5/24 brd 172.16.214.255 scope global dynamic noprefixroute ens33 valid_lft 53810sec preferred_lft 53810sec inet6 fe80::fd8f:e0f5:1f03:57ac/64 scope link noprefixroute valid_lft forever preferred_lft forever RX: bytes packets errors dropped overrun mcast 80.0M 138k 0 0 0 0 TX: bytes packets errors dropped carrier collsns 113M 149k 0 0 0 0 字段与 ifconfig 基本类似。 ip route/ip r 1234567891011121314151617$ ip routedefault via 172.16.214.1 dev ens33 proto dhcp metric 100169.254.0.0/16 dev ens33 scope link metric 1000172.16.214.0/24 dev ens33 proto kernel scope link src 172.16.214.5 metric 100172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1192.168.0.0 via 172.16.214.2 dev tunl0 proto bird onlink192.168.0.0/24 via 172.16.214.2 dev tunl0 proto bird onlinkunreachable 192.168.1.0/24 proto birdunreachable 192.168.2.0/24 proto birdunreachable 192.168.3.0/24 proto birdblackhole 192.168.76.128/26 proto bird192.168.76.137 dev calie2066d21eda scope link192.168.76.138 dev cali3ef2c7cdd89 scope link192.168.76.139 dev calic440f455693 scope link192.168.109.64/26 via 172.16.214.3 dev tunl0 proto bird onlink192.168.140.64/26 via 172.16.214.4 dev tunl0 proto bird onlink192.168.235.192/26 via 172.16.214.2 dev tunl0 proto bird onlink proto：路由协定 redirect 路由是由ICMP重定向加入的 kernel 路由是由内核在自动配置期间加入的 boot 路由是启动过程中加入的，如果一个路由监控程序将要启动，这些路由都会被清除； static 为了覆盖动态路由，由系统管理员手工添加的路由。路由监控程序也会优先考虑这类路由，甚至可能通告给其对端； ra 路由是通过路由发现协议加入的 (Router Discovery Protocol) scope：路由的范围 link 与本设备有关的直接连接 brctlReference https://ittroubleshooter.in/ifconfig-ip-command-tips-tricks https://networkengineering.stackexchange.com/questions/57920/what-does-the-flag-and-mtu-means-in-here https://www.wumingx.com/linux/ipcommand.html https://blog.csdn.net/kikajack/article/details/80457841 https://www.cyberciti.biz/faq/what-is-a-routing-table/","link":"/2021/10/16/983672269a29.html"},{"title":"3 | Spinnaker 如何执行 pipeline","text":"本篇文章记录以发布单的形式启动的一个流水线的执行过程，并对相关敏感信息做了删除，但不影响对整体流程的介绍。 通过 POST 调用 gate 服务的 pipelines/v2/{application}/{pipeline} 1234@POST(&quot;pipelines/v2/{application}/{pipeline}&quot;)Call&lt;Map&lt;String, Object&gt;&gt; postPipeline(@Path(&quot;application&quot;) String application, @Path(&quot;pipeline&quot;) String pipeline, @Body TaskPipeline taskPipeline); 进入 gate gate请求：/v2/{application}/{pipelineNameOrId:.+} 位置：gate-web/src/main/groovy/com/netflix/spinnaker/gate/controllers/PipelineController.groovy 请求进入 gate 之后，会先校验当前用户是否有此流水线的执行权限，然后调用 echo 触发流水线。 12@POST('/')String postEvent(@Body Map event) 此时的参数 eventMap 为： 123456789101112131415161718192021222324252627282930313233343536373839{ &quot;content&quot;: { &quot;application&quot;: &quot;artifacturlteam1&quot;, &quot;pipelineNameOrId&quot;: &quot;ccbae2c9-ba68-43f3-87ba-669b1bb27831&quot;, &quot;trigger&quot;: { &quot;buildNumber&quot;: &quot;0&quot;, &quot;type&quot;: &quot;manual&quot;, &quot;dryRun&quot;: false, &quot;parameters&quot;: {}, &quot;user&quot;: &quot;vskycorpltd&quot;, &quot;artifacts&quot;: [ { &quot;artifactAccount&quot;: &quot;generic-repo::1&quot;, &quot;customKind&quot;: false, &quot;id&quot;: &quot;94141c3b-1f0f-4674-99e1-cb138905ac25&quot;, &quot;name&quot;: &quot;vskycorpltdcorp-generic.pkg.vskycorpltd.com/vsky/generic-repo/abc/efg.txt&quot;, &quot;parentType&quot;: &quot;generic&quot;, &quot;pkgId&quot;: 2, &quot;projectId&quot;: 1, &quot;projectName&quot;: &quot;vsky&quot;, &quot;reference&quot;: &quot;&quot;, &quot;repoName&quot;: &quot;generic-repo&quot;, &quot;type&quot;: &quot;vskycorpltd_artifact/generic&quot;, &quot;uriName&quot;: &quot;vsky&quot; } ], &quot;customName&quot;: &quot;20201016-artifacturl-p1&quot;, &quot;customDescription&quot;: &quot;&quot;, &quot;projectUrlName&quot;: &quot;vsky&quot;, &quot;vskycorpltdNickname&quot;: &quot;vskycorpltd&quot;, &quot;eventId&quot;: &quot;2796229f-fbea-4da8-a8af-fd3de334f765&quot;, &quot;executionId&quot;: &quot;01EN7GSM1KA2XHV9SX956YGKCD&quot; }, &quot;user&quot;: &quot;vskycorpltd&quot; }, &quot;details&quot;: { &quot;type&quot;: &quot;manual&quot; }} 进入 echo echo位置：echo-web/src/main/java/com/netflix/spinnaker/echo/history/HistoryController.java 在 echo 中，上面的参数被转换成一个 echoEvent，然后将此事件，交给事件监听者来处理， 123456789101112131415161718192021222324@RequestMapping(value = &quot;/&quot;, method = RequestMethod.POST)public void saveHistory(@RequestBody Event event) { propagator.processEvent(event);}public void processEvent(Event event) { Observable.from(listeners) .map( listener -&gt; AuthenticatedRequest.propagate( () -&gt; { listener.processEvent(event); return null; })) .observeOn(scheduler) .subscribe( callable -&gt; { try { callable.call(); } catch (Exception e) { log.error(&quot;failed processing event: {}&quot;, event.content, e); } });} listeners 来在容器中所有的 EchoEventListener bean。 12345678@Beanpublic EventPropagator propagator() { EventPropagator instance = new EventPropagator(); for (EchoEventListener e : context.getBeansOfType(EchoEventListener.class).values()) { instance.addListener(e); } return instance;} 此处有 5 个监听者，他们的继承关系如下（观察者模式）： 此处仅关注 TriggerEventListener，它将是触发流水线的入口。随后 TriggerEventListener 会将事件交给 所有注册进来的 triggerMonitors 处理。 12345public void processEvent(Event event) { for (TriggerMonitor triggerMonitor : triggerMonitors) { triggerMonitor.processEvent(event); }} 每个 TriggerMonitor 包含一个 TriggerEventHandler，并且在初始化 TriggerEventListener 时，从容器中将所有的 TriggerEventHandler 都捞出来，用 TriggerMonitor 包裹一层，放入 triggerMonitors 中。 123456789101112131415161718public TriggerEventListener( @NonNull PipelineCache pipelineCache, @NonNull PipelineInitiator pipelineInitiator, @NonNull Registry registry, @NonNull PipelinePostProcessorHandler pipelinePostProcessorHandler, @NonNull List&lt;TriggerEventHandler&lt;?&gt;&gt; eventHandlers) { this.triggerMonitors = eventHandlers.stream() .map( e -&gt; new TriggerMonitor&lt;&gt;( pipelineCache, pipelineInitiator, registry, pipelinePostProcessorHandler, e)) .collect(Collectors.toList());} 但是并不是所有的 triggerMonitor 都处理这个事件，他们只负责处理各自能处理的事件。 12345678public void processEvent(Event event) { validateEvent(event); if (eventHandler.handleEventType(event.getDetails().getType())) { recordMetrics(); T triggerEvent = eventHandler.convertEvent(event); triggerMatchingPipelines(triggerEvent); }} 因此有若干个 TriggerEventHandler ，他们分别对应若干触发方式，如下： 此处我们是以手动的方式启动的，在 Event 的 detail 中，type 记录为 manual。 并且判断一个 TriggerEventHandler 能否处理某个事件的方式为：子类覆盖 handleEventType() 方法，并将相应能处理的事件的类型与当前 event.detail.type 对比，以 DockerEventHandler 为例： 123456789@Overridepublic boolean handleEventType(String eventType) { return eventType.equalsIgnoreCase(DockerEvent.TYPE);}public class DockerEvent extends TriggerEvent { public static final String TYPE = &quot;DOCKER&quot;; // ...} 因此，我们最终的入口便是 ManualEventHandler 。开始触发流水线。最终在 echo PipelineInitiator 的 triggerPipelineImpl() 方法中，通过 triggerWithRetries() 实现对 orca 的 HTTP 调用。 orca接口：/orchestrate 位置：OperationsController 经过一番折腾后，边开始执行 pipeline，并返回一个 id 给到 echo。其间有几个比较重要的步骤： 执行parseAndValidatePipeline(pipeline)，解决制品问题。最终调用的是：ArtifactResolver.resolveArtifacts()。 进行了一次 contextParameterProcessor.process() ，对 pipeline 中的表达式进行计算。 将 pipeline 信息转化成 Execution，然后再将其转化成一个 StartExecution 后，存入到一个 Queue 里面。 1234567891011override fun start(execution: Execution) = queue.push(StartExecution(execution)) @JsonTypeName(&quot;startExecution&quot;)data class StartExecution(override val executionType: ExecutionType,override val executionId: String,override val application: String) : Message(), ExecutionLevel {constructor(source: Execution) : this(source.type, source.id, source.application)} 其中，StartExecution 的值如下： 12345678{ &quot;kind&quot;: &quot;startExecution&quot;, &quot;attributes&quot;: [], &quot;ackTimeoutMs&quot;: null, &quot;executionType&quot;: &quot;PIPELINE&quot;, &quot;executionId&quot;: &quot;01ENCS32B8B8AP83FAHYTCCKHN&quot;, &quot;application&quot;: &quot;asgteam1&quot;} 发布&amp;获取事件Queue 的实现为 RedisQueue，它 push 的代码逻辑如下： 1234567891011121314override fun push(message: Message, delay: TemporalAmount) { pool.resource.use { redis -&gt; redis.firstFingerprint(queueKey, message.fingerprint()).also { fingerprint -&gt; if (fingerprint != null) { // ... redis.zadd(queueKey, score(delay), fingerprint, zAddParams().xx()) fire(MessageDuplicate(message)) } else { redis.queueMessage(message, delay) fire(MessagePushed(message)) } } }} 先将 message 即 StartExecution 的摘要信息存入到一个有序集合中，集合的键为 orca.task.queue.queue，可以查看 redis 中相应的值，结果如下： 然后通过 fire 函数，发布一个事件，这里应该是利用了 spring 的事件发布机制。 12345678@Beanfun queueEventPublisher( applicationEventPublisher: ApplicationEventPublisher) = object : EventPublisher { override fun publishEvent(event: QueueEvent) { applicationEventPublisher.publishEvent(event) }} ApplicationEventPublisher 是 spring-context 包下的一个接口。它是一个AnnotationConfigServletWebServerApplicationContext 的实例，且继承自AbstractApplicationContext ，它有一个 publishEvent() 方法。 获取消息 位置：com/netflix/spinnaker/q/QueueProcessor.kt 可以参考：https://spinnaker.io/guides/developer/service-overviews/orca/ 简而言之：不同的消息类型，对应不同的 handler。例如：StartExecution 消息，对应 StartExecutionHandler。 StartExecutionHandler12345678initialStages.forEach { queue.push(StartStage(it)) }fun Execution.initialStages() = stages .filter { it.isInitial() }fun Stage.isInitial(): Boolean = requisiteStageRefIds.isEmpty() 往 Queue 中塞若干个 StartStage，这些 Stage 必须不依赖其他 stage (配置除外)，这里是并行执行多个 Stage 的入口。 StartStageHandlerstage.plan() 函数执行逻辑： 1234567891011private fun Stage.plan() { builder().let { builder -&gt; // if we have a top level stage, ensure that context expressions are processed val mergedStage = if (this.parentStageId == null) this.withMergedContext() else this builder.addContextFlags(mergedStage) builder.buildTasks(mergedStage) builder.buildBeforeStages(mergedStage) { it: Stage -&gt; repository.addStage(it.withMergedContext()) } }} 根据 stage 的定义将 Task 加入到 stage 的 tasks 列表中。 1234567891011121314151617181920212223242526fun StageDefinitionBuilder.buildTasks(stage: Stage) { buildTaskGraph(stage) .listIterator() .forEachWithMetadata { processTaskNode(stage, it) }}default @Nonnull TaskGraph buildTaskGraph(@Nonnull Stage stage) { Builder graphBuilder = Builder(FULL); taskGraph(stage, graphBuilder); return graphBuilder.build();}// 在 Stage 中自定义的 taskGraph()@Overridevoid taskGraph(Stage stage, TaskNode.Builder builder) { if (isTopLevelStage(stage)) { builder .withTask(&quot;completeParallel&quot;, CompleteParallelBakeTask) } else { builder .withTask(&quot;createBake&quot;, CreateBakeTask) .withTask(&quot;monitorBake&quot;, MonitorBakeTask) .withTask(&quot;completedBake&quot;, CompletedBakeTask) .withTask(&quot;bindProducedArtifacts&quot;, BindProducedArtifactsTask) }} withTask() 方法将会将 taskName，taskImp类，封装到 TaskDefinition 中，并保存在 builder 的 graph 中。 12345public Builder withTask( String name, Class&lt;? extends com.netflix.spinnaker.orca.Task&gt; implementingClass) { graph.add(new TaskDefinition(name, implementingClass)); return this;} 然后通过 processTaskNode() 将所有的 task 保存到 stage 的 tasks 中。 123456789101112131415161718192021222324252627private fun processTaskNode( stage: Stage, element: IteratorElement&lt;TaskNode&gt;, isSubGraph: Boolean = false) { element.apply { when (value) { is TaskDefinition -&gt; { val task = Task() task.id = (stage.tasks.size + 1).toString() task.name = value.name task.implementingClass = value.implementingClass.name if (isSubGraph) { task.isLoopStart = isFirst task.isLoopEnd = isLast } else { task.isStageStart = isFirst task.isStageEnd = isLast } stage.tasks.add(task) } is TaskGraph -&gt; { // 递归执行... } } }} 让一个 Stage 包含两个 Stage 简单说就是在一个 Bake 阶段，似乎产生了两个 Bake，并且每个 Bake 的 task 还不一样，但他们都在一个 Bake 阶段里面，如下： 它的实现只需要在自定义 Stage 中实现 buildBeforeStage() 方法，并在这个方法中，在 graph 中，添加一个新的 Stage，它的本质是为 Bake A 阶段，添加了一个前置阶段 Bake in ap-beijing。 12345678910@Overridevoid beforeStages(@Nonnull Stage parent, @Nonnull StageGraphBuilder graph) { if (isTopLevelStage(parent)) { parallelContexts(parent) .collect({ context -&gt; newStage(parent.execution, type, &quot;Bake in ${context.region}&quot;, context, parent, STAGE_BEFORE) }) .forEach({Stage s -&gt; graph.add(s) }) }} 在搞定整个 Stage 的构造之后，开始 stage.start()，此处，会将上面创建的两个 Stage 分开运行。 1234567891011121314151617181920212223private fun Stage.start() { val beforeStages = firstBeforeStages() if (beforeStages.isEmpty()) { val task = firstTask() if (task == null) { // TODO: after stages are no longer planned at this point. We could skip this val afterStages = firstAfterStages() if (afterStages.isEmpty()) { queue.push(CompleteStage(this)) } else { afterStages.forEach { queue.push(StartStage(it)) } } } else { queue.push(StartTask(this, task.id)) } } else { beforeStages.forEach { queue.push(StartStage(it)) } }} 第一步的 val beforeStages = firstBeforeStages() 会先获取到创建的 Bake in ap-beijing 阶段，并通过 queue.push(StartStage(it)) 先执行 Bake in ap-beijing 。所以，只执行完 queue.push(StartStage(it)) ,代码的处理逻辑，又会进入 StartStageHandler中，如下： 接着通过 queue.push(StartTask(this, task.id))，开始执行第一个 Task，即 createBake。 StartTaskHandler12345678910message.withTask { stage, task -&gt; task.status = RUNNING task.startTime = clock.millis() val mergedContextStage = stage.withMergedContext() repository.storeStage(mergedContextStage) queue.push(RunTask(message, task.id, task.type)) publisher.publishEvent(TaskStarted(this, mergedContextStage, task))} 这里记录了 task 的开始时间、并保存到数据库中，同时通过 queue.push(RunTask(message, task.id, task.type)) 开启 task。 这里的 message.withTask 里面的套了好几层逻辑，与后续的 RunTask 有类似之处。 RunTaskHandler在 handle() 方法中，通过解析，最终得到了实际的 task，即 CreateBakeTask。 CreateBakeTask在此 Task 中，主要是对 bake 所需参数进行拼凑，主要步骤如下： 根据 account 获取 secret_id 和 secret_key。 根据 pipeline 中的设置，整理出 packer 使用的配置。 调用 rosco，并等待请求返回。 返回 task 执行成功。 task 执行完成当 CreateBakeTask 返回的状态为成功时，后续会触发 CompleteTask 事件，也就是对应 CompleteTaskHandler。 CompleteTaskHandler当一个 task 结束时，会判断 task 所属 stage 是否结束、是否已被手动跳过、已经进行触发下个 task。 1234567mergedContextStage.nextTask(task).let { if (it == null) { queue.push(NoDownstreamTasks(message)) } else { queue.push(StartTask(message, it.id)) }} 其中查找下一个 task 的逻辑只是将下标 +1 1234567fun Stage.nextTask(task: Task): Task? = if (task.isStageEnd) { null } else { val index = tasks.indexOf(task) tasks[index + 1] } 接着，便开始了一个新的循环，分别开始 MonitorBakeTask、CompletedBakeTask、BindProducedArtifactsTask。每个 task 都会像 CreateBakeTask 一样，经历下面的 3 个阶段： StartTaskHandler RunTaskHandler CompleteTaskHandler 当最后一个 task 执行完了之后，仍然会到达 CompleteTaskHandler 的 handle() 方法，此时会触发 CompleteStage。 CompleteStageHandler主要逻辑分两个，一个是对 afterStage 的处理，一个是对 nextStage 的处理。 与前面的 beforeStage 对应，还有一个 afterStage，逻辑应该与 beforeStage 类似，当执行完一个 stage 之后，再执行它的 afterStage。 stage.startNext() 获取接下来的 stages 的逻辑：并发执行所有接下来的 stage 123456789101112131415fun Stage.startNext() { execution.let { execution -&gt; val downstreamStages = downstreamStages() val phase = syntheticStageOwner if (downstreamStages.isNotEmpty()) { downstreamStages.forEach { queue.push(StartStage(it)) } } else if (phase != null) { queue.ensure(ContinueParentStage(parent(), phase), Duration.ZERO) } else { queue.push(CompleteExecution(execution)) } }} 如何确定接下来的 stages 根据当前 stage 的 refId，到 pipeline 中去遍历所有的 stage，只要该 stage 的 requisiteStageRefIds 里面有当前 stage 的 refId，那么它就将要被执行。 123456@JsonIgnorepublic List&lt;Stage&gt; downstreamStages() { return getExecution().getStages().stream() .filter(it -&gt; it.getRequisiteStageRefIds().contains(getRefId())) .collect(toList());}","link":"/2020/10/31/6ce2d2364228.html"},{"title":"3 | SpringCloud：Gateway从入门到出坑","text":"说句实话，我觉得Spring Cloud Gateway看起来很牛逼。首先是因为zuul的难产，颇有一种谁行谁上的感觉；再一个是WebFlux的加持，瞬间逼格就上去了。但是感觉苦逼的又回到了原点，因为WebFlux看简介是说基于Netty来实现的，绕来绕去又回到了Netty。 言归正传，如果只是简单的使用，对路由在yaml文件中进行配置是最简单的，以及进行断言、过滤。整体使用，感觉不难。但是，我相信，源码应该不好看?。 配置步骤①新建名叫gateway的module，导入spring-cloud-starter-gateway依赖到pom，并加入对nacos配置、服务发现相关的依赖，如下： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; spring-cloud-starter-gateway的依赖树如下： 这个netty相关的依赖看着有点眼熟。 ②编写启动类，开启服务注册与发现 1234567@SpringBootApplication@EnableDiscoveryClientpublic class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); }} ③在resouces下编写bootstrap.yaml配置文件（本来配置原本打算是要放到nacos里面，这里图个方便，直接放bootstrap里面了，所以这里看起来可能有点怪），最简单的是在这里定义路由、断言。 123456789101112131415161718192021server: port: 7777spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true routes: - id: hello uri: lb://module01 predicates: - Path=/hello/** nacos: discovery: server-addr: localhost:80 config: server-addr: localhost:80 file-extension: yaml ④此时启动gateway模块，通过7777端口即可访问到相应的接口，如下： ⑤还可以对gateway转发的每一条请求，做一个filter操作，如下： 1234567891011121314@Componentpublic class CustomFilter implements Ordered, GlobalFilter { Logger logger = Logger.getLogger(this.getClass().getName()); @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { logger.info(&quot;收到请求，来自：&quot; + exchange.getRequest().getRemoteAddress().getHostName()); return chain.filter(exchange); } @Override public int getOrder() { return 0; }} 此时的控制台会有日志打出，说明拦截生效了： 此处filter的可操作空间就比较大了，可以放一些针对全局请求的处理。 疑问：cloud.gateway.discovery.locator.enabled值默认为false，但是不加这个配置，通过服务名称+lb的配置也能生效，因此对它的作用应该不是开启微服务名转发的功能，那它的功能究竟是什么？ 答案是这个。 gateway在项目中的使用（以测试环境为例）①所有的请求走34的30450端口。这个端口是nginx，做静态页面与后端接口的转发。 ②由于34是k8s的一个node，因此通过信息查询，可以得出占用30450端口的pod ③进入main-src-web-test查看nginx的配置信息 ④找到31898端口对应的服务 ⑤此服务即项目中的gateway服务，其gateway相关的配置信息如下： 1234567891011121314151617181920212223242526272829server: port: 9898 context: excludePaths: - /emc-admin spring: cloud: sentinel: transport: port: 2${server.port} dashboard: 192.168.100.34:30858 datasource: default: nacos: serverAddr: ${nacos.server} dataId: sentinel-${spring.application.name}.json groupId: DEFAULT_GROUP dataType: json ruleType: flow gateway: routes: - id: emc-admin uri: lb://emc-admin predicates: - Path=/emc-admin/** filters: - StripPrefix=1 项目中的gateway还集成了sentinel，也就是自定义了一个Filter，并在其中，对每一条请求，都交给sentinel进行处理，由此实现熔断、降级、限流。实现如下： 123456789101112131415private Mono&lt;Void&gt; chainFilter(ServerWebExchange exchange, GatewayFilterChain chain, String requestURI) { try { Route route = exchange.getAttribute(GATEWAY_ROUTE_ATTR); ContextUtil.enter(route.getUri().toString()); AsyncEntry entry = SphU.asyncEntry(requestURI, EntryType.IN); return chain.filter(exchange).doFinally(type -&gt; { ContextUtil.runOnContext(entry.getAsyncContext(), () -&gt; { entry.exit(); }); }); } catch (BlockException ex) { log.warn(&quot;{} request blocked&quot;, requestURI); return responseFailure(exchange.getResponse(), HttpStatus.SERVICE_UNAVAILABLE); }}","link":"/2020/03/15/16c993d6b6a3.html"},{"title":"3 | Spring：AOP实现原理","text":"看给容器中注册了什么组件，这个组件什么时候工作，功能是什么？ @EnableAspectJAutoProxy工作流程①首先从@EnableAspectJAutoProxy注解入手，它使用@Import注解，加入了一个实现了ImportBeanDefinitionRegistrar的类，叫做AspectJAutoProxyRegistrar 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy { boolean proxyTargetClass() default false; boolean exposeProxy() default false;} ②也就是说它会往IOC容器中加入相应的bean，到底加入了什么呢？ 1234567891011121314151617@Overridepublic void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) { if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) { AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); } if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) { AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); } }} 从registerBeanDefinitions()方法开始，可以一直跟到AopConfigUtils.registerOrEscalateApcAsRequired()，在这个函数里面，它往IOC容器中注册了一个AnnotationAwareAspectJAutoProxyCreator，名称为AUTO_PROXY_CREATOR_BEAN_NAME，即org.springframework.aop.config.internalAutoProxyCreator。 123456789101112131415161718192021222324252627282930313233343536373839@Nullablepublic static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry) { return registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry, null);}@Nullablepublic static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary( BeanDefinitionRegistry registry, @Nullable Object source) { return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);}@Nullableprivate static BeanDefinition registerOrEscalateApcAsRequired( Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) { Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); // 此时不存在bean的定义 if (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) { BeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME); if (!cls.getName().equals(apcDefinition.getBeanClassName())) { int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) { apcDefinition.setBeanClassName(cls.getName()); } } return null; } // 创建AnnotationAwareAspectJAutoProxyCreator的bean， // 名称为AUTO_PROXY_CREATOR_BEAN_NAME RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE); beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); registry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition); return beanDefinition;} AnnotationAwareAspectJAutoProxyCreator了解AnnotationAwareAspectJAutoProxyCreator的功能，就等于知道了AOP的原理。首先看看它的继承关系图。 它的父类中，实现了两个接口，这两个接口参见bean的生命周期，所以搞清楚这两个接口在何时工作、工作内容即可搞明白AOP的整理流程。 ①有一个BeanFactoryAware接口； ②还有一个SmartInstantiationAwareBeanPostProcessor接口，它继承自InstantiationAwareBeanPostProcessor，它继承自BeanPostProcessor，但是与BeanPostProcessor不一样。InstantiationAwareBeanPostProcessor作用于实例化阶段的前后，BeanPostProcessor作用于初始化阶段的前后。 工作时机BeanFactoryAware按照上面类图中，从最先实现BeanFactoryAware接口的类，依次往下找相关的实现，即setBeanFactory()方法： AbstractAutoProxyCreator.setBeanFactory() 1234@Overridepublic void setBeanFactory(BeanFactory beanFactory) { this.beanFactory = beanFactory;} AbstractAdvisorAutoProxyCreator.setBeanFactory() 1234567891011@Overridepublic void setBeanFactory(BeanFactory beanFactory) { super.setBeanFactory(beanFactory); ... initBeanFactory((ConfigurableListableBeanFactory) beanFactory);}protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) { this.advisorRetrievalHelper = new BeanFactoryAdvisorRetrievalHelperAdapter(beanFactory);} AnnotationAwareAspectJAutoProxyCreator 123456789@Overrideprotected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) { super.initBeanFactory(beanFactory); if (this.aspectJAdvisorFactory == null) { this.aspectJAdvisorFactory = new ReflectiveAspectJAdvisorFactory(beanFactory); } this.aspectJAdvisorsBuilder = new BeanFactoryAspectJAdvisorsBuilderAdapter(beanFactory, this.aspectJAdvisorFactory);} 分别打上断点。 SmartInstantiationAwareBeanPostProcessor按照上面的类图，从最先实现SmartInstantiationAwareBeanPostProcessor接口的类开始，逐步往下寻找相关方法实现，如下： AbstractAutoProxyCreator 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) { if (bean != null) { Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) { return wrapIfNecessary(bean, beanName, cacheKey); } } return bean;}@Overridepublic Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) { Object cacheKey = getCacheKey(beanClass, beanName); if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) { if (this.advisedBeans.containsKey(cacheKey)) { return null; } if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; } } // Create proxy here if we have a custom TargetSource. // Suppresses unnecessary default instantiation of the target bean: // The TargetSource will handle target instances in a custom fashion. TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) { if (StringUtils.hasLength(beanName)) { this.targetSourcedBeans.add(beanName); } Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; } return null;} 分别打上断点。 工作流程梳理 InstantiationAwareBeanPostProcessor作为一个bean，被加载到beanFactory中。并执行其BeanFactoryAware接口的方法。 当其他bean初始化时，InstantiationAwareBeanPostProcessor会拦截其他bean的实例化，并创建代理对象返回。也就是执行postProcessBeforeInstantiation和postProcessAfterInitialization。 上面的结论是错的，经过后续的debug跟代码，发现最终Divider被Cglib代理是在BeanPostProcessor的afterInitialization中，如下： 其中的创建代理对象的逻辑如下： Cglib执行代理流程这个像一个有限套娃，也有点像递归，这种包装办法真的很厉害，很服气。 1234567891011121314151617181920212223242526272829303132333435①AfterThrowingtry { return mi.proceed();②}catch (Throwable ex) { if (shouldInvokeOnThrowing(ex)) { invokeAdviceMethod(getJoinPointMatch(), null, ex); } throw ex;}②AfterReturningObject retVal = mi.proceed();③this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis());return retVal;③Aftertry { return mi.proceed();④}finally { invokeAdviceMethod(getJoinPointMatch(), null, null);}④Beforethis.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis());return mi.proceed();⑤⑤invokeJoinpoint(); Netty源码学习系列④接收消息 Spring Cloud Alibaba Sentinel简易搭建与配置 Spring Boot Admin构建及用途 xxljob分布式定时任务 ELK日志系统搭建 elasticsearch、logstash、kibana kafka集群搭建 redis集群搭建 Spring Boot自动配置原理 raft算法演示以及nacos的CP与AP","link":"/2020/03/26/cf93c885e48c.html"},{"title":"3 分钟带你搞定 Kubernetes CNI 插件开发","text":"本文介绍 CNI 插件调用的时机、CNI 插件配置的读取，以及 CNI 插件的调用、执行。读完此文，您将清楚 CNI 插件的运行机制、调用细节，并能够自信地写出一个简单的 CNI 插件。 CRI：containerd CNI plugin：flannel CNI 的调用时机 源码位置：containerd - pkg/cri/server/service.go#L61 CRI 的RunPodSandbox()实现中。 RunPodSandbox的启动流程 生成 container id，名称； 确保 Infra 容器用的镜像存在，不存在的话就拉取； 确定 ociRuntime，比如 runC； 创建 Infra 容器将要托管的网络； 按照 ociRuntime 规范创建所要求的 spec； 生成 spec opts； 创建容器； 基于容器配置来创建 Task 启动 Task； 因此，Network Namespace 的创建，早于容器的创建。 CNI 配置文件的读取 源码位置：containerd - pkg/cri/server/service.go#L149 先在 containerd 的配置文件中，配置 CNI 的配置路径，如下。 123[plugins.&quot;io.containerd.grpc.v1.cri&quot;.cni] bin_dir = &quot;/opt/cni/bin&quot; conf_dir = &quot;/etc/cni/net.d&quot; 在 containerd 启动时读取该目录下的配置文件，封装成一个网络插件，最终保存在 libcni 里。 1234567891011121314type libcni struct { config cniConfig cnilibrary.CNI networkCount int // minimum network plugin configurations needed to initialize cni networks []*Network sync.RWMutex}type Network struct { cni cnilibrary.CNI config *cnilibrary.NetworkConfigList ifName string} libcni 中有个 Network 数组，通常这个数组有两个元素，最终分别用来设置 loopback、eth0这两个网卡。 总结一下这里的过程，可以概述为以下 3 点： containerd 会读取 conf_dir 下的内容，生成默认的网络插件（还可以添加其他路径，来生成其他网络插件）； 如果 conf_dir 下面有 N 个配置文件，会生成 N + 1 个 Network； Network 会生成相应的网络设备，默认名称为 eth0、eth1…。 CNI 配置文件示例 (flannel)在 K8s 节点上的路径：/etc/cni/net.d/10-flannel.conflist 12345678910111213141516171819{ &quot;name&quot;: &quot;cbr0&quot;, &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: { &quot;portMappings&quot;: true } } ]} CNI 插件的调用 源码位置：containerd - pkg/cri/server/sandbox_run.go#L377 总体流程 获取网络插件； 调用网络插件(libcni)的 Setup() 方法。 创建 namespace； 创建网络设备； 遍历所有的网络 Network； lo eth0 调用 CNI 接口 AddNetworkList。 遍历该 Network 中所有的 Plugins flannel portmap 检查 plugin 是否存在。（默认：/opt/cni/bin/{type}） 校验参数 执行插件命令。（环境变量 CNI_COMMAND 值为 ADD） 整理创建结果。 整理结果； 给 CNI 插件所传环境变量的分类： CNI 保留字段 CNI_COMMAND CNI_CONTAINERID CNI_NETNS CNI_ARGS CNI 自定义参数由 map 转成 string 后的字符串 CNI_IFNAME CNI_PATH CNI 自定义参数 调用 CNI 插件时，详细的传参如下： 1exec.ExecPlugin(ctx, pluginPath, netconf, args.AsEnv()) pluginPath 插件的完整路径； netconf plugin 配置； args.AsEnv() 将所有上述环境变量转换成 key=value 后得到的数组。 CNI 插件的执行 项目地址：github.com/flannel-io/cni-plugin 插件作为二进制直接被调用，执行时，根据 CNI_COMMAND 取值不同，走不同的处理流程(由 switch 分发逻辑)。还有一套对这种操作的封装，只需提供 ADD、DEL、CHECK 的实现函数。 ADD 操作 总结为两个步骤： 填充 delegate 字段的参数； 以填充后的 delegate 字段作为参数去调用其他的组件，来完成目标。 此时，插件拿到的网络配置数据 1234567{ &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true }} 设置 delegate 将要调用的命令为 bridge，插件填充完数据之后，得到的 delegate 字段如下： 12345678910111213141516171819202122232425{ &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;hairpinMode&quot;: true, &quot;ipMasq&quot;: false, &quot;ipam&quot;: { &quot;ranges&quot;: [ [ { &quot;subnet&quot;: &quot;10.244.1.0/24&quot; } ] ], &quot;routes&quot;: [ { &quot;dst&quot;: &quot;10.244.0.0/16&quot; } ], &quot;type&quot;: &quot;host-local&quot; }, &quot;isDefaultGateway&quot;: true, &quot;isGateway&quot;: true, &quot;mtu&quot;: 1450, &quot;name&quot;: &quot;cbr0&quot;, &quot;type&quot;: &quot;bridge&quot;} 调用其他组件来完成配置 1ExecPluginWithResult(ctx, pluginPath, netconf, delegateArgs(&quot;ADD&quot;), realExec)","link":"/2022/08/05/4cc0e7190731.html"},{"title":"4 | Netty：JavaNIO概览","text":"在正式开始Netty相关的学习之前，我决定还是要先回顾一下Java NIO，至少要对Java NIO相关的概念有一个了解，如Channel、ByteBuffer、Selector等。要自己动手写一写相关的demo实例、并且要尽可能地去了解其后面是如何实现的，也就是稍微看看相关jdk的源代码。 Java NIO 由以下几个核心部分组成：Buffer, Channel, Selector。传统的IO操作面向数据流，面向流 的 I/O 系统一次一个字节地处理数据，意味着每次从流中读一个或多个字节，直至完成，数据没有被缓存在任何地方；NIO操作面向缓冲区（ 面向块），数据从Channel读取到Buffer缓冲区，随后在Buffer中处理数据。 Buffer可以理解成煤矿里面挖煤的小车，把煤从井底运地面上面。它的属性与子类如下： Buffer是一个抽象类，继承自Object，拥有多个子类。此类在JDK源码中的注释如下： A container for data of a specific primitive type. A buffer is a linear, finite sequence of elements of a specific primitive type. Aside from its content, the essential properties of a buffer are its capacity, limit, and position: A buffer’s capacity is the number of elements it contains. The capacity of a buffer is never negative and never changes. A buffer’s limit is the index of the first element that should not be read or written. A buffer’s limit is never negative and is never greater than its capacity. 写模式下，limit表示最多能往Buffer里写多少数据，等于capacity值；读模式下，limit表示最多可以读取多少数据，小于等于 capacity 值。 A buffer’s position is the index of the next element to be read or written. A buffer’s position is never negative and is never greater than its limit. There is one subclass of this class for each non-boolean primitive type. Transferring dataEach subclass of this class defines two categories of get and put operations: Relative operations read or write one or more elements starting at the current position and then increment the position by the number of elements transferred. If the requested transfer exceeds the limit then a relative get operation throws a BufferUnderflowException and a relative put operation throws a BufferOverflowException; in either case, no data is transferred. Absolute operations take an explicit element index and do not affect the position. Absolute get and put operations throw an IndexOutOfBoundsException if the index argument exceeds the limit. Data may also, of course, be transferred in to or out of a buffer by the I/O operations of an appropriate channel, which are always relative to the current position. Marking and resettingA buffer’s mark is the index to which its position will be reset when the reset method is invoked. The mark is not always defined, but when it is defined it is never negative and is never greater than the position. If the mark is defined then it is discarded when the position or the limit is adjusted to a value smaller than the mark. If the mark is not defined then invoking the reset method causes an InvalidMarkException to be thrown. InvariantsThe following invariant holds for the mark, position, limit, and capacity values: 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity A newly-created buffer always has a position of zero and a mark that is undefined. The initial limit may be zero, or it may be some other value that depends upon the type of the buffer and the manner in which it is constructed. Each element of a newly-allocated buffer is initialized to zero. Clearing, flipping, and rewindingIn addition to methods for accessing the position, limit, and capacity values and for marking and resetting, this class also defines the following operations upon buffers: clear() makes a buffer ready for a new sequence of channel-read or relative put operations: It sets the limit to the capacity and the position to zero. flip() makes a buffer ready for a new sequence of channel-write or relative get operations: It sets the limit to the current position and then sets the position to zero. rewind() makes a buffer ready for re-reading the data that it already contains: It leaves the limit unchanged and sets the position to zero. Read-only buffersEvery buffer is readable, but not every buffer is writable. The mutation methods of each buffer class are specified as optional operations that will throw a ReadOnlyBufferException when invoked upon a read-only buffer. A read-only buffer does not allow its content to be changed, but its mark, position, and limit values are mutable. Whether or not a buffer is read-only may be determined by invoking its isReadOnly method. Thread safetyBuffers are not safe for use by multiple concurrent threads. If a buffer is to be used by more than one thread then access to the buffer should be controlled by appropriate synchronization. Invocation chainingMethods in this class that do not otherwise have a value to return are specified to return the buffer upon which they are invoked. This allows method invocations to be chained; for example, the sequence of statements 123b.flip();b.position(23);b.limit(42); can be replaced by the single, more compact statementb.flip().position(23).limit(42); clear()方法 1234567// 清除Buffer中的信息，只将参数恢复成默认public final Buffer clear() { position = 0; limit = capacity; mark = -1; return this;} flip()方法 1234567// 将limit记录成当前的位置，指针指向头部，为读取做准备public final Buffer flip() { limit = position; position = 0; mark = -1; return this;} rewind()方法 123456// 指针指向头部，可以用于再次读取public final Buffer rewind() { position = 0; mark = -1; return this;} 如何使用Java NIO读取文件内容遇到坑了，但是感觉可以透过这个问题更加深入理解Java NIO的这些概念。出现问题的代码： 12345678910public static void fileChannel() throws IOException { FileInputStream fis = new FileInputStream(&quot;/Users/yangyu/Documents/data.json&quot;); FileChannel fileChannel = fis.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while ((fileChannel.read(byteBuffer)) != -1) { while (byteBuffer.hasRemaining()) { System.out.print((char) byteBuffer.get()); } }} 上面的代码读取不到数据，一直在做循环，但是不输出数据。为什么？因为hasRemaining()是以position和limit作对比，如下： 123public final boolean hasRemaining() { return position &lt; limit;} 当从fileChannel中读取数据到byteBuffer中之后，limit与capacity相等（初始化既如此），此时的position也与capacity相同，导致hasRemaining()为false，无法向控制台输出。 所以需要将position设置成从0开始，让读取从0开始，直到读到之前的容量，所以使用flip()来完成这个目的，即： 此时却发现控制台无限打印东西，为了弄明白这是为什么，我把byteBuffer的大小调成了8，跑起来之后的输出如下： 这是为什么呢？这个问题应该与byteBuffer里面的那几个参数有关系： 猜测应该是与fileChannel.read(byteBuffer)中的具体实现有关。粗略看了看fileChannel.read(byteBuffer)的实现，大致流程如下： 计算byteBuffer的剩余量，即limit - position。对于上面的情况，剩余量为0。 找出缓存buffer，此时缓存buffer为上次read得到的，第一次为空会直接分配；第二次read的时候，其3大属性全部为8，也即上次读取的结果。 将缓存的buffer进行rewind()、flip(剩余量)，得到一个[pos=0, limit=0, capacity=8]的buffer。 进行读取的时候回根据缓存buffer的pos、limit来确定能读取的数量，也即： 123456789101112// 其中var1为缓存bufferint var5 = var1.position();int var6 = var1.limit();assert var5 &lt;= var6;// var6 - var5 = limit - position = 0int var7 = var5 &lt;= var6 ? var6 - var5 : 0;// var7 = 0if (var7 == 0) { // 0 即读取的字节数 return 0;} 如果能读到数据，会将缓存buffer里面的的内容再转移到byteBuffer（也就是我们read()里面传的ByteBuffer）中： 123456789// var5即缓存buffer，读取内容到var5中int var6 = readIntoNativeBuffer(var0, var5, var2, var4);// 准备用来读取var5.flip();// var1是我们传入的byteBuffer，如果读取到的字节数大于0，if (var6 &gt; 0) { // 将var5中的内容拷贝到var1中 var1.put(var5);} 直到发现flip()的注释里面有这样一段注释： Compacts this buffer (optional operation).The bytes between the buffer’s current position and its limit, if any, are copied to the beginning of the buffer. That is, the byte at index p = position() is copied to index zero, the byte at index p + 1 is copied to index one, and so forth until the byte at index limit() - 1 is copied to index n = limit() - 1 - p. The buffer’s position is then set to n+1 and its limit is set to its capacity. The mark, if defined, is discarded. The buffer’s position is set to the number of bytes copied, rather than to zero, so that an invocation of this method can be followed immediately by an invocation of another relative put method. Invoke this method after writing data from a buffer in case the write was incomplete. The following loop, for example, copies bytes from one channel to another via the buffer buf: 123456buf.clear(); // Prepare buffer for usewhile (in.read(buf) &gt;= 0 || buf.position != 0) { buf.flip(); out.write(buf); buf.compact(); // In case of partial write} 加上这段代码buf.compact()便可以正常读取文件内容。到这里就有点心累了，为什么写个读取都这么多坑。感觉有问题的时候往这三个参数上面想就行了。 Channel煤矿厂里面运煤的通道，需要看的子类总共有4个，分别为： FileChannel：文件通道，用于文件的读和写。不支持非阻塞 DatagramChannel：用于 UDP 连接的接收和发送 SocketChannel：把它理解为 TCP 连接通道，简单理解就是 TCP 客户端 ServerSocketChannel：TCP 对应的服务端，用于监听某个端口进来的请求 Selector只有自己写过的代码才会有更深刻的印象，哪怕是从别的地方抄来的，自己慢慢debug一下，找出自己对代码的疑问，然后再去搞清楚这些问题，我觉得这样让我对它的了解会更深。这两段代码基本和网上的教程类似，大部分是抄的，但是自己有一定的加工，也遇到了1个问题，外加一个疑问。 客户端代码客户端的代码很简单：①读标准输入。②发送给Server端。 1234567891011121314151617181920212223// Client端的代码很像八股文，这样弄就行了。public static void main(String[] args) throws Exception { SocketChannel sc = SocketChannel.open(); sc.configureBlocking(false); sc.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 8086)); Scanner scanner = new Scanner(System.in); if (sc.finishConnect()) { ByteBuffer buffer = ByteBuffer.allocate(1024); while (scanner.hasNextLine()) { // 读标准输入 String info = scanner.nextLine(); buffer.clear(); buffer.put(info.getBytes()); buffer.flip(); while (buffer.hasRemaining()) { System.out.println(buffer); // 发送给Server端 sc.write(buffer); } } }} 服务端代码主要参考了一篇CSDN上的博客和一篇简书上的博客，简书上面的这边对我的帮助很大，十分感谢。我的问题主要有两点，第一个是少了it.remove();，第二个是关于如何触发SelectionKey.OP_WRITE事件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 八股文的感觉。public static void startServer() throws IOException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); ssc.socket().bind(new InetSocketAddress(8086)); Selector selector = Selector.open(); ssc.register(selector, SelectionKey.OP_ACCEPT); while (true) { selector.select(); Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey key = it.next(); // 一定要remove掉，不然上次的事件会累积。 // 也就是对同一事件会处理两次，这样可能会导致报错。 it.remove(); if (key.isAcceptable()) { System.out.println(&quot;ACCEPT&quot;); ServerSocketChannel ssChannel = (ServerSocketChannel)key.channel(); SocketChannel sc = ssChannel.accept(); sc.configureBlocking(false); sc.register(key.selector(), SelectionKey.OP_READ, ByteBuffer.allocateDirect(BUF_SIZE)); } else if (key.isReadable()) { System.out.print(&quot;READ：&quot;); SocketChannel sc = (SocketChannel)key.channel(); ByteBuffer buf = (ByteBuffer)key.attachment(); long bytesRead = sc.read(buf); while(bytesRead&gt;0){ buf.flip(); while(buf.hasRemaining()){ System.out.print((char)buf.get()); } System.out.println(); buf.clear(); bytesRead = sc.read(buf); } if(bytesRead == -1){ sc.close(); } } else if (key.isWritable()) { // OP_WRITE事件如何触发？ System.out.print(&quot;WRITE：&quot;); ByteBuffer buf = (ByteBuffer) key.attachment(); buf.flip(); SocketChannel sc = (SocketChannel) key.channel(); while(buf.hasRemaining()){ sc.write(buf); } buf.compact(); } else if (key.isConnectable()) { System.out.println(&quot;CONNECT&quot;); } else { System.out.println(&quot;UNKNOWN&quot;); } } }} 如果缺少it.remove()方法的调用，那么会导致事件会堆积在Selector的Set&lt;SelectionKey&gt; publicSelectedKeys中，引发对同一事件会处理两次，这样可能会导致报错。 如何触发SelectionKey.OP_WRITE？因为我看到大部分关于selector的博客，都没有写如何触发该事件，并且也未对读事件做出说明。 首先肯定要在调用ssChannel.accept()之后，将得到的SocketChannel多注册一个OP_WRITE事件。即修改成： 123SocketChannel sc = ssChannel.accept();sc.configureBlocking(false);sc.register(key.selector(), SelectionKey.OP_READ | SelectionKey.OP_WRITE,ByteBuffer.allocateDirect(BUF_SIZE)); 然后会发现程序卡死，屏幕一直输出Write。为什么会有这么多OP_WRITE事件？因为Java NIO的事件触发是水平触发，即只要满足条件，就触发一个事件，所以只要内核缓冲区还不满，就一直发出OP_WRITE事件。 与水平触发对应的还有一个叫做边缘触发，即每当状态变化时，触发一个事件。对之前的Netty的事件是边缘触发又有了一个认识。","link":"/2020/02/18/32c129172610.html"},{"title":"4 | Spinnaker orca 如何处理 pipeline 中的制品","text":"处理所在的接口：/orchestrate，位置：OperationsController 进入接口后，执行parseAndValidatePipeline(pipeline)，最终会调用：ArtifactResolver.resolveArtifacts()。调用栈如下： OperationsController.orchestrate(@RequestBody Map pipeline, HttpServletResponse response) OperationsController.planOrOrchestratePipeline(Map pipeline) OperationsController.orchestratePipeline(Map pipeline) OperationsController.parseAndValidatePipeline(Map pipeline) OperationsController.parseAndValidatePipeline(Map pipeline, boolean resolveArtifacts) OperationsController.parsePipelineTrigger(ExecutionRepository executionRepository, BuildService buildService, Map pipeline, boolean resolveArtifacts) 在 parsePipelineTrigger() 方法中，调用 artifactResolver?.resolveArtifacts(pipeline)。 各种 Artifact首先，Artifact 的来源是 ExpectedArtifact，它包含一个制品的匹配规则（matchArtifact）、一个默认的制品（defaultArtifact）以及一个绑定制品（boundArtifact，暂不明用途），他们的关系如下所示： 其次，在流水线的 json 配置中的表现形式则为： 12345678910111213141516171819202122232425262728{ &quot;expectedArtifacts&quot;: [ { &quot;defaultArtifact&quot;: { &quot;customKind&quot;: false, &quot;id&quot;: &quot;292e6782-8e60-4bfe-9693-c9f6619daf76&quot; }, &quot;displayName&quot;: &quot;black-cat-45&quot;, &quot;id&quot;: &quot;8435f791-fb44-41c3-851d-4334dae63d80&quot;, &quot;matchArtifact&quot;: { &quot;artifactAccount&quot;: &quot;generic-repo::1&quot;, &quot;customKind&quot;: false, &quot;id&quot;: &quot;4ddf512b-35df-4672-b315-8c0faf8347eb&quot;, &quot;name&quot;: &quot;codingcorp-generic.pkg.coding.com/adb/generic-repo/curl-time.sh&quot;, &quot;parentType&quot;: &quot;generic&quot;, &quot;pkgId&quot;: 2, &quot;pkgName&quot;: &quot;curl-time.sh&quot;, &quot;projectId&quot;: 2, &quot;projectName&quot;: &quot;adb&quot;, &quot;repoName&quot;: &quot;generic-repo&quot;, &quot;type&quot;: &quot;coding_artifact/generic&quot;, &quot;uriName&quot;: &quot;adb&quot; }, &quot;useDefaultArtifact&quot;: false, &quot;usePriorArtifact&quot;: false } ]} 接着，看代码中所定义的几种制品， expectedArtifacts此处的解析如上文所述，包含匹配规则、默认制品以及绑定制品。 receivedArtifactsFromPipeline取自 receivedArtifacts 字段，顾名思义，它是上个 pipeline 中产生的制品。它的设置在请求到达 orca 前，就已经完成，即在 echo 的 MannualEventHandler.buildTrigger() 方法中已经处理完成。 处理的逻辑就是将 Trigger 中所携带的制品，添加到 pipeline 的 receivedArtifacts 字段中。 artifactsFromTrigger此处的 artifact 来自 trigger，应该是被包含在 pipeline.receivedArtifacts 中，即被 receivedArtifactsFromPipeline 所包含。 12trigger = pipeline.get(&quot;trigger&quot;);artifactsFromTrigger = trigger.get(&quot;artifacts&quot;); receivedArtifacts为 artifactsFromTrigger 与 receivedArtifactsFromPipeline 并集并去重。 1234List&lt;Artifact&gt; receivedArtifacts = Stream.concat(receivedArtifactsFromPipeline.stream(), artifactsFromTrigger.stream()) .distinct() .collect(toList()) 经过上面的处理后，trigger 里面的 artifacts 就别替换成了 receivedArtifacts。 priorArtifacts主是各个 stage 的 output 字段中，所记录的 artifacts，也就是其他阶段产生的制品。如果 includeTrigger 标志位 true，则还会加入 trigger 中的制品。所以，它是 trigger + 其他阶段所产生制品的总和。 resolvedArtifacts即进行制品规则匹配后，符合条件的制品。它的处理逻辑为： 12LinkedHashSet&lt;Artifact&gt; resolvedArtifacts = resolveExpectedArtifacts(expectedArtifacts, receivedArtifacts, priorArtifacts, true); 之后，便会为每一个 expectedArtifact 进行制品匹配，也即如下： 12345678910111213141516171819202122public Artifact resolveSingleArtifact( ExpectedArtifact expectedArtifact, List&lt;Artifact&gt; possibleMatches, List&lt;Artifact&gt; priorArtifacts, boolean requireUniqueMatches) { Artifact resolved = matchSingleArtifact(expectedArtifact, possibleMatches, requireUniqueMatches); if (resolved == null &amp;&amp; expectedArtifact.isUsePriorArtifact() &amp;&amp; priorArtifacts != null) { resolved = matchSingleArtifact(expectedArtifact, priorArtifacts, requireUniqueMatches); expectedArtifact.setBoundArtifact(resolved); } if (resolved == null &amp;&amp; expectedArtifact.isUseDefaultArtifact() &amp;&amp; expectedArtifact.getDefaultArtifact() != null) { resolved = expectedArtifact.getDefaultArtifact(); expectedArtifact.setBoundArtifact(resolved); } return resolved;} 上面的代码逻辑分三步，匹配失败的时候，进入下一步骤： 优先使用 receivedArtifacts 去匹配制品。 次优使用 priorArtifacs 去匹配制品。 如果上面都没有匹配上，最后再使用默认制品（前提：isUseDefaultArtifact 开关开启，并配置了默认制品）。 其中 所期望制品 与 **能拿到的制品 **的匹配逻辑为： 12345678910111213141516171819202122232425262728293031323334353637private Artifact matchSingleArtifact( ExpectedArtifact expectedArtifact, List&lt;Artifact&gt; possibleMatches, boolean requireUniqueMatches) { if (expectedArtifact.getBoundArtifact() != null) { return expectedArtifact.getBoundArtifact(); } expectedArtifact .getMatchArtifact() .setType(&quot;.*&quot; + expectedArtifact.getMatchArtifact().getType()); if (!StringUtils.isEmpty(expectedArtifact.getMatchArtifact().getVersion())) { expectedArtifact .getMatchArtifact() .setVersion(&quot;.*&quot; + expectedArtifact.getMatchArtifact().getVersion()); } List&lt;Artifact&gt; matches = possibleMatches.stream().filter(expectedArtifact::matches).collect(toList()); Artifact result; switch (matches.size()) { case 0: return null; case 1: result = matches.get(0); break; default: if (requireUniqueMatches) { throw new InvalidRequestException( &quot;Expected artifact &quot; + expectedArtifact + &quot; matches multiple artifacts &quot; + matches); } result = matches.get(0); } expectedArtifact.setBoundArtifact(result); return result;} 没填写版本、类型的匹配规则，被设置为 .* ，后面会被当做正则表达式使用，即匹配所有。 只能有一个制品，才能匹配成功 匹配成功后，将匹配所得的制品，塞到 expectedArtifact 的 boundArtifact 中。 其中，如何才能算得上匹配，其实就是对比 传入的Artifacts 的各个属性（type, name, version, reference）是否符合正则表达，即： 1234567891011121314151617public boolean matches(Artifact other) { String thisType = matchArtifact.getType(); String otherType = other.getType(); if (!matches(thisType, otherType)) { return false; }// ... return true;}private boolean matches(String us, String other) { return StringUtils.isEmpty(us) || (other != null &amp;&amp; patternMatches(us, other));}private boolean patternMatches(String us, String other) { return Pattern.compile(us).matcher(other).matches();} allArtifactsresolvedArtifacts + receivedArtifacts 经过上面的处理后，trigger 中的各项 artifacts 会被更新： artifacts -&gt; allArtifacts expectedArtifacts -&gt; expectedArtifacts resolvedExpectedArtifacts -&gt; expectedArtifacts 至此，orca 在开启流水线之前的制品匹配，已经处理完成。","link":"/2020/10/31/f223bee55ee4.html"},{"title":"6 | Netty：新连接的建立","text":"当服务端启动好了之后，也就是说，服务端已经在执行NioEventLoop的一个死循环方法run()中，一直轮询事件，并且此时的监听的事件为OP_ACCEPT。如果有新连接接入，那么首先会在上述的run()方法中触发… 收到新的连接首先，服务端启动好了之后，会进入等待事件的状态，也就是调用JDK的NIO的API： 123456// NioEventLoop.java -&gt; run()if (!hasTasks()) { strategy = select(curDeadlineNanos);}// 核心是调用jdk的apiselector.select(); 收到新的连接后，将会通过processSelectedKeys()进行处理，处理内容包括：创建、初始化NioSocketChannel。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// NioEventLoop.javaprivate void processSelectedKeys() { if (selectedKeys != null) { processSelectedKeysOptimized(); } else { processSelectedKeysPlain(selector.selectedKeys()); }}private void processSelectedKeysOptimized() { for (int i = 0; i &lt; selectedKeys.size; ++i) { final SelectionKey k = selectedKeys.keys[i]; // 帮助GC selectedKeys.keys[i] = null; // attachment是NioServerSocketChannel // 服务端注册selectionKey时传入 final Object a = k.attachment(); if (a instanceof AbstractNioChannel) { // 此处真正进入处理新连接事件 processSelectedKey(k, (AbstractNioChannel) a); } else { @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); } //... }}private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); // ... try { // 此时的readyOps为OP_ACCEPT，也就是16，即二进制10000 int readyOps = k.readyOps(); // ... // 处理新连接的逻辑开始 // SelectionKey.OP_READ | SelectionKey.OP_ACCEPT = 10001 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { // 此处的unsafe与创建连接时的unsafe不是同一个实现 unsafe.read(); } } // ...} 创建、初始化NioSocketChannel上面的unsafe的具体实现是在一个叫做NioMessageUnsafe的内部类中，在它的read方法中： ①创建了NioSocketChannel。②通过pipeline中的Handler，即ServerBootstrap$ServerBootstrapAcceptor中初始化NioSocketChannel。 12345678910111213141516171819202122232425262728293031323334353637383940414243// @Overridepublic void read() { assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try { try { do { // ①创建了NioSocketChannel,并加入到readBuf这个List中 int localRead = doReadMessages(readBuf); if (localRead == 0) { break; } if (localRead &lt; 0) { closed = true; break; } allocHandle.incMessagesRead(localRead); } while (allocHandle.continueReading()); } catch (Throwable t) { exception = t; } int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) { readPending = false; // ②在ServerBootstrap$ServerBootstrapAcceptor中初始化NioSocketChannel pipeline.fireChannelRead(readBuf.get(i)); } readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); // ... } // ...} 创建创建NioSocketChannel的主要流程，就是先通过调用JDK的API获取SocketChannel，然后再将其作为一个值传给NioSocketChannel。因此从另一个方面来看，可以理解成NioSocketChannel是SocketChannel的封装。 123456789101112131415@Overrideprotected int doReadMessages(List&lt;Object&gt; buf) throws Exception { // 实际调用时serverSocketChannel.accept() SocketChannel ch = SocketUtils.accept(javaChannel()); try { if (ch != null) { // 创建NioSocketChannel buf.add(new NioSocketChannel(this, ch)); return 1; } } // ... return 0;} 初始化主要依靠pipeline中的相应事件传递。比如说，将channel注册到EventLoop中这个事件，就是靠pipeline中的Handler，ServerBootstrapAcceptor来完成。 123456789101112131415161718192021222324252627282930313233343536373839// 调用pipeline中的不可覆盖方法fireChannelReadpipeline.fireChannelRead(readBuf.get(i));// 与之前的流程类似，从pipeline中的头handler开始传递事件@Overridepublic final ChannelPipeline fireChannelRead(Object msg) { AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;}// 一个静态模板方法，掉用next的invokeChannelRead()方法static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) { final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, &quot;msg&quot;), next); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeChannelRead(m); } else { executor.execute(new Runnable() { @Override public void run() { next.invokeChannelRead(m); } }); }}// 还是一个模板方法，用于真实执行hander的read事件处理方法private void invokeChannelRead(Object msg) { if (invokeHandler()) { try { // 触发handler的read事件，模板模式 ((ChannelInboundHandler) handler()).channelRead(this, msg); } catch (Throwable t) { notifyHandlerException(t); } } else { fireChannelRead(msg); }} 到这里，事件的往后续handler传递，都是调用上面的这个两个方法，来执行后续handler的相应read方法。此时pipeline中的handler有： 12345671) DefaultChannelPipeline$HeadContext2) io.netty.handler.logging.LoggingHandler3) io.netty.bootstrap.ServerBootstrap$ServerBootstrapAcceptor4) DefaultChannelPipeline$TailContext 其中，head对read只是做简单的传递： 12345678910111213// DefaultChannelPipeline$HeadContext@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) { ctx.fireChannelRead(msg);}// AbstractChannelHandlerContext.java@Overridepublic ChannelHandlerContext fireChannelRead(final Object msg) { // 调用上面代码片段中的静态模板方法，实现事件传递 invokeChannelRead(findContextInbound(MASK_CHANNEL_READ), msg); return this;} 对LoggingHandler而言，简易打印日志，并往后传递事件： 12345678// LoggingHandler.java@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { if (logger.isEnabled(internalLevel)) { logger.log(internalLevel, format(ctx, &quot;READ&quot;, msg)); } ctx.fireChannelRead(msg);} 到ServerBootstrapAcceptor的read方法时，初始化便真正地开始了（此时的线程为bossGroup中的EventLoop）： 12345678910111213141516171819202122232425// ServerBootstrapAcceptor@Override@SuppressWarnings(&quot;unchecked&quot;)public void channelRead(ChannelHandlerContext ctx, Object msg) { final Channel child = (Channel) msg; // 将ChannelInitializer添加到pipeline中，等执行完initial方法后，会被移除 child.pipeline().addLast(childHandler); // 设置NioSocketChannel属性 setChannelOptions(child, childOptions, logger); setAttributes(child, childAttrs); try { // 将NioSocketChannel绑定到一个workGroup中的NioEventLoop上 childGroup.register(child).addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { forceClose(child, future.cause()); } } }); } catch (Throwable t) { forceClose(child, t); }} register的过程与服务端启动时的绑定类似，先选出一个EventLoop，选的时候，有两种方式，根据不同的线程数，使用不同的选择方式。然后经过辗转，来到对register0()的执行，这个方法时主要的register操作。但是此时的线程是bossGroup中的EventLoop，而register0()会在workGroup中的线程中执行。所以会先将task放入队列中，然后启动线程，并进入NioEventLoop的run()死循环方法，通过不断遍历是否有已监听事件以及执行队列中的任务，最终来执行该task。 12345678910111213141516171819202122232425262728293031323334353637383940414243// MultithreadEventLoopGroup.java@Overridepublic ChannelFuture register(Channel channel) { return next().register(channel);}// SingleThreadEventLoop.java@Overridepublic ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this));}@Overridepublic ChannelFuture register(final ChannelPromise promise) { ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); return promise;}// AbstractChannel.java@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) { // ... AbstractChannel.this.eventLoop = eventLoop; // 此时的线程是bossGroup中的EventLoop， // 此处的eventLoop则为上面分配的wordGroup中的线程。 if (eventLoop.inEventLoop()) { register0(promise); } else { // 所以会执行此方法，此时该eventLoop中的线程还未启动，会将此task放入队列中 // 然后会通过eventLoop.execute来启动线程，并进入NioEventLoop的run()方法 // 通过不断遍历是否有已监听事件以及执行队列中的任务，最终来执行该task。 try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } // ... }} 此时，线程切换到workGroup中的EventLoop。主要执行好几个操作：先调用jdk的api，注册selectionKey；再发布相应的事件；最后修改interestOps为OP_READ。 123456789101112131415161718192021222324252627282930private void register0(ChannelPromise promise) { try { // ... boolean firstRegistration = neverRegistered; // 调用jdk的api，注册selectionKey doRegister(); neverRegistered = false; registered = true; // 处理ChannelInitializer，并移除掉它 pipeline.invokeHandlerAddedIfNeeded(); // 在服务端启动的时候，会以观察者模式调用操作完成的Listener // doBind操作就是这样被封装到了其中，但处理客户端连接没有doBind操作 safeSetSuccess(promise); // 从pipeline的head开始传递registered事件 pipeline.fireChannelRegistered(); // 此时已经被激活 if (isActive()) { // 第一次进行register操作，被视为建立连接 if (firstRegistration) { // 与服务端类似，会在此处将监听的事件改为OP_READ pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // 真的有数据来了 beginRead(); } } } // ...} 调用jdk的api，注册selectionKey 12345678910111213// AbstractNioChannel.java@Overrideprotected void doRegister() throws Exception { boolean selected = false; for (;;) { try { // 监听的事件为0，attachment是channel自己 selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; } // ... }} 对channle已激活的事件传递中，会将NioSocketChannel的interestOps修改为OP_READ。下面的代码是事件在pipeline中的传递，与上面的分析内容一致，在此不多赘述。 123456789101112131415161718192021222324252627282930313233// DefaultChannelPipeline.java@Overridepublic final ChannelPipeline fireChannelActive() { AbstractChannelHandlerContext.invokeChannelActive(head); return this;}// AbstractChannelHandlerContext.javastatic void invokeChannelActive(final AbstractChannelHandlerContext next) { EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeChannelActive(); } else { executor.execute(new Runnable() { @Override public void run() { next.invokeChannelActive(); } }); }}private void invokeChannelActive() { if (invokeHandler()) { try { ((ChannelInboundHandler) handler()).channelActive(this); } catch (Throwable t) { notifyHandlerException(t); } } else { fireChannelActive(); }} 唯一有区别的是：pipeline中的head，即HeadContext对active事件的处理方式，多了一块对interestOps的处理： 12345678910111213// DefaultChannelPipeline.java $ HeadContext@Overridepublic void channelActive(ChannelHandlerContext ctx) { ctx.fireChannelActive(); // 修改interestOps readIfIsAutoRead();}private void readIfIsAutoRead() { if (channel.config().isAutoRead()) { channel.read(); }} 这里会在pipeline中传递read事件，但是是从tail开始，可以直接跳到TailContext的read()方法中： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// AbstractChannel.java@Overridepublic Channel read() { pipeline.read(); return this;}// DefaultChannelPipeline.java@Overridepublic final ChannelPipeline read() { tail.read(); return this;}// AbstractChannelHandlerContext.java@Overridepublic ChannelHandlerContext read() { final AbstractChannelHandlerContext next = findContextOutbound(MASK_READ); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeRead(); } else { Tasks tasks = next.invokeTasks; if (tasks == null) { next.invokeTasks = tasks = new Tasks(next); } executor.execute(tasks.invokeReadTask); } return this;}private void invokeRead() { if (invokeHandler()) { try { ((ChannelOutboundHandler) handler()).read(this); } catch (Throwable t) { notifyHandlerException(t); } } else { read(); }}// DefaultChannelPipeline.java@Overridepublic void read(ChannelHandlerContext ctx) { unsafe.beginRead();} 此处便到了修改的interestOps的主要逻辑处： 123456789101112131415161718192021222324252627282930313233343536373839// AbstractChannel.java@Overridepublic final void beginRead() { assertEventLoop(); if (!isActive()) { return; } try { doBeginRead(); } catch (final Exception e) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireExceptionCaught(e); } }); close(voidPromise()); }}// AbstractNioChannel.java@Overrideprotected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); // 此时interestOps为0，所以if中的条件一定会成立 if ((interestOps &amp; readInterestOp) == 0) { selectionKey.interestOps(interestOps | readInterestOp); }} 至此，对新建连接的处理基本完成。","link":"/2020/03/11/b04a730e5e11.html"},{"title":"5 | Netty：服务端启动流程分析","text":"目前对于Netty的理解是：一套完善了Java NIO操作的框架，因为Netty的最底层还是调用jdk的nio相关的API，但是又在jdk的nio基础上做了很多的封装，并衍生出来了自己相关的概念。 服务启动的主线操作以EchoServer为例，一条可参考的服务启动的主线操作如下： main thread 创建selector 创建serversocketchannel 初始化serversocketchannel 给serversocketchannel从bossgroup中选择一个NioEventLoop boss thread 将serversocketchannel注册到选择的NioEventLoop的selector 绑定地址启动 注册接受连接事件(OP_ACCEPT)到selector上 对应到代码中的操作依次为： 12345678910// 1. 创建selectorSelector selector = sun.nio.ch.SelectorProviderImpl.openSelector();// 2. 创建serversocketchannelServerSocketChannel serverSocketChannel = provider.openServerSocketChannel();// 将serversocketchannel注册到选择的NioEventLoop的selectorselectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); // 绑定地址启动javaChannel().bind(localAddress, config.getBacklog());// 注册接受连接事件(OP_ACCEPT)到selector上selectionKey.interestOps(OP_ACCEPT); 根据上面的启动主线，以它为一个参考，我觉得这个主线过于简略，也就是说很多操作并不能体现出来。所以我将创建一个server的步骤分成如下3个大的步骤。下面会对上述3个大步骤做适当、尽可能详细的分析，并将之前看过的源码内容与服务创建联系起来。 创建EventLoopGroupEventLoopGroup的个数决定具体reactor模式，在EchoServer中使用了两个EventLoopGroup，也就是使用了主从Reactor多线程模式；而EventLoopGroup的类型决定使用的IO模式，这里使用的是``NioEventLoopGroup也就是使用的IO模式为NIO。对应于EchoServer`中的代码为： 12EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup(); 到这里有若干个问题，但是主线中不会提及，因为主线关注的是操作链条，在大致了解主线操作之后，加强对个各个细节处的理解，才能理解得更加透彻。这里的问题主要来自心中的疑问。 什么是EventLoopGroup、EventLoop之前的初略理解是：EventLoopGroup是一个线程池、EventLoop则对应一个线程。 EventLoopGroup是一个接口，有多种实现方式，在EchoServer中，它的实现是NioEventLoopGroup。 Channel、EventLoop、EventLoopGroup之间的关系如下图所示： 一个EventLoopGroup包含一个或者多个EventLoop； 一个EventLoop在它的生命周期内只和一个Thread绑定； 所有由EventLoop处理的I/O事件都将在它专有的Thread上被处理； 一个Channel在它的生命周期内只注册于一个EventLoop； 一个EventLoop可能会被分配给一个或多个Channel。 为什么new NioEventLoopGroup(1)传1在前面的一篇文章中有分析过为什么传1，因为对于boss group来说，只会有一个channel，所以只绑定1个线程，也就只需要1个EventLoop。 如果不传任何参数，线程数在NioEventLoopGroup中会先传0，在父类MultithreadEventLoopGroup先再做判断，如果为0，那么会默认为： 123456DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt( &quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2));protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) { super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args);} 获取SelectorProvider1234567891011121314151617181920212223// 在NioEventLoopGroup.java中public NioEventLoopGroup(ThreadFactory threadFactory) { this(0, threadFactory, SelectorProvider.provider());}// 在SelectorProvider.java中public static SelectorProvider provider() { synchronized (lock) { if (provider != null) return provider; return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() { public SelectorProvider run() { if (loadProviderFromProperty()) return provider; if (loadProviderAsService()) return provider; provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; } }); }} 其中sun.nio.ch.DefaultSelectorProvider在不同平台jdk中、其实现不一样，从而以此达到，统一不同平台下Selector的实现。其中Windows下的实现如下： 12345678public class DefaultSelectorProvider { private DefaultSelectorProvider() { } public static SelectorProvider create() { return new WindowsSelectorProvider(); }} 根据线程数创建EventExecutor数组并初始化在MultithreadEventExecutorGroup的构造函数中，会初始化一个EventExecutor数组，其实这就是NioEventLoop数组。 123456789101112131415161718children = new EventExecutor[nThreads];for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { // 创建EventLoopGroup失败，释放资源 } }}// chooserFactory是用来创建一个选择器的工厂类。chooser = chooserFactory.newChooser(children); 选择器是用来选择一个EventLoop，供进行事件处理。具体有两种策略，一种是EventLoop个数为2的倍数（通过&amp;运算）、一种是普通的（通过%运算）。说真的，我对这两者的差异没有啥感觉。 对于newChild()这个方法，我们找到对应的NioEventLoopGroup的实现： 也就是说，在初始化NioEventLoopGroup的时候，就已经将所有的NioEventLoop初始化完成。 NioEventLoop的初始化 打开openSelector()操作。说明selector在初始化NioEventLoop时就被打开。 1234567891011final SelectorTuple selectorTuple = openSelector();private SelectorTuple openSelector() { final Selector unwrappedSelector; try { unwrappedSelector = provider.openSelector(); } catch (IOException e) { throw new ChannelException(&quot;failed to open a new selector&quot;, e); } ...} 初始化一个包装Runnable后的executor。 12345678910111213141516171819202122232425262728this.executor = ThreadExecutorMap.apply(executor, this);public static Executor apply(final Executor executor, final EventExecutor eventExecutor) { ObjectUtil.checkNotNull(executor, &quot;executor&quot;); ObjectUtil.checkNotNull(eventExecutor, &quot;eventExecutor&quot;); return new Executor() { @Override public void execute(final Runnable command) { executor.execute(apply(command, eventExecutor)); } };}// 包装Runnable后，再返回一个包装后的Runnablepublic static Runnable apply(final Runnable command, final EventExecutor eventExecutor) { ObjectUtil.checkNotNull(command, &quot;command&quot;); ObjectUtil.checkNotNull(eventExecutor, &quot;eventExecutor&quot;); return new Runnable() { @Override public void run() { setCurrentEventExecutor(eventExecutor); try { command.run(); } finally { setCurrentEventExecutor(null); } } };} 通过Bootstrap设置相关参数绑定端口并启动这一步骤有多个重要的过程。 创建NioServerSocketChannel1234567891011121314151617181920212223// 指定channel类型为NioServerSocketChannelb.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class)// 设置一个生成channel的工厂类public B channel(Class&lt;? extends C&gt; channelClass) { return channelFactory(new ReflectiveChannelFactory&lt;C&gt;( ObjectUtil.checkNotNull(channelClass, &quot;channelClass&quot;) ));}public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) { return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);}public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) { ObjectUtil.checkNotNull(channelFactory, &quot;channelFactory&quot;); if (this.channelFactory != null) { throw new IllegalStateException(&quot;channelFactory set already&quot;); } // 后续channel由channleFactory产生 this.channelFactory = channelFactory; return self();} 此处的channelFactory是一个ReflectiveChannelFactory，它的实现比较简单，通过class获取到构造器，然后通过构造器即可创建出新的对象。简单的逻辑如下： 1234567891011121314151617public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) { ObjectUtil.checkNotNull(clazz, &quot;clazz&quot;); try { this.constructor = clazz.getConstructor(); } catch (NoSuchMethodException e) { throw new IllegalArgumentException(...); }}@Overridepublic T newChannel() { try { return constructor.newInstance(); } catch (Throwable t) { throw new ChannelException(...); }} 初始化完channelFactory之后，进入doBind()阶段，此时会通过一个channelFactory来创建一个新的对象，即NioServerSocketChannel。如下： 12345678final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); // ... } // ...} 在NioServerSocketChannel创建的时候，会创建一个ServerSocketChannel，调用栈依次为： 1234567891011121314151617181920212223242526272829303132333435363738// SelectorProvider.provider()可参见前文中的内容SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider();public NioServerSocketChannel() { this(newSocket(DEFAULT_SELECTOR_PROVIDER));}public NioServerSocketChannel(ServerSocketChannel channel) { super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());}protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent, ch, readInterestOp);}protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) { super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try { ch.configureBlocking(false); } catch (IOException e) { // ... }}protected AbstractChannel(Channel parent) { this.parent = parent; id = newId(); unsafe = newUnsafe(); // 添加一个默认的pipeline，类型为DefaultChannelPipeline pipeline = newChannelPipeline();}protected DefaultChannelPipeline newChannelPipeline() { return new DefaultChannelPipeline(this);} 初始化刚创建的NioServerSocketChannel123456789final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); // ... } // ...} 在init()中，主要是给新创建的NioServerSocketChannel设置参数，然后在它的pipeline上面添加一个ChannelHandler，用来处理新建立的连接，也就是ServerBootstrapAcceptor。 12345678910111213141516171819202122232425262728@Overridevoid init(Channel channel) { // ... ChannelPipeline p = channel.pipeline(); // ... // 此处的执行p.addLast时，因为channel还未注册到eventloop上， // 所以会将这个ChannelInitializer保存到ctx中， // 并将ctx封装成一个PendingHandlerAddedTask，添加到pipeline中， // 等待注册到eventloop后触发 p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} 其中，p.addLast()执行的时候，如果当前channel，即NioServerSocketChannel，没有注册到一个EventLoop，那么将会以PendingHandlerCallback的形式，保存到pipeline的pengdingHandlerCallbackHead这个链表上。 其中PendingHandlerCallback可以简单理解成：只是一个保存有AbstractChannelHandlerContext的Runnable，并且具有单向链表结构。它的设计目的，就是等待某个时候被执行。 注册channel到eventloop从ChannelFuture regFuture = config().group().register(channel);开始，一路可以追踪到AbstractChannel的register方法里面。刚开始有一段状态判断的代码，这段代码可以印证前面的一个说法：一个channel只能注册到一个eventloop。 接着在eventLoop的线程中执行register0()方法，也就是说main线程开始返回。 1234567891011121314// 紧接上面的代码if (eventLoop.inEventLoop()) { register0(promise);} else { try { eventLoop.execute(new Runnable() { @Override public void run() { register0(promise); } }); } // ...} 也就是说，initAndRegister()返回之后会拿到一个ChannelFuture， 1234567891011final ChannelFuture initAndRegister() { Channel channel = null; try { channel = channelFactory.newChannel(); init(channel); } // ... ChannelFuture regFuture = config().group().register(channel); // ... return regFuture;} 如果在eventLoop中执行register0()完毕，那么将继续执行doBind0()，在main线程中；如果没执行完毕，会等register0()在eventLoop中执行完毕之后，再执行doBind0()，此时的线程是eventLoop。 1234567891011121314151617181920private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); // ... if (regFuture.isDone()) { ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; } else { final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { //... doBind0(regFuture, channel, localAddress, promise); } }); return promise; }} 至此，EchoServer中ChannelFuture f = b.bind(PORT).sync()中的b.bind(PORT)在main线程中的操作已经完成。所以当前步骤又分成了两个，即：1. register0；2. doBind0。 1. register0此函数关键操作的流程如下： 123456789101112131415161718192021222324252627282930313233343536373839// AbstractChannel.javaprivate void register0(ChannelPromise promise) { try { // ... // 一个由子类继承的方法，这里是AbstractNioChannel的实现，即： // selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); doRegister(); neverRegistered = false; // channel变成已注册到EventLoop，若该channel再注册到其他EventLoop会失败。 registered = true; // 执行之前未绑定EventLoop时，添加的PendingHandlerCallback // 详细可以参考下面的执行PendingHandlerCallback的流程 pipeline.invokeHandlerAddedIfNeeded(); // 此方法在设置了promise的执行状态后，再通过观察者模式， // 通知所有的ChannelFutureListener，也就是会接着执行doBind0()。 safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) { if (firstRegistration) { pipeline.fireChannelActive(); } else if (config().isAutoRead()) { // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); } } } catch (Throwable t) { // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); }} 执行PendingHandlerCallback的流程123456789101112131415161718192021222324252627282930313233// DefaultChannelPipeline.javafinal void invokeHandlerAddedIfNeeded() { assert channel.eventLoop().inEventLoop(); if (firstRegistration) { firstRegistration = false; // 已将Channel注册到EventLoop，现在开始执行handlerAdded这个回调。 callHandlerAddedForAllHandlers(); }}// DefaultChannelPipeline.javaprivate void callHandlerAddedForAllHandlers() { final PendingHandlerCallback pendingHandlerCallbackHead; synchronized (this) { assert !registered; // 设置已注册的标志位 registered = true; // 获取之前的pendingHandlerCallbackHead， 并将其置null pendingHandlerCallbackHead = this.pendingHandlerCallbackHead; // 方便GC this.pendingHandlerCallbackHead = null; } // This must happen outside of the synchronized(...) block as otherwise handlerAdded(...) may be called while // holding the lock and so produce a deadlock if handlerAdded(...) will try to add another handler from outside // the EventLoop. PendingHandlerCallback task = pendingHandlerCallbackHead; // 依次遍历执行所有的pendingHandlerCallback while (task != null) { task.execute(); task = task.next; }} PendingHandlerAddedTask的结构在前面已有描述，这里补充一下它的代码实现。其实task.execute();最终执行的代码是callHandlerAdded0(ctx)。 123456789101112131415161718192021222324252627282930313233343536// DefaultChannelPipeline.javaprivate abstract static class PendingHandlerCallback implements Runnable { // 保存ctx final AbstractChannelHandlerContext ctx; // 单向链表 PendingHandlerCallback next; PendingHandlerCallback(AbstractChannelHandlerContext ctx) { this.ctx = ctx; } abstract void execute();}private final class PendingHandlerAddedTask extends PendingHandlerCallback { // ... @Override public void run() { callHandlerAdded0(ctx); } @Override void execute() { EventExecutor executor = ctx.executor(); // 此时执行的线程是eventLoop if (executor.inEventLoop()) { callHandlerAdded0(ctx); } else { try { executor.execute(this); } catch (RejectedExecutionException e) { // ... atomicRemoveFromHandlerList(ctx); ctx.setRemoved(); } } }} 执行完ChanneInitializer之后，将其从pipeline中移除。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// DefaultChannelPipeline.javaprivate void callHandlerAdded0(final AbstractChannelHandlerContext ctx) { try { ctx.callHandlerAdded(); } catch (Throwable t) { boolean removed = false; try { atomicRemoveFromHandlerList(ctx); ctx.callHandlerRemoved(); removed = true; } // ... }}// AbstractChannelHandlerContext.javafinal void callHandlerAdded() throws Exception { // We must call setAddComplete before calling handlerAdded. Otherwise if the handlerAdded method generates // any pipeline events ctx.handler() will miss them because the state will not allow it. // 上述注释存疑，可待后续分析 if (setAddComplete()) { // handler在此处即ChannelInitialzer handler().handlerAdded(this); }}// ChannelInitialzer.java@Overridepublic void handlerAdded(ChannelHandlerContext ctx) throws Exception { if (ctx.channel().isRegistered()) { // This should always be true with our current DefaultChannelPipeline implementation. // The good thing about calling initChannel(...) in handlerAdded(...) is that there will be no ordering // surprises if a ChannelInitializer will add another ChannelInitializer. This is as all handlers // will be added in the expected order. if (initChannel(ctx)) { // We are done with init the Channel, removing the initializer now. removeState(ctx); } }}private boolean initChannel(ChannelHandlerContext ctx) throws Exception { if (initMap.add(ctx)) { // Guard against re-entrance. try { // 调用initChannel() initChannel((C) ctx.channel()); } catch (Throwable cause) { // ... } finally { ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) { // 移除ChannelInitializer pipeline.remove(this); } } return true; } return false;}protected abstract void initChannel(C ch) throws Exception; 再来看一眼当时的initChannel是如何实现的。 12345678910111213141516171819// ServerBootStrap.javap.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) { pipeline.addLast(handler); } ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); }}); 此时的pipeline.addLast(new ServerBootstrapAcceptor...)中的ServerBootstrapAcceptor，是不是也会像ChannleInitializer一样被删除呢？ 从直觉上来说，是不会的，因为如果删掉了谁来处理新建立的连接，那么它为什么没有被删掉呢？因为ServerBootstrapAcceptor并没有重写handlerAdded()这个方法，使用的父类默认实现，即啥都不干。它与ChannelInitializer同是继承自ChannelInboundHandlerAdapter，但是ChannelInitializer重写了handlerAdded()， 并在这个函数中，在初始化之后，将自身从pipeline上移除掉了。因为它只需要执行一次就即可。 safeSetSuccess(promise)使用了观察者模式，将执行之前注册到ChannelFuture上面的ChannelFutureListener，也就是会接着执行doBind0()。这部分代码逻辑比较明了，看关键的代码片段即可： 经典的观察者模式，套路满满。 12345678910111213141516// 多个Listener的时候，循环里面调用notifyListener0()方法private void notifyListeners0(DefaultFutureListeners listeners) { GenericFutureListener&lt;?&gt;[] a = listeners.listeners(); int size = listeners.size(); for (int i = 0; i &lt; size; i ++) { notifyListener0(this, a[i]); }}// 单个Listener的时候执行private static void notifyListener0(Future future, GenericFutureListener l) { try { l.operationComplete(future); } catch (Throwable t) { //... }} 执行此ChannelFutureListener，也就是进入doBind0()阶段，这个操作内容不多，只是将bind的具体操作放到了Runnable中，然后扔到eventLoop的taskQueue中，等待下次eventLoop执行该task。 1234567891011121314151617181920212223242526272829303132// AbstractBootstrap.javaregFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // ... } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } }});private static void doBind0(...) { // This method is invoked before channelRegistered() is triggered. // Give user handlers a chance to set up the pipeline // in its channelRegistered() implementation. channel.eventLoop().execute(new Runnable() { @Override public void run() { if (regFuture.isSuccess()) { channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } });} fireChannelRegistered关于消息的传递，可以放到后续的连接建立后的消息发送模块。这里先提出我的几个问题： 事件如何在pipeline中传递？ 什么是executionMask？这个实现看起来很有趣，通过executionMask与对应的事件编码相与，得出此Handler是否可以处理此消息。详细可后续进一步分析。 至此register0的操作完成。 2. doBind0框架代码的流程：从pipeline的tail出发，触发bind事件。 12345678910111213// AbstractBootstrap.javachannel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE);// AbstractChannel.java@Overridepublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return pipeline.bind(localAddress, promise);}// DefaultChannelPipeline.javapublic final ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) { return tail.bind(localAddress, promise);} 此处的tail是LoggingHandler，也就是说会打印出bind日志： 12345678910111213141516171819202122232425262728293031323334353637383940414243// AbstractChannelHandlerContext.java@Overridepublic ChannelFuture bind(final SocketAddress localAddress, final ChannelPromise promise) { // ... // 从tail,即DefaultChannelPipeline#TailContext开始，往前传递bind事件。 final AbstractChannelHandlerContext next = findContextOutbound(MASK_BIND); // tail的前驱是LoggingHandler EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeBind(localAddress, promise); } else { safeExecute(executor, new Runnable() { @Override public void run() { next.invokeBind(localAddress, promise); } }, promise, null, false); } return promise;}private void invokeBind(SocketAddress localAddress, ChannelPromise promise) { if (invokeHandler()) { try { // 执行LogginHandler的bind方法。 ((ChannelOutboundHandler) handler()).bind(this, localAddress, promise); } catch (Throwable t) { notifyOutboundHandlerException(t, promise); } } else { bind(localAddress, promise); }}// LogginHandler.java@Overridepublic void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception { if (logger.isEnabled(internalLevel)) { logger.log(internalLevel, format(ctx, &quot;BIND&quot;, localAddress)); } // 继续触发bind事件，必须传递，否则会出问题。 ctx.bind(localAddress, promise);} 从这里开始，又回到这个代码串的bind()方法处，直到执行invokeBind()时，才跳转到LoggingHandler的前驱，一个DefaultChannelPipeline#HeadContext，它才是bind操作的主要流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243// DefaultChannelPipeline#HeadContext@Overridepublic void bind(ChannelHandlerContext, SocketAddress, ChannelPromise) { unsafe.bind(localAddress, promise);}// AbstractChannel.javaprotected abstract void doBind(SocketAddress localAddress) throws Exception;@Overridepublic final void bind(final SocketAddress localAddress, final ChannelPromise promise) { // ... boolean wasActive = isActive(); try { // 实际bind操作，调用jdk的api doBind(localAddress); } catch (Throwable t) { safeSetFailure(promise, t); closeIfClosed(); return; } if (!wasActive &amp;&amp; isActive()) { // 只是将此Runnable添加到taskQueue中，等待下次触发执行 invokeLater(new Runnable() { @Override public void run() { pipeline.fireChannelActive(); } }); } // safeSetSuccess(promise);}// NioServerSocketChannel.java@Overrideprotected void doBind(SocketAddress localAddress) throws Exception { if (PlatformDependent.javaVersion() &gt;= 7) { javaChannel().bind(localAddress, config.getBacklog()); } else { javaChannel().socket().bind(localAddress, config.getBacklog()); }} 调用栈： 至此bind操作完成。 3. fireChannelActive与fireChannelRegistered的调用类似，也是从pipeline的head开始触发，只是事件的名称换了，并且多了一个设置OP_ACCEPT的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117// DefaultChannelPipeline.javafinal class HeadContext extends AbstractChannelHandlerContextimplements ChannelOutboundHandler, ChannelInboundHandler { @Override public void channelActive(ChannelHandlerContext ctx) { // 传递给pipeline中head后面的handler ctx.fireChannelActive(); // 设置OP_ACCEPT事件 readIfIsAutoRead(); } //...}private void readIfIsAutoRead() { if (channel.config().isAutoRead()) { channel.read(); }}// AbstractChannel.java@Overridepublic Channel read() { pipeline.read(); return this;}// DefaultChannelPipeline.java@Overridepublic final ChannelPipeline read() { // tail即TailContext tail.read(); return this;}// AbstractChannelHandlerContext.java@Overridepublic ChannelHandlerContext read() { // next此时为HeadContext也就是head final AbstractChannelHandlerContext next = findContextOutbound(MASK_READ); EventExecutor executor = next.executor(); if (executor.inEventLoop()) { // 执行线程为eventloop next.invokeRead(); } else { // ... } return this;}private void invokeRead() { if (invokeHandler()) { try { ((ChannelOutboundHandler) handler()).read(this); } catch (Throwable t) { notifyHandlerException(t); } } else { read(); }}// DefaultChannelPipeline.java$HeadContext@Overridepublic void read(ChannelHandlerContext ctx) { unsafe.beginRead();}// AbstractChannel.java$AbstractUnsafe@Overridepublic final void beginRead() { assertEventLoop(); if (!isActive()) { return; } try { doBeginRead(); } catch (final Exception e) { invokeLater(new Runnable() { @Override public void run() { pipeline.fireExceptionCaught(e); } }); close(voidPromise()); }}// AbstractNioMessageChannel.java@Overrideprotected void doBeginRead() throws Exception { if (inputShutdown) { return; } super.doBeginRead();}// AbstractNioChannel.java@Overrideprotected void doBeginRead() throws Exception { // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) { return; } readPending = true; final int interestOps = selectionKey.interestOps(); // 将channel注册到selector上时，interestOps设置为0 // readInterestOp为16，所以此时interestOps &amp; readInterestOp肯定会为0 if ((interestOps &amp; readInterestOp) == 0) { // 设置成监听OP_ACCEPT事件,为1 &lt;&lt; 4，即16 selectionKey.interestOps(interestOps | readInterestOp); }} 调用栈为： 通过eventLoop来执行task的方式，其实是通过一个taskQueue来接收这些Runnable，然后eventLoop再通过统一调度，获取taskQueue里面的task，然后依次执行它们。所以这里还有最后一个问题：eventLoop是怎么启动起来的以及如何进行调度？ EventLoop的启动与调度时机：第一次在main线程中，调用EventLoop执行task的时候，会进行初始化。最早出现在initAndRegister()这个方法中，这个方法进行register()的时候，会将register0放到一个Runnable中，扔给eventLoop去执行，即： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// AbstractChannel.javaeventLoop.execute(new Runnable() { @Override public void run() { register0(promise); }});// SingleThreadEventExecutor.javaprivate void execute(Runnable task, boolean immediate) { boolean inEventLoop = inEventLoop(); addTask(task); if (!inEventLoop) { startThread(); if (isShutdown()) { boolean reject = false; try { if (removeTask(task)) { reject = true; } } catch (UnsupportedOperationException e) { // ... } if (reject) { reject(); } } } if (!addTaskWakesUp &amp;&amp; immediate) { wakeup(inEventLoop); }}private void startThread() { if (state == ST_NOT_STARTED) { if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) { boolean success = false; try { doStartThread(); success = true; } finally { if (!success) { STATE_UPDATER.compareAndSet(this, ST_STARTED, ST_NOT_STARTED); } } } }}protected abstract void run();private void doStartThread() { assert thread == null; executor.execute(new Runnable() { @Override public void run() { // 此时的线程为EventLoop thread = Thread.currentThread(); if (interrupted) { thread.interrupt(); } boolean success = false; updateLastExecutionTime(); try { // 对EchoServer这个例子来说this为NioEventLoop SingleThreadEventExecutor.this.run(); success = true; } // ... } });} 下面的代码是对整个事件处理的核心： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// NioEventLoop.java@Overrideprotected void run() { int selectCnt = 0; for (;;) { try { int strategy; try { strategy = selectStrategy.calculateStrategy(selectNowSupplier, hasTasks()); switch (strategy) { case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: // fall-through to SELECT since the busy-wait is not supported with NIO case SelectStrategy.SELECT: long curDeadlineNanos = nextScheduledTaskDeadlineNanos(); if (curDeadlineNanos == -1L) { curDeadlineNanos = NONE; // nothing on the calendar } nextWakeupNanos.set(curDeadlineNanos); try { if (!hasTasks()) { strategy = select(curDeadlineNanos); } } finally { // This update is just to help block unnecessary selector wakeups // so use of lazySet is ok (no race condition) nextWakeupNanos.lazySet(AWAKE); } // fall through default: } } catch (IOException e) { // If we receive an IOException here its because the Selector is messed up. Let's rebuild // the selector and retry. https://github.com/netty/netty/issues/8566 rebuildSelector0(); selectCnt = 0; handleLoopException(e); continue; } selectCnt++; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; boolean ranTasks; if (ioRatio == 100) { try { if (strategy &gt; 0) { processSelectedKeys(); } } finally { // Ensure we always run tasks. ranTasks = runAllTasks(); } } else if (strategy &gt; 0) { final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; ranTasks = runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } else { ranTasks = runAllTasks(0); // This will run the minimum number of tasks } if (ranTasks || strategy &gt; 0) { if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS &amp;&amp; logger.isDebugEnabled()) { logger.debug(&quot;Selector.select() returned prematurely {} times in a row for Selector {}.&quot;, selectCnt - 1, selector); } selectCnt = 0; } else if (unexpectedSelectorWakeup(selectCnt)) { // Unexpected wakeup (unusual case) selectCnt = 0; } } catch (CancelledKeyException e) { // Harmless exception - log anyway if (logger.isDebugEnabled()) { logger.debug(CancelledKeyException.class.getSimpleName() + &quot; raised by a Selector {} - JDK bug?&quot;, selector, e); } } catch (Throwable t) { handleLoopException(t); } // Always handle shutdown even if the loop processing threw an exception. try { if (isShuttingDown()) { closeAll(); if (confirmShutdown()) { return; } } } catch (Throwable t) { handleLoopException(t); } }}","link":"/2020/02/28/001684b38465.html"},{"title":"APUE系列·Mac下环境配置","text":"心中的执念太多、乘着年轻，我想去一一实现。也许不为目的，就是为了实现当初给自己吹的牛逼。优秀的人那么多，为什么我不是其中一个？付出完全匹配不上野心，可否知道该如何去做？自律是一件可怕的事，因为那意味着战胜了自己的惰性。看见一个榜样、我觉得你将是我追逐的目标。—–开篇 前言开始学习《UNIX环境高级编程》。按照之前对这本书的理解，这本书是一个介绍UNIX内核API的书，在介绍UNIX API的同时，还会讲解与之相关的知识。这本书是一本算得上比较底层的书。之前学习过，但是止步于第四章，原因已经忘记了。不过之前是在Ubuntu下，现在是在Mac下，可能这也是我执着于Mac的一个原因，因为Mac的内核是UNIX系的，可以用来运行APUE中的代码。想想这真的算是一种执念，所以不能没有下文。 配置运行环境网址：http://www.apuebook.com/apue3e.html 或者直接下载：http://www.apuebook.com/src.3e.tar.gz下载好了之后，解压，进入解压后的目录，并将error.c和apue.h拷贝到系统的相应路径，如下： 12cp include/apue.h /usr/local/includecp lib/error.c /usr/local/include/ 然后将拷贝过去的apue.h中的最后一个#endif前，将error.c使用#include进去，如下： 测试编译并运行，结果如下：或者直接在命令行中通过gcc命令来编译源代码，不报错基本上就是没问题，再运行试试即可。","link":"/2018/11/27/974463c43f12.html"},{"title":"AWS使用过程中遇到的问题","text":"RDS连接不上数据库的排除办法检查RDS的安全组。初次尝试，数据库连不上；后面又重试着不使用默认的安全组进行配置，可以连上。这里有一个检测是否可以成功连接的命令，如果连不上，可以试试这样能不能检测到连接。https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/CHAP_Troubleshooting.html EC2安装的数据库无法连接 确保3306端口已经打开。 确保已经在MySQL的配置文件中，改成允许远程访问。系统相关信息如下：MySQL版本后面因为删掉了，版本信息找不到了。这个配置文件的路径就当一个参考吧，到时候可能还需要自己找一找这个配置文件的路径。配置文件路径：/etc/mysql/mysql.conf.d/mysqld.cnf 如果root密码已经忘记，那么可以考虑使用mysqladmin等一系列操作重设MySQL的root密码","link":"/2018/12/03/50d42c21ba78.html"},{"title":"Android8.1原生系统网络感叹号消除","text":"原生系统Android8.1上，WiFi上出现感叹号，此时WiFi可正常访问。 原因这是Android 5.0引入的网络评估机制：就是当你连上网络后，会给目标产生204响应的服务器发送给一个请求，如果服务器返回的是状态码为204的响应，那么就被认为网络可以访问；否则，如返回的是其他状态码，那么将被视为网络访问需要登录操作等；没有响应的话，就被认为是网络不可访问。这里的情况就是，目标服务器不能正常访问 产生204响应的服务器加粗网址亲测可行，其余未测试，但可作为一个参考 http://connect.rom.miui.com/generate_204 http://www.v2ex.com/generate_204 https://captive.v2ex.co/generate_204 http://www.noisyfox.cn/generate_204 http://www.google.cn/ 修改&amp;恢复默认测试系统：Android 8.1。默认使用https来验证，如要使用http，需要先写入关闭https验证的配置，再填写http服务器。然后开启飞行模式，再打开感叹号即可消失。其中，xxxxx即服务器的URL。 12345678910# 查看所有配置adb shell settings list global# 使用httpsadb shell settings put global captive_portal_https_url xxxxx# 使用httpadb shell settings put global captive_portal_use_https 0adb shell settings put global captive_portal_http_url xxxxx# 使用默认，即删除配置adb shell settings delete global captive_portal_http_urladb shell settings delete global captive_portal_https_url 禁用此功能按照上述方法，设置captive_portal_mode的值如下： 0：彻底禁用检测 1：检测到需要登录则弹窗提醒（默认值） 2：检测到需要登录则自动断开此热点并不再自动连接 Android8.0相关源码代码：源代码链接，无需梯子可直达。 参考https://www.noisyfox.io/android-captive-portal.htmlhttp://www.pixcn.cn/article-2990-1.htmlhttp://blog.sina.com.cn/s/blog_5fdac4c90102wv27.html","link":"/2018/06/20/3f2e57fe4b1a.html"},{"title":"Android中的apk打包","text":"前言使用友盟对应用进行信息收集时，其中包含有一个渠道名。渠道姑且可以认为是一个商店吧，如果应用要在很多个商店上面上架的话，一直改太麻烦了。有一个叫做多渠道打包的东西自然而然地走了过来。 多渠道打包实现123456&lt;meta-data android:name=&quot;UMENG_APPKEY&quot; android:value=&quot;xxxxxxxxxxxxxxxxxxxxxx&quot; /&gt;&lt;meta-data android:name=&quot;UMENG_CHANNEL&quot; android:value=&quot;Google Play Store&quot; /&gt; 如上所示，如果需要换一个渠道的话，重新改的话就特别麻烦了。先将其中的value替换成占位符${UMENG_CHANNEL_VALUE}。接下来到模块下的build.gradle中进行相应的修改。修改大致如下： 123&lt;meta-data android:name=&quot;UMENG_CHANNEL&quot; android:value=&quot;${UMENG_CHANNEL_NAME}&quot; /&gt; 接下来配置build.gradle 1234567891011121314151617181920defaultConfig { ... // 默认是umeng的渠道 manifestPlaceholders = [UMENG_CHANNEL_VALUE: &quot;umeng&quot;]}// 友盟多渠道打包flavorDimensions &quot;wtf&quot;productFlavors{ google { dimension &quot;wtf&quot; } coolapk { dimension &quot;wtf&quot; }}productFlavors.all { flavor -&gt; flavor.manifestPlaceholders = [UMENG_CHANNEL_VALUE: name]} 自动设置应用签名在buildType{}前添加下段，并在buildType的release中添加signingConfig signingConfigs.release 123456789101112signingConfigs { debug { // No debug config } release { storeFile file(&quot;../yourapp.keystore&quot;) storePassword &quot;your password&quot; keyAlias &quot;your alias&quot; keyPassword &quot;your password&quot; }} 打release版本的包时就会使用其中所配置的签名了。 修改AS生成的apk默认名不同gradle版本间存在一些差异，如果报错了，google修改一下。 1234567891011121314applicationVariants.all { variant -&gt; variant.outputs.all { output -&gt;// outputFileName = new File(// &quot;JPreader-&quot; + ${variant.productFlavors[0].name} +// buildType.name + &quot;-v&quot; +// defaultConfig.versionName + &quot;-&quot; +// defaultConfig.versionCode + &quot;.apk&quot; ) if (outputFile != null &amp;&amp; outputFile.name.endsWith('.apk')) { // 输出apk名称为ruijie_v1.0_wandoujia.apk def fileName = &quot;JPreader_v${defaultConfig.versionName}_${variant.productFlavors[0].name}.apk&quot; outputFileName = new File(fileName) } }} 小结build.gradle真的是神奇，有一些用法还是可以去学学。当前的build.gradle文件的整体如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576android { compileSdkVersion 26 buildToolsVersion '26.0.2' defaultConfig { applicationId &quot;cn.xuchuanjun.nhknews&quot; minSdkVersion 19 targetSdkVersion 26 versionCode 2 versionName &quot;1.1&quot; testInstrumentationRunner &quot;android.support.test.runner.AndroidJUnitRunner&quot;// jackOptions {// enabled true// } //multiDexEnable true //突破应用方法数65535的一个限制 manifestPlaceholders=[UMENG_CHANNEL_NAME:&quot;Google Play Store&quot;] } signingConfigs { debug { } myReleaseConfig { storeFile file(&quot;xxxxxxxxxxxxxxxxx.jks&quot;) storePassword &quot;xxxxxxxx&quot; keyAlias &quot;xxxxxx&quot; keyPassword &quot;xxxxxxxx&quot; } } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' signingConfig signingConfigs.myReleaseConfig applicationVariants.all { variant -&gt; variant.outputs.all { output -&gt;// outputFileName = new File(// &quot;JPreader-&quot; + ${variant.productFlavors[0].name} +// buildType.name + &quot;-v&quot; +// defaultConfig.versionName + &quot;-&quot; +// defaultConfig.versionCode + &quot;.apk&quot; ) if (outputFile != null &amp;&amp; outputFile.name.endsWith('.apk')) { // 输出apk名称为ruijie_v1.0_wandoujia.apk def fileName = &quot;JPreader_v${defaultConfig.versionName}_${variant.productFlavors[0].name}.apk&quot; outputFileName = new File(fileName) } } } } } flavorDimensions &quot;wtf&quot; productFlavors{ google { dimension &quot;wtf&quot; } coolapk { dimension &quot;wtf&quot; } } productFlavors.all{ flavor -&gt; flavor.manifestPlaceholders = [UMENG_CHANNEL_NAME:name] } compileOptions { targetCompatibility 1.8 sourceCompatibility 1.8 } repositories { flatDir { dirs 'libs' } }}","link":"/2017/12/26/f63384973df3.html"},{"title":"Android中的looper与handler","text":"前言为什么会有这么一篇网上有很多种解说版本的博客？因为我看懂了很多次，都没有把自己的想法记下来，然后就忘了。那样不仅浪费时间、而且还有点伤积极性。 从一个异常出发开始在《第一行代码》中看到了关于异步处理消息的用法时，有没有想过可以在子线程中去new一个Handler？现在就开始着手，从一个子线程中去new一个Handler，看看会有什么发生。 123456new Thread(new Runnable() { @Override public void run() { new Handler(); }}).start(); 结果就出现了RuntimeException异常，仔细看它的信息说明。 java.lang.RuntimeException: Can't create handler inside thread that has not called Looper.prepare() 那么可知，在每个线程new Handler()时，都必须先调用Looper.prepare()或者调用一个能够达到相同效果的函数。那么在主线程中可以new Handler()的原因，想必就是已经调用过了。以下代码位于AcitivityThread.java中，是一段初始化主线程的内容。 1234567891011121314151617Looper.prepareMainLooper();ActivityThread thread = new ActivityThread();thread.attach(false);if (sMainThreadHandler == null) { sMainThreadHandler = thread.getHandler();}if (false) { Looper.myLooper().setMessageLogging( new LogPrinter(Log.DEBUG, &quot;ActivityThread&quot;));}// End of event ActivityThreadMain.Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER);Looper.loop(); 其它的都忽略，就看Looper相关的。Looper.prepareMainLooper()想必是达到了相同的效果吧。那么，这个效果到底是什么呢？让我们慢慢拨开云雾。 寻找那个异常于是，我们很自然地在子线程中加入了Looper.prepare()，并随手按着Ctrl，左键点击鼠标，进入了prepare()函数中。 123456789101112131415161718/*Initialize the current thread as a looper. This gives you a chance to create handlers that then reference this looper, before actually starting the loop. Be sure to call {@link #loop()} after calling this method, and end it by calling{@link #quit()}.*/public static void prepare() { prepare(true);}private static void prepare(boolean quitAllowed) { if (sThreadLocal.get() != null) { throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;); } sThreadLocal.set(new Looper(quitAllowed));}...private Looper(boolean quitAllowed) { mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread();} 当初的那个异常不就在眼前？但是，这sThreadLocal又是什么？它是什么暂时抛开，这时我们知道了我们的线程中已经有了一个Looper，并且为这个Looper设置好了一个MessageQueue。因为一个线程只能有一个Looper，所以一个Looper也就只能拥有一个MessageQueue。但是AcitivityThread中，经过Looper.loop()后就再也没有下文了？所以，这个loop()又是干啥的呢？ 繁忙的loop()1234567891011121314151617181920212223242526272829303132333435/** Return the Looper object associated with the current thread. Returns null if the calling thread is not associated with a Looper.*/public static @Nullable Looper myLooper() { return sThreadLocal.get();}/*** Run the message queue in this thread. Be sure to call* {@link #quit()} to end the loop.*/public static void loop() { final Looper me = myLooper(); if (me == null) { throw new RuntimeException(&quot;No Looper; Looper.prepare() wasn't called on this thread.&quot;); } final MessageQueue queue = me.mQueue; ... for (;;) { Message msg = queue.next(); // might block if (msg == null) { // No message indicates that the message queue is quitting. return; } ... try { msg.target.dispatchMessage(msg); end = (slowDispatchThresholdMs == 0) ? 0 : SystemClock.uptimeMillis(); } finally { if (traceTag != 0) { Trace.traceEnd(traceTag); } } ... msg.recycleUnchecked(); }} 因为其中一个大大的死循环，所以调用了loop()之后，其后就没有实际代码了。这个死循环就是用来处理Message，不断地从队列中取，然后不断地进行分发到相应的Handler，进行处理。此时，这个for(;;)所处的线程，就是你调用Looper.loop()时所在的线程。因此，它分发msg给了相应的Handler的handleMessage之后，还是在此线程中执行。然后，在想想，发送Message时所处在的线程，就焕然大悟这个异步操作了。 123456789101112131415/*** Handle system messages here.*/public void dispatchMessage(Message msg) { if (msg.callback != null) { handleCallback(msg); } else { if (mCallback != null) { if (mCallback.handleMessage(msg)) { return; } } handleMessage(msg); }} handleMessage(msg)不正是我们创建Handler时候，所覆盖的方法吗？ 进一步思考，如果我只在主线程中new Handler，那么Looper就是主线程，所有的msg都会在主线程中被处理；那如果我想让msg在子线程中被处理呢？当然可以Looper.prepare()巴拉巴拉，然后Looper.loop()。但是Android还为我们提供了一个更为便捷的封装。那就是HandlerThread。 子线程处理msg的封装HandlerThread12345678910111213@Overridepublic void run() { mTid = Process.myTid(); Looper.prepare(); synchronized (this) { mLooper = Looper.myLooper(); notifyAll(); } Process.setThreadPriority(mPriority); onLooperPrepared(); Looper.loop(); mTid = -1;} 源代码比较短。它继承自Thread，并在run方法中初始化好了Looper，可以通过其getThreadHandler()方法，获取到与该Looper所绑定的Handler，然后sendMessage()，最后在该线程中处理msg。 小结因此，一个Thread可以有一个Looper和一个MessageQueue，一个Looper却可以与多个Handler绑定，但是一个Handler只能与一个Looper绑定。原因可以从Handler的构造方法中寻找的。","link":"/2017/12/18/3fa176e87f9d.html"},{"title":"Android中的签名","text":"签名，顾名思义与生活中的签名类似，为某个东西签了名，那么这个东西就与所签的名字产生了某种关系，如归属等。 为什么要为Android应用签名？这是因为Android系统的要求就是这样，Android系统要求每一个Android应用程序必须要经过数字签名才能够安装到系统中，也就是说如果一个Android应用程序没有经过数字签名，就无法安装到系统中。 为什么在AS中直接RUN可以安装到系统上？因为这种方式会使用Android Studio默认生成的debug签名，去给应用进行签名。 签名不同会怎样如果同一应用使用不同的签名，那么将不能覆盖安装，必须先卸载之前的，然后再安装。 1）两个程序的入口Activity是否相同。两个程序如果包名不一样，即使其它所有代码完全一样，也不会被视为同一个程序的不同版本； 2）两个程序所采用的签名是否相同。如果两个程序所采用的签名不同，即使包名相同，也不会被视为同一个程序的不同版本，不能覆盖安装。 所以这也是为什么，同样一份代码，由不同的机器RUN，然后安装到同一台设备上时，需要先卸载之前的应用，而后再安装此次的。 原因就是每台机器默认生成的debug签名都不一样！ 结论应用商城不接受用debug签名签的应用，必须使用自己的签名。 使用自己的签名可以避免应用不具备升级功能。","link":"/2017/12/20/fb56c6aa1402.html"},{"title":"Android中遇到的问题","text":"遇到了挺多的问题，但是每个问题都写篇文章感觉有点不实在，所以还是选择将这些小知识点都汇集到这一篇文章，方便自己再次查看吧。好多问题解决了之后没有及时记录下来，现在忘得差不多了。 替换Fragment的问题 这个问题遇到过好几次了,但是还是没有很快地解决它.不过最终还是解决了~所以还是记下来踩过的坑吧 现象代码如下. 在我们看来这可能是再平常不过的代码了,但是它就是报错了,而且就是在replace这个函数这里. 它需要的就是一个Fragment呀,我的fragment也是一个继承了Fragment类, 为什么就不能完成类型匹配呢? 所以很是纠结 123getFragmentManager().beginTransaction() .replace(R.id.container, fragment) .commit(); 但是,我心里清楚,我的fragment是继承自android.support.v4.app.Fragment, 而且我还记得之前使用过一个叫做getSupportFragmentManager()的方法, 但是为什么在这个Activity里面就是调用不出来! 气愤啊, 但是想到了一个叫做AppCompatActivity的适用性高的类, 因此只能想到是不是只有support类型的Activity才有getSupportFragmentManager(). 让宿主Activity继承AppCompatActivity, 最后调用出了getSupportFragmentManager(), 解决了这个莫名其妙的问题! 总结 FragmentManager也有两种, 一个是android.support.v4.app包下的,一个是android.app包下的. 继承自Activity的活动里面,只能获取到android.app.FragmentManager; 继承自AppCompatActivity才可以获得android.support.v4.app.FragmentManager 不同包下面的FragmentManager只能替换继承自同一个包下面的Fragment. 两个不同包下面的具体类如下所示 Calendar中获取到的月份比实际月份少1不算是bug吧。就像数组一样，月份也从0开始算。 123456789101112131415161718192021/** * Field number for &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;set&lt;/code&gt; indicating the * month. This is a calendar-specific value. The first month of * the year in the Gregorian and Julian calendars is * &lt;code&gt;JANUARY&lt;/code&gt; which is 0; the last depends on the number * of months in a year. * * @see #JANUARY * @see #FEBRUARY * @see #MARCH * @see #APRIL * @see #MAY * @see #JUNE * @see #JULY * @see #AUGUST * @see #SEPTEMBER * @see #OCTOBER * @see #NOVEMBER * @see #DECEMBER * @see #UNDECIMBER */ SQLite中有两张表时出现SQLiteLog: (1) no such table其实这个问题的出现，是对SQLiteOpenHelper没有了解清楚的一种表现。这段回答确实是醍醐灌顶。 SQLiteOpenHelper onCreate() and onUpgrade() callbacks are invoked when the database is actually opened, for example by a call to getWritableDatabase(). The database is not opened when the database helper object itself is created. SQLiteOpenHelper versions the database files. The version number is the int argument passed to the constructor. In the database file, the version number is stored in PRAGMA user_version. onCreate() is only run when the database file did not exist and was just created. If onCreate()returns successfully (doesn’t throw an exception), the database is assumed to be created with the requested version number. As an implication, you should not catch SQLExceptions in onCreate()yourself. onUpgrade() is only called when the database file exists but the stored version number is lower than requested in constructor. The onUpgrade() should update the table schema to the requested version. When changing the table schema in code (onCreate()), you should make sure the database is updated. Two main approaches: Delete the old database file so that onCreate() is run again. This is often preferred at development time where you have control over the installed versions and data loss is not an issue. Some ways to to delete the database file: Uninstall the application. Use the application manager or adb uninstall your.package.name from shell. Clear application data. Use the application manager. Increment the database version so that onUpgrade() is invoked. This is slightly more complicated as more code is needed. For development time schema upgrades where data loss is not an issue, you can just use execSQL(&quot;DROP TABLE IF EXISTS &lt;tablename&gt;&quot;) in to remove your existing tables and call onCreate() to recreate the database. For released versions, you should implement data migration in onUpgrade() so your users don’t lose their data. 出现这样的错误的情景为： 有两张表，开始的时候创建了一个**Helper继承自SQLiteOpenHelper，然后又需要创建一张表的时候，又创建了一个类继承自SQLiteOpenHelper，里面的数据库名相同，版本号相同，只有表名、创建的SQL语句不同。这样做的原因是因为以为每次都会执行onCreate()，然后表就被创建了。这样的想法是错误的，根本就不是这么一回事。没有好好看过数据库相关的啊~ 在没看到这个回答之前，有过两次尝试，都解决了问题，但是为什么解决了，我竟然不知道！！ 尝试一：把两个数据库名改成不同的。这样就会在/data/data/**/databases/下面存在两个数据库文件。解决了问题。 尝试二：后来感觉可能与数据库的版本有关系，所以这次不改数据库名，但是将后者的版本号提高，并重载onDowngrade()方法，让它不干任何事情。 最终方案：将两个继承自SQLiteOpenHelper的类全部写到一个类里面，将另外一个删除掉。我觉得这是比较完美的解决方案，也大致明白了这背后的原因。好好地又上了一课。如下所示： WebView显示中文网页乱码很久之前也遇到过这个问题，但是到现在记得的也就是可以通过设置某些参数，然后就可以正常显示中文了。 这次还是直接把这个它的设置方法贴出来吧，让自己不用再找了。 123webView.getSettings().setDefaultTextEncodingName(&quot;UTF -8&quot;);//设置默认为utf-8//webView.loadData(data, &quot;text/html&quot;, &quot;UTF -8&quot;); //API提供的标准用法，无法解决乱码问题webView.loadData(data, &quot;text/html; charset=UTF-8&quot;, null);//这种写法可以正确解码 String.replace()无法替换成功其实这个问题挺奇怪的，但是也算不上一个问题吧。 这个方法并不会改变调用这个方法的String，而是返回一个替换了之后的String 写着写着忘记了这个，结果浪费了好久的时间。 RecyclerView如何创建ContextMenu先上成功创建并获取到了所需信息的链接吧! 网上的说话基本上是ListView的，但是RecyclerView与它又不相同。因此按照网上的说法，基本上通过getMenuInfo()获取到的是空，好伤。如果不是空的话，那么会得到AdapterView.AdapterContextMenuInfo，这个里面包含了一些信息如position，应该是该项在整个RecyclerView中的位置吧。 网上的做法有两种，一种是： 为ViewHolder设置setOnCreateContextMenuListener()，但是这样还是无法直接将所需要的信息传递进来，所以还需要设置setOnMenuItemClickListener()，用来处理点击该项后需要进行的事项，因此，这这里可以直接获取当前RecyclerView中的item并对其进行相关的操作。这个做法来自链接。 123456itemView.setOnCreateContextMenuListener((menu, v, menuInfo) -&gt; { menu.add(&quot;稍后阅读&quot;).setOnMenuItemClickListener(item -&gt; { Logger.e(easyNews.getNewsId()); return false; });}); 可以参考这段代码，没有尝试过，但是mark一下吧！链接，这种做法挺靠谱的感觉。 关键是下面这段代码，其余的可以按照ListView的那样进行操作。 123456789101112131415161718192021222324252627public class RecyclerViewImplementsContextMenu extends RecyclerView { private AdapterView.AdapterContextMenuInfo contextMenuInfo; public RecyclerViewImplementsContextMenu(Context context) { super(context); } public RecyclerViewImplementsContextMenu(Context context, @Nullable AttributeSet attrs) { super(context, attrs); } public RecyclerViewImplementsContextMenu(Context context, @Nullable AttributeSet attrs, int defStyle) { super(context, attrs, defStyle); } @Override public AdapterView.AdapterContextMenuInfo getContextMenuInfo() { return contextMenuInfo; } @Override public boolean showContextMenuForChild(View originalView) { int position = getChildAdapterPosition(originalView); long longId = getChildItemId(originalView); contextMenuInfo = new AdapterView.AdapterContextMenuInfo(originalView, position, longId); return super.showContextMenuForChild(originalView); }} Intent中如何传递一个普通对象在做小应用的时候遇到了这种问题，网上的解答也比较完整。方式一：Serializable 方式使用Intent 来传递对象通常有两种实现方式，Serializable 和Parcelable，我们先来学习一下第一种的实现方式。Serializable 是序列化的意思，表示将一个对象转换成可存储或可传输的状态。序列化后的对象可以在网络上进行传输，也可以存储到本地。至于序列化的方法也很简单，只需要让一个类去实现Serializable 这个接口就可以了。比如说有一个Person 类，其中包含了name 和age 这两个字段，想要将它序列化就可以这样写： 12345678910111213141516public class Person implements Serializable{ private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } 其中get、set 方法都是用于赋值和读取字段数据的，最重要的部分是在第一行。这里让Person 类去实现了Serializable 接口，这样所有的Person 对象就都是可序列化的了。接下来在FirstActivity 中的写法非常简单： 123456Person person = new Person(); person.setName(&quot;Tom&quot;); person.setAge(20); Intent intent = new Intent(FirstActivity.this, SecondActivity.class); intent.putExtra(&quot;person_data&quot;, person); startActivity(intent); 可以看到，这里我们创建了一个Person 的实例，然后就直接将它传入到putExtra()方法中了。由于Person 类实现了Serializable 接口，所以才可以这样写。接下来在SecondActivity 中获取这个对象也很简单，写法如下： 1Person person = (Person) getIntent().getSerializableExtra(&quot;person_data&quot;); 这里调用了getSerializableExtra()方法来获取通过参数传递过来的序列化对象，接着再将它向下转型成Person 对象，这样我们就成功实现了使用Intent 来传递对象的功能了。 方式二：Parcelable除了Serializable 之外，使用Parcelable 也可以实现相同的效果，不过不同于将对象进行序列化，Parcelable 方式的实现原理是将一个完整的对象进行分解，而分解后的每一部分都是Intent 所支持的数据类型，这样也就实现传递对象的功能了。下面我们来看一下Parcelable 的实现方式，修改Person 中的代码，如下所示： 1234567891011121314151617181920212223242526272829303132333435public class Person implements Parcelable { private String name; private int age; @Override public int describeContents() { // TODO Auto-generated method stub return 0; } @Override public void writeToParcel(Parcel dest, int flags) { // TODO Auto-generated method stub dest.writeString(name); dest.writeInt(age); } public static final Parcelable.Creator&lt;Person&gt; CREATOR=new Parcelable.Creator&lt;Person&gt;() { @Override public Person createFromParcel(Parcel source) { // TODO Auto-generated method stub Person person=new Person(); person.name=source.readString(); person.age=source.readInt(); return person; } @Override public Person[] newArray(int size) { // TODO Auto-generated method stub return new Person[size]; } }; } Parcelable 的实现方式要稍微复杂一些。可以看到，首先我们让Person 类去实现了Parcelable 接口，这样就必须重写describeContents()和writeToParcel()这两个方法。其中describeContents()方法直接返回0 就可以了，而writeToParcel()方法中我们需要调用Parcel的writeXxx()方法将Person 类中的字段一一写出。注意字符串型数据就调用writeString()方法，整型数据就调用writeInt()方法，以此类推。除此之外，我们还必须在Person 类中提供一个名为CREATOR 的常量，这里创建了Parcelable.Creator 接口的一个实现，并将泛型指定为Person。接着需要重写createFromParcel()和newArray()这两个方法，在createFromParcel()方法中我们要去读取刚才写出的name 和age字段，并创建一个Person 对象进行返回，其中name 和age 都是调用Parcel 的readXxx()方法读取到的，注意这里读取的顺序一定要和刚才写出的顺序完全相同。而newArray()方法中的实现就简单多了，只需要new 出一个Person 数组，并使用方法中传入的size 作为数组大小就可以了。接下来在FirstActivity 中我们仍然可以使用相同的代码来传递Person 对象，只不过在SecondActivity 中获取对象的时候需要稍加改动，如下所示： 1Person person = (Person) getIntent().getParcelableExtra(&quot;person_data&quot;); 注意这里不再是调用getSerializableExtra()方法，而是调用getParcelableExtra()方法来获取传递过来的对象了，其他的地方都完全相同。这样我们就把使用Intent 来传递对象的两种实现方式都学习完了，对比一下，Serializable的方式较为简单，但由于会把整个对象进行序列化，因此效率方面会比Parcelable 方式低一些，所以在通常情况下还是更加推荐使用Parcelable 的方式来实现Intent 传递对象的功能。 作为一名Android开发人员，时常遇到Android Studio抽风的情况。之前也遇到过，没有记录，之后就忘了，还得去重新去查解决办法，真的是有点痛心疾首。所以在这里特地记录下，在开发过程中，所遇到的一些关于AS的一些问题，让自己进步得更快。 Error type 3 as中更换包名后出现的问题 原因修改了原本的包名. 现象1之后R文件也出现了问题, 这个现场截图已经找不到了, 大致是这样的. 所有代码中应用了R文件的地方都出现了错误,并且将鼠标移到其上,可以通过Alt + Enter导入R文件.但是这个R文件是上一个包名下的R文件, 导入了也没用, 还是该报错的地方报错. 后来, 找到了Manifest.xml文件中的package 属性, 发现它是修改包名之前的包名, 所以改了之后, rebuild了一下, 就解决了 现象2如上图所示. 所有的代码基本上修改好了, 开开心心的点了一下Run,结果给了我一大段红色的error…面对这个确实也比较无奈.我感觉这个应该与应用配置有关系, 也就是与那一堆Gradle Scripts有关系, 但是不知道该修改哪里的哪个参数.不过网上还是有比我先遇到这个问题的人, 解决方案也有了~如下: I had the same error after renaming/refactoring. What I did was add the applicationId property attribute to my build.gradle file, and set its value to the application package. Like this: 12345android{ defaultConfig{ applicationId &quot;com.example.mypackage&quot; }} from Stack Overflow Enable Jack直接上方法吧。引用自：Stackoverflow The details on what is required to use Jack and how can be found in the documentation. Here is the relevant part from the docs that goes in build.gradle on how to use jackOptions and set the compileOptions for java 1.8. android { … defaultConfig { … jackOptions { enabled true } } compileOptions { sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 } }UPDATE The Jack toolchain is now considered deprecated according to this post and work is being done to natively support Java 8 features as part of the Android build system in the coming weeks according to the post. The post also mentions that there should be little to no work migrating from Jack to the new method in case you still wanted to try enabling Java 8 features with Jack. UPDATE 2 Preview Built-in Support You can now try out the new built-in support for Java 8 using the latest Android Studio preview 2.4 preview 6. For more information on how to enable it or migrate from Jack or Retrolambda see the documentation. Gradle版本降级导入TO-DO-MVP这个Google官方给的例子时，需要把Android Studio的Gradle插件版本从3.0.0-alpha4的版本降为 2.3.3。操作时，碰到了一个问题如下： 123Error:(28, 0) Could not find method implementation() for arguments [com.android.support:appcompat-v7:25.3.1] on object of type org.gradle.api.internal.artifacts.dsl.dependencies.DefaultDependencyHandler.Please install the Android Support Repository from the Android SDK Manager.&lt;a href=&quot;openAndroidSdkManager&quot;&gt;Open Android SDK Manager&lt;/a&gt; 其实这两个版本间Gradle的一些关键词有一些不同，改回2.3.3之后，需要将关键词也改回来。有点想吐槽~这都不兼容了！ 基本上是把Iementation改回Compile就好了，注意一些地方的大小写。 Android Studio显示No debuggable process正在开发的程序已经被运行起来了，可是这里却显示没有debuggable process。 修改方法真的是一语道破天机啊~ You also should have Tools-&gt;Android-&gt;Enable ADB Integration active. Android Studio中Error:String index out of range: 0 出现这种错误有点莫名其妙，网上上的解释是values下面的文件有出错的情况，检查了每个文件，都没出现&lt;string name=&quot;&quot;&gt;&lt;/string&gt; 这种类型的情况。很是苦恼，网上的说法也基本上与此种情况类似。在检查到gradle.properties这个配置文件的时候，发现了git无法自动合并而让我们手动解决合并冲突的痕迹，而此冲突却并没有被手动解决。如下图所示： 删掉了不必要的东西之后，一切正常。 出现这种错误，有点不应该。但是同时也说明了，网上的东西只能当参考啊！","link":"/2017/10/19/29364bc7b465.html"},{"title":"Android开发工具系之ADB","text":"ADB的相关概念&amp;工作原理 通过WLAN使用ADB感觉这个挺有意思，但是又在情理之中。1、电脑与设备连入同一个局域网，并能连通。2、将设备接上电脑，设置端口。 12λ adb tcpip 5555restarting in TCP mode port: 5555 3、断开设备4、找出设备的IP地址5、连接设备 123456λ adb cconnect 10.240.100.52connected to 10.240.100.52:5555λ adb devicesList of devices attached10.240.100.52:5555 device 一些常用参数&amp;命令 多个设备连接时，对特定设备进行操作-s serial_number :-e :-d : 安装/卸载应用install path_to_apk:uninstall package_name: 端口转发forward local remote push/pullpull remote localpush local remote: 开启/关闭adb服务器start-serverkill-server 其它wait-for-device cmds:等待设备在线了执行cmds如：adb wait-for-device install app.apk 解决adb remount后还是提示Read-Only file system的问题需要用到最新的adb 工具包，因为它才支持adb disable-verity命令，如果是Linux开发环境，则可使用工程编译结果目录out/host/linux-x86/bin下的adb执行文件。 什么样的才算是最新的呢？这个不太好说啊，如果提示没有那个命令，那么应该旅就是adb的版本问题。我输入adb version后的信息如下：1234➜ ~ adb versionAndroid Debug Bridge version 1.0.39Revision 3db08f2c6889-androidInstalled as /Users/asahi/Library/Android/sdk/platform-tools/adb 步骤如下：12345adb root adb disable-verity adb rebootadb root adb remount 现在可以对system分区进行读写了 adb shell am用法特别多start intentforce-stop pkg_name pm用法特别多path pkg_name dumpsys screencap screenrecord adb help123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145Android Debug Bridge version 1.0.32 -a - directs adb to listen on all interfaces for a connection -d - directs command to the only connected USB device returns an error if more than one USB device is present. -e - directs command to the only running emulator. returns an error if more than one emulator is running. -s &lt;specific device&gt; - directs command to the device or emulator with the given serial number or qualifier. Overrides ANDROID_SERIAL environment variable. -p &lt;product name or path&gt; - simple product name like 'sooner', or a relative/absolute path to a product out directory like 'out/target/product/sooner'. If -p is not specified, the ANDROID_PRODUCT_OUT environment variable is used, which must be an absolute path. -H - Name of adb server host (default: localhost) -P - Port of adb server (default: 5037) devices [-l] - list all connected devices ('-l' will also list device qualifiers) connect &lt;host&gt;[:&lt;port&gt;] - connect to a device via TCP/IP Port 5555 is used by default if no port number is specified. disconnect [&lt;host&gt;[:&lt;port&gt;]] - disconnect from a TCP/IP device. Port 5555 is used by default if no port number is specified. Using this command with no additional arguments will disconnect from all connected TCP/IP devices. device commands: adb push [-p] &lt;local&gt; &lt;remote&gt; - copy file/dir to device ('-p' to display the transfer progress) adb pull [-p] [-a] &lt;remote&gt; [&lt;local&gt;] - copy file/dir from device ('-p' to display the transfer progress) ('-a' means copy timestamp and mode) adb sync [ &lt;directory&gt; ] - copy host-&gt;device only if changed (-l means list but don't copy) (see 'adb help all') adb shell - run remote shell interactively adb shell &lt;command&gt; - run remote shell command adb emu &lt;command&gt; - run emulator console command adb logcat [ &lt;filter-spec&gt; ] - View device log adb forward --list - list all forward socket connections. the format is a list of lines with the following format: &lt;serial&gt; &quot; &quot; &lt;local&gt; &quot; &quot; &lt;remote&gt; &quot;\\n&quot; adb forward &lt;local&gt; &lt;remote&gt; - forward socket connections forward specs are one of: tcp:&lt;port&gt; localabstract:&lt;unix domain socket name&gt; localreserved:&lt;unix domain socket name&gt; localfilesystem:&lt;unix domain socket name&gt; dev:&lt;character device name&gt; jdwp:&lt;process pid&gt; (remote only) adb forward --no-rebind &lt;local&gt; &lt;remote&gt; - same as 'adb forward &lt;local&gt; &lt;remote&gt;' but fails if &lt;local&gt; is already forwarded adb forward --remove &lt;local&gt; - remove a specific forward socket connection adb forward --remove-all - remove all forward socket connections adb reverse --list - list all reverse socket connections from device adb reverse &lt;remote&gt; &lt;local&gt; - reverse socket connections reverse specs are one of: tcp:&lt;port&gt; localabstract:&lt;unix domain socket name&gt; localreserved:&lt;unix domain socket name&gt; localfilesystem:&lt;unix domain socket name&gt; adb reverse --norebind &lt;remote&gt; &lt;local&gt; - same as 'adb reverse &lt;remote&gt; &lt;local&gt;' but fails if &lt;remote&gt; is already reversed. adb reverse --remove &lt;remote&gt; - remove a specific reversed socket connection adb reverse --remove-all - remove all reversed socket connections from device adb jdwp - list PIDs of processes hosting a JDWP transport adb install [-lrtsd] &lt;file&gt; adb install-multiple [-lrtsdp] &lt;file...&gt; - push this package file to the device and install it (-l: forward lock application) (-r: replace existing application) (-t: allow test packages) (-s: install application on sdcard) (-d: allow version code downgrade) (-p: partial application install) adb uninstall [-k] &lt;package&gt; - remove this app package from the device ('-k' means keep the data and cache directories) adb bugreport - return all information from the device that should be included in a bug report. adb backup [-f &lt;file&gt;] [-apk|-noapk] [-obb|-noobb] [-shared|-noshared] [-all] [-system|-nosystem] [&lt;packages...&gt;] - write an archive of the device's data to &lt;file&gt;. If no -f option is supplied then the data is written to &quot;backup.ab&quot; in the current directory. (-apk|-noapk enable/disable backup of the .apks themselves in the archive; the default is noapk.) (-obb|-noobb enable/disable backup of any installed apk expansion (aka .obb) files associated with each application; the default is noobb.) (-shared|-noshared enable/disable backup of the device's shared storage / SD card contents; the default is noshared.) (-all means to back up all installed applications) (-system|-nosystem toggles whether -all automatically includes system applications; the default is to include system apps) (&lt;packages...&gt; is the list of applications to be backed up. If the -all or -shared flags are passed, then the package list is optional. Applications explicitly given on the command line will be included even if -nosystem would ordinarily cause them to be omitted.) adb restore &lt;file&gt; - restore device contents from the &lt;file&gt; backup archive adb help - show this help message adb version - show version num scripting: adb wait-for-device - block until device is online adb start-server - ensure that there is a server running adb kill-server - kill the server if it is running adb get-state - prints: offline | bootloader | device adb get-serialno - prints: &lt;serial-number&gt; adb get-devpath - prints: &lt;device-path&gt; adb status-window - continuously print device status for a specified device adb remount - remounts the /system and /vendor (if present) partitions on the device read-write adb reboot [bootloader|recovery] - reboots the device, optionally into the bootloader or recovery program adb reboot-bootloader - reboots the device into the bootloader adb root - restarts the adbd daemon with root permissions adb usb - restarts the adbd daemon listening on USB adb tcpip &lt;port&gt; - restarts the adbd daemon listening on TCP on the specified port networking: adb ppp &lt;tty&gt; [parameters] - Run PPP over USB. Note: you should not automatically start a PPP connection. &lt;tty&gt; refers to the tty for PPP stream. Eg. dev:/dev/omap_csmi_tty1 [parameters] - Eg. defaultroute debug dump local notty usepeerdns adb sync notes: adb sync [ &lt;directory&gt; ] &lt;localdir&gt; can be interpreted in several ways: - If &lt;directory&gt; is not specified, /system, /vendor (if present), and /data partitions will be updated. - If it is &quot;system&quot;, &quot;vendor&quot; or &quot;data&quot;, only the corresponding partition is updated. environmental variables: ADB_TRACE - Print debug information. A comma separated list of the following values 1 or all, adb, sockets, packets, rwx, usb, sync, sysdeps, transport, jdwp ANDROID_SERIAL - The serial number to connect to. -s takes priority over this if given. ANDROID_LOG_TAGS - When used with the logcat option, only these debug tags are printed.","link":"/2018/01/21/b00570593d4c.html"},{"title":"Ansible ad-hoc 执行流程","text":"背景Ansible 封装了很多脚本，以 Module、Play 的形式呈现，这里以一条简单的 shell 命令作为切入点。在开始前，将目标机的信息，先写入 cat /etc/ansible/hosts 中。 19.134.124.159:36000 所用到的命令如下： 1ansible all -vvv -a &quot;ls /root&quot; -u root 通过打开一些 debug 日志，可以确定执行连接操作时，一定会执行 ansible/lib/ansible/plugins/connection/ssh.py 中的代码。 执行步骤完整的日志 12345678910111213141516171819202122232425262728293031323334353637383940414243444546META: ran handlers&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo ~root &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'/root\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'( umask 77 &amp;&amp; mkdir -p &quot;` echo /root/.ansible/tmp `&quot;&amp;&amp; mkdir &quot;` echo /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036 `&quot; &amp;&amp; echo ansible-tmp-1599536717.558343-92837-98923700243036=&quot;` echo /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036 `&quot; ) &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'ansible-tmp-1599536717.558343-92837-98923700243036=/root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036\\n', b'')&lt;9.134.124.159&gt; Attempting python interpreter discovery&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo PLATFORM; uname; echo FOUND; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/bin/python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.7'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.6'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.5'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python2.7'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python2.6'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/libexec/platform-python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/bin/python3'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; echo ENDFOUND &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'PLATFORM\\nLinux\\nFOUND\\n/usr/bin/python\\n/usr/bin/python3.6\\n/usr/bin/python2.7\\n/usr/bin/python2.6\\n/usr/libexec/platform-python\\n/usr/bin/python3\\n/usr/bin/python\\nENDFOUND\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'{&quot;osrelease_content&quot;: &quot;NAME=\\\\&quot;Tencent tlinux\\\\&quot;\\\\nVERSION=\\\\&quot;2.2 (Final)\\\\&quot;\\\\nID=\\\\&quot;tlinux\\\\&quot;\\\\nID_LIKE=\\\\&quot;rhel fedora centos\\\\&quot;\\\\nVERSION_ID=\\\\&quot;2.2\\\\&quot;\\\\nPRETTY_NAME=\\\\&quot;Tencent tlinux 2.2 (Final)\\\\&quot;\\\\nANSI_COLOR=\\\\&quot;0;31\\\\&quot;\\\\nCPE_NAME=\\\\&quot;cpe:/o:tlinux:linux:2\\\\&quot;\\\\nHOME_URL=\\\\&quot;http://tlinux.oa.com/\\\\&quot;\\\\nBUG_REPORT_URL=\\\\&quot;http://tapd.oa.com/tlinux/bugtrace/bugreports/my_view/\\\\&quot;\\\\n\\\\n&quot;, &quot;platform_dist_result&quot;: [&quot;centos&quot;, &quot;7.2&quot;, &quot;Final&quot;]}\\n', b'')Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/command.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-9283485g9ot9_/tmpkr7p4e1t TO /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/AnsiballZ_command.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-9283485g9ot9_/tmpkr7p4e1t /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/AnsiballZ_command.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/ /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/AnsiballZ_command.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/AnsiballZ_command.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;changed&quot;: true, &quot;end&quot;: &quot;2020-09-08 11:45:53.183432&quot;, &quot;stdout&quot;: &quot;11.sh\\\\n11.zip\\\\nInstallHalyard.sh\\\\n[\\\\nabc.txt\\\\nagent.zip\\\\nbefore.txt\\\\ncloud-agent.log\\\\nclouddriver-prome.yaml\\\\nclouddriver.git?token=bd40137b365a6a789b7f5904cff87958ba5b158b\\\\nclouddriver.log\\\\ncoding-cd\\\\ncoding-cd-grpc.yaml\\\\nconfig_hub_oa_com.sh\\\\nconfig_vscode_server.sh\\\\ndemo\\\\ndemo.yaml\\\\ndev\\\\ndevopsAgent\\\\ndevopsDaemon\\\\nenable_internet_proxy.sh\\\\nfile.txt\\\\nfix_devcloud.logs\\\\ngeneric-aloe.txt\\\\nhi.db\\\\niProxy.sh\\\\nindex.html\\\\ninit_data_disk.sh\\\\ninit_devcloud_remote.sh\\\\ninstall.sh\\\\ninstallAgent.sh\\\\ninstall_ift.sh\\\\njre\\\\njre.zip\\\\nlog.txt\\\\nlogs\\\\npost-script.text\\\\nprome.yaml\\\\npush_master\\\\nrevert_image_source.sh\\\\nruntime\\\\nset_linux_welcome.sh\\\\nstart.sh\\\\nstop.sh\\\\nszx\\\\ntelegraf.conf\\\\nuninstall.sh\\\\nworker-agent.jar\\\\nworkspace&quot;, &quot;cmd&quot;: [&quot;ls&quot;, &quot;/root&quot;], &quot;rc&quot;: 0, &quot;start&quot;: &quot;2020-09-08 11:45:53.178756&quot;, &quot;stderr&quot;: &quot;&quot;, &quot;delta&quot;: &quot;0:00:00.004676&quot;, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;creates&quot;: null, &quot;executable&quot;: null, &quot;_uses_shell&quot;: false, &quot;strip_empty_ends&quot;: true, &quot;_raw_params&quot;: &quot;ls /root&quot;, &quot;removes&quot;: null, &quot;argv&quot;: null, &quot;warn&quot;: false, &quot;chdir&quot;: null, &quot;stdin_add_newline&quot;: true, &quot;stdin&quot;: null}}}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'rm -f -r /root/.ansible/tmp/ansible-tmp-1599536717.558343-92837-98923700243036/ &gt; /dev/null 2&gt;&amp;1 &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')9.134.124.159 | CHANGED | rc=0 &gt;&gt;11.sh11.zipInstallHalyard.sh[abc.txt...META: ran handlersMETA: ran handlersProcess finished with exit code 0 对上述日志进行简化，可知其大致有 7 个步骤，分别如下：简化后，其所执行的命令如下： 123456789ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo ~root &amp;&amp; sleep 0'&quot;'&quot;''ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'( umask 77 &amp;&amp; mkdir -p &quot;` echo /root/.ansible/tmp `&quot;&amp;&amp; mkdir &quot;` echo /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140 `&quot; &amp;&amp; echo ansible-tmp-1599546740.791937-1678-254955456024140=&quot;` echo /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140 `&quot; ) &amp;&amp; sleep 0'&quot;'&quot;''ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo PLATFORM; uname; echo FOUND; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/bin/python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.7'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.6'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python3.5'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python2.7'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python2.6'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/libexec/platform-python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'/usr/bin/python3'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; command -v '&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'python'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'; echo ENDFOUND &amp;&amp; sleep 0'&quot;'&quot;''ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python &amp;&amp; sleep 0'&quot;'&quot;''sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140/ /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140/AnsiballZ_command.py &amp;&amp; sleep 0'&quot;'&quot;''ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140/AnsiballZ_command.py &amp;&amp; sleep 0'&quot;'&quot;''ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'rm -f -r /root/.ansible/tmp/ansible-tmp-1599546740.791937-1678-254955456024140/ &gt; /dev/null 2&gt;&amp;1 &amp;&amp; sleep 0'&quot;'&quot;'' 上传到被控端的文件上传到被控制的文件，在 ~/.ansible/tmp/xxx 下，是一个 Python 脚本，名称为：AnsiballZ_command.py，里面还包含一段压缩文件的 base64。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#!/usr/bin/python# -*- coding: utf-8 -*-_ANSIBALLZ_WRAPPER = True # For test-module.py script to tell this is a ANSIBALLZ_WRAPPERdef _ansiballz_main(): import os import os.path import sys import __main__ scriptdir = None try: scriptdir = os.path.dirname(os.path.realpath(__main__.__file__)) except (AttributeError, OSError): pass excludes = set(('', '.', scriptdir)) sys.path = [p for p in sys.path if p not in excludes] import base64 import runpy import shutil import tempfile import zipfile if sys.version_info &lt; (3,): PY3 = False else: PY3 = True # ZIPDATA 的值已经省略 ZIPDATA = &quot;&quot;&quot;xxxxxxxxxxx&quot;&quot;&quot; def invoke_module(modlib_path, temp_path, json_params): z = zipfile.ZipFile(modlib_path, mode='a') sitecustomize = u'import sys\\nsys.path.insert(0,&quot;%s&quot;)\\n' % modlib_path sitecustomize = sitecustomize.encode('utf-8') zinfo = zipfile.ZipInfo() zinfo.filename = 'sitecustomize.py' zinfo.date_time = ( 2020, 9, 7, 5, 54, 28) z.writestr(zinfo, sitecustomize) z.close() sys.path.insert(0, modlib_path) from ansible.module_utils import basic basic._ANSIBLE_ARGS = json_params runpy.run_module(mod_name='ansible.modules.command', init_globals=None, run_name='__main__', alter_sys=True) print('{&quot;msg&quot;: &quot;New-style module did not handle its own exit&quot;, &quot;failed&quot;: true}') sys.exit(1) def debug(command, zipped_mod, json_params): basedir = os.path.join(os.path.abspath(os.path.dirname(__file__)), 'debug_dir') args_path = os.path.join(basedir, 'args') if command == 'explode': z = zipfile.ZipFile(zipped_mod) for filename in z.namelist(): if filename.startswith('/'): raise Exception('Something wrong with this module zip file: should not contain absolute paths') dest_filename = os.path.join(basedir, filename) if dest_filename.endswith(os.path.sep) and not os.path.exists(dest_filename): os.makedirs(dest_filename) else: directory = os.path.dirname(dest_filename) if not os.path.exists(directory): os.makedirs(directory) f = open(dest_filename, 'wb') f.write(z.read(filename)) f.close() f = open(args_path, 'wb') f.write(json_params) f.close() print('Module expanded into:') print('%s' % basedir) exitcode = 0 elif command == 'execute': sys.path.insert(0, basedir) with open(args_path, 'rb') as f: json_params = f.read() from ansible.module_utils import basic basic._ANSIBLE_ARGS = json_params runpy.run_module(mod_name='ansible.modules.command', init_globals=None, run_name='__main__', alter_sys=True) print('{&quot;msg&quot;: &quot;New-style module did not handle its own exit&quot;, &quot;failed&quot;: true}') sys.exit(1) else: print('WARNING: Unknown debug command. Doing nothing.') exitcode = 0 return exitcode ANSIBALLZ_PARAMS = '{&quot;ANSIBLE_MODULE_ARGS&quot;: {&quot;_raw_params&quot;: &quot;ls /root&quot;, &quot;_ansible_check_mode&quot;: false, &quot;_ansible_no_log&quot;: false, &quot;_ansible_debug&quot;: false, &quot;_ansible_diff&quot;: false, &quot;_ansible_verbosity&quot;: 3, &quot;_ansible_version&quot;: &quot;2.11.0.dev0&quot;, &quot;_ansible_module_name&quot;: &quot;ansible.legacy.command&quot;, &quot;_ansible_syslog_facility&quot;: &quot;LOG_USER&quot;, &quot;_ansible_selinux_special_fs&quot;: [&quot;fuse&quot;, &quot;nfs&quot;, &quot;vboxsf&quot;, &quot;ramfs&quot;, &quot;9p&quot;, &quot;vfat&quot;], &quot;_ansible_string_conversion_action&quot;: &quot;warn&quot;, &quot;_ansible_socket&quot;: null, &quot;_ansible_shell_executable&quot;: &quot;/bin/sh&quot;, &quot;_ansible_keep_remote_files&quot;: false, &quot;_ansible_tmpdir&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1599457948.85933-15430-201759115318770/&quot;, &quot;_ansible_remote_tmp&quot;: &quot;~/.ansible/tmp&quot;}}' if PY3: ANSIBALLZ_PARAMS = ANSIBALLZ_PARAMS.encode('utf-8') try: temp_path = tempfile.mkdtemp(prefix='ansible_ansible.legacy.command_payload_') zipped_mod = os.path.join(temp_path, 'ansible_ansible.legacy.command_payload.zip') with open(zipped_mod, 'wb') as modlib: modlib.write(base64.b64decode(ZIPDATA)) if len(sys.argv) == 2: exitcode = debug(sys.argv[1], zipped_mod, ANSIBALLZ_PARAMS) else: invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS) finally: try: shutil.rmtree(temp_path) except (NameError, OSError): pass sys.exit(exitcode)if __name__ == '__main__': _ansiballz_main() 当 AnsiballZ_command.py 执行时，会首先将 ZIPDATA 还原成一个压缩文件，然后在压缩文件中加入一个 sitecustomize.py。准备完成后，将以 runpy.run_module() 的方式，执行压缩文件中的 Python 代码。可以看出，我们所需要执行的命令，储存在 ANSIBALLZ_PARAMS 变量中，并赋值给了 basic._ANSIBLE_ARGS。 ZIPDATA 压缩包首先，压缩文件中的内容如下。此压缩包通过手段获取到后，解压后，名称为 ansible，里面的文件如 basic.py、command.py 来自所执行命令 ansible 所在的包下。 123456789101112131415161718192021222324252627282930313233343536373839╰─$ tree ansibleansible├── __init__.py├── module_utils│ ├── __init__.py│ ├── _text.py│ ├── basic.py│ ├── common│ │ ├── __init__.py│ │ ├── _collections_compat.py│ │ ├── _json_compat.py│ │ ├── _utils.py│ │ ├── collections.py│ │ ├── file.py│ │ ├── parameters.py│ │ ├── process.py│ │ ├── sys_info.py│ │ ├── text│ │ │ ├── __init__.py│ │ │ ├── converters.py│ │ │ └── formatters.py│ │ ├── validation.py│ │ └── warnings.py│ ├── compat│ │ ├── __init__.py│ │ ├── _selectors2.py│ │ └── selectors.py│ ├── distro│ │ ├── __init__.py│ │ └── _distro.py│ ├── parsing│ │ ├── __init__.py│ │ └── convert_bool.py│ ├── pycompat24.py│ └── six│ └── __init__.py└── modules ├── __init__.py └── command.py 其次，压缩文件中代码的执行。从 runpy.run_module 中的 mod_name='ansible.modules.command' 猜测，是要执行压缩包下的 modules/command.py。此文件的执行，包括了一个 AnsibleModule 的初始化，在它的构造函数中，可以看出来，获取了 basic._ANSIBLE_ARGS 的值。 12345678910111213141516171819class AnsibleModule(object): def __init__(self, argument_spec, bypass_checks=False, no_log=False, mutually_exclusive=None, required_together=None, required_one_of=None, add_file_common_args=False, supports_check_mode=False, required_if=None, required_by=None): ... self._load_params() ...##############################basic.py##############################def _load_params(self): self.params = _load_params()##############################basic.py##############################def _load_params(): global _ANSIBLE_ARGS if _ANSIBLE_ARGS is not None: buffer = _ANSIBLE_ARGS .... 最终，从 command.py 执行到 basic.py，以开启执行系统命令，作为我们所要脚本（即：ls /root）执行的开始 1cmd = subprocess.Popen(args, **kwargs) 等待 shell 命令执行完毕在此处，为 cmd 的 stdout、stderr 注册了可读事件到 selector，并在一个死循环中轮训 selector，如果有 cmd.stdout、cmd.stderr 可读事件，就将对应的数据，追加到相应的变量上。当 cmd 执行完成后，退出死循环，并返回 cmd 执行后的 stdout、stderr。 1234567891011121314151617181920212223242526272829selector.register(cmd.stdout, selectors.EVENT_READ)selector.register(cmd.stderr, selectors.EVENT_READ)...while True: events = selector.select(1) for key, event in events: b_chunk = key.fileobj.read() if b_chunk == b(''): selector.unregister(key.fileobj) if key.fileobj == cmd.stdout: stdout += b_chunk elif key.fileobj == cmd.stderr: stderr += b_chunk ... # only break out if no pipes are left to read or # the pipes are completely read and # the process is terminated if (not events or not selector.get_map()) and cmd.poll() is not None: break # No pipes are left to read but process is not yet terminated # Only then it is safe to wait for the process to be finished # NOTE: Actually cmd.poll() is always None here if no selectors are left elif not selector.get_map() and cmd.poll() is None: cmd.wait() # The process is terminated. Since no pipes to read from are # left, there is no need to call select() again. break...return (rc, stdout, stderr) 控制中心是什么地方定义上上面这 8 个步骤？产生上面 8 个步骤的地方，开始于：ansible/plugins/action/command.py，其中 self._execute_module() 完成了前面的 7 个操作，self._remove_tmp_path() 完成了删除 ~/.ansible/tmp/xxxxx 的任务。 重试机制 什么时候进行重试 an exception is caught ssh returns 255（ControlPersist 超时不能用或者远程主机连不上） 什么时候不进行重试。 sshpass returns 5 (invalid password, to prevent account lockouts) remaining_tries is &lt; 2 retries limit reached 重试的方式，是通过一个对连接函数的闭包操作完成。 123456789101112131415def _ssh_retry(func): @wraps(func) def wrapped(self, *args, **kwargs): remaining_tries = int(C.ANSIBLE_SSH_RETRIES) + 1 cmd_summary = u&quot;%s...&quot; % to_text(args[0]) conn_password = self.get_option('password') or self._play_context.password for attempt in range(remaining_tries): ... return wrapped################################################################@_ssh_retrydef _run(self, cmd, in_data, sudoable=True, checkrc=True): &quot;&quot;&quot;Wrapper around _bare_run that retries the connection &quot;&quot;&quot; return self._bare_run(cmd, in_data, sudoable=sudoable, checkrc=checkrc) 可借鉴点 复用已有链接：https://ldpreload.com/blog/ssh-control","link":"/2020/09/29/9c1a666f4592.html"},{"title":"Ansible playbook 执行流程","text":"背景超时主要分两个场景，一个是建立 SSH 连接时，另外一个为通过 SSH 执行命令时的超时。前者主要依靠 SSH 命令的自带参数 ConnectTimeout，后者则有一套 Ansible 自己的实现。 建立连接超时ansible 2 -u root -m ping -T 30。底层实现使用 ssh -o ConnectTimeout=30。 执行命令超时（playbook）在 playbook 的 task 中加入 async 和 poll 属性。 async 表示这个step的最长等待时长, 如果设置为0, 表示一直等待下去直到动作完成； poll 表示检查step操作结果的间隔时长，poll 设置为0, 表示不用等待执行结果, 该step执行成功。 测试用的 playbook 如下： 123456789101112--- - hosts: &quot;1&quot; vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: Sleep30s shell: &quot;sleep 30s&quot; async: 10 poll: 1 启动命令如下： 1ansible-playbook pb.yml 效果： 执行命令超时（playbook）的流程在此 playbook 中，有一个 task，但是在执行上面定义的 task 之前，会执行一个 Gathering Facts 的 task，这里将此不太相干的 task 去掉了。task Sleep30s 的执行日志如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203TASK [Sleep30s] ****************************************************************task path: /Users/yangyu/pb.yml:8&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo ~root &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'/root\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'( umask 77 &amp;&amp; mkdir -p &quot;` echo /root/.ansible/tmp `&quot;&amp;&amp; mkdir &quot;` echo /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145 `&quot; &amp;&amp; echo ansible-tmp-1600333356.414965-42861-191307013081145=&quot;` echo /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145 `&quot; ) &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'ansible-tmp-1600333356.414965-42861-191307013081145=/root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145\\n', b'')Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/command.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_66m3nen TO /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/AnsiballZ_command.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_66m3nen /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/AnsiballZ_command.py\\n', b'')&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmplmizhdvg TO /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/async_wrapper.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmplmizhdvg /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/async_wrapper.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/ /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/AnsiballZ_command.py /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/async_wrapper.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'ANSIBLE_ASYNC_DIR='&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'~/.ansible_async'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;'&quot;' /usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/async_wrapper.py 48991476669 10 /root/.ansible/tmp/ansible-tmp-1600333356.414965-42861-191307013081145/AnsiballZ_command.py _ &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'{&quot;started&quot;: 1, &quot;_ansible_suppress_tmpdir_delete&quot;: true, &quot;finished&quot;: 0, &quot;results_file&quot;: &quot;/root/.ansible_async/48991476669.20840&quot;, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'echo ~root &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'/root\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'( umask 77 &amp;&amp; mkdir -p &quot;` echo /root/.ansible/tmp `&quot;&amp;&amp; mkdir &quot;` echo /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103 `&quot; &amp;&amp; echo ansible-tmp-1600333358.847193-42861-146017266031103=&quot;` echo /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103 `&quot; ) &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'ansible-tmp-1600333358.847193-42861-146017266031103=/root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103\\n', b'')Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpgapz8kyp TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpgapz8kyp /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpph94rjs7 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpph94rjs7 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpia9_huhw TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpia9_huhw /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp0dw1l581 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp0dw1l581 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp640778bz TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp640778bz /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_snd1eu9 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_snd1eu9 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpk13c6mm6 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpk13c6mm6 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpfjdhm2l7 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpfjdhm2l7 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpzqpsa6hl TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmpzqpsa6hl /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0Using module file /Users/yangyu/projects/ansible/lib/ansible/modules/async_status.py&lt;9.134.124.159&gt; PUT /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_66e23_9 TO /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py&lt;9.134.124.159&gt; SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 '[9.134.124.159]'&lt;9.134.124.159&gt; (0, b'sftp&gt; put /Users/yangyu/.ansible/tmp/ansible-local-42839upbl7lkg/tmp_66e23_9 /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py\\n', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 9.134.124.159 '/bin/sh -c '&quot;'&quot;'chmod u+x /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/ /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'', b'')&lt;9.134.124.159&gt; ESTABLISH SSH CONNECTION FOR USER: root&lt;9.134.124.159&gt; SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o Port=36000 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=&quot;root&quot;' -o ConnectTimeout=10 -o ControlPath=/Users/yangyu/.ansible/cp/4846fe66a5 -tt 9.134.124.159 '/bin/sh -c '&quot;'&quot;'/usr/bin/python /root/.ansible/tmp/ansible-tmp-1600333358.847193-42861-146017266031103/AnsiballZ_async_status.py &amp;&amp; sleep 0'&quot;'&quot;''&lt;9.134.124.159&gt; (0, b'\\r\\n{&quot;started&quot;: 1, &quot;invocation&quot;: {&quot;module_args&quot;: {&quot;jid&quot;: &quot;48991476669.20840&quot;, &quot;mode&quot;: &quot;status&quot;, &quot;_async_dir&quot;: &quot;/root/.ansible_async&quot;}}, &quot;finished&quot;: 0, &quot;ansible_job_id&quot;: &quot;48991476669.20840&quot;}\\r\\n', b'Shared connection to 9.134.124.159 closed.\\r\\n')ASYNC POLL on 9.134.124.159: jid=48991476669.20840 started=1 finished=0fatal: [9.134.124.159]: FAILED! =&gt; { &quot;changed&quot;: false, &quot;msg&quot;: &quot;async task did not complete within the requested time - 10s&quot;}PLAY RECAP *********************************************************************9.134.124.159 : ok=1 changed=0 unreachable=0 failed=1 skipped=0 rescued=0 ignored=0 Process finished with exit code 2 主要分两个步骤，先将任务在被控端跑起来，再在主控端定时轮训任务状态。第一个步骤与前文所述内容差不多，多了一份 py 代码 async_wrapper.py。 task Sleep30s 入口： 从 debug 数据可以看出，在 playbook 中设置的 async 和 poll 是作为是否开启等待与轮训任务状态的开关。 完整流程 此部分的流程只包含 Sleep30s Task，无 Gathering facts Task。 lib/ansible/plugins/action/command.py此处通过判断 task 的 async 的值来判断是否进行 async 操作，此处为 10，即 playbook 中定义的 async 值为 10。 lib/ansible/plugins/action/__init__.py _execute_module 方法 self._make_tmp_path() 创建临时目录 获取当前用户的家目录：echo ~root &amp;&amp; sleep 0 创建临时目录：( umask 77 &amp;&amp; mkdir -p &quot; echo /root/.ansible/tmp &quot;&amp;&amp; mkdir &quot; echo /root/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278 &quot; &amp;&amp; echo ansible-tmp-1600668712.8156748-24387-134124052814278=&quot; echo /root/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278 &quot; ) &amp;&amp; sleep 0 至此，完成临时目录的创建。 拷贝 AnsiballZ_command.py 到 /root/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278/ 目录下。其功能如前文所述 wiki: #3685 定时轮训逻辑（这是相比 #3685 多出来的流程）这里多出来的逻辑是拷贝了一个 async_wrapper.py 文件到目标主机其中 async_limit 为 task 中定义的 async 值，async_jid 为随机数。接着生成了一个 async_cmd，也就是通过 ssh 命令，调用目标主机上的 async_wrapper.py 文件的命令。最终生成的命令为： 1'ANSIBLE_ASYNC_DIR=\\'~/.ansible_async\\' /usr/bin/python /root/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278/async_wrapper.py 586569230138 10 /root/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278/AnsiballZ_command.py _' 其中 async_wrapper.py 文件的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#!/usr/bin/python# -*- coding: utf-8 -*-_ANSIBALLZ_WRAPPER = True # For test-module.py script to tell this is a ANSIBALLZ_WRAPPERdef _ansiballz_main(): import os import os.path import sys import __main__ scriptdir = None try: scriptdir = os.path.dirname(os.path.realpath(__main__.__file__)) except (AttributeError, OSError): pass excludes = set(('', '.', scriptdir)) sys.path = [p for p in sys.path if p not in excludes] import base64 import runpy import shutil import tempfile import zipfile if sys.version_info &lt; (3,): PY3 = False else: PY3 = True ZIPDATA = &quot;&quot;&quot;omitted...&quot;&quot;&quot; def invoke_module(modlib_path, temp_path, json_params): z = zipfile.ZipFile(modlib_path, mode='a') sitecustomize = u'import sys\\nsys.path.insert(0,&quot;%s&quot;)\\n' % modlib_path sitecustomize = sitecustomize.encode('utf-8') zinfo = zipfile.ZipInfo() zinfo.filename = 'sitecustomize.py' zinfo.date_time = ( 2020, 9, 21, 6, 26, 19) z.writestr(zinfo, sitecustomize) z.close() sys.path.insert(0, modlib_path) from ansible.module_utils import basic basic._ANSIBLE_ARGS = json_params runpy.run_module(mod_name='ansible.modules.async_wrapper', init_globals=None, run_name='__main__', alter_sys=True) print('{&quot;msg&quot;: &quot;New-style module did not handle its own exit&quot;, &quot;failed&quot;: true}') sys.exit(1) def debug(command, zipped_mod, json_params): basedir = os.path.join(os.path.abspath(os.path.dirname(__file__)), 'debug_dir') args_path = os.path.join(basedir, 'args') if command == 'explode': z = zipfile.ZipFile(zipped_mod) for filename in z.namelist(): if filename.startswith('/'): raise Exception('Something wrong with this module zip file: should not contain absolute paths') dest_filename = os.path.join(basedir, filename) if dest_filename.endswith(os.path.sep) and not os.path.exists(dest_filename): os.makedirs(dest_filename) else: directory = os.path.dirname(dest_filename) if not os.path.exists(directory): os.makedirs(directory) f = open(dest_filename, 'wb') f.write(z.read(filename)) f.close() f = open(args_path, 'wb') f.write(json_params) f.close() print('Module expanded into:') print('%s' % basedir) exitcode = 0 elif command == 'execute': sys.path.insert(0, basedir) with open(args_path, 'rb') as f: json_params = f.read() from ansible.module_utils import basic basic._ANSIBLE_ARGS = json_params runpy.run_module(mod_name='ansible.modules.async_wrapper', init_globals=None, run_name='__main__', alter_sys=True) print('{&quot;msg&quot;: &quot;New-style module did not handle its own exit&quot;, &quot;failed&quot;: true}') sys.exit(1) else: print('WARNING: Unknown debug command. Doing nothing.') exitcode = 0 return exitcode ANSIBALLZ_PARAMS = '{&quot;ANSIBLE_MODULE_ARGS&quot;: {}}' if PY3: ANSIBALLZ_PARAMS = ANSIBALLZ_PARAMS.encode('utf-8') try: temp_path = tempfile.mkdtemp(prefix='ansible_ansible.legacy.async_wrapper_payload_') zipped_mod = os.path.join(temp_path, 'ansible_ansible.legacy.async_wrapper_payload.zip') with open(zipped_mod, 'wb') as modlib: modlib.write(base64.b64decode(ZIPDATA)) if len(sys.argv) == 2: exitcode = debug(sys.argv[1], zipped_mod, ANSIBALLZ_PARAMS) else: invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS) finally: try: shutil.rmtree(temp_path) except (NameError, OSError): pass sys.exit(exitcode)if __name__ == '__main__': _ansiballz_main() 与 AnsiballZ_command.py 中的逻辑类似，最终执行的代码来自 ZIP_DATA 中的数据，此处为 ansible.modules.async_wrapper 中的 main 函数，同理，此函数也可以在 ansible 的源代码中找到，其内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940➜ tree ansible.├── __init__.py├── module_utils│ ├── __init__.py│ ├── _text.py│ ├── basic.py│ ├── common│ │ ├── __init__.py│ │ ├── _collections_compat.py│ │ ├── _json_compat.py│ │ ├── _utils.py│ │ ├── collections.py│ │ ├── file.py│ │ ├── parameters.py│ │ ├── process.py│ │ ├── sys_info.py│ │ ├── text│ │ │ ├── __init__.py│ │ │ ├── converters.py│ │ │ └── formatters.py│ │ ├── validation.py│ │ └── warnings.py│ ├── compat│ │ ├── __init__.py│ │ ├── _selectors2.py│ │ └── selectors.py│ ├── distro│ │ ├── __init__.py│ │ └── _distro.py│ ├── parsing│ │ ├── __init__.py│ │ └── convert_bool.py│ ├── pycompat24.py│ └── six│ └── __init__.py└── modules ├── __init__.py └── async_wrapper.py8 directories, 29 files 其中 async_wrapper.py 在 ansible 中的位置为：lib/ansible/modules/async_wrapper.py。 实际执行任务。这里执行的其实是 async_wrapper.py，通过 async_wrapper.py 来调用 AnsiballZ_command.py。此处总共分成两个步骤： 加权限：chmod u+x ~/.ansible/tmp/ansible-tmp-1600668712.8156748-24387-134124052814278/ ...AnsiballZ_command.py ...async_wrapper.py &amp;&amp; sleep 0（路径有省略） 执行 async_wrapper.py：python ...async_wrapper.py 586569230138 10 ...AnsiballZ_command.py _ &amp;&amp; sleep 0（路径有省略） 承接第3小点，此处最终执行的是 ansible/modules/async_wrapper.py 的代码逻辑 ansible/modules/async_wrapper.py 取出传入的参数，即 async、command.py 等 确定实际要执行的命令（业务命令，也就是对用户来说，相在目标机上执行的命令） 通过 os.fork() 剥离主进程与子进程，子进程执行 XXX_command.py，主进程返回结束。此处涉及大量的进程间通信（IPC），代码逻辑有点绕，但是有如下几点可以确认： 父（主）进程提前返回，也就是 ssh 命令执行完毕。 子进程在父进程退出后，变成孤儿进程，然后通过 daemonize_self() 函数，将自己变成一个脱离父进程的新进程。 新进程会再次 fork，创建一个新子进程，并在新子进程中执行 XXX_command.py ，新进程会一直等待新子进程执行完毕。 经过上述步骤，ssh 命令已返回。 轮训执行结果执行完上述流程后，会返回一个 result，内容如下： 123456789{ &quot;started&quot;: 1, &quot;finished&quot;: 0, &quot;results_file&quot;: &quot;/root/.ansible_async/732064027558.2514&quot;, &quot;ansible_job_id&quot;: &quot;732064027558.2514&quot;, &quot;_ansible_parsed&quot;: true, &quot;changed&quot;: true, &quot;_ansible_no_log&quot;: false} 可以看出，结果是存放在被控端的某个目录下，并在 lib/ansible/executor/task_executor.py 中，通过对 task 中的 async 和 poll 值的判断，来决定是否进行结果轮询： 轮训的流程与执行一条 ansible 命令类似，详见 #3685 ，此处不再赘述，不同的地方在于： 上传的文件是 AnsiballZ_async_status.py 通过 ssh 开始执行的文件是 AnsiballZ_async_status.py，最终执行的是： lib/ansible/modules/async_status.py。 拿到被控机上面的 task log 后，会对 task 的执行状态进行判断： 如果在 async 秒内，没有完成 task，此 task 将直接返回超时； 不过从此处来看，当 task 执行完毕后，可能还存在主控端去被控端轮询 task 的情况。","link":"/2020/09/29/7df9f6ffa556.html"},{"title":"Argo CD Sync 同步操作逻辑梳理","text":"sync 子命令做的事情就两件：从 git repo 拉取 Manifest、然后执行 kubectl apply。 入口：app.go -&gt; NewApplicationSyncCommand 执行命令：argocd app sync aaa 命令行客户端 先创建一个 client 1acdClient := argocdclient.NewClientOrDie(clientOpts) 其中 client 的属性如下 123456789101112131415161718type client struct { ServerAddr string PlainText bool Insecure bool CertPEMData []byte ClientCert *tls.Certificate AuthToken string RefreshToken string UserAgent string GRPCWeb bool GRPCWebRootPath string Headers []string proxyMutex *sync.Mutex proxyListener net.Listener proxyServer *grpc.Server proxyUsersCount int} 再通过 acdClient 创建一个 applicationpkg.ApplicationServiceClient 1conn, appIf := acdClient.NewApplicationClientOrDie() appIf 它包含一个 grpc 连接，如下： 123type applicationServiceClient struct { cc *grpc.ClientConn} 其中初始化 ApplicationServiceClient 之前，会先与 grpc 服务端建立连接，并将这个连接传递给到 ApplicationServiceClient。 12345678910111213141516func (c *client) NewApplicationClient() (io.Closer, applicationpkg.ApplicationServiceClient, error) { conn, closer, err := c.newConn() ... appIf := applicationpkg.NewApplicationServiceClient(conn) return closer, appIf, nil}func (c *client) newConn() (*grpc.ClientConn, io.Closer, error) { ... conn, e := grpc_util.BlockingDial(ctx, network, serverAddr, creds, dialOpts...) return conn, argoio.NewCloser(...), e}func NewApplicationServiceClient(cc *grpc.ClientConn) ApplicationServiceClient { return &amp;applicationServiceClient{cc}} 设置发送请求的参数 applicationpkg.ApplicationSyncRequest。主要包括两个方面参数的处理： selector。这个主要去筛选满足 selector 要求的 Application，并将 Application 的 Name 添加到待处理的 application 列表中。 selectedLabels。这个主要针对 Application 下面的各项资源。当 Application 下各项资源的 Label 中含有符合对应的 labels 时，会将该资源以 GVK 的形式追加在 resources 后。 命令行发送 Sync 请求前、所有的参数如下： 123456789syncReq := applicationpkg.ApplicationSyncRequest{ Name: &amp;appName, DryRun: dryRun, Revision: revision, // &quot;&quot; Resources: selectedResources,// 由 resource 转换而来 Prune: prune, Manifests: localObjsStrings, // [] Infos: getInfos(infos),} 然后就是发送 gRPC 请求。由于 appIf 其实是 applicationServiceClient 的一个实例，因此可以从 applicationServiceClient 的相关定义中，找到 Sync 的实现，如下： 12345678910_, err := appIf.Sync(ctx, &amp;syncReq)func (c *applicationServiceClient) Sync(ctx context.Context, in *ApplicationSyncRequest, opts ...grpc.CallOption) (*v1alpha1.Application, error) { out := new(v1alpha1.Application) err := c.cc.Invoke(ctx, &quot;/application.ApplicationService/Sync&quot;, in, out, opts...) if err != nil { return nil, err } return out, nil} gRPC 服务端逻辑服务端的逻辑从 gRPC 对 /application.ApplicationService/Sync 处理开始。其中对 /application.ApplicationService/Sync 的关联在 application.pb.go 的 _ApplicationService_Sync_Handler 方法中，如下： 1234567891011121314151617func _ApplicationService_Sync_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) { in := new(ApplicationSyncRequest) if err := dec(in); err != nil { return nil, err } if interceptor == nil { return srv.(ApplicationServiceServer).Sync(ctx, in) } info := &amp;grpc.UnaryServerInfo{ Server: srv, FullMethod: &quot;/application.ApplicationService/Sync&quot;, } handler := func(ctx context.Context, req interface{}) (interface{}, error) { return srv.(ApplicationServiceServer).Sync(ctx, req.(*ApplicationSyncRequest)) } return interceptor(ctx, in, info, handler)} 通过 gRPC 的注册过程，不难发现，最终 Sync() 的实现来自 server/application/application.go 的 Server 结构体，如下： 123func (s *Server) Sync(ctx context.Context, syncReq *application.ApplicationSyncRequest) (*appv1.Application, error) { ...} 可以看到当 gRPC server(在 pod argocd-server 中) 收到请求后，带过来的参数如下： name:\\&quot;aaa\\&quot; revision:\\&quot;\\&quot; dryRun:false prune:false strategy:&lt;hook:&lt;syncStrategyApply:&lt;force:false &gt; &gt; &gt; 下面有几个比较关键的逻辑： 从 k8s 集群中获取名为 aaa 的 application CRD。 123456789101112131415appIf := s.appclientset.ArgoprojV1alpha1().Applications(s.ns)a, err := appIf.Get(ctx, *syncReq.Name, metav1.GetOptions{})// afunc (c *applications) Get(ctx context.Context, name string, options v1.GetOptions) (result *v1alpha1.Application, err error) { result = &amp;v1alpha1.Application{} err = c.client.Get(). Namespace(c.ns). Resource(&quot;applications&quot;). Name(name). VersionedParams(&amp;options, scheme.ParameterCodec). Do(ctx). Into(result) return} 获取 revision、displayRevision 1revision, displayRevision, err := s.resolveRevision(ctx, a, syncReq) 由于 gRPC 请求携带的 revision 为空，所以这里会默认取 HEAD commit。如果是 revision 是 branch、tag，则会从 Git Repo 里面查询出其所对应的 commit id。 12345678910111213141516171819202122ambiguousRevision := syncReq.Revisionif ambiguousRevision == &quot;&quot; { ambiguousRevision = app.Spec.Source.TargetRevision}...if git.IsCommitSHA(ambiguousRevision) { // If it's already a commit SHA, then no need to look it up return ambiguousRevision, ambiguousRevision, nil}repo, err := s.db.GetRepository(ctx, app.Spec.Source.RepoURL)if err != nil { return &quot;&quot;, &quot;&quot;, err}gitClient, err := git.NewClient(repo.Repo, repo.GetGitCreds(), repo.IsInsecure(), repo.IsLFSEnabled())if err != nil { return &quot;&quot;, &quot;&quot;, err}revision, err = gitClient.LsRemote(ambiguousRevision)if err != nil { return &quot;&quot;, &quot;&quot;, err}return revision, fmt.Sprintf(&quot;%s (%s)&quot;, ambiguousRevision, revision), nil 得到目标 commit id 之后，开始组装请求 123456789101112131415op := appv1.Operation{ Sync: &amp;appv1.SyncOperation{ Revision: revision, Prune: syncReq.Prune, DryRun: syncReq.DryRun, SyncOptions: syncOptions, SyncStrategy: syncReq.Strategy, Resources: syncReq.Resources, Manifests: syncReq.Manifests, }, InitiatedBy: appv1.OperationInitiator{Username: session.Username(ctx)}, Info: syncReq.Infos,}a, err = argo.SetAppOperation(appIf, *syncReq.Name, &amp;op) 请求发出来后、会开启一个死循环、来执行 Update 操作、直到操作成功，以此来解决冲突问题（？）。 1234567891011121314151617// SetAppOperation updates an application with the specified operation, retrying conflict errorsfunc SetAppOperation(appIf v1alpha1.ApplicationInterface, appName string, op *argoappv1.Operation) (*argoappv1.Application, error) { for { a, err := appIf.Get(context.Background(), appName, metav1.GetOptions{}) ... a.Operation = op a.Status.OperationState = nil a, err = appIf.Update(context.Background(), a, metav1.UpdateOptions{}) if op.Sync == nil { return nil, status.Errorf(codes.InvalidArgument, &quot;Operation unspecified&quot;) } if err == nil { return a, nil } ... }} 其中 appIf.Get() 在前面已经介绍过了、就是从 k8s 集群中查找相应名称的 Application CRD，而 appIf.Update() 顾名思义、与 Get 类似，只是对 k8s 集群做更新操作： 12345678910111213// Update takes the representation of a application and updates it. Returns the server's representation of the application, and an error, if there is any.func (c *applications) Update(ctx context.Context, application *v1alpha1.Application, opts v1.UpdateOptions) (result *v1alpha1.Application, err error) { result = &amp;v1alpha1.Application{} err = c.client.Put(). Namespace(c.ns). Resource(&quot;applications&quot;). Name(application.Name). VersionedParams(&amp;opts, scheme.ParameterCodec). Body(application). Do(ctx). Into(result) return} 而整个 Sync 步骤已经完成了，更新完 CRD 之后，后续所需要作出来的更新操作，应该放到了对应的 CRD controller 里面去。 以下是当 cli 工具执行命令时，argocd-server 所打印的日志，可以在一定程度上佐证上述分析： 12345678910111213141516time=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;finished unary call with code OK&quot; grpc.code=OK grpc.method=Version grpc.service=version.VersionService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; grpc.time_ms=0.737 span.kind=server system=grpctime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;received unary call /application.ApplicationService/Sync&quot; grpc.method=Sync grpc.request.claims=&quot;{\\&quot;exp\\&quot;:1618734626,\\&quot;iat\\&quot;:1618648226,\\&quot;iss\\&quot;:\\&quot;argocd\\&quot;,\\&quot;jti\\&quot;:\\&quot;18520eac-1579-47b7-b12d-cba5c24a6c23\\&quot;,\\&quot;nbf\\&quot;:1618648226,\\&quot;sub\\&quot;:\\&quot;admin\\&quot;}&quot; grpc.request.content=&quot;name:\\&quot;aaa\\&quot; revision:\\&quot;\\&quot; dryRun:false prune:false strategy:&lt;hook:&lt;syncStrategyApply:&lt;force:false &gt; &gt; &gt; &quot; grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; span.kind=server system=grpctime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;admin initiated sync to HEAD (5acebc82a613b73b46a09be1b023a1720ea3f7e9)&quot; application=aaa dest-namespace=cc dest-server=&quot;https://kubernetes.default.svc&quot; reason=OperationStarted type=Normaltime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;finished unary call with code OK&quot; grpc.code=OK grpc.method=Sync grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; grpc.time_ms=268.642 span.kind=server system=grpctime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;received unary call /application.ApplicationService/Get&quot; grpc.method=Get grpc.request.claims=&quot;{\\&quot;exp\\&quot;:1618734626,\\&quot;iat\\&quot;:1618648226,\\&quot;iss\\&quot;:\\&quot;argocd\\&quot;,\\&quot;jti\\&quot;:\\&quot;18520eac-1579-47b7-b12d-cba5c24a6c23\\&quot;,\\&quot;nbf\\&quot;:1618648226,\\&quot;sub\\&quot;:\\&quot;admin\\&quot;}&quot; grpc.request.content=&quot;name:\\&quot;aaa\\&quot; resourceVersion:\\&quot;\\&quot; selector:\\&quot;\\&quot; repo:\\&quot;\\&quot; &quot; grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; span.kind=server system=grpctime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;finished unary call with code OK&quot; grpc.code=OK grpc.method=Get grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; grpc.time_ms=19.895 span.kind=server system=grpctime=&quot;2021-04-17T10:03:38Z&quot; level=info msg=&quot;received streaming call /application.ApplicationService/Watch&quot; grpc.method=Watch grpc.request.claims=&quot;{\\&quot;exp\\&quot;:1618734626,\\&quot;iat\\&quot;:1618648226,\\&quot;iss\\&quot;:\\&quot;argocd\\&quot;,\\&quot;jti\\&quot;:\\&quot;18520eac-1579-47b7-b12d-cba5c24a6c23\\&quot;,\\&quot;nbf\\&quot;:1618648226,\\&quot;sub\\&quot;:\\&quot;admin\\&quot;}&quot; grpc.request.content=&quot;name:\\&quot;aaa\\&quot; resourceVersion:\\&quot;39352\\&quot; selector:\\&quot;\\&quot; repo:\\&quot;\\&quot; &quot; grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; span.kind=server system=grpctime=&quot;2021-04-17T10:03:40Z&quot; level=info msg=&quot;received unary call /application.ApplicationService/Get&quot; grpc.method=Get grpc.request.claims=&quot;{\\&quot;exp\\&quot;:1618734626,\\&quot;iat\\&quot;:1618648226,\\&quot;iss\\&quot;:\\&quot;argocd\\&quot;,\\&quot;jti\\&quot;:\\&quot;18520eac-1579-47b7-b12d-cba5c24a6c23\\&quot;,\\&quot;nbf\\&quot;:1618648226,\\&quot;sub\\&quot;:\\&quot;admin\\&quot;}&quot; grpc.request.content=&quot;name:\\&quot;aaa\\&quot; refresh:\\&quot;normal\\&quot; resourceVersion:\\&quot;\\&quot; selector:\\&quot;\\&quot; repo:\\&quot;\\&quot; &quot; grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:40Z&quot; span.kind=server system=grpctime=&quot;2021-04-17T10:03:40Z&quot; level=info msg=&quot;Requested app 'aaa' refresh&quot;time=&quot;2021-04-17T10:03:41Z&quot; level=info msg=&quot;finished unary call with code OK&quot; grpc.code=OK grpc.method=Get grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:40Z&quot; grpc.time_ms=937.08 span.kind=server system=grpctime=&quot;2021-04-17T10:03:41Z&quot; level=info msg=&quot;received unary call /cluster.SettingsService/Get&quot; grpc.method=Get grpc.request.claims=&quot;{\\&quot;exp\\&quot;:1618734626,\\&quot;iat\\&quot;:1618648226,\\&quot;iss\\&quot;:\\&quot;argocd\\&quot;,\\&quot;jti\\&quot;:\\&quot;18520eac-1579-47b7-b12d-cba5c24a6c23\\&quot;,\\&quot;nbf\\&quot;:1618648226,\\&quot;sub\\&quot;:\\&quot;admin\\&quot;}&quot; grpc.request.content= grpc.service=cluster.SettingsService grpc.start_time=&quot;2021-04-17T10:03:41Z&quot; span.kind=server system=grpctime=&quot;2021-04-17T10:03:41Z&quot; level=info msg=&quot;Ignore status for CustomResourceDefinitions&quot;time=&quot;2021-04-17T10:03:41Z&quot; level=info msg=&quot;finished unary call with code OK&quot; grpc.code=OK grpc.method=Get grpc.service=cluster.SettingsService grpc.start_time=&quot;2021-04-17T10:03:41Z&quot; grpc.time_ms=2.212 span.kind=server system=grpctime=&quot;2021-04-17T10:03:41Z&quot; level=info msg=&quot;finished streaming call with code OK&quot; grpc.code=OK grpc.method=Watch grpc.service=application.ApplicationService grpc.start_time=&quot;2021-04-17T10:03:38Z&quot; grpc.time_ms=2771.24 span.kind=server system=grpctime=&quot;2021-04-17T10:03:47Z&quot; level=warning msg=&quot;Failed to resync revoked tokens. retrying again in 1 minute: dial tcp 10.103.83.103:6379: connect: connection refused&quot;time=&quot;2021-04-17T10:04:47Z&quot; level=warning msg=&quot;Failed to resync revoked tokens. retrying again in 1 minute: dial tcp 10.103.83.103:6379: connect: connection refused&quot; CRD Controller入口：argocd_application_controller.go -&gt; NewCommand()，主要步骤如下： 1234567891011121314151617...appController, err := controller.NewApplicationController( namespace, settingsMgr, kubeClient, appClient, repoClientset, cache, kubectl, resyncDuration, time.Duration(selfHealTimeoutSeconds)*time.Second, metricsPort, metricsCacheExpiration, kubectlParallelismLimit, clusterFilter)...go appController.Run(ctx, statusProcessors, operationProcessors) 首先，创建的 appController 包含两个 Informer： appInformer 监听 Application CRD，事件根据不同类型按需送往 appRefreshQueue、appComparisonTypeRefreshQueue、appOperationQueue。 projInformer 监听 AppProject CRD，事件全部送往 projectRefreshQueue 其中 appInformer 中所涉及到的三个 Queue 的区别如下： appRefreshQueue：key 格式为：namespace/name AddFunc 添加事件 UpdateFunc 添加事件（不一定） DeleteFunc 添加事件 appComparisonTypeRefreshQueue：key 格式为：namespace/name/(int) UpdateFunc 添加事件 appOperationQueue：key 格式为：namespace/name AddFunc 添加事件 UpdateFunc 添加事件 其次，appController.Run()做得内容比较直观，所做的内容可以分成两类。 其一是将 Informer 新开一个协程跑起来。 12go ctrl.appInformer.Run(ctx.Done())go ctrl.projInformer.Run(ctx.Done()) 其二是监听上面所涉及到的 4 个 Queue，当有新元素入队后、会立即调用相应的处理逻辑。 1234567for ctrl.processAppRefreshQueueItem() {}...for ctrl.processAppOperationQueueItem() {}...for ctrl.processAppComparisonTypeQueueItem() {}...for ctrl.processProjectQueueItem() {} 执行一次 argocd app sync aaa 后，controller pod 打印的日志如下： 12345678910111213141516171819202122232425time=&quot;2021-04-17T15:53:04Z&quot; level=info msg=&quot;updated 'aaa' operation (phase: Running)&quot;time=&quot;2021-04-17T15:53:04Z&quot; level=info msg=&quot;Initialized new operation: {&amp;SyncOperation{Revision:5acebc82a613b73b46a09be1b023a1720ea3f7e9,Prune:false,DryRun:false,SyncStrategy:&amp;SyncStrategy{Apply:nil,Hook:&amp;SyncStrategyHook{SyncStrategyApply:SyncStrategyApply{Force:false,},},},Resources:[]SyncOperationResource{},Source:nil,Manifests:[],SyncOptions:[],} {admin false} [] {0 nil}}&quot; application=aaatime=&quot;2021-04-17T15:53:04Z&quot; level=info msg=&quot;Ignore status for CustomResourceDefinitions&quot;time=&quot;2021-04-17T15:53:04Z&quot; level=info msg=&quot;Comparing app state (cluster: https://kubernetes.default.svc, namespace: cc)&quot; application=aaatime=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;getRepoObjs stats&quot; application=aaa build_options_ms=0 helm_ms=0 plugins_ms=0 repo_ms=0 time_ms=560 unmarshal_ms=560 version_ms=0time=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;Ignore status for CustomResourceDefinitions&quot;time=&quot;2021-04-17T15:53:05Z&quot; level=info msg=Syncing application=aaa skipHooks=false started=false syncId=00005-oqqyxtime=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;sync/terminate complete&quot; application=aaa duration=327.6219ms syncId=00005-oqqyxtime=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;updated 'aaa' operation (phase: Failed)&quot;time=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;Sync operation to 5acebc82a613b73b46a09be1b023a1720ea3f7e9 failed: one or more objects failed to apply&quot; application=aaa dest-namespace=cc dest-server=&quot;https://kubernetes.default.svc&quot; reason=OperationCompleted type=Warningtime=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;Refreshing app status (controller refresh requested), level (2)&quot; application=aaatime=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;Ignore status for CustomResourceDefinitions&quot;time=&quot;2021-04-17T15:53:05Z&quot; level=info msg=&quot;Comparing app state (cluster: https://kubernetes.default.svc, namespace: cc)&quot; application=aaatime=&quot;2021-04-17T15:53:06Z&quot; level=warning msg=&quot;Failed to save clusters info: dial tcp 10.103.83.103:6379: connect: connection refused&quot;time=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;getRepoObjs stats&quot; application=aaa build_options_ms=0 helm_ms=0 plugins_ms=0 repo_ms=0 time_ms=696 unmarshal_ms=695 version_ms=0time=&quot;2021-04-17T15:53:06Z&quot; level=error msg=&quot;Failed to cache app resources: dial tcp 10.103.83.103:6379: connect: connection refused&quot; application=aaa dedup_ms=0 diff_ms=64 git_ms=696 health_ms=0 live_ms=0 settings_ms=0 sync_ms=0time=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;Update successful&quot; application=aaatime=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;Reconciliation completed&quot; application=aaa dedup_ms=0 dest-name= dest-namespace=cc dest-server=&quot;https://kubernetes.default.svc&quot; diff_ms=64 fields.level=2 git_ms=696 health_ms=0 live_ms=0 settings_ms=0 sync_ms=0 time_ms=891time=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;Refreshing app status (normal refresh requested), level (2)&quot; application=aaatime=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;Ignore status for CustomResourceDefinitions&quot;time=&quot;2021-04-17T15:53:06Z&quot; level=info msg=&quot;Comparing app state (cluster: https://kubernetes.default.svc, namespace: cc)&quot; application=aaatime=&quot;2021-04-17T15:53:07Z&quot; level=info msg=&quot;getRepoObjs stats&quot; application=aaa build_options_ms=0 helm_ms=0 plugins_ms=0 repo_ms=0 time_ms=745 unmarshal_ms=744 version_ms=0time=&quot;2021-04-17T15:53:07Z&quot; level=error msg=&quot;Failed to cache app resources: dial tcp 10.103.83.103:6379: connect: connection refused&quot; application=aaa dedup_ms=0 diff_ms=0 git_ms=745 health_ms=0 live_ms=0 settings_ms=0 sync_ms=0time=&quot;2021-04-17T15:53:07Z&quot; level=info msg=&quot;Update successful&quot; application=aaatime=&quot;2021-04-17T15:53:07Z&quot; level=info msg=&quot;Reconciliation completed&quot; application=aaa dedup_ms=0 dest-name= dest-namespace=cc dest-server=&quot;https://kubernetes.default.svc&quot; diff_ms=0 fields.level=2 git_ms=745 health_ms=0 live_ms=0 settings_ms=0 sync_ms=0 time_ms=858 根据上面的日志内容，可以大致推测 argocd 对更新 Application CRD 后的处理逻辑。 从日志的第一、二行可以看出，appOperationQueue 被新增了 key。即 processAppOperationQueueItem 从 Queue 中 Get 的操作，脱离堵塞状态，开始执行对 Queue 中事件的处理逻辑。获取到被更新的 Application 的 key（namespace/name）之后，先从 Indexer 中获取到完整的 Application 定义，再开始对它的处理。 12345678910111213141516func (ctrl *ApplicationController) processAppOperationQueueItem() (processNext bool) { appKey, shutdown := ctrl.appOperationQueue.Get() ... obj, exists, err := ctrl.appInformer.GetIndexer().GetByKey(appKey.(string)) ... origApp, ok := obj.(*appv1.Application) ... app := origApp.DeepCopy() if app.Operation != nil { ctrl.processRequestedAppOperation(app) } else if app.DeletionTimestamp != nil &amp;&amp; app.CascadedDeletion() { ... } return} 在其后processRequestedAppOperation的处理中、会先把 Application CRD 的状态以 PATCH 的方式设置成 RUNNING。 1234567state = &amp;appv1.OperationState{ Phase: synccommon.OperationRunning, Operation: *app.Operation, StartedAt: metav1.Now()}ctrl.setOperationState(app, state)logCtx.Infof(&quot;Initialized new operation: %v&quot;, *app.Operation) 然后开始同步状态 1ctrl.appStateManager.SyncAppState(app, state) 再设置为同步之后的状态 1ctrl.setOperationState(app, state) SyncAppState在这一步、基本上将同步所做的事情干完了。 GetAppProject获取 AppProject CRD 用来作为 CompareAppState 的入参。 CompareAppState对比 Git 仓库中 yaml 与 k8s 中在跑资源的 yaml。这里会返回一个 comparisonResult，其中包含 DiffResultList、ReconciliationResult。 调用 gRPC 接口获取指定 commit id 的 yaml，得到一个 targetObjs，内容为 []*unstructured.Unstructured 由 [] string 转换而来。 在获取到 Git 仓库最新的 yaml 后，会对 yaml 中的资源进行一次去重，重复的判定标准为：G/K/Namespace/Name，去重之后，保证相同的标准的资源的数量为1。 12targetObjs, dedupConditions, err := DeduplicateTargetObjects(app.Spec.Destination.Namespace, targetObjs, infoProvider) 在资源去重后、会根据过滤规则、再对资源进行一次过滤。 再从 k8s 集群(本地缓存)中获取当前应用的资源。得到一个 liveObjByKey，它是一个 Map，结构为：map[kube.ResourceKey]*unstructured.Unstructured。 1liveObjByKey, err := m.liveStateCache.GetManagedLiveObjs(app, targetObjs) 过滤掉liveObjByKey中不允许出现的资源 Reconcile产生了一个规律比较奇怪的数据结构、可能是后续使用到这个数据结构的时候、也会遵照某种规律。其实主要是用于 Diff，可以简单理解：对新增的资源，live 中没有，因此对比的时候它的值应该为 nil，而 target 中有具体值，这样就能显示出 git diff 中新增文件时的展示效果：一边有值、一边没有值。 将 liveObjByKey 中的 uid 相同的资源全部删除、只留1个。（前提是：targetObjs中也含有相同的资源） target 增加几个 nil 值，个数为 target 中存在、但是 live 里面不存在的资源个数。 managedLiveObj 基本等同 liveObj、具体为 target 中有、但 live 中没有。 返回的数据结构： 12345return ReconciliationResult{ Target: targetObjs, Hooks: hooks, Live: managedLiveObj,} Diff这里有一个分支、但不论走哪个分支，都会调用 diff.Diff() 方法。 123456if noCache || specChanged || revisionChanged || m.cache.GetAppManagedResources(app.Name, &amp;cachedDiff) != nil { // (rare) cache miss diffResults, err = diff.DiffArray(reconciliation.Target, reconciliation.Live, diffOpts...)} else { diffResults, err = m.diffArrayCached(reconciliation.Target, reconciliation.Live, cachedDiff, diffOpts...)} 在 Diff() 方法中，存在 ThreeWayDiff 和 TwoWayDiff 这两种方式。看 label 来决定。最终结果得到一个类似于 git diff 的结果列表（每个资源有一个 Diff）。 sync.NewSyncContext这个方法里面初始化了一个 syncContext 其中它的 resource 值是通过一个 roupResources(reconciliationResult) 方法获取到。它的处理逻辑如下： 123456789101112func groupResources(reconciliationResult ReconciliationResult) map[kubeutil.ResourceKey]reconciledResource { resources := make(map[kube.ResourceKey]reconciledResource) for i := 0; i &lt; len(reconciliationResult.Target); i++ { res := reconciledResource{ Target: reconciliationResult.Target[i], Live: reconciliationResult.Live[i], } ... resources[kube.GetResourceKey(obj)] = res } return resources} 返回的是一个以 G/K/NS/NAME 为键，以 reconciledResource 为值的 Map，也就是说此 map 中同时含有修改前、修改后的 yaml 内容。 syncCtx.Sync() 获取到 task。task 中包含 syncTask 列表，包含 targetObj 与 liveObj。 对每个 task 执行 dry-run，来检查 yaml 是否存在错误。失败则直接退出。 启动所有任务 1runState := sc.runTasks(tasks, false) 先执行 prene 任务（task.targetObj 为空），最终调用 kubectl delete，并等待所有任务执行完成。 在执行应用最新的 yaml 前，会将部分符合要求的待更新资源（task.liveObj）先执行删除操作、在进行 apply。 部分符合要求的待更新资源： 123func (t *syncTask) deleteBeforeCreation() bool { return t.liveObj != nil &amp;&amp; t.pending() &amp;&amp; t.hasHookDeletePolicy(common.HookDeletePolicyBeforeHookCreation)}","link":"/2021/05/16/65dbfe09c7bd.html"},{"title":"Argo CD 从入门教程来看其架构","text":"本文的目标是能对 Argo CD 基本操作有一定的了解，同时可以对 Argo CD 的架构、组成有一定的认识。 准备 kubectl kubernetes 集群 安装12kubectl create namespace argocdkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 执行完上述命令后，会创建一个 argocd 命名空间，并将所有的 argo cd 服务都安装在该命名空间下。 使用先获取用户名和登陆密码 用户名：admin 登陆密码（可通过如下方式获得） 1kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&quot;{.data.password}&quot; | base64 -d 再将本地 8080 端口转发到 Argo CD 的 argocd-server 服务 1kubectl port-forward svc/argocd-server -n argocd 8080:443 接下来可以通过两种方式来操作运行在 kubernetes 集群中的 Argo CD 服务，分别为： Web UI 方式 打开浏览器，输入 localhost:8080/，选择相信证书，输入用户名、密码即可登陆。 Command CLI 方式 安装 argocd 命令行： 1brew install argocd 通过命令行登陆： 1argocd login localhost:8080 按提示输入即可。 更进一步apply yaml 时的输出如下： 12345678910111213141516171819202122232425262728293031323334353637383940customresourcedefinition.apiextensions.k8s.io/applications.argoproj.io createdcustomresourcedefinition.apiextensions.k8s.io/appprojects.argoproj.io createdserviceaccount/argocd-application-controller createdserviceaccount/argocd-dex-server createdserviceaccount/argocd-redis createdserviceaccount/argocd-server createdrole.rbac.authorization.k8s.io/argocd-application-controller createdrole.rbac.authorization.k8s.io/argocd-dex-server createdrole.rbac.authorization.k8s.io/argocd-redis createdrole.rbac.authorization.k8s.io/argocd-server createdclusterrole.rbac.authorization.k8s.io/argocd-application-controller createdclusterrole.rbac.authorization.k8s.io/argocd-server createdrolebinding.rbac.authorization.k8s.io/argocd-application-controller createdrolebinding.rbac.authorization.k8s.io/argocd-dex-server createdrolebinding.rbac.authorization.k8s.io/argocd-redis createdrolebinding.rbac.authorization.k8s.io/argocd-server createdclusterrolebinding.rbac.authorization.k8s.io/argocd-application-controller createdclusterrolebinding.rbac.authorization.k8s.io/argocd-server createdconfigmap/argocd-cm createdconfigmap/argocd-gpg-keys-cm createdconfigmap/argocd-rbac-cm createdconfigmap/argocd-ssh-known-hosts-cm createdconfigmap/argocd-tls-certs-cm createdsecret/argocd-secret createdservice/argocd-dex-server createdservice/argocd-metrics createdservice/argocd-redis createdservice/argocd-repo-server createdservice/argocd-server createdservice/argocd-server-metrics createddeployment.apps/argocd-dex-server createddeployment.apps/argocd-redis createddeployment.apps/argocd-repo-server createddeployment.apps/argocd-server createdstatefulset.apps/argocd-application-controller creatednetworkpolicy.networking.k8s.io/argocd-application-controller-network-policy creatednetworkpolicy.networking.k8s.io/argocd-dex-server-network-policy creatednetworkpolicy.networking.k8s.io/argocd-redis-network-policy creatednetworkpolicy.networking.k8s.io/argocd-repo-server-network-policy creatednetworkpolicy.networking.k8s.io/argocd-server-network-policy created 这个 yaml 文件 中所包含的资源如下： 可以从中看出，其主要功能的是 5 个组件，分别为： argocd-server 与外界进行交互，所有流量的入口。包括 Web UI 流量入口、Command CLI 流量入口以及相应 Git 仓库的 Webhook事件等。可通过上述使用过程中的 port-forward 来理解，我们只需要将该模块的 443 端口映射处理便可以使用这个 Argo CD 的功能。 argocd-dex-server Argo CD 内部所使用到的工具 argocd-repo-server 在本地维护 Git 仓库缓存，并生成 yaml argocd-application-controller kubernetes controller，持续监听 application crd 并比较当前状态（集群中的状态）与所期望状态（Git 仓库中所定义的状态）。 argocd-redis Argo CD 内部所使用到的缓存数据库 因此可以看出，argocd-server + argocd-dex-server 就组成了下面架构图中的 API 部分： 还有一个有意思的地方：Argo CD 相关的 3 个 Deployment 及 1 个 StatefulSet 所使用的镜像是一样的。这里需要涉及到它的打包方式，可以从源码中看出：Argo CD 服务所使用的二进制是相同的，但他们的启动命令不同；不同的启动命令对应不同的功能组（可通过 源文件 查看）。 12345678910111213141516171819202122232425262728293031const binaryNameEnv = &quot;ARGOCD_BINARY_NAME&quot;func main() { var command *cobra.Command binaryName := filepath.Base(os.Args[0]) if val := os.Getenv(binaryNameEnv); val != &quot;&quot; { binaryName = val } switch binaryName { case &quot;argocd&quot;, &quot;argocd-linux-amd64&quot;, &quot;argocd-darwin-amd64&quot;, &quot;argocd-windows-amd64.exe&quot;: command = cli.NewCommand() case &quot;argocd-util&quot;, &quot;argocd-util-linux-amd64&quot;, &quot;argocd-util-darwin-amd64&quot;, &quot;argocd-util-windows-amd64.exe&quot;: command = util.NewCommand() case &quot;argocd-server&quot;: command = apiserver.NewCommand() case &quot;argocd-application-controller&quot;: command = appcontroller.NewCommand() case &quot;argocd-repo-server&quot;: command = reposerver.NewCommand() case &quot;argocd-dex&quot;: command = dex.NewCommand() default: // ... } if err := command.Execute(); err != nil { fmt.Println(err) os.Exit(1) }} 新建一个 Application 之后，可以在 Web UI 里面看到新建的应用及其状态如下： 其中所展示的状态均来自对应的 CRD，如下： 详情如下： 1234567891011121314151617181920212223242526272829303132333435spec: destination: namespace: nginx-ns server: 'https://kubernetes.default.svc' project: default source: path: nginx repoURL: 'https://xxxxxxxx/argocd-yamls.git' targetRevision: HEADstatus: health: status: Missing reconciledAt: '2021-06-17T07:30:33Z' resources: - group: apps health: status: Missing kind: Deployment name: nginx-deployment namespace: nginx-ns status: OutOfSync version: v1 sourceType: Directory summary: {} sync: comparedTo: destination: namespace: nginx-ns server: 'https://kubernetes.default.svc' source: path: nginx repoURL: 'https://xxxxxxxx/argocd-yamls.git' targetRevision: HEAD revision: 5acebc82a613b73b46a09be1b023a1720ea3f7e9 status: OutOfSync Reference https://argoproj.github.io/argo-cd https://argoproj.github.io/argo-cd/getting_started","link":"/2021/06/17/593a83dfbda4.html"},{"title":"Argo CD 创建 Application 时的逻辑分析","text":"在 Argo CD 里面，同时提供了 HTTP 接口（Web UI）、gRPC 接口（Command CLI），但是只用到了一个端口，并且实现逻辑的代码是同一份代码，是怎么做到的呢？创建应用时都做了哪些操作逻辑？ 请求跟踪当在 Argo CD 的 Web UI 页面中，创建一个 Application 时，会发出一个 HTTP 请求，详情如下： 翻开 Argo CD 的源代码，跟踪到服务的创建。由于是 HTTP 请求，所以入口模块为：argocd-server，即入口处为：cmd/argocd-server/commands/argocd_server.go 的 NewCommand() 函数。可以看出其中启动一个 server 的代码在： 路径：cmd/argocd-server/commands/argocd_server.go 的 154 行 argocd.Run(...) Run() 方法中主要的代码逻辑如下： 12345678910111213141516171819202122232425262728// 创建 gRPC 服务grpcS := a.newGRPCServer()// gRPC 服务被包装成了 Web 服务grpcWebS := grpcweb.WrapServer(grpcS)var httpS *http.Servervar httpsS *http.Serverif a.useTLS() { httpS = newRedirectServer(port, a.RootPath) // 竟然传递了 gRPC 包装后的 Web 服务 httpsS = a.newHTTPServer(ctx, port, grpcWebS)} else { httpS = a.newHTTPServer(ctx, port, grpcWebS)}// ...// Cmux is used to support servicing gRPC and HTTP1.1+JSON on the same porttcpm := cmux.New(conn)//...// 启动 gRPC 和 HTTP 服务go func() { a.checkServeErr(&quot;grpcS&quot;, grpcS.Serve(grpcL)) }()go func() { a.checkServeErr(&quot;httpS&quot;, httpS.Serve(httpL)) }()if a.useTLS() { go func() { a.checkServeErr(&quot;httpsS&quot;, httpsS.Serve(httpsL)) }() go func() { a.checkServeErr(&quot;tlsm&quot;, tlsm.Serve()) }()} 这一块代码看着有点凌乱，但是从零零总总的信息中抽离出下列信息： gRPC 和 HTTP 共用了一个端口 没有找到 HTTP 接口的定义处 看起来 gRPC 与 HTTP 服务之间存在一个映射关系 gRPC 与 HTTP 服务之间的映射关系具体为什么样？怎么样才能搞清楚其中的关联关系？ 这是当时的问题，怀着这个问题，去搜了一下相关的关键字。 经过一段时间的信息搜集，锁定了一个叫做 grpc-gateway 的一个项目，可以实现上面所列出的 3 个问题点。并且通过对该项目中 示例 proto 文件 的观察，初步锁定 gRPC 与 HTTP 接口之间的关联关系就在 proto 文件中。 1234567891011121314151617181920212223// Echo service responds to incoming echo requests.service EchoService { // EchoBody method receives a simple message and returns it. rpc EchoBody(SimpleMessage) returns (SimpleMessage) { option (google.api.http) = { post: &quot;/v1/example/echo_body&quot; body: &quot;*&quot; }; } // EchoDelete method receives a simple message and returns it. rpc EchoDelete(SimpleMessage) returns (SimpleMessage) { option (google.api.http) = { delete: &quot;/v1/example/echo_delete&quot; }; } // EchoPatch method receives a NonStandardUpdateRequest and returns it. rpc EchoPatch(DynamicMessageUpdate) returns (DynamicMessageUpdate) { option (google.api.http) = { patch: &quot;/v1/example/echo_patch&quot; body: &quot;body&quot; }; }} 因此只要找到相关 proto 的定义即可找到对应关系，也就找到了相应接口的实现代码。 grpc-gateway项目地址：https://github.com/grpc-ecosystem/grpc-gateway 实现逻辑在源码中搜索 *.proto 可以看到 application.proto，并且可以找到 /api/v1/applications 接口对应的 rpc 方法（路径为：server/application/application.proto）： 123456789101112message ApplicationCreateRequest { required github.com.argoproj.argo_cd.v2.pkg.apis.application.v1alpha1.Application application = 1 [(gogoproto.nullable) = false]; optional bool upsert = 2; optional bool validate = 3;}// Create creates an applicationrpc Create (ApplicationCreateRequest) returns (github.com.argoproj.argo_cd.v2.pkg.apis.application.v1alpha1.Application) { option (google.api.http) = { post: &quot;/api/v1/applications&quot; body: &quot;application&quot; };} 并且在同目录下找到相应的实现 application.go（路径为：server/application/application.go），其接口入参与返回值如下： 1func (s *Server) Create(ctx context.Context, q *application.ApplicationCreateRequest) (*appv1.Application, error) {...} 入参和响应的结构都是 Application CRD，与 Web UI 中的请求一致。其逻辑大致如下： 123456789101112131415161718// 校验是否有权限操作s.enf.EnforceErr(ctx.Value(&quot;claims&quot;), rbacpolicy.ResourceApplications, rbacpolicy.ActionCreate, appRBACName(q.Application));// ① 加锁 + 解锁s.projectLock.RLock(q.Application.Spec.Project)defer s.projectLock.RUnlock(q.Application.Spec.Project)// 校验用户输入是否合法err := s.validateAndNormalizeApp(ctx, &amp;a, validate)// 创建 Application CRDcreated, err := s.appclientset.ArgoprojV1alpha1().Applications(s.ns).Create(ctx, &amp;a, metav1.CreateOptions{})// 产生 Events.logAppEvent(created, ctx, argo.EventReasonResourceCreated, &quot;created application&quot;)// ② 等待缓存刷新s.waitSync(created) ① 加、解锁时是 RWLock，非分布式锁 ② 等待缓存刷新时，是通过一个 死循环 + deadline 来实现 1234567891011121314151617181920212223func (s *Server) waitSync(app *appv1.Application) { logCtx := log.WithField(&quot;application&quot;, app.Name) deadline := time.Now().Add(informerSyncTimeout) minVersion, err := strconv.Atoi(app.ResourceVersion) if err != nil { logCtx.Warnf(&quot;waitSync failed: could not parse resource version %s&quot;, app.ResourceVersion) time.Sleep(50 * time.Millisecond) // sleep anyways return } for { if currApp, err := s.appLister.Get(app.Name); err == nil { currVersion, err := strconv.Atoi(currApp.ResourceVersion) if err == nil &amp;&amp; currVersion &gt;= minVersion { return } } if time.Now().After(deadline) { break } time.Sleep(20 * time.Millisecond) } logCtx.Warnf(&quot;waitSync failed: timed out&quot;)} 此时，kubernetes 中便存在了一个名为 first-app Application CRD。 Reference https://segmentfault.com/a/1190000013339403","link":"/2021/06/17/2461a3728194.html"},{"title":"ArrayList源代码分析","text":"此篇主要解析 ArrayList 的源码处理逻辑 继承关系 几个有意思的参数12345678910// 默认初始容量private static final int DEFAULT_CAPACITY = 10;// 共享空数组private static final Object[] EMPTY_ELEMENTDATA = {};// 同上private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};// 指向实际存储数据的数组transient Object[] elementData;// 当前列表中所含元素的个数private int size; 为什么会有两个空数组源代码中的解释：为了在添加第一个元素时，确定初始空间的大小。此话怎讲？先从上述两变量的引用处说起。初始化一个 ArrayList 对象的构造函数有 3 个，分别如下 1234567891011121314151617181920212223242526272829// 不带任何参数public ArrayList() { // 当第一次添加元素时，元素个数小于10，初始容量置为10 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;}// 指明容器初始容量public ArrayList(int initialCapacity) { if (initialCapacity &gt; 0) { // 初始化成指定的容量 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); }}// 从集合中添加public ArrayList(Collection&lt;? extends E&gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; }} 可以看出，只有没有指明容量的情况下，才会使用 DEFAULTCAPACITY_EMPTY_ELEMENTDATA。且在添加第一个元素时，会进行相应的判断，如果为 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 就会使用默认的容量 10。 123456789101112public boolean add(E e) { ensureCapacityInternal(size + 1); elementData[size++] = e; return true;}private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } // 由此看来，初始化的容量会因为上述两个空数组的不同而不同 ensureExplicitCapacity(minCapacity);} 那为什么不能在 ArrayList() 中使用 EMPTY_ELEMENTDATA 呢？因为这样会与 ArrayList(int initialCapacity) 一样，但后者必须初始化成指定的容量，如 0。 为什么可以序列化却使用了transient修饰elementData数组中所有的容量并非一直都被元素占用，可能会存在此数组大部分空间并未使用的情况，此时序列化所有的元素会比较浪费空间。因此在这里源码选择的是，将所有添加的元素，进行序列化。 123456789101112private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) { s.writeObject(elementData[i]); } // ...} 对于new ArrayList()和new ArrayList(0)之间的差别是什么添加第一个元素之后，容量不一样。 增加元素增加元素到list当中，也就是我们常用的add()。有两种增加方式，一种是添加元素到尾端： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 添加到列表的尾部public boolean add(E e) { ensureCapacityInternal(size + 1); // 此时elementData的长度已经被保证可以存下当前元素 elementData[size++] = e; return true;}// 此函数的主要作用是确定列表初始容量private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); }// 此处的解析如前面对初始容量那块所述 ensureExplicitCapacity(minCapacity);}// 检测是否需要扩容private void ensureExplicitCapacity(int minCapacity) { modCount++; //当前的minCapacity为size+1或10，所以当此条件成立时，说明再不扩容 //将有可能导致溢出 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);}// 扩容private void grow(int minCapacity) { // 防止溢出 int oldCapacity = elementData.length; // 右移1位，变成一半，因此此时的容量变成了之前的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 若新的容量比所需要的最小容量小，那么将新容量改成最小所需容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 若新的容量比MAX_ARRAY_SIZE大 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 分配新的数组，并将原数据拷贝到其中 elementData = Arrays.copyOf(elementData, newCapacity);}private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private static int hugeCapacity(int minCapacity) { // 此时已超过Integer.MAX_VALUE，变成负数，溢出 if (minCapacity &lt; 0) throw new OutOfMemoryError(); // 到这一步，有两个原因： // 1. 通过扩容至原来的1.5倍，引起比MAX_ARRAY_SIZE大； // 2. 此次加入的元素数量太多，以至于1.5倍的扩容也不能满足。 return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE :// 此处为第二种情况 MAX_ARRAY_SIZE;// 此处为第一种情况} 一种是将元素添加元素到列表中的某一位置。 123456789101112// 添加到列表中的某个位置public void add(int index, E element) { rangeCheckForAdd(index);// 检查index是否合理，比如说超出当前size以及小于0 ensureCapacityInternal(size + 1); // 如前所述 // 将elementData中从index起的size-index个元素，依次拷贝到elementData中index+1起后续位置上 // 简而言之，就是从index位起，整体后移1位 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 复制到目标位置上 elementData[index] = element; size++;} 删除元素删除确定元素（删除最先加入的那个元素，如果存在的话） 1234567891011121314151617181920212223242526public boolean remove(Object o) { if (o == null) {// 为什么要做这个判断？为避免NullPointer for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { // 遍历全部元素，找到第一个相同的，将其删除 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;}private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; // 大于0说明：所删除的不是最后一项 // 因为其最多等于0，且为0时index为最后一项，即size - 1 == index. if (numMoved &gt; 0)// 从index+1项起，整体前移1位 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; //注意：此处置空的是最后一位。} 删除指定下标的元素 1234567891011public E remove(int index) { rangeCheck(index);//不要超过size modCount++; E oldValue = elementData(index);//先取出元素。为负数，如何处理？ int numMoved = size - index - 1;//计算其位置 if (numMoved &gt; 0) // 同前述 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // 同前述 return oldValue;//返回所删除的元素} 批量删除元素。这两个函数的唯一差别在于传给batchRemove()的第二个参数，前者为false，后者为true。它们之间的差距，我们可以通过后续源码进行分析。 12345678public boolean removeAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c);// 处理为null情况 return batchRemove(c, false);}public boolean retainAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c);// 处理为null情况 return batchRemove(c, true);} 批量处理删除 1234567891011121314151617181920212223242526272829303132private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) { final Object[] elementData = this.elementData;// 指向当前list元素数组 int r = 0, w = 0; boolean modified = false; try { for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; // 体现差距的地方，就在这里：对于elementData中的每个元素， // complement为true：c中存在，则将其移动到最前端；c中不存在，略过。 // 为false：c中存在，略过；c中不存在，保留。 } finally { // r未达到size，说明中途遇到错误 if (r != size) { // 将r到size的元素，保存到w后面 System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; } // w未达到size，说明需要删除某些元素；==size说明，全部保留，不作处理。 if (w != size) { // 从w位开始，到size-1，全部置为空 for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; } } return modified;} 清空列表1234567public void clear() { modCount++; for (int i = 0; i &lt; size; i++) elementData[i] = null;// 全部置空 size = 0; } 查询访问非常便捷。 1234567public E get(int index) { rangeCheck(index); return elementData(index);}E elementData(int index) { return (E) elementData[index];} 修改修改同样非常便捷。 123456public E set(int index, E element) { rangeCheck(index); E oldValue = elementData(index); elementData[index] = element;//更新 return oldValue;//返回之前的值} 关键的一些操作，感觉已经摸得差不多了。其它的一些查询、更新，都比较简单。","link":"/2018/05/30/ff59e7b8bcf8.html"},{"title":"ButterKnife官方使用指南","text":"看到了ButterKnife之后，感觉它实在是太棒了，可以省略掉一大堆无趣的findViewById()，整个代码看起来都舒服多了。这篇使用说明来自它的官方网站的简易介绍，用起来非常简单，但是也是有挺多的情况，所以还是觉得自己翻译出来，方便以后查阅吧！ 使用@BindView和ID注解相应的变量，ButterKnife就会在你的layout文件中找到所对应的View并赋值给它。 123456789101112class ExampleActivity extends Activity { @BindView(R.id.title) TextView title; @BindView(R.id.subtitle) TextView subtitle; @BindView(R.id.footer) TextView footer; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.simple_activity); ButterKnife.bind(this); // TODO Use fields... }} 上面例子中，所生成的代码大致与下面代码等同： 12345public void bind(ExampleActivity activity) { activity.subtitle = (android.widget.TextView) activity.findViewById(2130968578); activity.footer = (android.widget.TextView) activity.findViewById(2130968579); activity.title = (android.widget.TextView) activity.findViewById(2130968577);} 资源绑定使用@BindBool, @BindColor, @BindDimen, @BindDrawable, @BindInt, @BindString与一个对应的ID来绑定定义好的资源， 1234567class ExampleActivity extends Activity { @BindString(R.string.title) String title; @BindDrawable(R.drawable.graphic) Drawable graphic; @BindColor(R.color.red) int red; // int or ColorStateList field @BindDimen(R.dimen.spacer) Float spacer; // int (for pixel size) or float (for exact value) field // ...} 非ACTIVITY绑定我们还可以在已知View的情况下，在任意的对象中，绑定该View中所含有的控件。比如在Fragment中： 1234567891011public class FancyFragment extends Fragment { @BindView(R.id.button1) Button button1; @BindView(R.id.button2) Button button2; @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) { View view = inflater.inflate(R.layout.fancy_fragment, container, false); ButterKnife.bind(this, view); // TODO Use fields... return view; }} 另外一个是在ViewHolder中： 1234567891011121314151617181920212223242526public class MyAdapter extends BaseAdapter { @Override public View getView(int position, View view, ViewGroup parent) { ViewHolder holder; if (view != null) { holder = (ViewHolder) view.getTag(); } else { view = inflater.inflate(R.layout.whatever, parent, false); holder = new ViewHolder(view); view.setTag(holder); } holder.name.setText(&quot;John Doe&quot;); // etc... return view; } static class ViewHolder { @BindView(R.id.title) TextView name; @BindView(R.id.job_title) TextView jobTitle; public ViewHolder(View view) { ButterKnife.bind(this, view); } }} 其它的绑定方式可使用Activity当做一个根View可以绑定任何对象。如果你使用了MVC模式，你可以使用ButterKnife.bind(this, activity)来绑定Controller。可使用ButterKnife.bind(this)来绑定一个View里面的子View。如果你在layout文件中使用了&lt;merge&gt;标签并且在View的构造器中填充，你可以在这之后立马调用它。或者，你也可以在onFinishInflate()回调中调用。 VIEW LISTS将所需要的控件，全部填充到一个List中。 12@BindViews({ R.id.first_name, R.id.middle_name, R.id.last_name })List&lt;EditText&gt; nameViews; apply()方法可以对List中所有的View执行某个操作。 12ButterKnife.apply(nameViews, DISABLE);ButterKnife.apply(nameViews, ENABLED, false); 可以指定一些简单的动作。 12345678910static final ButterKnife.Action&lt;View&gt; DISABLE = new ButterKnife.Action&lt;View&gt;() { @Override public void apply(View view, int index) { view.setEnabled(false); }};static final ButterKnife.Setter&lt;View, Boolean&gt; ENABLED = new ButterKnife.Setter&lt;View, Boolean&gt;() { @Override public void set(View view, Boolean value, int index) { view.setEnabled(value); }}; 当然也可以在apply()方法中指定一个Android中控件的属性名。 ButterKnife.apply(nameViews, View.ALPHA, 0.0f); 绑定LISTENER监听器也可以自动配置到相应的View上。 1234@OnClick(R.id.submit)public void submit(View view) { // TODO submit data to server...} 监听器函数的参数都是可选的。 1234@OnClick(R.id.submit)public void submit() { // TODO submit data to server...} 指定一个确定的类型，它将会被自动转换成之。 1234@OnClick(R.id.submit)public void sayHi(Button button) { button.setText(&quot;Hello!&quot;);} 还可以为将一个监听器函数，绑定到多个控件上。 12345678@OnClick({ R.id.door1, R.id.door2, R.id.door3 })public void pickDoor(DoorView door) { if (door.hasPrizeBehind()) { Toast.makeText(this, &quot;You win!&quot;, LENGTH_SHORT).show(); } else { Toast.makeText(this, &quot;Try again&quot;, LENGTH_SHORT).show(); }} 自定义View时，绑定自己的监听器函数不需要设置ID。 123456public class FancyButton extends Button { @OnClick public void onClick() { // TODO do something! }} 重置绑定Fragment和Activity的生命周期不同。当在Fragment的onCreateView()中使用了绑定，就需要在onDestroyView()中将变量置为null。ButterKnife在调用绑定时会返回一个Unbinder的实例，在适当的生命周期回调中，调用这个实例的unbind()方法。 1234567891011121314151617public class FancyFragment extends Fragment { @BindView(R.id.button1) Button button1; @BindView(R.id.button2) Button button2; private Unbinder unbinder; @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) { View view = inflater.inflate(R.layout.fancy_fragment, container, false); unbinder = ButterKnife.bind(this, view); // TODO Use fields... return view; } @Override public void onDestroyView() { super.onDestroyView(); unbinder.unbind(); }} 其它绑定通常@Bind和监听器绑定都是必须的。如果在目标View中为找到相应ID的控件，则会抛出异常。 为了抑制住这中异常，创建一个可选的绑定，可以使用@Nullable或@Optional来注解变量或方法。 注 : 可使用任何名为@Nullable的注解来注解变量，但推荐Android support-annotations中的@Nullable 。 12345@Nullable @BindView(R.id.might_not_be_there) TextView mightNotBeThere;@Optional @OnClick(R.id.maybe_missing) void onMaybeMissingClicked() { // TODO ...} 多方法监听器可在注解中加入参数来区分。 123456789@OnItemSelected(R.id.list_view)void onItemSelected(int position) { // TODO ...}@OnItemSelected(value = R.id.maybe_missing, callback = NOTHING_SELECTED)void onNothingSelected() { // TODO ...} 下载GRADLE12compile 'com.jakewharton:butterknife:(insert latest version)'annotationProcessor 'com.jakewharton:butterknife-compiler:(insert latest version)'","link":"/2018/04/07/2983ade087a2.html"},{"title":"C++中引用、指针与const","text":"const与引用别名。一初始化，就必须指向某个对象，不能指向引用。 1234567891011121314151617int ival = 1024;int &amp;refVal = ival;refVal = 1;cout &lt;&lt; &quot;ival = &quot; &lt;&lt; ival &lt;&lt; &quot;, refVal = &quot; &lt;&lt; refVal &lt;&lt; endl;const int ci = 1024;const int &amp;r1 = ci;// r1 = 42; 不能修改const int r2 = ival;// r2 = 2048; 不能通过r2修改ivalint i = 1024;int *p = &amp;i;int *&amp;refVal2 = p; // refVal2是一个引用，它引用的对象是一个指针，指向int类型。cout &lt;&lt; *refVal2 &lt;&lt; endl; const与指针指向常量的指针（pointer to const）不能用于修改其所指对象的值，常量对象的指针，只能使用指向常量的指针。 1234567891011const double pi = 3.14;//double *ptr = π 需要指向一个double常量const double *cptr = π//*cptr = 42; 不能通过此指针修改值double dval = 3.14;cptr = &amp;dval;//*cptr = 3.15; 不能通过此指针修改值cout &lt;&lt; *cptr &lt;&lt; endl;...3.14 const指针常量指针必须初始化，且初始化完成后，其值不能再改变，也就是说只能一直指向某一个地址。可以通过此指针改变所指向对象的值。 12345678 int errNumb = 0; int *const curErr = &amp;errNumb; // 只能指向errNumb *curErr = 1; // 可修改所指向的对象 const double pi = 3.14159; const double pi2 = 3.14159; const double *const pip = π//pip = &amp;pi2; //❌pip的值不能修改 从右往左法则以const double *const pip = &amp;pi为例，离pip最近的是const，说明pip本身的值不能改变，在往左，pip的类型是一个指针，说明pip是一个常量指针；在往左，说明pip是一个常量指针，它指向的对象是double类型；再往左，说明pip是一个常量指针，它指向的对象是一个double型常量的。","link":"/2018/05/24/1e33322920cb.html"},{"title":"CentOS7中FTP服务器的搭建","text":"安装1sudo yum -y install vsftpd 配置首先要新建一个目录，用来充当主目录，然后再新建一个不可登录的用户，指定主目录为之前创建的目录。 1234sudo mkdir /home/ftpfile # 新建目录sudo useradd ftpuser -d /home/ftpfile -s /sbin/nologin # 新建不可登录用户sudo chown -R ftpuser.ftpuser /home/ftpfile # 将归属改成新用户sudo passwd ftpuser # 给新用户设密码 配置可用来登录ftp服务器的用户 12345# 将上面新建的用户名填写进去，然后保存退出sudo vim /etc/vsftpd/chroot_list # 显示结果如下：[asahi@localhost ~]$ cat /etc/vsftpd/chroot_listftpuser 打开vsftpd的配置文件，位置为：/etc/vsftpd/vsftpd.conf 12345678910111213141516# 登录成功时的欢迎信息ftpd_banner=Welcome to blah FTP service.# 登录用户的主页目录local_root=/home/ftpfile# 匿名用户的主页目录anon_root=/home/ftpfile# 不允许匿名登录，可考虑删除/注释上面一条anonymous_enable=NO# 使用本地时间use_localtime=YES# 参考一些遇到的问题的解释allow_writeable_chroot=YES# 设置可登录的账号chroot_local_user=NOchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_list # 指向之前创建的chroot_list文件 启动/重启/关闭vsftpd服务 1234sudo systemctl start vsftpd.servicesudo systemctl restart vsftpd.servicesudo systemctl stop vsftpd.servicesudo systemctl status vsftpd.service 一些遇到的问题ftp相关端口无法访问：因其防火墙设置的原因，相应的端口未开放，所以开启ftp服务后没办法访问。在CentOS7中可以参考下面的设置，来将ftp所需要的一些端口，加入防火墙的开放端口中： 1234567891011# 暫時開放 ftp 服務firewall-cmd --add-service=ftp# 永久開放 ftp 服務firewall-cmd --add-service=ftp --permanent# 永久關閉firewall-cmd --remove-service=ftp --permanent# 讓設定生效systemctl restart firewalld **vsftpd：500 OOPS: vsftpd: refusing to run with writable root inside chroot ()**：从2.3.5之后，vsftpd增强了安全检查，如果用户被限定在了其主目录下，则该用户的主目录不能再具有写权限了！如果检查发现还有写权限，就会报该错误。要修复这个错误，可以用命令chmod a-w /home/user去除用户主目录的写权限，注意把目录替换成你自己的。或者你可以在vsftpd的配置文件中增加下列两项中的一项：allow_writeable_chroot=YES Mac中没有ftp命令如何解决：10.13 以后就没了……..这样操作亲测可以恢复 123brew install telnet brew install inetutils brew link --overwrite inetutils 参考：https://blog.csdn.net/bluishglc/article/details/42399439http://blog.sina.com.cn/s/blog_43b39e250102v4zt.htmlhttps://blog.csdn.net/zwlww1/article/details/78994698","link":"/2018/09/02/023a972f6440.html"},{"title":"CentOS7中Redis的安装与基本配置","text":"安装123sudo yum install redis # 看yum源中是否有redis，我试的没有。不过应该是没有的，要从源码编译安装sudo yum install epel-release # 下载fedora的epel库sudo yum install redis # 再次安装 启动、关闭、连接123456789101112# 启动redisservice redis start# 停止redisservice redis stop# 查看redis运行状态service redis status# 查看redis进程ps -ef | grep redis# 进入本机redisredis-cli# 列出所有keykeys * 配置开机启动 12# 设置redis为开机自动启动chkconfig redis on 从防火墙开放端口12sudo firewall-cmd --zone=public --add-port=6379/tcp --permanent # 开放6379端口sudo firewall-cmd --reload # 重新加载配置 开启远程访问默认是只能在本机访问、所以通过网络访问需要额外的配置。配置文件的目录在：/etc/redis.conf。然后分别修改下面两处配置： 测试12345678910111213import redis.clients.jedis.Jedis;public class TestRedis { public static void main(String[] args) { Jedis redis = new Jedis(&quot;192.168.102.6&quot;); System.out.println(redis.ping()); }}/* 输出：* PONG* * Process finished with exit code 0* / 参考：https://www.cnblogs.com/rslai/p/8249812.htmlhttps://blog.csdn.net/xujian_2001/article/details/78927706","link":"/2018/09/14/76004c683377.html"},{"title":"CentOS7中安装MySQL的详细过程以及配置","text":"首先使用yum安装mariadb，它是MySQL的一个分支。 12sudo yum install -y mariadb-server # 安装mariadbrpm -qa | grep mariadb # 查看mariadb已安装的相关包 要连上数据库，就得先启动它。所以先尝试下面的启动命令。 1234systemctl start mariadb.service #启动服务systemctl enable mariadb.service #设置开机启动systemctl restart mariadb.service #重新启动systemctl stop mariadb.service #停止MariaDB 启动后，在命令行中输入mysql -u root -p，root密码默认为空，直接按回车即可。此时的密码为空，先设置一个密码，方法有多种，如下： 12345678910111213141.用root 进入mysql后mysql&gt;set password =password('你的密码');# 或者mysql&gt;set password for root@localhost = password('hellomysql');mysql&gt;flush privileges;2.使用GRANT语句 mysql&gt;grant all on *.* to 'root'@'localhost' IDENTIFIED BY '你的密码'with grant option ;mysql&gt;flush privileges;3.进入mysql库修改user表mysql&gt;use mysql;mysql&gt;update user set password=password('你的密码') where user='root'; mysql&gt;flush privileges; 如果要从局域网中访问数据库，那么需要紧接着进行下面的配置： 123456# 选择mysql这个数据库use mysql;# 这一句执行完可能会报错，不用管它。update user set host = '%' where user = 'root';# 刷新配置FLUSH PRIVILEGES; 接下来配置防火墙，将3306端口开放： 12sudo firewall-cmd --add-port=3306/tcp --permanent # 开放3306端口sudo firewall-cmd --reload # 重新读入配置 这个时候应该就可以通过局域网访问了。 如果忘记了root密码怎么办？ 123456789101112131415# 首先，先关闭mysql原来的服务：systemctl stop mariadb.service# 开启mysql的安全模式sudo mysqld_safe --skip-grant-tables&amp;# 进入mysql，直接修改表中root的密码mysql&gt;update user set password=password(&quot;hellomysql&quot;) where user='root';mysql&gt;flush privileges; # 刷新权限mysql&gt;exit;# 然后关闭mysql的安全模式。这里只需要将之前开启的mysql进程关闭掉即可。ps aux | grep mysqld # 列出mysql的进程信息sudo kill -s 9 xxxx # 强制关闭进程# 重新打开mysql服务systemctl start mariadb.service 关于MySQL中的用户与host仔细观察这个表，我们可以发现同一个root，可能对于不同的host。换个角度，也就是说，同一个用户的不同host，我们可以设置不同的权限以及密码。这是一个在解决了局域网中不能访问数据库这个问题后，本地访问数据库出现了不能访问的情况。不能用密码访问，但是可以无密码访问，无密码访问后，没有任何修改的权限。仔细看上表中的第5行，之前不是这样，上图是被我修改过之后，正常运行的截图。未修改之前，User那一栏是空的，Password也是空的，其它三项权限都是N，所以也不难理解为什么会出现上述的情况。后面手动修改成上面的数据后，变可以以“root+密码”进行访问，并且有相应的权限。","link":"/2018/09/04/5d21a06dc6b4.html"},{"title":"CentOS服务器的简单配置","text":"修改软件源这里使用阿里云的源，阿里云的镜像地址为：https://opsx.alibaba.com/mirror1、备份mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 2、下载新的CentOS-Base.repo 到/etc/yum.repos.d/CentOS 5wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repoCentOS 6wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repoCentOS 7wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、之后运行yum makecache生成缓存 安装以及配置JDK1、卸载预装的OpenJDK 12rpm -qa | grep jdksudo yum remove ****（软件包名，上条命令的输出结果） 2、从Oracle官网下载JDK 下载地址 3、下载完成后，进行安装 1234# 安装sudo rpm -ivh jdk-8u181-linux-x64.rpm# 验证安装是否成功java -version 安装&amp;配置Tomcat安装操作如下1234567wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.33/bin/apache-tomcat-8.5.33.tar.gztar -xzvf apache-tomcat-8.5.33.tar.gzsudo vim /etc/profile# 添加CATALINA_HOME到最后一行# export CATALINA_HOME=/home/asahi/devtools/apache-tomcat-8.5.33# 保存-退出source /etc/profile 配置UTF-8字符集因为默认不使用UTF-8，所以我们在web中使用中文时，会出现乱码。所要修改文件的位置：conf/server.xml文件需要修改的地方：","link":"/2018/09/02/01736cc13255.html"},{"title":"Certified Calico Operator: Level 1 笔记","text":"证书课程地址：Course | CCO-L1 | Tigera还有一份可能有用的电子书：Tigera_eBook_Intro_to_Kubernetes_Networking.pdf Kubernetes Network Model 每个 Pod 都有一个 IP 地址； 同一个 Pod 中的容器共享同一 IP 地址，并能通过该地址相互通信； Pod 与 Pod 之间可以通过 IP 通信（无需地址转换）； 网络隔离可以限制哪里 Pod 可以访问哪些不可以。 安装测试集群1234curl https://raw.githubusercontent.com/tigera/ccol1/main/control-init.yaml | multipass launch -n control -m 2048M 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/node1-init.yaml | multipass launch -n node1 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/node2-init.yaml | multipass launch -n node2 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/host1-init.yaml | multipass launch -n host1 20.04 --cloud-init - 重启系统后，可能需要启动所有的虚拟机 1multipass start --all 安装 Calico4 种安装方式 Manifest Operator Managed Kubernetes Services Kubernetes Distros and Installers Operator 方式安装可参考：Quickstart for Calico on Kubernetes注意事项： Pod 的网段 calico 版本与 kubernetes 版本之间的兼容关系（最好就用教程里面的安装命令）1234567891011121314kubectl create -f https://docs.projectcalico.org/archive/v3.21/manifests/tigera-operator.yamlcat &lt;&lt;EOF | kubectl apply -f -apiVersion: operator.tigera.io/v1kind: Installationmetadata: name: defaultspec: calicoNetwork: containerIPForwarding: Enabled ipPools: - cidr: 198.19.16.0/20 natOutgoing: Enabled encapsulation: NoneEOF 删除 tigera-operator 命名空间1234curl -H &quot;Content-Type: application/json&quot; \\-XPUT \\-d '{&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Namespace&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;tigera-operator&quot;},&quot;spec&quot;:{&quot;finalizers&quot;:[]}}' \\http://localhost:8001/api/v1/namespaces/tigera-operator/finalize 相关 Pod 的工作内容： tigera-operator/tigera-operator-xxxx-xxx 监听 Installation CR，并按照配置安装 calico CNI。 calico-system/calico-node DaemonSet，网络策略实现；设置Node节点上的路由；为 IPIP、VXLAN、WireGuard 管理虚拟接口。 calico-system/calico-typha StatefulSet，作为 calico-node 用来查询、监听 api-server 时的缓存层，避免直接访问 api-server。它由 tigera-operator 来随着 node 的变化，进行扩缩容。 calico-system/calico-controller calico 的各种 controller 集合，用于自动同步资源状态。","link":"/2023/06/12/1c3fe39c1f3f.html"},{"title":"CKA备考心得！这证没有值不值，想拿就拿就完了！","text":"如果拿到证后，能报销考试费，或者有补贴，上车就完事了 报考CKA or CKA-CN CKA 英文试题、监考官和你用英文和你聊天、考试时出示证件为护照； CKA-CN 中文试题、监考官用中文和你聊天、考试时出示证件为身份证。 报名 地址：CKA (Certified Kubernetes Administrator) (linuxfoundation.cn) 考试大纲 报完名交完钱后，后续的操作基本不在 linuxfoundation.cn。 选考试时间 Linux Foundation帮助文档-如何注册考试码及预约考试 建议注册 Linux Foundation ID（LFID） 时，不要选用 Google、FaceBook 之类明显需要翻墙的账号创建。 报考到考试期间的准备Vim 或者其他在服务器 Terminal 中可以进行编辑的工具 Vim 用得越溜，编辑得越快，考试时做题的速度也就越快。 技术|Vim 快捷键速查表 (linux.cn) Vim (vi) 编辑器快捷键大全【图解】- SegmentFault 思否 刷题 Killer Shell - CKS CKA CKAD Simulator 这个是报完名/确定完考试时间后，官方赠送的一次模拟考试的机会。 这个题一定要做，和考试题型基本一样，难度比考试题略高。 找个拥有较长空闲时间的时间段，争取一次性/尽快做完，因为一旦开始这个模拟考试，有效期只有1天（又好像是2天，具体可以到时候关注一下时间）。 模拟题目可以导出，有两次模拟的机会，但两次模拟的题目是一样的==。 刷了两遍 按照考纲，看官方文档：kubernetes.io 模拟题： Kubernetes CKA 证书备考笔记 - 知乎 (zhihu.com) 2021年12月cka考题总结及考试注意事项 - 记忆流年 - 博客园 (cnblogs.com) 2022 年 CKA 考题 2022.06.31 刚过_cl18707602767的博客-CSDN博客 alijahnas/CKA-practice-exercises: This is a guide for passing the CNCF Certified Kubernetes Administrator (CKA) with practice exercises. Good luck! (github.com) chadmcrowell/CKA-Exercises: Practice for the Certified Kubernetes Administrator (CKA) Exam (github.com) 其他资料 walidshaari/Kubernetes-Certified-Administrator CKA考试环境预览 花钱课程（不建议） 考试开始前15分钟 Tips 提前检查考试电脑的兼容性 WebDelivery Compatibility Check (examslocal.com) 考试全程需要录屏、录音；需要一个无人的房间；桌子上面、下面不能出现纸质、电子资料；考试前会让你拿着电脑，转动摄像头，展示桌子上面、下面以及整个房间； 不要说话、不要交谈； 考试时使用插电源的笔记本电脑； 考试前会让你将其他进程都关掉（macOS 上就只剩下 Finder 和 浏览器两个进程）； 准备好、调试好梯子以备不时之需（考试时没有使用梯子，但刚进入考试界面时，页面载入特别慢）； 考官的作用： 给你下发指令，做考试前准备； 当你有问题时，和你网聊； 当时间快到时，给你提醒。 考试开始后 进入考试界面后，先简单设置一下 vim、bash，方便在后面答题中的使用。 Vim简略的 Vim 常用配置 ~/.vimrc，可以提高 Vim 的使用幸福感（考试时需要凭记忆手动配置）。 12345678910# 显示行号，方便移动set nu# 上色，不上色可能看不清syntax on# 按下 Tab 键时，Vim 显示的空格数。set tabstop=2# 在文本上按下&gt;&gt;（增加一级缩进）、&lt;&lt;（取消一级缩进）或者==（取消全部缩进）时，每一级的字符数。set shiftwidth=2# 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格。set expandtab 快捷命令 检查是否配置了 kubectl 命令补全（按 tab 是否有提示）或通过 source &lt;(kubectl completion bash) 来设置命令补全； 为 kubectl 创建别名 alias k=kubectl。 考试中开始每一道题目之前，需要注意一下3点是否符合题意： context namespace node 操作完了之后记得 k describe/get 相应的资源看看，检查一下。 快速命令 使用 kubectl create/run 来创建资源； 当其创建的资源不满足要求时，可以考虑使用下面的模式答题 k create/run xxxxxx --dry-run=client -o yaml &gt; 1.yaml 将生成好的 yaml 保存到本地 vim 1.yaml 然后用 vim 之类的工具编辑 k apply -f 1.yaml 再提交给 k8s 使用 kubectl expose 来暴露服务； k edit 直接修改资源； --all-namespace =&gt; -A； --namesapce =&gt; -n； 救命命令 --help/-h k explain pods.spec.containers 查看某个资源有哪些具体字段及说明 最后的倔强在 kubernetes.io 中使用搜索功能搜索关键字。只要在文档中找到了相应的关键字，基本上就能获取到题目相关的 yaml。将 yaml 粘贴保存到本地后，用 Vim 编辑，然后 apply。 其他 不是越往后越难，该跳就跳，不要浪费时间； 没搞定的题可以打标签，做完一遍后，在下拉菜单回顾时，可以很清楚的看到； 考试界面有个做笔记的 Web 应用，可以用来暂存一些信息。 印象比较深刻的题k8s 故障恢复 印象中是使用 kubeadm 安装的 k8s 集群，所以得熟悉一下用 kubeadm 搭建 k8s 集群。 Master 节点问题 看 kube-system 命名空间下的 pod 是否正常。可考虑看异常 pod 的日志 1k -n kube-system logs xxxx Node 节点 kubelet 启动（由 systemd 托管）问题 看 kubelet 进程状态 systemctl status kubelet 看 kubelet 日志 journalctl -xefu kubelet 看 kubelet 命令是否存在(xxx.service 中定义的 kubelet 路径是否存在)； Node 节点 join 问题 当修复好 Node 节点上面的 kubelet 问题后，在 Master 节点上面，通过 kubeadm 重新生成 bootstrap-token 1kubeadm token create --print-join-command 再使用 kubeadm join xxxxx，将 Node 节点加入集群。 记录某个操作命令行里面加 --record 参数 etcd 的备份与恢复基本会考，但是不难，就两条命令记下就好。证书路径别记错了。 Operating etcd clusters for Kubernetes | Kubernetes ingress &amp; egress（网络策略） Network Policies | Kubernetes 多容器Pod与sidecar 多个容器共享同一个目录 印象中这道题我没做完，错误理解题意了，修改 yaml 贼慢，并且时间来不及了。 最后祝愿各位明天拿证！！！","link":"/2022/07/30/ceffd765678b.html"},{"title":"Cmake的基本使用","text":"这几天项目中接触到了NDK相关的东西，顺便把Cmake相关的东西补了一下。搞明白了之后， 使用CLion都得心应手了！这篇博客记录一些自己使用到了的并且理解了用法。 Cmake是什么cmake最终生成的是相应的所需要的Makefile，但是Makefile有很多种，因此它可以起到一个跨平台的作用。 使用基本指令 命令 解释 示例 add_library 生成库，如.so add_library(TestLib SHARED library.c library.h) add_executable 生成可执行文件 add_executable(leetcode007 leetcode_007.cpp) target_link_libraries 链接其他库到目标库或者可执行文件上 target_link_libraries(executor ${PROJECT_SOURCE_DIR}/../TestCppLib/cmake-build-debug/libTestLib.so) include_directories 添加其他需要编译的文件 include_directories(${CMAKE_SOURCE_DIR}/src/main/cpp/include ) CLion中的应用每添加一个可执行的程序，就会添加一个运行目标。明白怎么搞成像Code::Blocks那样的功能了，加上它的代码提示，要上天啊。生成的so库在这里更多可参考：http://www.hahack.com/codes/cmake/","link":"/2018/04/29/39d094fb0f99.html"},{"title":"C与C++中的函数与指针","text":"用用就知道多厉害了，墙裂推荐这个将C语言声明翻译成口语的翻译器：C语言声明翻译器–在线版 对表达式声明的理解float f,g;当对其求值时，表达式f和g的类型为浮点数类型（float）。float ((f));当对其求值时，表达式((f))的类型为浮点数类型（float）。float ff();表达式ff()求值结果是一个浮点数，也就是说，ff是一个返回值为浮点类型的函数。float *pf;表达式*pf是一个浮点数，也就是说，pf是一个指向浮点数的指针。 float *g(), (*h)()()的优先级高于*，所以前者为float *(g());，即g是一个函数，该函数的返回值是一个指向浮点数的指针。所以，h是一个函数指针，返回值是一个浮点数。 (float (*)()) 类型转换符 int *f()==int *(f()) 函数调用操作符()的优先级高于间接访问操作符*。因此，f是一个函数，它的返回值类型是一个指向整型的指针。 int (*f)() 程序中的每个函数都位于内存中的某个位置，所以存在着指向那个位置的指针。 理解C语言声明的优先规则（自《C专家编程》） 序号 详情 A 声明从它的名字开始读取，然后按照优先级顺序依次读取。 B 优先级从高到低依次是：1. 声明中被括号括起来的那部分2. 后缀操作符：括号()表示这是一个函数，方括号[]表示为一个数组。3. 前缀操作符：星号*表示“指向…的指针” char * const *(*next)(); (*next) next是一个指针2.(*next)() next是一个指针，指向一个函数。这个函数接受的参数为空。 *(*next)() next是一个指针，指向一个函数。这个函数接受的参数为空，返回的参数为一个指针。 char * const *(*next)() next是一个指针，指向一个函数。这个函数接受的参数为空，返回的参数为一个指针，它指向的对象是一个指向char的常量指针。即：declare next as pointer to function returning pointer to const pointer to char 其它表达式 表达式 解析 char *(*c[10])(int **p); declare c as array 10 of pointer to function (pointer to pointer to int) returning pointer to char int (*(*foo)(void ))[3]; declare foo as pointer to function (void) returning pointer to array 3 of int int (*f)(int *, int (*)(int*)); declare f as pointer to function (pointer to int, pointer to function (pointer to int) returning int) returning int int (*f[5])(int *); declare f as array 5 of pointer to function (pointer to int) returning int int (*(*f)[5])(int *); declare f as pointer to array 5 of pointer to function (pointer to int) returning int int (*(*f)(int *))[5]; declare f as pointer to function (pointer to int) returning pointer to array 5 of int int (*(*f)[5][6])[7][8]; declare f as pointer to array 5 of array 6 of pointer to array 7 of array 8 of int int (*(*(*f)(int *))[5])(int *); declare f as pointer to function (pointer to int) returning pointer to array 5 of pointer to function (pointer to int) returning int int (*(*f[7][8][9])(int*))[5]; declare f as array 7 of array 8 of array 9 of pointer to function (pointer to int) returning pointer to array 5 of int","link":"/2018/05/28/9c734fe6cc30.html"},{"title":"Dockerfiles 官网 doc 笔记","text":"Docker 通过 Dockerfile 中的指令来构建镜像。Docker 镜像由很多镜像构成，每一层对应一个 Dockerfile 里面的指令。一个运行中的容器，由镜像的所有层加上可写层构成，所有的读写都在最上面的可写层。容器应该是无状态的，销毁、重建应该花费最小的配置。 （build context）构建上下文1docker build -f ~/Dockerfile.hi context-dir 通过 -f 指定 Dockerfile 的路径 context-dir 即为构建上下文，该文件夹下面所有的内容都会被传递给 Docker daemon，用来构建镜像。构建上下文包含不相关的内容，会影响构建速度、镜像大小。 可通过编写 .dockerignore 文件，并放置在构建上下文的目录下，达到类似于 .gitignore 的效果，将不必要的文件（夹）不发送给 Docker Daemon。 有如下几种从 stdin 构建镜像的方式： - 表是占位，从 stdin 读取 无构建上下文（不需要拷贝文件到镜像中） 模板 1docker build [OPTIONS] - 示例 1echo -e 'FROM busybox\\nRUN echo &quot;hello world&quot;' | docker build - 或 1234docker build -&lt;&lt;EOFFROM busyboxRUN echo &quot;hello world&quot;EOF 上述两种方式，都不会给 Docker Daemon 发送构建上下文，但是注意不要在 Dockerfile 中使用 COPY 、 ADD ，这样会导致构建失败。 传递本地构建上下文 模板 1docker build [OPTIONS] -f- PATH 示例 12345678910111213# create a directory to work inmkdir examplecd example# create an example filetouch somefile.txt# build an image using the current directory as context, and a Dockerfile passed through stdindocker build -t myimage:latest -f- . &lt;&lt;EOFFROM busyboxCOPY somefile.txt .RUN cat /somefile.txtEOF 传递远程构建上下文 模板 1docker build [OPTIONS] -f- PATH 示例 1234docker build -t myimage:latest -f- https://github.com/docker-library/hello-world.git &lt;&lt;EOFFROM busyboxCOPY hello.c .EOF 多阶段构建使 Dockerfile 在容易维护、阅读的基础上，减少镜像的大小 基础用法在一个 Dockerfile 中使用多个 FROM，每个 FROM 构建一个镜像，在镜像之间的拷贝操作变得容易。如下： 1234567891011FROM golang:1.7.3WORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/html COPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latest RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=0 /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 对 --from=0 ，按照数组下标从 0 开始，第一个 FROM 构建的镜像为0，依次类推。当然也可以给 FROM 构建的镜像命名： 1234567891011FROM golang:1.7.3 AS builderWORKDIR /go/src/github.com/alexellis/href-counter/RUN go get -d -v golang.org/x/net/html COPY app.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .FROM alpine:latest RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /go/src/github.com/alexellis/href-counter/app .CMD [&quot;./app&quot;] 其实 --from=xxx 中的 xxx 也可以为其它的、不在此 Dockerfile 中产生的镜像 其它用法 只构建指定的构建阶段，即某特定 FROM 所代表的镜像。沿用前面的例子，可以只构建 builder 阶段的镜像。 1docker build --target builder -t alexellis2/href-counter:latest . 后续的 FROM 可以以前面的 FROM 构建的镜像做为 base。 12345678910FROM alpine:latest as builderRUN apk --no-cache add build-baseFROM builder as build1COPY source1.cpp source.cppRUN g++ -o /binary source.cppFROM builder as build2COPY source2.cpp source.cppRUN g++ -o /binary source.cpp 构建缓存显式声明不使用缓存： docker build --no-cache=true ... 。不做显式声明，默认可能会利用构建缓存，能成功利用构建缓存的情况： 如果从缓存中存在的一个镜像开始构建，那么会将基于此父镜像的所有子镜像的 Dockerfile 拉出来做一个对比，看下一条指令是否相同，如果不相同，缓存失效。 对比 Dockerfile 内容是否相同。一些特殊命令，需要更多检测。 对 ADD 和 COPY ，它们操作的文件对象都会被作为 checksum 的一部分，不一致则缓存失效。 除了 ADD 和 COPY ，其他命令带来的文件改变，不会被计入 checksum，也就是在匹配镜像时，会忽略此部分的文件的不同。 其他建议写法 不安装多余的包。降低复杂度、依赖性、镜像大小和构建时间。 解耦应用，一个容器只关心一件事情，以达到水平扩展和容器的复用。但是并意味着一个容器一个进程一成不变。 减少镜像的层数。只有 RUN , COPY , ADD 三个指令添加层数，其他的指令只会创建临时的层，并不会增加镜像大小。所以，分多个阶段来构建镜像，只拷贝需要的文件到镜像中，能有效减少镜像的大小。 为多行参数排序。按字母顺序排序。避免包重复。如下： 123456RUN apt-get update &amp;&amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion Dockerfile 指令FROM三种方式 123FROM [--platform=&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]FROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]FROM [--platform=&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;] 几个要点 FROM 开启一个构建 Dockerfile 的第一个必须是 FROM ，但是 FROM 前面可以有 ARG 来声明变量 Dockerfile 中可以出现多个 FROM 来实现多阶段构建 可以为构建阶段添加别名，在后续 FROM 和 COPY --from=&lt;name|index&gt; 中使用 ARG 的使用样例 123456ARG CODE_VERSION=latestFROM base:${CODE_VERSION}CMD /code/run-appFROM extras:${CODE_VERSION}CMD /code/run-extras LABEL注意事项 字符串中含有空格，必须转义或使用 &quot;&quot; 字符串中含有 &quot; ，必须转义 用自己的反转域名作为 label 前缀，必须对域名有权限 Docker 保留的前缀： com.docker.* , io.docker.* , org.dockerproject.* key 应该使用小写字母数字、 . 、 - - 示例 12345678910111213141516# Set one or more individual labelsLABEL com.example.version=&quot;0.0.1-beta&quot;LABEL vendor1=&quot;ACME Incorporated&quot;LABEL vendor2=ZENITH\\ IncorporatedLABEL com.example.release-date=&quot;2015-02-12&quot;LABEL com.example.version.is-production=&quot;&quot;# Set multiple labels on one lineLABEL com.example.version=&quot;0.0.1-beta&quot; com.example.release-date=&quot;2015-02-12&quot;# Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\\ Incorporated \\ com.example.is-beta= \\ com.example.is-production=&quot;&quot; \\ com.example.version=&quot;0.0.1-beta&quot; \\ com.example.release-date=&quot;2015-02-12&quot; 查看 label 1docker image inspect RUN两种形式 12345# shell formRUN &lt;command&gt;# exec formRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] shell form 将会在 shell 中运行，Linux 默认为 /bin/sh -C ，Windows 默认为 cmd /S /C ，默认 shell 可以通过 SHELL 指令进行指定。 exec form 会被解析成 JSON 数组，因此需要用 &quot; 扩起来。 注： RUN [ &quot;echo&quot;, &quot;$HOME&quot; ] 无法读取变量，要用 RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 才行。 在镜像顶层之上，创建新的镜像层，然后运行命令，结束后，持久化为一个只读镜像层。 apt-get使用 RUN 指令，最多的就是执行 apt-get 之类的代码，来安装依赖。有如下注意点： 避免运行 apt-get upgrade 和 dist-upgrade 使用 apt-get install -y foo 来自动升级一个依赖包 将 RUN apt-get update 和 apt-get install 包含在同一个 RUN 指令中 一个比较推荐的写法 1234567891011121314RUN apt-get update &amp;&amp; apt-get install -y \\ aufs-tools \\ automake \\ build-essential \\ curl \\ dpkg-sig \\ libcap-dev \\ libsqlite3-dev \\ mercurial \\ reprepro \\ ruby1.9.1 \\ ruby1.9.1-dev \\ s3cmd=1.1.* \\ &amp;&amp; rm -rf /var/lib/apt/lists/* Debian 和 Ubuntu 会自动运行 apt-get clean 管道符1RUN wget -O - https://some.site | wc -l &gt; /number 默认只以最后一个命令 wc 的状态作为整个 RUN 指令的成功或失败，即使 wget 失败了。但可以通过设置 set -o pipefail 避免失败被忽略。如下： 1RUN set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number CMD CMD 指令和我印象中的不太一样。 三种形式 CMD [“executable”,”param1”,”param2”] (exec form, 首推) CMD [“param1”,”param2”] (作为 ENTRYPOINT 的默认参数， 不推荐使用，除非很了解 ENTRYPOINT) CMD command param1 param2 (shell form) 只能有一个 CMD 指令，多个 CMD 指令的情况，最后一个 CMD 指令生效。目的是提供可执行命令或参数（此时必须指定 ENTRYPOINT）。exec form 不提供变量替换。shell form 默认使用 /bin/sh -c 执行；当执行命令不需要 shell 时，可以使用 exec shell。 在构建期间：RUN 会执行，并将结果作为镜像层进行提交；CMD 则不会执行。 CMD 的使用示例（以 nginx 为例）： 错误❌ ： CMD service nginx start 正确✅ ： CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 CMD service nginx start 会被理解为 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;] ，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。 EXPOSE 这个指令印象中是暴露一个容器的端口，但仔细想了想这个指令，对它的作用产生了怀疑。如果这个指令能暴露端口的话，那么和 docker run -p 是什么关系。 EXPOSE 声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。这个指令的好处为： 方便镜像使用者理解以配置端口映射 运行时，使用 docker run -P 为被 EXPOSE 声明过的容器的端口，随机映射一个宿主机端口。 ENV 单纯设置环境变量 格式有两种： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 在 ENV 后面的指令/运行时，能访问该环境变量。 COPY 从宿主机，拷贝文件到镜像中 如果源路径为文件夹，复制的时候不是直接复制该文件夹，而是将文件夹中的内容复制到目标路径。 权限问题：默认情况下，新拷贝的文件的 UID 和 GID 都是 0，即归属 root 用户。可以通过 --chown USER:GROUP 来修改文件所属（仅适合用于创建 Linux 容器）。 从 STDIN 构建的话，没有构建上下文，不能使用 COPY。 COPY 还可以接受 --from=&lt;name|index&gt; 从镜像中拷贝文件。 ADD 之前没见过 与 COPY 类似，但是会自动将压缩包解压到目标文件夹。如下： ADD rootfs.tar.xz / 。 一般情况用 COPY，需要自动解压压缩包的情景再用 ADD。 ENTRYPOINT 这部分内容之前并没仔细了解过，觉得就是简单的容器的启动命令，填上就行，但是看完这部分的文档后，刷新了认知。 两种启动模式： exec form (preferred form)： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] shell form： ENTRYPOINT command param1 param2 PID 1 进程顾名思义，进程号为 1 的进程。特殊的地方在于，PID 1 进程可以接收发给容器的 UNIX 信号。 PID 1 进程的用处，可以通过下面的 Dockerfile 来展示： 12FROM ubuntuENTRYPOINT top -b 构建完成后，执行下面的命令，可以看到关闭容器花费了非常长的时间： 当执行 docker stop 时，容器并未完全退出， docker stop 会在超时后，发送 SIGKILL 关闭容器中的其他进程。 如果 top -b 是 PID 1 进程呢？修改一下 Dockerfile 如下： 12FROM ubuntuENTRYPOINT exec top -b 可以很明显看出，很顺畅地就完成了 docker stop exec formENTRYPOINT 中的命令默认 PID 为 1，即不会通过某种 shell 来启动（也就无法进行变量替换）。如果是以一个脚本来启动服务，需要在脚本中使用 exec 或 gosu 来执行。 什么是 gosu? https://github.com/tianon/gosu https://segmentfault.com/a/1190000004527476 什么是 exec? shell form CMD、 docker run 命令行参数都会被忽略掉。 ENTRYPOINT 会以 /bin/sh -c 的子进程运行，即非 PID 1 进程，无法接收 UNIX 信号。 可以通过 exec 达到让 ENTRYPOINT 指定的服务 PID 为 1。 ENTRYPOINT &amp; CMD两者之间的规定： Dockerfile 中至少有一个 ENTRYPOINT 或 CMD。也就说可以有多个，但是最后一个才会生效。 ENTRYPOINT should be defined when using the container as an executable.Why？ CMD 可以用作 ENTRYPOINT 的默认参数 或 for executing an ad-hoc command in a container. CMD will be overridden when running the container with alternative arguments.What? 两者之间的协同关系： No ENTRYPOINT ENTRYPOINT exec_entry p1_entry (shell form) ENTRYPOINT [“exec_entry”, “p1_entry”]（exec form） No CMD error, not allowed /bin/sh -c exec_entry p1_entry exec_entry p1_entry CMD [“exec_cmd”, “p1_cmd”] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry exec_cmd p1_cmd CMD [“p1_cmd”, “p2_cmd”] p1_cmd p2_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry p1_cmd p2_cmd CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd VOLUME含义：直接设置镜像的一个挂载点用途：存放镜像创建的文件、配置、数据库的数据文件。易变、镜像中的用户数据。方式： 1VOLUME [&quot;/data&quot;] 或 12VOLUME /var/logVOLUME /var/log /var/db USER含义：指定镜像运行时的用户和用户组（不指定默认为 root）。USER 指令之后的 CMD、RUN、ENTRYPOINT 都将以 USER 指定的用户和用户组运行。方式： 12USER &lt;user&gt;[:&lt;group&gt;]USER &lt;UID&gt;[:&lt;GID&gt;] 避免使用 sudo，它会有一定的问题。确有需要考虑使用 gosu。 WORKDIR含义：指定工作目录，建议使用绝对路径（使用相对路径时，会以当前目录中的文件夹为工作目录）。可以根据需要多次指定，避免使用 cd。此指令对后续的 Dockerfile 指令生效，如：RUN, CMD, ENTRYPOINT, COPY, ADD方式： 1WORKDIR /path/to/workdir ONBUILD含义：构建 BaseImage 时，加入 ONBUILD 指令，会在使用（FROM BaseImage）的构建中，执行 ONBUILD 指令后，才执行此构建的构建指令。方式： 12ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src 使用场景：使用 maven 编译 jar 包，并构建我们自己的业务镜像。所以我们的 Dockerfile 可以如下编写： 12FROM maven:3.3-jdk-8-onbuildCMD [&quot;java&quot;,&quot;-jar&quot;,&quot;/usr/src/app/target/demo-1.0-SNAPSHOT-jar-with-dependencies.jar&quot;] 为啥可以这样？这是因为在 maven:3.3-jdk-8-onbuild 这个镜像中，有 ONBUILD 指令，如下： 12345678FROM maven:3-jdk-8RUN mkdir -p /usr/src/appWORKDIR /usr/src/appONBUILD ADD . /usr/src/appONBUILD RUN mvn install Example Link 工作流程： 遇到 ONBUILD 指令，添加触发器到镜像的 metadata 中，所以 ONBUILD 不影响当前构建的镜像。 在构建完成后，触发器会被添加到镜像的 manifest 中，可以通过 docker inspect 进行查看。 当被用作基础镜像（FROM xxx）后，新构建执行触发器，即 ONBUILD 指令，全部成功执行完后，才开始新镜像的构建。 触发器在执行后会被清除。 HEALTHCHECK方式： 1234# check container health by running a command inside the containerHEALTHCHECK [OPTIONS] CMD command# disable any healthcheck inherited from the base imageHEALTHCHECK NONE 其中 OPTIONS 可以做如下设置： --interval=DURATION (default: 30s) --timeout=DURATION (default: 30s) --start-period=DURATION (default: 0s) --retries=N (default: 3) docker 容器的健康状况： starting：初始状态。 healthy：当有任何一次健康检查通过时 unhealthy：当连续 retries 次健康检查都失败时 failed：单次检查时间超过 timeout 如何写一条 HEALTHCHECK 指令？本质上是执行一条 shell 命令，不同的返回值，表示不同的含义。 0：成功 1：失败 2：预留，勿用 示例： 12HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1 针对此容器的健康检查，只检查 80 端口的服务，是否能正常返回。 Reference: https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ https://docs.docker.com/engine/reference/builder/","link":"/2020/09/08/172fdf84bb45.html"},{"title":"ES6与JavaScript之间的关系","text":"挺迷惑的，不过感觉可以粗浅地理解ES6是一种标准，JavaScript是ES6的一种实现。 js与node.jsJS是由ES(ECMAScript)、DOM(浏览器文档对象)、BOM(浏览器对象模型)组成。 其中Node.Js就只有ES，目前浏览器比较流行的版本就是ES6(ES2015)，老浏览器的版本基本上都是ES5。所以alert和document不能在Node运行(因为Node没有dom和bom)。 ECMAScript 6简介ECMAScript 6.0（以下简称ES6）是JavaScript语言的下一代标准，已经在2015年6月正式发布了。它的目标，是使得JavaScript语言可以用来编写复杂的大型应用程序，成为企业级开发语言。 ECMAScript和JavaScript的关系一个常见的问题是，ECMAScript和JavaScript到底是什么关系？ 要讲清楚这个问题，需要回顾历史。1996年11月，JavaScript的创造者Netscape公司，决定将JavaScript提交给国际标准化组织ECMA，希望这种语言能够成为国际标准。次年，ECMA发布262号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为ECMAScript，这个版本就是1.0版。 该标准从一开始就是针对JavaScript语言制定的，但是之所以不叫JavaScript，有两个原因。一是商标，Java是Sun公司的商标，根据授权协议，只有Netscape公司可以合法地使用JavaScript这个名字，且JavaScript本身也已经被Netscape公司注册为商标。二是想体现这门语言的制定者是ECMA，不是Netscape，这样有利于保证这门语言的开放性和中立性。 因此，ECMAScript和JavaScript的关系是，前者是后者的规格，后者是前者的一种实现（另外的ECMAScript方言还有Jscript和ActionScript）。日常场合，这两个词是可以互换的。 ES6与ECMAScript 2015的关系媒体里面经常可以看到”ECMAScript 2015“这个词，它与ES6是什么关系呢？ 2011年，ECMAScript 5.1版发布后，就开始制定6.0版了。因此，”ES6”这个词的原意，就是指JavaScript语言的下一个版本。 但是，因为这个版本引入的语法功能太多，而且制定过程当中，还有很多组织和个人不断提交新功能。事情很快就变得清楚了，不可能在一个版本里面包括所有将要引入的功能。常规的做法是先发布6.0版，过一段时间再发6.1版，然后是6.2版、6.3版等等。 但是，标准的制定者不想这样做。他们想让标准的升级成为常规流程：任何人在任何时候，都可以向标准委员会提交新语法的提案，然后标准委员会每个月开一次会，评估这些提案是否可以接受，需要哪些改进。如果经过多次会议以后，一个提案足够成熟了，就可以正式进入标准了。这就是说，标准的版本升级成为了一个不断滚动的流程，每个月都会有变动。 标准委员会最终决定，标准在每年的6月份正式发布一次，作为当年的正式版本。接下来的时间，就在这个版本的基础上做改动，直到下一年的6月份，草案就自然变成了新一年的版本。这样一来，就不需要以前的版本号了，只要用年份标记就可以了。 ES6的第一个版本，就这样在2015年6月发布了，正式名称就是《ECMAScript 2015标准》（简称ES2015）。2016年6月，小幅修订的《ECMAScript 2016标准》（简称ES2016）如期发布，这个版本可以看作是ES6.1版，因为两者的差异非常小（只新增了数组实例的includes方法和指数运算符），基本上是同一个标准。根据计划，2017年6月将发布ES2017标准。 因此，ES6既是一个历史名词，也是一个泛指，含义是5.1版以后的JavaScript的下一代标准，涵盖了ES2015、ES2016、ES2017等等，而ES2015则是正式名称，特指该年发布的正式版本的语言标准。本书中提到“ES6”的地方，一般是指ES2015标准，但有时也是泛指“下一代JavaScript语言”。 参考：http://es6.ruanyifeng.com/#docs/intro","link":"/2018/07/31/fec8981da763.html"},{"title":"EXT4中的inode的简易再理解","text":"之前在鸟哥的linux上面，了解过inode相关的内容。最近被要求出一个面试题，想到了这个，然后自己复习了一下inode相关的内容，简短地描述如下 认识文件系统是数据组织方式，定义数据在磁盘上的保存、读取和更新方法。不同的文件系统可以根据存储设备的不同进行优化，提高效率。可以为每个磁盘分区设置一个或多个不同的文件系统。每种文件系统有自己的优缺点和独有特性。常见的文件系统如：FAT、exFAT、ext3、ext4、XFS、NTFS(Windows)、HFS(macOS) 什么是inode一个文件由文件名+inode+数据块组成，inode包含文件的字节数、文件拥有者的User ID、文件的Group ID、文件的rwx权限、文件的时间戳、链接数、文件数据block的位置。 软链接与硬链接的差异文件名是否指向同一个inode","link":"/2019/02/20/75be99f318f6.html"},{"title":"EventBus3的基本使用指南","text":"使用EventBus可以省略繁杂的Handler，效果也是类似的，使用方法也很简单。这里从官网上面做一个小小的总结，可以看得更全面一些。 入门贴官方教程 定义事件事件就是一个普通的Java类，POJO就好。 123456public class MessageEvent { public final String message; public MessageEvent(String message) { this.message = message; }} 订阅事件事件的订阅者会被调用以处理相应的事件。使用@Subscribe定义。EventBus 3对函数名没有要求。 12345678910// 当MessageEvent事件被发送的时候，此方法会被调用(在主线程中)@Subscribe(threadMode = ThreadMode.MAIN)public void onMessageEvent(MessageEvent event) { Toast.makeText(getActivity(), event.message, Toast.LENGTH_SHORT).show();}//当SomeOtherEvent方法被发送的时候，此方法会被调用@Subscribepublic void handleSomethingElse(SomeOtherEvent event) { doSomethingWith(event);} 事件的订阅函数所在的地方，需要先声明订阅，并且最好在相应的时候取消事件的订阅。只有订阅了，才会收到事件消息。因此一般会在Activity或Fragment的生命周期中进行上述操作。 1234567891011@Overridepublic void onStart() { super.onStart(); EventBus.getDefault().register(this);} @Overridepublic void onStop() { EventBus.getDefault().unregister(this); super.onStop();} 发送事件你可以在任何代码中进行事件的发送。所有对匹配此事件的订阅者都将会收到此事件。 EventBus.getDefault().post(new MessageEvent(&quot;Hello everyone!&quot;)); 指定订阅者函数执行的线程如果不指定线程，那么将默认与发送事件处于相同的线程。 ThreadMode 说明 POSTING 默认模式，与发送事件时所处的线程相同。 MAIN 主线程。注意在订阅函数内不用做太多耗时的操作，以免堵塞主线程。如果事件是在主线程中发送的，那么订阅者将会立即执行对于的函数。 MAIN_ORDERED 主线程。如果已经有一个订阅者的函数在执行，那么将等待它执行完毕后，才执行当前订阅者的函数。与其名字相呼应吧！ BACKGROUND background线程。如果事件不是在主线程中发送的，那么订阅者将立刻在此发送线程中执行；如果是在主线中发送的，那么将会开启一个线程，并在此线程中依次发送所有的事件，当订阅者收到此事件时，将会在此线程中执行吧！ ASYNC 会开启一个独立的线程来执行订阅者函数。可以考虑将比较耗时的操作设为此模式，如网络访问。这些线程会被一个线程池管理，以提高重新利用的效率。 配置示例是配置当没有订阅者时的一些操作。 1234EventBus eventBus = EventBus.builder() .logNoSubscriberMessages(false) .sendNoSubscriberEvent(false) .build(); 上面获取到EventBus实例的方式与之前示例中获取到EventBus实例不太一样。其中的差距此处获取到的只是当前的实例，后者是默认的实例。如何才能配置默认的实例呢？ EventBus.builder().throwSubscriberException(BuildConfig.DEBUG).installDefaultEventBus(); 其中installDefaultEventBus()只能调用一次。 参考 http://greenrobot.org/eventbus/documentation/","link":"/2018/04/29/779d4e5acb73.html"},{"title":"Exception与Error的区别解析(源代码的注释)","text":"ExceptionThe class Exception and its subclasses are a form of Throwable that indicates conditions that a reasonable application might want to catch. The class Exception and any subclasses that are not also subclasses of RuntimeException are checked exceptions. Checked exceptions need to be declared in a method or constructor’s throws clause if they can be thrown by the execution of the method or constructor and propagate outside the method or constructor boundary. RuntimeExceptionRuntimeException is the superclass of those exceptions that can be thrown during the normal operation of the Java Virtual Machine.RuntimeException and its subclasses are unchecked exceptions. Unchecked exceptions do not need to be declared in a method or constructor’s throws clause if they can be thrown by the execution of the method or constructor and propagate outside the method or constructor boundary. ErrorAn Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a “normal” condition, is also a subclass of Error because most applications should not try to catch it.A method is not required to declare in its throws clause any subclasses of Error that might be thrown during the execution of the method but not caught, since these errors are abnormal conditions that should never occur. That is, Error and its subclasses are regarded as unchecked exceptions for the purposes of compile-time checking of exceptions.","link":"/2018/07/16/060c6fe2d78d.html"},{"title":"Flask如何使用logging.FileHandler将日志保存到文件","text":"需求将日志尽可能往文件中输，自带的默认只输出到屏幕上。 代码获取文件名 1234567891011def get_custom_file_name(): def make_dir(make_dir_path): path = make_dir_path.strip() if not os.path.exists(path): os.makedirs(path) return path log_dir = &quot;ac_logs&quot; file_name = 'logger-' + time.strftime('%Y-%m-%d', time.localtime(time.time())) + '.log' file_folder = os.path.abspath(os.path.dirname(__file__)) + os.sep + log_dir make_dir(file_folder) return file_folder + os.sep + file_name 配置logging 1234567891011121314151617181920212223dictConfig({ 'version': 1, 'formatters': {'default': { 'format': '%(asctime)s - %(levelname)s - %(filename)s - %(funcName)s - %(lineno)s - %(message)s', }}, 'handlers': { 'default': { 'class': 'logging.StreamHandler', 'stream': 'ext://flask.logging.wsgi_errors_stream', 'formatter': 'default' }, 'custom': { 'class' : 'logging.FileHandler', 'formatter': 'default', 'filename' : get_custom_file_name(), 'encoding' : 'utf-8' }, }, 'root': { 'level': 'INFO', 'handlers': ['custom'] }}) 代码分析在官方文档中，有一个默认的handler，当我添加一个自定义的handler，名叫custom的时候，读取配置失败，程序中断，也就无法继续执行下去，提示说，少一个叫做filename的参数。 loggin.FileHandler的构造函数中，有一个必填的参数，叫做filename。如下： 12345678910111213141516class FileHandler(StreamHandler): &quot;&quot;&quot; A handler class which writes formatted logging records to disk files. &quot;&quot;&quot; def __init__(self, filename, mode='a', encoding=None, delay=False): &quot;&quot;&quot; Open the specified file and use it as the stream for logging. &quot;&quot;&quot; # Issue #27493: add support for Path objects to be passed in filename = os.fspath(filename) #keep the absolute path, otherwise derived classes which use this #may come a cropper when the current directory changes self.baseFilename = os.path.abspath(filename) self.mode = mode self.encoding = encoding self.delay = delay 如何才能传入参数filename? ①进入dictConfig() 123def dictConfig(config): &quot;&quot;&quot;Configure logging using a dictionary.&quot;&quot;&quot; dictConfigClass(config).configure() ②进入configure()，找到对handler的处理逻辑，如下： 123456789101112131415161718# 前面的代码省略# 获取handlershandlers = config.get('handlers', EMPTY_DICT)deferred = []# 遍历其中的每一个handlerfor name in sorted(handlers): try: # 具体处理每一个handler handler = self.configure_handler(handlers[name]) handler.name = name handlers[name] = handler except Exception as e: if 'target not configured yet' in str(e.__cause__): deferred.append(name) else: raise ValueError('Unable to configure handler ' '%r' % name) from e# 后面的代码省略 ③进入具体处理handler的逻辑，self.configure_handler()： 1234567891011121314151617181920212223def configure_handler(self, config): # 省略代码若干行 ... if '()' in config: c = config.pop('()') if not callable(c): c = self.resolve(c) factory = c else: cname = config.pop('class') klass = self.resolve(cname) # 省略代码若干行 ... # 此处的kclass就是配置的class名所对应的类 factory = klass props = config.pop('.', None) # 读取完类名，获取到该类、获取了formatter之后，接着读取conf里面的数据 # 在这里将剩下所定义的参数，弄成dict类型的数据 kwargs = {k: config[k] for k in config if valid_ident(k)} try: # 直接将dict类型的数据作为函数入参，实例化出一个FileHandler result = factory(**kwargs) except TypeError as te: if &quot;'stream'&quot; not in str(te): raise 其中的调试数据截图如下：如果没有配置filename的信息，那么实例化类的时候就报错也是理所应当，因此还可以尝试性地配置encoding参数到其中，工作正常。 总结虽然对这一块的整体了解还不够，但是对于能够参照官方文档，参考源代码实现，完成自己的想法，做到的那一刻还是有点成就感。 【参考】官方文档：http://flask.pocoo.org/docs/dev/logging","link":"/2019/04/20/789be84ae481.html"},{"title":"Git 操作及原理","text":"Git Diff 的工作原理Myers差分算法 创建基于某个 commit id 的分支1git checkout -b dev c99d6500 查看指定分支的提交12git log mastergit config --global alias.nicelog &quot;log --graph --abbrev-commit --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset'&quot; 如下所示： git 如何存储 图解git原理的几个关键概念 git 如何 merge git merge的原理（递归三路合并算法） 当我们git-merge的时候到底在merge什么. git 如何 rebase Git应用详解第九讲：Git cherry-pick与Git rebase 是否能 cherry-pick 所有的 commit Git应用详解第九讲：Git cherry-pick与Git rebase","link":"/2023/06/12/916fff7d458d.html"},{"title":"Golang面试题库","text":"Goalng context作用，原理，超时控制golang context的理解，context主要用于父子任务之间的同步取消信号，本质上是一种协程调度的方式。另外在使用context时有两点值得注意：上游任务仅仅使用context通知下游任务不再需要，但不会直接干涉和中断下游任务的执行，由下游任务自行决定后续的处理操作，也就是说context的取消操作是无侵入的；context是线程安全的，因为context本身是不可变的（immutable），因此可以放心地在多个协程中传递使用。 切片和数组区别基础问题。 channel关闭阻塞问题，goroutine如何调度，gopark是怎么回事？PMG模型描述，谁创建的PMG,runtime是怎么个东西，怎么启动第一个goroutinegolang CPS并发模型和PMG模型的理解。 go逃逸分析怎么回事，内存什么时候栈分配什么时候堆分配内存方面问题，这个网上很多，自己理解完整正确。 sync.Map实现原理，适用的场景go 1.9 官方提供sync.Map 来优化线程安全的并发读写的map。该实现也是基于内置map关键字来实现的。这个实现类似于一个线程安全的 map[interface{}]interface{} . 这个map的优化主要适用了以下场景：（1）给定key的键值对只写了一次，但是读了很多次，比如在只增长的缓存中；（2）当多个goroutine读取、写入和覆盖的key值不相交时。更进一步，可看sync.Map源码。 go语言有什么优点和缺点优势：容易学习，生产力，并发，动态语法。劣势：包管理，错误处理，缺乏框架。 Go框架用过哪些，有看源码吗优势：beego，go-micro，gin等 Go GC算法，三色标记法描述自己找，网上有 Go内存模型(tcmalloc)tcmalloc是线程缓存的malloc，实现了高效的多线程内存管理，用于替代系统的内存分配相关的函数 算法 行列都是有序的二维数组，查找k是否存在,时间复杂度 123451 3 5 7 93 5 7 9 114 6 8 10 12 二分查找：O(log2（max(m,n))) 有序数组，有2N+1个数，其中N个数成对出现，仅1个数单独出现，找出那个单独出现的数.,时间复杂度1，1，2，2，3，4，4，5，5，6，6，7，7答案为3 O(log2（2N))二分查找，查找中间位置的数相等值是在左边还是右边？左边则再左子数组继续查找，右边则在右子数组继续查找。 100亿个数求top100,时间复杂度分组查找或bitmap 100亿个数和100亿个数求交集，时间复杂度全排列问题，自己找去 hash算法实现(类似crc32或者murmur)，保证随机性和均匀性，减少哈希冲突考的是hash算法的了解，需要知道一些经典哈希算法实现。 100个球，一次只能拿2-5个，你先拿，我后拿，怎么保证你能拿到最后一个球一次2-5，去掉先手，最后回合剩余7个即可保证拿到最后一个球。因此，先手拿2个，每一回合保证拿掉球的总数为7，即可。（100-2）/7=14回合。 正整数数组，求和为sum的组合 换零钱，1,5,10元都很充足，给你N元去换零钱，多少种换法算法题给定一个有n个正整数的数组A和一个整数sum,求选择数组A中部分数字和为sum的方案数，动态规划法。 图的最短路径 操作系统 Select/epoll，IO多路复用，底层数据结构，epoll的几个函数，两种模式Select/epoll 问题，网上很多 抢占式调度是什么回事进程优先级和时间分片等方面理解 用户态和内核态系统态(内核态)，操作系统在系统态运行——运行操作系统程序用户态(也称为目态)，应用程序只能在用户态运行——运行用户程序 MySQL innodb和myisam区别(事务，索引，锁。。。) B+树和B树区别，优缺点B树每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为null。只有叶子节点存储data，叶子节点包含了这棵树的所有键值，叶子节点不存储指针，顺序访问指针，也就是每个叶子节点增加一个指向相邻叶子节点的指针。 B树和二叉查找树或者红黑色区别 聚簇索引什么特点，为什么这样，顺序查询的实现，回表查询，联合索引特性聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因 大表分页查询,10亿行数据，查找第N页数据，怎么优化根据查询的页数和查询的记录数可以算出查询的id的范围，可以使用 id between and 来查询。 悲观锁和乐观锁，mysql相关锁说一下说下概念，其他网上找：乐观锁（ Optimistic Locking）：对加锁持有一种乐观的态度，即先进行业务操作，不到最后一步不进行加锁，”乐观”的认为加锁一定会成功的，在最后一步更新数据的时候再进行加锁。悲观锁（Pessimistic Lock）：悲观锁对数据加锁持有一种悲观的态度。因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 如何分库分表1）垂直分表也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。2）垂直分库垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。切分后，要放在多个服务器上，提高性能。3）水平分库分表将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。 Redis 几种数据结构(list,set,zset,geohash,bitmap)实现原理 pipline用来干嘛pipeline的作用是将一批命令进行打包，然后发送给服务器，服务器执行完按顺序打包返回。 事务redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 备份(aof/rdb)原理，哪些参数可调RDB是根据指定的规则定时将内存中的数据备份到硬盘上，AOF是在每次执行命令后命令本身记录下来，所以RDB的备份文件是一个二进制文件，而AOF的备份文件是一个文本文件。至于调参，网上可找。 网络模型redis网络模型，网上找，需要理解。 为什么单线程就能hold住几万qpsI/O复用，Reactor 设计模式 热点key怎么处理 热key加载到系统内存中，直接从系统内存中取，而不走到redis层。 redis集群，热点备份分布到集群中，避免单台redis集中访问。 一致性hash解决什么问题redis集群和负载均衡 redis集群(主从，高可用，扩展节点) Kafka 消息是否按照时间有序，kafka分区的数据是否有序，如何保证有序不保证按时间有序，主题在单个分区是有序的。 如何保证有序？kafka topic 只设置一个分区，或者producer将消息发送到指定分区 Kafka为什么吞吐量高1）顺序读写kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能，顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写。2）零拷贝利用Linux kernel”零拷贝(zero-copy)”系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”。3）分区kafka中的topic中的内容可以被分为多分区存在，每个分区又分为多个段，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力。4）批量发送kafka允许进行批量发送消息，producter发送消息的时候，可以将消息缓存在本地,等到了固定条件发送到kafka等消息条数到固定条数，一段时间发送一次。5）数据压缩Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩。压缩的好处就是减少传输的数据量，减轻对网络传输的压力 kafka的存储模型 Kafka消费者多个group消费同一个topic,会重复消费吗？ 项目问题 遇到过内存溢出吗？怎么解决主要了解有没有处理过内存泄漏导致的问题，C/C++定位内存泄漏问题；Golang和JAVA主要与GC的工作机制有关，堆内存一直增长，导致应用内存溢出等。 布隆过滤器怎么设置m,n,k的值，怎么合理安排key(用户和item越来越多，怎么保证内存不会爆)m,n,k 网上有实践经验，可参考。item越来越多的话，进行item的拆分，拆分本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。 服务雪崩怎么处理，怎么解决保证不影响线上限流，降级，熔断方面措施，结合后端系统架构阐述，如网关的限流和快速失败。 redis和mysql数据一致性怎么保证重点考虑业务逻辑上写和数据的流程（异常和错误处理等），结合MQ做异步重试处理。 分布式锁应用场景，哪些坑锁过期了，业务还没执行完；分布式锁，redis主从同步的坑；获取到锁后，线程异常。","link":"/2020/09/07/bcbf447aaf6e.html"},{"title":"Golang：半个月从入门到辞退?","text":"这不是标题党，这是一份学习笔记，记录遇到的问题，包括但不仅仅限于 golang 的语法格式、常用用法、神奇操作等。 Update: 本以为一篇长文就可以搞定这个入门到辞退，感觉东西好多啊，还是分开多篇吧。 关键字func编译报错，返回值要么都有名，要么都没有名称。 123func funcMui(x, y int) (sum int, error) { return x + y, nil} range123456789101112func main() { slice := []int{0, 1, 2, 3} m := make(map[int]*int) for key, val := range slice { m[key] = &amp;val } for k, v := range m { fmt.Println(k, &quot;-&gt;&quot;, *v) }} 输出： 12345[Running] go run &quot;/tmp/main.go&quot;0 -&gt; 31 -&gt; 32 -&gt; 33 -&gt; 3 defer是用来延迟执行某个操作，可以是语句、也可以是函数，而且延迟发生在调用函数 return 之后。defer 的重要用途 清理释放资源执行 recover被 defer 的函数在 return 之后执行，这个时机点正好可以捕获函数抛出的 panic，因而 defer 的另一个重要用途就是执行 recover。recover 只有在 defer 中使用才更有意义，如果在其他地方使用，由于 program 已经调用结束而提前返回而无法有效捕捉错误。 1234567891011package mainimport &quot;fmt&quot;func main() { defer func() { if ok := recover(); ok != nil { fmt.Println(&quot;recover&quot;) } }() panic(&quot;error&quot;)} 多个 defer 后进先出将 defer 视为一个入栈操作，内容是函数或语句，如果有 defer 语句，但是没有执行到，也就没有入栈，最终也不会执行。 123456789101112func test() { defer func() { fmt.Println(&quot;2&quot;) }() defer func() { fmt.Println(&quot;3&quot;) }() defer func() { fmt.Println(&quot;4&quot;) }() panic(&quot;触发异常&quot;)}func main() { defer func() { fmt.Println(&quot;1&quot;) }() test()} 运行结果为： 被 deferred 函数的参数在 defer 时确定12345678910111213141516171819202122func a() { i := 0 defer fmt.Println(i) i++ return}// 输出 0func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret}func main() { a := 1 b := 2 defer calc(&quot;1&quot;, a, calc(&quot;10&quot;, a, b)) a = 0 return}// 输出 // 10, 1, 2, 3// 1, 1, 3, 4 被 defer 的函数可以读取和修改带名称的返回值1234func c() (i int) { defer func() { i++ }() return 1} 返回2 new内建函数，函数原型为 1func new(Type) *Type 官方文档描述为： The new build-in function allocates memory（仅仅分配空间）. The first argument is a type, not a value, and the value returned is a pointer to a newly allocated zero value of that type. 内置函数 new 分配空间。传递给new 函数的是一个类型，不是一个值。返回值是 指向这个新分配的零值的指针。 根据这段描述，我们也可以自己实现一个类似 new 的功能 12345func newInt *int { var i int return &amp;i //为何可以返回局部变量呢？}someInt := newInt() 这里要注意的第一点是，返回值是一个指针。 为何一个golang 中的函数可以返回局部变量呢？ golang 和 c 语言不一样，栈区分配的存储空间不会随着函数的返回而释放，本地变量地址所占据的存储空间会生存下来。那么什么时候会释放呢？ 什么情况下才会释放呢？ make内建函数，函数原型是： 1func make(Type, size IntegerType) Type 第一个参数是一个类型，第二个参数是长度，返回值是一个类型 make 仅用于创建 Slice, Map 和 Channel The make built-in function allocates and initializes an object（分配空间 + 初始化） of type slice, map or chan**(only)**. Like new , the first arguement is a type, not a value. Unlike new, make’s return type is the same as the type of its argument, not a pointer to it. The specification of the result depends on the type. Slice:The size specifies the length. The capacity of the slice is equal to its length. A second integer argument may be provided to specify a different capacity; it must be no smaller than the length. For example, make([]int, 0, 10) allocates an underlying array of size 10 and returns a slice of length 0 and capacity 10 that is backed by this underlying array. Map:An empty map is allocated with enough space to hold the specified number of elements. The size may be omitted, in which case a small starting size is allocated. Channel:The channel’s buffer is initialized with the specified buffer capacity. If zero, or the size is omitted, the channel is unbuffered. 内建函数 make 分配并且初始化 一个 slice, 或者 map 或者 chan 对象。 并且只能是这三种对象。 和 new 一样，第一个参数是 类型，不是一个值。 但是make 的返回值就是这个类型（即使一个引用类型），而不是指针。 具体的返回值，依赖具体传入的类型。 Slice : 第二个参数 size 指定了它的长度，此时它的容量和长度相同。你可以传入第三个参数 来指定不同的容量值，但是必须不能比长度值小。比如: make([]int, 0, 10) Map: 根据size 大小来初始化分配内存，不过分配后的 map 长度为0。 如果 size 被忽略了，那么会在初始化分配内存的时候 分配一个小尺寸的内存。 Channel: 管道缓冲区依据缓冲区容量被初始化。如果容量为 0 或者被 忽略，管道是没有缓冲区的。 12var p *[]int = new([]int)var v []int = make([]int, 10) 上述第一条语句 使用 new() 函数为 切片结构分配内存，*p == nil （这意味着什么？ 意味着没有对Slice结构进行初始化）， 但是在实际中这种用法很少使用。第二条语句使用 make() 函数创建了一个有10个元素的 Slice对象。 123456789101112// [0 0 0 0 0 1 2 3]func main1() { s := make([]int, 5) s = append(s, 1, 2, 3) fmt.Println(s)}// [1 2 3 4]func main2() { s := make([]int, 0) s = append(s, 1, 2, 3, 4) fmt.Println(s)} 协程协程间通信如何让主协程等待子协程特定的时间，比如说 3s，超时后忽略子协程。 持续更新 ing… Reference https://studygolang.com/articles/3496 https://sanyuesha.com/2017/07/23/go-defer/","link":"/2020/08/03/fb9b4d686ed9.html"},{"title":"Google搜索技巧集合","text":"最为一个我们生活、工作中都离不开的一种搜索工具，其实它远比我们想象中的要强得多。所以就有了这一篇对搜索技巧的收集，也许暂时不会用上，需要的时候能想起来就是一件再好不过的事情。 完全匹配搜索关键字对比效果显而易见：加上双引号，即为需要完全匹配；不加则为部分匹配。 排除关键字 或在默认搜索下, 搜索引擎会反馈所有和查询词汇相关的结果, 如果通过OR 搜索, 可以得到和两个关键词分别相关的结果, 而不仅仅是和两个关键词都同时相关的结果. 同义词加~ 站内搜索指定某个网站，在改网站类搜索关键字 模糊匹配 数值之间搜索 指定文件类型下电子书的福音啊，感觉非常实用 相关网站这个搜索命令并没有看太懂，先留坑。 inurl指令用于搜索查询词出现在url 中的页面。 intitle指令返回的是页面title 中包含关键词的页面。 参考链接：https://daily.zhihu.com/story/1175http://www.ecaa.ntu.edu.tw/weifang/cea/%E5%96%84%E7%94%A8GOOGLE.htm","link":"/2019/01/01/6159946465cf.html"},{"title":"Go与C、汇编之间的调用","text":"Go调用汇编新建如下目录 12345asm├── add│ ├── add.go│ └── add_amd64.s└── main.go 在 add.go 中定义一个函数声明，如下： 123package addfunc Add(a, b uint64) uint64 同时在 add.go 的同一目录层级下，新建 add_amd64.s 文件，如下： 123456TEXT ·Add+0(SB),$0-24MOVQ a+0(FP),BXMOVQ b+8(FP),BPADDQ BP,BXMOVQ BX,res+16(FP)RET ; 最后在 main.go 中写入调用代码，如下： 1234567891011package mainimport ( &quot;fmt&quot; &quot;golang-exercise/asm/add&quot;)func main() { fmt.Println(add.Add(2, 1)) fmt.Println(add.Add(1, 1))} 输出结果： 1232","link":"/2022/06/01/5c4e354e0c1f.html"},{"title":"Gradle 使用笔记","text":"操作环境：macOS Big Sur 安装 Gradle Releases 最方便的还是使用 brew 来安装：brew install gradle，如果不太方便使用（因为会安装所依赖的 openjdk），可以采用下面的手动安装方式： 1234curl -LO https://services.gradle.org/distributions/gradle-7.1-bin.zipunzip gradle-7.1-bin.zipmv gradle-7.1/ /usr/local/Cellar/gradleln -s /usr/local/Cellar/gradle/bin/gradle /usr/local/bin/gradle 测试输出如下： 1234567891011121314$ gradle -v------------------------------------------------------------Gradle 7.1------------------------------------------------------------Build time: 2021-06-14 14:47:26 UTCRevision: 989ccc9952b140ee6ab88870e8a12f1b2998369eKotlin: 1.4.31Groovy: 3.0.7Ant: Apache Ant(TM) version 1.10.9 compiled on September 27 2020JVM: 11.0.10 (Oracle Corporation 11.0.10+8-LTS-162)OS: Mac OS X 10.16 x86_64 Hello World新建一个目录叫做 gradle-test，并在改目录下创建一个 build.gradle 123mkdir gradle-testcd gradle-testvim build.gradle gradle 内容如下： 12345task hello { doLast { println 'Hello world!' }} Reference https://www.cnblogs.com/hellxz/p/helloworld-gradle.html https://docs.gradle.org/current/userguide/tutorial_using_tasks.html","link":"/2021/06/18/dd2109c3e2a6.html"},{"title":"HDOJ 1003 最大子序列和","text":"这道关于DP的经典题终于花时间弄明白了。一定要记录一下啊。题目链接。 思路对这个题目，其实最重要的是思路。参考了此博客上面的思路，在这里对DP求解的思路做一些整理。 设数组$arr$的长度为$n$，下标从$0$到$n-1$，则最后一个元素表示为$arr[n-1]$。对连续和最大的子数组（后称”最大子数组“），最后一个元素$arr[n-1]$有如下三种情况： $arr[n-1]$单独构成最大子数组 最大子数组以$arr[n-1]$结尾 最大子数组跟$arr[n-1]$没关系，最大子数组在$arr[0-n-2]$范围内，转为考虑元素$arr[n-2]$ 从上面我们可以看出，问题分解成了三个子问题，最大子数组就是这三个子问题的最大值，现假设： 以$arr[n-1]$为结尾的最大子数组和为$End[n-1]$ 在$[0,n-1]$范围内的最大子数组和为$All[n-1]$ 如果最大子数组跟最后一个元素无关，即最大和为$All[n-2]$（存在范围为$[0, n-2]$），则解 $All[n-1]$ 为下述三种情况的最大值，即 $arr[n-1]$ $End[n-1]$ $All[n-2]$ 从后向前考虑，初始化的情况分别为$arr[0]$，以$arr[0]$结尾，即$End[0] = arr[0]$，最大和范围在$[0,0]$之内，即$All[0]=arr[0]$。根据上面分析，$All[i]$ 的值应该取下述三种情况的最大值： $arr[i]$ $End[i-1]+arr[i]$ $All[i-1]$ 伪代码表示为： 12345678910111213141516/* DP base version*/#define max(a,b) ( a &gt; b ? a : b) int Maxsum_dp(int * arr, int size){ int End[30] = {-INF}; int All[30] = {-INF}; End[0] = All[0] = arr[0]; for(int i = 1; i &lt; size; ++i) { End[i] = max(End[i-1]+arr[i],arr[i]); All[i] = max(End[i],All[i-1]); } return All[size-1];} 仔细看上面DP方案的代码，End[i] = max{arr[i],End[i-1]+arr[i]}，如果$End[i-1]&lt;0$，那么$End[i]=arr[i]$，什么意思？ $End[i]$表示以i元素为结尾的子数组和，如果某一位置使得它小于0了，那么就自当前的$arr[i]$从新开始，且$End[i]$最初是从$arr[0]$开始累加的。 所以这可以启示我们：我们只需从头遍历数组元素，并累加求和，如果和小于0了就自当前元素从新开始，否则就一直累加，取其中的最大值便求得解。 为什么当sum&lt;0时可以舍弃序列并重新扫描呢？证明如下： 设$i$表示子序列的起始下标，$j$ 表示子序列的终止下标。 当我们得到一个子序列，如果子序列的第一个数是非正数，那么可以舍去，即$i = i + 1$ 当一个子序列的前$n$个元素和为非正数时，是否也可以舍去呢？答案是可以的。 假设 $k\\in[i,j]$，$sum(a,b)=\\sum_{i=a}^barr[i]$，得： $sum(i,j)&lt;0$ $\\because sum(i,k)&gt;0$ 且 $sum(i,k)+sum(k,j)=sum(i,j)$$\\therefore sum(k,j)&lt;sum(i,j)&lt;0$ 所以如果把 $k$ 到 $j$ 的序列附加到 $j$ 之后的序列上，只会使序列越来越小。所以 $i$ 到 $j$ 的序列都可以舍去。 代码1234567891011121314151617181920212223242526272829303132333435363738import java.io.FileInputStream;import java.io.FileNotFoundException;import java.util.Scanner;public class Main { public static void main(String[] args) throws FileNotFoundException { Scanner sc = new Scanner(System.in); //sc = new Scanner(new FileInputStream(&quot;src\\\\oj\\\\hdoj\\\\Q1003.txt&quot;)); int N = sc.nextInt(); for (int l = 0; l &lt; N; l++) { int n = sc.nextInt(); int max = -999999, sum = 0, ci = 0, i = 0, j = 0; for (int k = 0; k &lt; n; k++) { int tmp = sc.nextInt(); if (sum &lt; 0){ sum = tmp; ci = k; } else { sum += tmp; } if (sum &gt; max){ j = k; i = ci; max = sum; } } System.out.println(&quot;Case &quot; + (l+1) + &quot;:&quot; ); System.out.println(max + &quot; &quot; + (i + 1) + &quot; &quot; + (j + 1)); if (l &lt; N - 1) { System.out.println(); } } }}","link":"/2018/06/29/7169bf24f6b4.html"},{"title":"Helm3进行template时如何处理Capabilities.KubeVersion字段","text":"在 helm3 中有一个 Capabilities.KubeVersion 字段，可以用来标识目标 Kubernetes 集群的版本，同时在 helm 中，可以通过模板语言，使用这个值来达到兼容性处理的目标。那么这个值，该怎么操作，才能跟随目标集群变动呢？ 场景使用到 Capabilities.KubeVersion 内置变量的场景非常简单，通过 helm create sample 即可在 sample 文件夹中，创建一个默认的 helm chart。在 templates/ingress.yaml 文件中，可以看到一段使用它的代码，如下： 1234567{{- if semverCompare &quot;&gt;=1.19-0&quot; .Capabilities.KubeVersion.GitVersion -}}apiVersion: networking.k8s.io/v1{{- else if semverCompare &quot;&gt;=1.14-0&quot; .Capabilities.KubeVersion.GitVersion -}}apiVersion: networking.k8s.io/v1beta1{{- else -}}apiVersion: extensions/v1beta1{{- end }} 当 Capabilities.KubeVersion 发生变更时，即所部署的目标集群的版本发生变化时，会为此 Ingress 资源渲染成不同的 apiVersion，达到兼容处理的目的。 历史变更当前最新的版本是 3.8.2。 在 helm 的 3.6.0 版本的 CHANGELOG 中，可以看到在 template 子命令中添加了 --kube-version 字段以及相关的测试代码。 也就是说从 3.6.0 版本之后，可以在命令行中直接通过 --kube-version 来设置 .Capabilities.KubeVersion 值。 Capabilities 是什么它的数据结构很简单，是一个简单的结构体，只包含三个属性： 123456789// Capabilities describes the capabilities of the Kubernetes cluster.type Capabilities struct { // KubeVersion is the Kubernetes version. KubeVersion KubeVersion // APIversions are supported Kubernetes API versions. APIVersions VersionSet // HelmVersion is the build information for this helm version HelmVersion helmversion.BuildInfo} APIVersions 是一个字符串数组：type VersionSet []string。KubeVersion 包含三个值： 123456// KubeVersion is the Kubernetes version.type KubeVersion struct { Version string // Kubernetes version Major string // Kubernetes major version Minor string // Kubernetes minor version} 它的这三个值之间的联系，可以通过解析输入版本是的逻辑来进行区分： 1234567891011func ParseKubeVersion(version string) (*KubeVersion, error) { sv, err := semver.NewVersion(version) if err != nil { return nil, err } return &amp;KubeVersion{ Version: &quot;v&quot; + sv.String(), Major: strconv.FormatUint(sv.Major(), 10), Minor: strconv.FormatUint(sv.Minor(), 10), }, nil} 还可以看到 KubeVersion.String() 和 KubeVersion.GitCommit() 都是返回 KubeVersion.Version 字段： 12func (kv *KubeVersion) String() string { return kv.Version }func (kv *KubeVersion) GitVersion() string { return kv.Version } 同时可以 添加--kubeconfig是否会自动去集群查询？按照我们潜意识里面的认知，添加了 --kubeconfig 之后，与集群相关的数据，会以集群中的实际数据为准，也就是我们觉得它会去集群中先获得集群的版本，然后再进行渲染，但是结果却不是这样的。 通过 minikube 创建一个版本为 1.18.20 的 Kubernetes 集群： 1minikube start --driver=hyperkit --kubernetes-version=v1.18.20 这个时候，如果指定刚创建集群的 kubeconfig，Ingress 的 apiVersion 应当是 networking.k8s.io/v1beta1，但却看到了 networking.k8s.io/v1。 12345helm template . --kubeconfig=/Users/yangyu/.kube/config---# Source: sample/templates/ingress.yamlapiVersion: networking.k8s.io/v1kind: Ingress 也就是说指定了 kubeconfig 之后，并没有按照我们预期的那样去执行。这是为什么？ 通过在 pkg/action/action.go:renderResources() 方法中的断点调试 我们可以看到，渲染时 .Capabilities.KubeVersion 的值是 v1.20.0。 这个值不是目标集群的值，同时我们也没有指定 --kube-version。那这个值是哪来的？通过对 KubeVersion 结构体的初始化调用的查看，可以看到有一处初始化默认版本的代码，如下： 1234567891011121314151617181920var ( // The Kubernetes version can be set by LDFLAGS. In order to do that the value // must be a string. k8sVersionMajor = &quot;1&quot; k8sVersionMinor = &quot;20&quot; // DefaultVersionSet is the default version set, which includes only Core V1 (&quot;v1&quot;). DefaultVersionSet = allKnownVersions() // DefaultCapabilities is the default set of capabilities. DefaultCapabilities = &amp;Capabilities{ KubeVersion: KubeVersion{ Version: fmt.Sprintf(&quot;v%s.%s.0&quot;, k8sVersionMajor, k8sVersionMinor), Major: k8sVersionMajor, Minor: k8sVersionMinor, }, APIVersions: DefaultVersionSet, HelmVersion: helmversion.Get(), }) 所以，v1.20.0 这个版本是默认的 KubeVersion。从而可以从侧面印证：即使指定了 kubeconfig，也不会从集群中获取集群的版本。 Helm template 时 Capabilities 的加载流程总共分为3个步骤，主要看 --validate 是否为 true。 初始化时读取 --kube-version在 template 子命令最开始运行时，会读取 --kube-version 的输入（前提是有设置 --kube-version） 1234567if kubeVersion != &quot;&quot; { parsedKubeVersion, err := chartutil.ParseKubeVersion(kubeVersion) if err != nil { return fmt.Errorf(&quot;invalid kube version '%s': %s&quot;, kubeVersion, err) } client.KubeVersion = parsedKubeVersion} 设置默认 Capabilities 或已读取的 --kube-version在快要进行渲染操作前，若为 ClientOnly 模式，则使用 DefaultCapabilities 或已读取的 --kube-version。 12345678910111213141516if i.ClientOnly { // Add mock objects in here so it doesn't use Kube API server // NOTE(bacongobbler): used for `helm template` i.cfg.Capabilities = chartutil.DefaultCapabilities.Copy() if i.KubeVersion != nil { i.cfg.Capabilities.KubeVersion = *i.KubeVersion } i.cfg.Capabilities.APIVersions = append(i.cfg.Capabilities.APIVersions, i.APIVersions...) i.cfg.KubeClient = &amp;kubefake.PrintingKubeClient{Out: ioutil.Discard} mem := driver.NewMemory() mem.SetNamespace(i.Namespace) i.cfg.Releases = storage.Init(mem)} else if !i.ClientOnly &amp;&amp; len(i.APIVersions) &gt; 0 { i.cfg.Log(&quot;API Version list given outside of client only mode, this list will be ignored&quot;)} 那什么是 ClientOnly 模式？在 template 命令初始化的时候，可以看到 1client.ClientOnly = !validate 其中 validate 来自 f.BoolVar(&amp;validate, &quot;validate&quot;, false, &quot;xxx&quot;)。也就是说，可以通过指定 --validate=true 来避免被设置成 DefaultCapabilities。 集群中读取 KubeVersion如果非 ClientOnly 模式，它是从 k8s 集群中获取。代码如下： 1234567891011121314151617181920caps, err := i.cfg.getCapabilities()// getCapabilities()if cfg.Capabilities != nil { return cfg.Capabilities, nil}dc, err := cfg.RESTClientGetter.ToDiscoveryClient()kubeVersion, err := dc.ServerVersion()apiVersions, err := GetVersionSet(dc)cfg.Capabilities = &amp;chartutil.Capabilities{ APIVersions: apiVersions, KubeVersion: chartutil.KubeVersion{ Version: kubeVersion.GitVersion, Major: kubeVersion.Major, Minor: kubeVersion.Minor, }, HelmVersion: chartutil.DefaultCapabilities.HelmVersion,}return cfg.Capabilities, nil 综上所述，Capablities 的初始化过程的脑图如下： 正确的姿势经过上面的分析，正确的处理方式只有两种，如下： 1helm template . --kubeconfig=/Users/yangyu/.kube/config --validate=true 或 1helm template . --kube-version=v1.15.0 所以，--kubeconfig 只是作为 --validate=true 时才会生效的一个选项。 Reference https://github.com/helm/helm https://helm.sh/docs/helm/helm_template","link":"/2022/05/01/573f5a05f677.html"},{"title":"HashMap源代码分析","text":"HashMap 是日常工作开发中经常使用到的一个集合类，并且 hash 这一类数据结构有着类似的实现，比如 redis 中的 hash 结构与 HashMap 就有着惊人的类似。因此读完 HashMap 会有一种举一反三的感觉，非常值得学习。 继承关系简要图 HashMap类前注释（搓翻译） 挑重点看，挑重点翻译~ 一种基于散列表的Map接口实现。允许null值与null键。HashMap与HashTable大致相同，区别在于前者是非同步且允许null。不保证顺序，且顺序可能会变。 如果hash函数足够好，这种实现中的基础操作（如get、put）只需常量时间即可。选择初始容量与加载因子非常重要，如果你非常在意Iterator的表现。 一个HashMap实例拥有两个影响它的性能的因素：初始容量和加载因子。 初始容量：在hash表创建时桶的个数，即数组长度； 加载因子：一种衡量哈希表所允许的最大容量的参数。 当 size 超过 capacity * 加载因子 时，哈希表将进行rehash操作，也即容量将翻1倍。 通常来说，默认的加载因子0.75可以在时间消耗和空间消耗之间取得一个较好的平衡。过高，会减少空间消耗但会增加查看消耗（表现在HashMap中的大部分操作，包括get和put）。 当设置它的初始容量时，为了减少rehash的次数，所预期的元素个数以及加载因子应当被考虑到。如果初始容量比元素的个数除以加载因子的结果要大，那么将不会发生rehash操作。 如果要存很多元素，给一个充分大的容量给它，将会比“给个小容量然后让其自动增长容量”这种方式更加高效。 如果使用了过多的经过hashCode()处理后得到相同值的键，无论在任何哈希表中，这都会表现得更慢。为了改善这种影响，当键是Comparable是，将对他们进行比较。 什么是对Map的结构性修改？添加或删除某个键值对，修改不是。 需要注意，此类不是线程同步的。 成员变量123456789101112131415161718// 默认起始容量-必须是2^nstatic final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 最大容量，如果任何具有参数的构造函数隐式指定较高的值，则使用该容量。static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 构造函数没有指定加载因子时的默认值static final float DEFAULT_LOAD_FACTOR = 0.75f;// 当添加节点时，节点数至少达到这个临界值，才尝试将链表转换成树static final int TREEIFY_THRESHOLD = 8;// resize 时树上节点小于等于此值时，树将变成链表static final int UNTREEIFY_THRESHOLD = 6;// 当链表上的节点数，大于 TREEIFY_THRESHOLD 且 tab.length &gt;= MIN_TREEIFY_CAPACITY// 才将链表转换成红黑树static final int MIN_TREEIFY_CAPACITY = 64; 如果在某个链表上节点个数达到 8，会尝试将链表结构转换成红黑树结构，最终是否转换成红黑树，还得看 tab.length 是否达到 MIN_TREEIFY_CAPACITY。 12// HashMap中的桶，也即一个 Node 数组transient Node&lt;K,V&gt;[] table; 链表节点先看链表节点的数据结构。这是一个单链表，其中包括了多项信息，诸如键、值、hash值以及下一个节点的引用。 12345678910111213141516171819202122232425262728293031323334353637static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash;// hash值 final K key;// 键 V value;// 值 Node&lt;K,V&gt; next;// 单向链表，指向下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) { // ... } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } // 这个hash值计算的是整个键值对的hash值 public final int hashCode() { // key的hash与value的hash相与 return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 判定两个 Node 是否相等：两者的键、值 equals 相等 public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp;// 键相同 Objects.equals(value, e.getValue()))// 值相同 return true; } return false; }} 上述代码中，使用的Objects的相应方法如下： 123456public static int hashCode(Object o) { return o != null ? o.hashCode() : 0;}public static boolean equals(Object a, Object b) { return (a == b) || (a != null &amp;&amp; a.equals(b));} 构造函数共3个。分别用于指定相应的加载因子与起始容量。如下： 1234567891011121314151617181920// 指定加载因子与起始容量public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;...&quot;); // MAXIMUM_CAPACITY 不是最大整数(2^31 - 1) if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;&quot;); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);}// 指定起始容量，加载因子默认public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);}// 全部默认public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; } 大致总结如下： 入参异常判断 最大值判断。如果超出了MAXIMUM_CAPACITY，那么将起始容量置为MAXIMUM_CAPACITY。 正常情况处理。通过 tableSizeFor() 为 initialCapacity 计算一个threshold，这个值是下次resize()时，需要扩展到的容量。 tableSizeFor其计算方式如下： 12345678910 // 对给定的容量，比它大的、为2^n的值static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 此处位运算略有抽象，通过代入数值进行手动计算、对比就知道它到底在执行什么操作。 通过无符号右移与相或，可以让原来数二进制的最高位到最低位，全部变成 1，也就是大于原数的2^n-1，后面加1，达到2^n。 假设传入的 initialCapacity 为 9，二进制为 1001，减 1 后为 1000。如下： 1234567891000 &gt;&gt;&gt; 1 = 01001000 | 0100 = 11001100 &gt;&gt;&gt; 2 = 00111100 | 0011 = 11111111 &gt;&gt;&gt; 4 = 00001111 | 0000 = 1111… 在构造函数里面没有对本实例中的容量做任何修改，那当我们初始化一个 HashMap 之后，其中的 capacity 是多少呢？ 初始化时，table 为空，所以 capacity 的来源只有 threshold 和 DEFAULT_INITIAL_CAPACITY(16)，分别对应有传 initialCapacity 和未传 initialCapacity 的情况。 12345final int capacity() { return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY;} 增加 - put()从put()开始，假设我们map.put(&quot;first&quot;, 1);。我们将计算出key的hash值，并跳转到putVal中。 123public V put(K key, V value) { return putVal(hash(key), key, value, false, true);} 其中传入了两个boolean变量： onlyIfAbsent，为 true 则已存在时覆盖改值 evict，为构建模式（creation mode） hash(key)干了什么? 1234567891011121314151617181920/*** Computes key.hashCode() and spreads (XORs) higher bits of hash* to lower. Because the table uses power-of-two masking, sets of* hashes that vary only in bits above the current mask will* always collide. (Among known examples are sets of Float keys* holding consecutive whole numbers in small tables.) So we* apply a transform that spreads the impact of higher bits* downward. There is a tradeoff between speed, utility, and* quality of bit-spreading. Because many common sets of hashes* are already reasonably distributed (so don't benefit from* spreading), and because we use trees to handle large sets of* collisions in bins, we just XOR some shifted bits in the* cheapest possible way to reduce systematic lossage, as well as* to incorporate impact of the highest bits that would otherwise* never be used in index calculations because of table bounds.*/static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);} 键为时就为0，否则先得到键的hashCode()，无符号右移16位后，再与原数异或，得到键的hash。 接下来进入 putVal 的流程，主要分成 3 块逻辑： 初始化：第一次插入。 数组上没有节点。直接将数组中相应位置，修改成该节点。 数组上存在节点。 如果数组上的第一个 Node与所 put 的Node相同，即已存在（判断条件：先判 hash，再判 equals），则视情况(onlyIfAbsent)来决定是否替换 value。 为树节点，则将节点添加到红黑树。 遍历 Node 链表 找到相同的 Node，视情况替换。 到达链表末端，添加新节点到链表末端。 如果链表上的数量大于等于 TREEIFY_THRESHOLD tab.length 小于 MIN_TREEIFY_CAPACITY 时进行 resize() 操作 否则，将链表转化成一颗红黑树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果桶数组为空，那么将利用resize()初始化一个桶数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 此处的位置，为什么还需要将hash与length-1？所以位置不是hash值？ // 好像不太对，n = 2^m，所以n-1应该是全1的某个数，如7,15。 // 因此位置还应该是hash值。 if ((p = tab[i = (n - 1) &amp; hash]) == null)// 位置上不存在键值对 tab[i] = newNode(hash, key, value, null);// 新建一个 else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;// 若键值对的hash,key都相同，则将p暂存到e中 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {// 键值不相同，从next遍历后续链表，如果存在就替换，不存在就添加到其上。 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) {// 没有后续节点 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash);// 怕是要变身 break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break;// 选择跳出，说明找到相同的键，并将该节点暂存到e中 p = e;// p指向e，即p.next，也就是p节点的下一个 } } if (e != null) { // e不为空说明键已存在 V oldValue = e.value; // 之前传进来的值起作用了。传进来的是false，此时会替换。 // 如果是true的话，且旧值为空，还是会替换。 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e);// 一个回调 return oldValue; } } ++modCount; if (++size &gt; threshold) resize();// 同样的，要变身 afterNodeInsertion(evict);// 还是一个回调 return null;} 扩容初始化或者将容量加倍时会调用resize()。主要分成两部分 计算新的容量与临界值 将原数组中的节点按照相应的规律分配到新数组中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; // ----------------- 我是分割线 ----------------- @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null)//该桶没有后续的节点 // 新数组上的位置可能与之前不同，可能是二倍 // newCap-1为0b11...11样式的二进制，比oldCap-1多一位1 // 相与的话，取决于hash值的前一位。所以可能是相同，可能是(原位置➕原容量) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order // 对拥有后续链表的桶，另做处理 // lo应该是low的缩写，hi是high的缩写，表示0或1 // 哪里的0或1呢？这是关键点，继续看 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历该桶的所有节点 do { next = e.next; // e.hash &amp; oldCap这个与之前的位置有什么差别呢？ // 之前算位置时，是用oldCap-1与hash相与，也就是1111...1样式的二进制， // 现在是10000..00样式的二进制，所以等不等于0 // 取决于hash值的前1位。 if ((e.hash &amp; oldCap) == 0) { // 为什么要用这个loTail？也就是尾。后续需要将尾位置上的节点的next指向e，也就是else所执行的。 if (loTail == null)// 说明还没有数据 loHead = e;// 首 else loTail.next = e;// 尾-&gt;next loTail = e;// 尾 = e; } else { // 逻辑同上，此时位置的二进制的第一位是1 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 组成了一个新的链表，位置在之前的位置的位置上，因为第1位为0 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 组成一个新的链表，位置是原位置+原容量，因为第1位为1 if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 确定新的容量及临界容量对这一部分代码的总体理解如下： 123456789101112131415161718192021222324252627282930Node&lt;K,V&gt;[] oldTab = table;int oldCap = (oldTab == null) ? 0 : oldTab.length;int oldThr = threshold;int newCap, newThr = 0;if (oldCap &gt; 0) { // 此时Map不为空，里面存在键值对 if (oldCap &gt;= MAXIMUM_CAPACITY) { // oldCap &gt;= 0x3fff ffff threshold = Integer.MAX_VALUE; // threshold = 0x7fff ffff return oldTab; } // newCap = oldCap * 2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1;}else if (oldThr &gt; 0) // 此时Map为空，但是new对象的时候，把capacity当做参数， newCap = oldThr; // 传给了HashMap的构造函数，造成了只有threshold有值。else { // 此时Map为空，使用的是无参构造器，threshold和capacity都没有值。 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);}// newThr在程序开始处的默认赋值为0if (newThr == 0) { // 此处补充上述没有为newThr赋值的情况，即 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);}// 使用newCap、newThr初始化扩容后的数组和thresholdthreshold = newThr;Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];table = newTab; 接下来对每段代码进行分析，总共分成3个片段，分别对应上述代码中的3中情况。 ①Map不为空，里面存在键值对代码片段： 123456789if (oldCap &gt; 0) { // 此时Map不为空，里面存在键值对 if (oldCap &gt;= MAXIMUM_CAPACITY) { // oldCap &gt;= 0x4000 0000 threshold = Integer.MAX_VALUE; // threshold = 0x7fff ffff return oldTab; } // newCap = oldCap * 2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1;} 有一个问题，如下： 为什么要做oldCap &gt;= MAXIMUM_CAPACITY判断 首先MAXIMUM_CAPACITY的赋值为1 &lt;&lt; 30，即0x4000 0000。然而Integer.MAX_VALUE = 0x7fff ffff，也就是说MAXIMUM_CAPACITY &lt;&lt; 1会变成0x8000 0000，也就是溢出。 为了模拟一次这种情况，特意编写了下面的代码，运行下面代码的时候，JVM默认的堆大小不够，设了一个最大堆大小为10GB，参数为：-Xmx10240m。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static void main(String[] args) throws Exception { disableWarning(); showHashMapInfo(0x1fffffff); System.out.println(&quot;------------------------------------&quot;); showHashMapInfo(0x3fffffff);}/**输出结果：initialCapacity is : 1fffffffAfter hashMap created, capacity is : 20000000, threshold is : 20000000After resize(initialization), capacity is : 20000000, threshold is : 18000000After resize(double size), capacity is : 40000000, threshold is : 7fffffff------------------------------------initialCapacity is : 3fffffffAfter hashMap created, capacity is : 40000000, threshold is : 40000000After resize(initialization), capacity is : 40000000, threshold is : 7fffffffAfter resize(double size), capacity is : 40000000, threshold is : 7fffffff **/private static void showHashMapInfo(int capacity) throws Exception { System.out.printf(&quot;initialCapacity is : %x\\n&quot;, capacity); HashMap&lt;String, String&gt; hashMap = new HashMap&lt;&gt;(capacity); Class&lt;?&gt; hashMapClass = hashMap.getClass(); // 通过反射的方式打印hashMap的属性值 Method resizeMethod = hashMapClass.getDeclaredMethod(&quot;resize&quot;); Method capacityMethod = hashMapClass.getDeclaredMethod(&quot;capacity&quot;); Field thresholdField = hashMapClass.getDeclaredField(&quot;threshold&quot;); resizeMethod.setAccessible(true); capacityMethod.setAccessible(true); thresholdField.setAccessible(true); System.out.printf(&quot;After hashMap created, capacity is : %x, threshold is : %x\\n&quot;, capacityMethod.invoke(hashMap), thresholdField.get(hashMap)); // 会调用resize初始化Node数组 hashMap.put(&quot;&quot;, &quot;&quot;); System.out.printf(&quot;After resize(initialization), capacity is : %x, threshold is : %x\\n&quot;, capacityMethod.invoke(hashMap), thresholdField.get(hashMap)); // 手动再次resize resizeMethod.invoke(hashMap); System.out.printf(&quot;After resize(double size), capacity is : %x, threshold is : %x\\n&quot;, capacityMethod.invoke(hashMap), thresholdField.get(hashMap));}// 去掉WARNINGprivate static void disableWarning() { System.err.close(); System.setErr(System.out);} 当在构造函数中指定了initialCapacity后，会先将threshold赋值成所需的capacity。所以先看tableSizeFor()函数，它用来将指定的initialCapacity转化成大于该值的2次幂。所以如果一开始capacity的初始值是大于或等于0x40000000的话，HashMap指定的capacity就是0x40000000。源代码如下： 123456789101112131415161718192021// 1public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR);}// 此处并未设置capacity，只是将期望的capacity赋值给了thresholdpublic HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); // initialCapacity超过0x40000000，只取0x40000000 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);}static final int tableSizeFor(int cap) { int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(cap - 1); return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} ②Map为空，但指定了初始大小这种情况对应于上面代码中的HashMap&lt;String, String&gt; hashMap = new HashMap&lt;&gt;(capacity);。这种情况下会将指this.threshold = tableSizeFor(initialCapacity);，导致int oldThr = threshold;能够获取到值，所以if (oldThr &gt; 0)成立，将newCap = oldThr，实现了在第一次resize()初始化数组时，按照指定的initialCapacitynew出数组。 ③Map为空，未指定任何参数这种情况使用默认参数： 12newCap = DEFAULT_INITIAL_CAPACITY; // 16newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 16 * 0.75 得到newCap和newThr之后便开始初始化数组大小。初始化数组后，会将原数组中的Node链表，按照某种规则迁移到新的数组上面去。 扩容后的位置调整如果oldTab == null，那么此次resize属于第一次初始化HashMap中的数组，直接返回刚new出来的新数组即可；当原数组中的第i为存在Node时，新的位置分布存在两种情况，即Node有无后续Node。这两种情况下，在原数组中的位置的计算方式是一样的，即：(n - 1) &amp; hash，其中n = tab.length,所以位置也就是Node的hash值与上length - 1。 1234// HashMap.putVal()n = tab.lengthif ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 无后续Node扩容后的位置新的位置为：e.hash &amp; (newCap - 1) 代码为：newTab[e.hash &amp; (newCap - 1)] = e; 与之前的位置相比，可能是原位，可能是oldCap + 原位 有后续Node扩容后的位置这条链表上面Node的hash值的与上oldCap结果的含义是：**oldCap的最高非0位对应在hash上的那一位到底是0还是1**。因为oldCap是0x400之类的值，只有最高位是1，其他位都是0。 如果结果是0，位置为：原位；如果结果是1，位置为：原位+oldCap 只不过在新位置上之后，可能还是以一个链表的形式存在。 查询 - get()我们先是通过常见的get(Object key)方法来获取相应的值，该方法如下： 1234public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;} 这个方法接受两个参数，一个是kek的hash值，一个是key，在一定程度上可以加快速度吧。 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} 删除 - remove()删除键值对，分两步，第一步是找到对应的键值对，第二步删除该键值对。删除时，可能会有两种情况（不考虑树结构），位于桶数组上或者位于后续的链表上。对于后者，因为此链表是单链表，我们需要将该键值对的前一个节点记录下来。 1234567891011121314151617181920212223242526272829303132333435363738394041final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 寻找键值对完毕，如果没找到node为null if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p)// 在桶数组上 tab[index] = node.next; else// 在链表上，将前个节点的后续改成该键值对的后续，即实现删除了该键值对 p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null;} 后记本文由本人的两篇对 HashMap 的学习总结拼凑而来，第一篇写于 2018 年，第二篇写于 2019 年，期间时隔一年，有一些明显的理解错误已经得到更正。现在是 2021 年，面对两篇曾经的笔记，仍然存在若干词不达意、表达不清、错别字的地方，部分地方是自己当前的理解。 非常感谢你的阅读。","link":"/2018/06/08/988a19122324.html"},{"title":"IDEA中的Debug模式的使用","text":"测试代码 12345678910111213public static void main(String[] args) { hello(); Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(&quot;1&quot;, &quot;1111&quot;); System.out.println(map); System.out.println(map); map.containsKey(&quot;1&quot;);}private static void hello(){ System.out.println(&quot;hello&quot;);} 都打上断点如下：点此开始debug自动跳到断点处，并且在断点之前会有数据结果显示操作说明 名称 快捷键 说明 Step Over F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内，跳到下一条执行语句 Step Into F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则会进入该内嵌的方法中 Force Step Into Alt + Shift + F7 强制进入某个其它类的方法、F7进不了的方法、它都能进 Step Out Shift + F8 跳出该方法，回到原来地方 Resume Program F9 跳出到下一个断点 问题：什么方法F7进入不了？请在IDEA中查看File (menu) -&gt; Settings -&gt; Build, Execution, Deployment -&gt; Debugger -&gt; Stepping -&gt; Do not step into the classes中的配置。如下： 进入hello方法中查看执行过程：F7下一步：F8这里如果用F7，将直接略过、并不会进入HashMap的构造方法，如果想进入其构造方法，需要使用：Alt + Shift +F7跳出此方法后回到new HashMap的地方，需要再按一次：Alt + Shift +F7回到主代码：这里才是感兴趣的地方，但是要进入其中，需要使用Alt + Shift +F7进入该类的方法其中：但是在进入putVal前会先计算hash()、也就是先进入hash()这个本类的方法，所以F7后会进入hash()。回到put后，再按F7将进入putVal，如下：resize()啊，一定要去看一下，F7：这些数据一目了然、看源代码的神器！！先退出这一系列方法到main函数：Shift + F8如果我想略过其中的system.out.pringln，直接到达下一个断点，F9即可：基本的使用方法如上所述。","link":"/2018/11/01/cad8e9ed16af.html"},{"title":"Iterator、Iterable、ListIterator与ArrayList","text":"Iterable从前文的继承关系图来看，Collection继承自Iterable。其接口详情如下：实现这个接口，就可以使用”for-each”循环来遍历其中的元素. 参考For-each Loop. 123456789101112131415161718// 此处返回一个Iterator，以遍历集合public Iterator&lt;E&gt; iterator() { return new Itr();// 此处的Itr请看后续解析}// 顾名思义，对每个元素都执行相应的操作actionpublic void forEach(Consumer&lt;? super E&gt; action) { Objects.requireNonNull(action);//判空 final int expectedModCount = modCount;//遍历时，不能对size更改，详细说明见下面说明 @SuppressWarnings(&quot;unchecked&quot;) final E[] elementData = (E[]) this.elementData;//获取所有元素 final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) { action.accept(elementData[i]);//对每个元素执行相应的操作 } if (modCount != expectedModCount) {// modCount终于派上用场 throw new ConcurrentModificationException(); }} 对于其中的modCount，它记录的是这个list被结构性改变的次数。结构性修改是指那些改变了list的size的操作。这段代码恰好解释了其的作用，如果遍历的过程中，修改了list导致size变化了，那么将会引起modCount的改变，所以此时会造成modCount != expectedModCount成立，即抛出异常。 Iterator上文中的Itr便实现了Iterator这个接口，这个接口的详情如下：Itr的具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263private class Itr implements Iterator&lt;E&gt; { int cursor; // 下一个元素的位置，可能会越界 int lastRet = -1; // 上一个返回了的元素的位置 int expectedModCount = modCount;// 获取初始化此类时的modCount值 public boolean hasNext() { return cursor != size;// cursor的最大值貌似只会到达size } @SuppressWarnings(&quot;unchecked&quot;) public E next() { checkForComodification(); int i = cursor;//获取下一个元素的位置 if (i &gt;= size) throw new NoSuchElementException(); // 获取存有所有元素的数组 Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1;// 指向下一个 return (E) elementData[lastRet = i];// 获取元素 } public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet);// 调用ArrayList的方法删除 cursor = lastRet;// 删除lastRet项后，元素前移，游标指向该项。 lastRet = -1;// 指向-1 expectedModCount = modCount;// 同步条件 } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } @Override @SuppressWarnings(&quot;unchecked&quot;) public void forEachRemaining(Consumer&lt;? super E&gt; consumer) { Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) { throw new ConcurrentModificationException(); } while (i != size &amp;&amp; modCount == expectedModCount) { consumer.accept((E) elementData[i++]);// 对每个元素执行相应的动作。 } cursor = i; lastRet = i - 1; checkForComodification(); } // 检查在遍历期间，是否被修改。 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); }} 因此，使用Iterator遍历，是一个单向的遍历过程，且在过程中不能进行修改size的操作，否者会报错。一些错误的示例代码如下： cursor==size时继续执行next() 123456789101112public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;Hello&quot;, &quot;world&quot;)); Iterator it = list.iterator(); it.next(); it.next(); // 此时cursor等于size，再执行next()操作会触发异常 it.next();}------Exception in thread &quot;main&quot; java.util.NoSuchElementException at java.util.ArrayList$Itr.next(ArrayList.java:854) at Main.main(Main.java:10) 遍历过程中执行改变size的操作 123456789101112public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;Hello&quot;, &quot;world&quot;)); Iterator it = list.iterator(); it.next(); list.add(&quot;too young&quot;);// 会导致modCount++ it.next();// modCount与expectedModCount不一致，抛异常}------Exception in thread &quot;main&quot; java.util.ConcurrentModificationExceptionat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:901)at java.util.ArrayList$Itr.next(ArrayList.java:851)at Main.main(Main.java:9) 关于forEach()的使用使用Iterato时，可以使用其中的forEachRemaining()，效果类似，只是对象是后续剩下的元素。123456789101112public static void main(String[] args) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;Hello&quot;, &quot;world&quot;)); list.forEach(System.out::println); list.forEach(item-&gt;{ System.out.println(&quot;for each : &quot;+item); });}------Helloworldfor each : Hellofor each : world ListIterator简易的继承关系图、接口主要方法如下图所示：之前并没有使用过ListIterator，但是在看Itr时，看到了这个实现，还是挺想知道这是干什么的。获取ListIterator的方式如下： 12345678public ListIterator&lt;E&gt; listIterator(int index) { if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index); return new ListItr(index);}public ListIterator&lt;E&gt; listIterator() { return new ListItr(0);} 其实现的源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 继承自Itr，实现了ListIterator接口private class ListItr extends Itr implements ListIterator&lt;E&gt; { ListItr(int index) { super(); cursor = index;// 指定cursor } public boolean hasPrevious() { return cursor != 0;// cursor为0时，没有前驱 } public int nextIndex() { return cursor;// cursor就是下一个元素的下标 } public int previousIndex() { return cursor - 1;// } @SuppressWarnings(&quot;unchecked&quot;) public E previous() {// 移动cursor向前，调整遍历的方向，并返回前一个元素。这是Itr中未实现的功能 checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[lastRet = i]; } // 将最后一个返回的元素替换成e public void set(E e) { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); // 调用ArrayList的set方法 try { ArrayList.this.set(lastRet, e); } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } // 添加元素到当前游标的位置 public void add(E e) { checkForComodification(); try { int i = cursor;// 位置为当前cursor ArrayList.this.add(i, e);// 调用ArrayList的add方法 cursor = i + 1; lastRet = -1; expectedModCount = modCount;// 修改条件 } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } }}","link":"/2018/06/01/01348ebc6c51.html"},{"title":"JDBC的使用笔记","text":"下午花了三四个小时，在慕课网上看了看关于JDBC的两个系列的视频，跟着做了做。因为之前也看过，所以一直都记得有这么一个视频存在，但是唯一不足的是没写上一些笔记。写个简易的学习笔记，加深一下对其中一些知识的理解，以后翻起来就不用去看视频了，看这个就好。还记录下自己在学习过程中所遇到的一些疑问以及自己所找到的答案。 视频链接如下： JDBC之“对岸的女孩看过来”JDBC之“对岸的女孩走过来” JDBC是什么JDBC（Java DataBase Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。从根本上说，JDBC是一种规范，它提供的接口，一套完整的，可移植的访问底层数据库的程序。具体实现由数据库厂商实现。 虽然在实践中，不会使用这个原始的工具，但是了解一下还是有一些好处的呢。 JDBC使用基本步骤用自己的话描述复述如下： 注册驱动 获取连接 通过连接执行SQL 代码示例： 加载驱动与获取数据库连接1234567891011121314151617181920212223package db;import java.sql.*;public class DBUtil { private static final String URL = &quot;jdbc:mysql://127.0.0.1:3306/imooc&quot;; private static final String NAME = &quot;root&quot;; private static final String PASSWORD = &quot;root&quot;; private static Connection conn; static { try { // 加载驱动程序 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); // 获得数据库连接 conn = DriverManager.getConnection(URL, NAME, PASSWORD); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } public static Connection getConnection(){ return conn; }} 执行SQL123456789public void deleteGoddess(int id) throws SQLException { Connection conn = DBUtil.getConnection(); String sql = &quot;&quot; + &quot; delete from imooc_goddess&quot; + &quot; where id = ?&quot;; PreparedStatement ptmt = conn.prepareStatement(sql); ptmt.setInt(1, id); ptmt.execute();} 基本的CURD123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package dao;import db.DBUtil;import model.Goddess;import java.sql.*;import java.util.ArrayList;import java.util.List;import java.util.Map;public class GoddessDao { public void addGoddess(Goddess goddess) throws SQLException { Connection conn = DBUtil.getConnection(); String sql = &quot;&quot; + &quot;insert into imooc_goddess&quot; + &quot;(user_name, sex, age, birthday, email, mobile, &quot;+ &quot;create_user, create_date, update_user, update_date, isdel)&quot; + &quot;values(&quot;+ &quot;?, ?, ?, ?, ?, ?, ?, current_date(), ?, current_date(), ?)&quot;; PreparedStatement ptmt = conn.prepareStatement(sql); ptmt.setString(1, goddess.getUser_name()); ptmt.setInt(2, goddess.getSex()); ptmt.setInt(3, goddess.getAge()); ptmt.setDate(4, new Date(goddess.getBirthday().getTime())); ptmt.setString(5, goddess.getEmail()); ptmt.setString(6, goddess.getMobile()); ptmt.setString(7, goddess.getCreate_user()); ptmt.setString(8, goddess.getUpdate_user()); ptmt.setInt(9, goddess.getIsdel()); ptmt.execute(); } public void updateGoddess(Goddess goddess) throws SQLException { Connection conn = DBUtil.getConnection(); String sql = &quot;&quot; + &quot; update imooc_goddess&quot; + &quot; set user_name=?, sex=?, age=?, birthday=?, email=?, mobile=?, &quot;+ &quot; update_user=?, update_date=current_date(), isdel=?&quot;+ &quot; where id = ?&quot;; PreparedStatement ptmt = conn.prepareStatement(sql); ptmt.setString(1, goddess.getUser_name()); ptmt.setInt(2, goddess.getSex()); ptmt.setInt(3, goddess.getAge()); ptmt.setDate(4, new Date(goddess.getBirthday().getTime())); ptmt.setString(5, goddess.getEmail()); ptmt.setString(6, goddess.getMobile()); ptmt.setString(7, goddess.getUpdate_user()); ptmt.setInt(8, goddess.getIsdel()); ptmt.setInt(9, goddess.getId()); ptmt.execute(); } public void deleteGoddess(int id) throws SQLException { Connection conn = DBUtil.getConnection(); String sql = &quot;&quot; + &quot; delete from imooc_goddess&quot; + &quot; where id = ?&quot;; PreparedStatement ptmt = conn.prepareStatement(sql); ptmt.setInt(1, id); ptmt.execute(); } public List&lt;Goddess&gt; query() throws SQLException { List&lt;Goddess&gt; gs = new ArrayList&lt;&gt;(); Connection conn = DBUtil.getConnection(); Statement stmt = conn.createStatement(); StringBuilder sb = new StringBuilder(&quot;select * from imooc_goddess&quot;); ResultSet rs = stmt.executeQuery(sb.toString()); Goddess g = null; while (rs.next()){ g = new Goddess(); g.setId(rs.getInt(&quot;id&quot;)); g.setUser_name(rs.getString(&quot;user_name&quot;)); g.setAge(rs.getInt(&quot;age&quot;)); g.setSex(rs.getInt(&quot;sex&quot;)); g.setBirthday(rs.getDate(&quot;birthday&quot;)); g.setEmail(rs.getString(&quot;email&quot;)); g.setMobile(rs.getString(&quot;mobile&quot;)); g.setCreate_date(rs.getDate(&quot;create_date&quot;)); g.setCreate_user(rs.getString(&quot;create_user&quot;)); g.setUpdate_date(rs.getDate(&quot;update_date&quot;)); g.setUpdate_user(rs.getString(&quot;update_user&quot;)); g.setIsdel(rs.getInt(&quot;isdel&quot;)); gs.add(g); } return gs; } public List&lt;Goddess&gt; query(List&lt;Map&lt;String, Object&gt;&gt; params) throws SQLException { List&lt;Goddess&gt; gs = new ArrayList&lt;&gt;(); Connection conn = DBUtil.getConnection(); // 这里有点厉害 StringBuilder sb = new StringBuilder(&quot;select * from imooc_goddess where 1=1&quot;); if (params != null &amp;&amp; params.size() &gt; 0){ for (int i = 0; i &lt; params.size(); i++) { Map&lt;String, Object&gt; map = params.get(i); sb.append(&quot; and &quot; + map.get(&quot;name&quot;) + &quot; &quot; + map.get(&quot;rela&quot;) + &quot; &quot; + map.get(&quot;value&quot;)); } } System.out.println(sb.toString()); PreparedStatement ptmt = conn.prepareStatement(sb.toString()); ResultSet rs = ptmt.executeQuery(); Goddess g = null; while (rs.next()){ g = new Goddess(); g.setUser_name(rs.getString(&quot;user_name&quot;)); g.setAge(rs.getInt(&quot;age&quot;)); g.setSex(rs.getInt(&quot;sex&quot;)); g.setBirthday(rs.getDate(&quot;birthday&quot;)); g.setEmail(rs.getString(&quot;email&quot;)); g.setMobile(rs.getString(&quot;mobile&quot;)); g.setCreate_date(rs.getDate(&quot;create_date&quot;)); g.setCreate_user(rs.getString(&quot;create_user&quot;)); g.setUpdate_date(rs.getDate(&quot;update_date&quot;)); g.setUpdate_user(rs.getString(&quot;update_user&quot;)); g.setIsdel(rs.getInt(&quot;isdel&quot;)); gs.add(g); } return gs; } public Goddess get(int id) throws SQLException { Connection conn = DBUtil.getConnection(); String sql = &quot;&quot; + &quot; select * from imooc_goddess&quot; + &quot; where id = ?&quot;; PreparedStatement ptmt = conn.prepareStatement(sql); ptmt.setInt(1, id); ResultSet rs = ptmt.executeQuery(); Goddess g = null; while (rs.next()){ g = new Goddess(); g.setUser_name(rs.getString(&quot;user_name&quot;)); g.setAge(rs.getInt(&quot;age&quot;)); g.setSex(rs.getInt(&quot;sex&quot;)); g.setBirthday(rs.getDate(&quot;birthday&quot;)); g.setEmail(rs.getString(&quot;email&quot;)); g.setMobile(rs.getString(&quot;mobile&quot;)); g.setCreate_date(rs.getDate(&quot;create_date&quot;)); g.setCreate_user(rs.getString(&quot;create_user&quot;)); g.setUpdate_date(rs.getDate(&quot;update_date&quot;)); g.setUpdate_user(rs.getString(&quot;update_user&quot;)); g.setIsdel(rs.getInt(&quot;isdel&quot;)); } return g; }} MVC架构其实这就是我为啥想看这个系列视频的理由咯。都知道M(Model)、V(View)、C(Controller)，但是在代码中是如何体现呢？非常想知道这一点。 在“本系列视频·上”中，V是使用命令行的黑窗口，通过黑窗口来输入命令。命令给到控制层后，由控制层进行相应的操作；而控制层则是通过调用dao来直接与数据库交流。其中黑窗口(View层)可学习的价值并不是很高。 学习时遇到的疑问为什么执行Class.forName(&quot;xxxxx&quot;)驱动就加载好了？在com.mysql.jdbc.Driver中，有一段静态代码，就是向DriverManager注册自身这个驱动。JDBC的规范吧，都需要这么写。 1234567static { try { DriverManager.registerDriver(new Driver()); } catch (SQLException var1) { throw new RuntimeException(&quot;Can't register driver!&quot;); }} Registers the given driver with the {@code DriverManager}.A newly-loaded driver class should call the method {@code registerDriver} to make itself known to the {@code DriverManager}. If the driver is currently registered, no action is taken. 1234567891011public static synchronized void registerDriver(java.sql.Driver driver,DriverAction da) throws SQLException { /* Register the driver if it has not already been added to our list */ if(driver != null) { registeredDrivers.addIfAbsent(new DriverInfo(driver, da)); } else { // This is for compatibility with the original DriverManager throw new NullPointerException(); } println(&quot;registerDriver: &quot; + driver);} 后面的获取连接是通过DriverManager的getConnection方法，通过此方法会调用其同名不同参数方法getConnection(String url, java.util.Properties info, Class&lt;?&gt; caller)，其中有段源代码是这样的： 1234567891011121314151617181920212223// 容器registeredDrivers则是保存着我们在上面代码中所注册的所有驱动的相关信息for(DriverInfo aDriver : registeredDrivers) { // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerCL)) { try { println(&quot; trying &quot; + aDriver.driver.getClass().getName()); Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(&quot;getConnection returning &quot; + aDriver.driver.getClass().getName()); //如果获取到的连接不为空，那么则通过其所需要的驱动，获取连接成功，并返回。 return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } } else { println(&quot; skipping: &quot; + aDriver.getClass().getName()); }} 因此，Class.forName(xxxx)在加载该类时触发了其中的static代码块，并在其中向DriverManager注册自身。然后通过DriverManager来遍历所有的驱动信息，并用之加载相应的url，如果成功获取到连接，表示驱动加载成功，并获取到了连接；否则，驱动加载失败或尚未注册驱动，连接获取失败。 PreparedStatement与Statement安全性的差异在哪里？使用Statement可能会被SQL注入。假设存在某个需求，对给定的用户id，返回该id所对应的所有信息。言外之意，只有返回相应id的信息才是正确的、可行的，如果获取得到了除了该id之外的信息，那么则将之称为信息泄露也不为过。然而，使用Statement就可能会被有心机的用户利用，获取到除了自身之外的其它用户信息，这想一想都是不允许也不应该发生的。代码演示如下： 12345678910111213141516171819202122232425public List&lt;Goddess&gt; query(String id) throws SQLException { List&lt;Goddess&gt; gs = new ArrayList&lt;&gt;(); Connection conn = DBUtil.getConnection(); Statement stmt = conn.createStatement(); String sql = &quot;select * from imooc_goddess where id = &quot; + id; ResultSet rs = stmt.executeQuery(sql); System.out.println(sql); Goddess g = null; while (rs.next()){ g = new Goddess(); g.setId(rs.getInt(&quot;id&quot;)); g.setUser_name(rs.getString(&quot;user_name&quot;)); g.setAge(rs.getInt(&quot;age&quot;)); gs.add(g); } return gs;}public static void main(String[] args) throws SQLException { // 别有心机的用户名&quot;1 or 1 = 1&quot; List&lt;Goddess&gt; list = new GoddessDao().query(&quot;1 or 1 = 1&quot;); for (int i = 0; i &lt; list.size(); i++) { System.out.println(list.get(i)); }} 输出的结果如下 JDBC调用存储过程存储过程是存储在数据库中的一个小代码，其标识符为Procedure，与开发语言中的函数类似。比如说在Pascal中，函数定义的标识符就是Procedure。在该函数中，可以不带参数，也可以带In类型参数、Out类型参数（顾名思义，传入、传出）。如何使用JDBC调用这些过程呢？ 无参存储过程调用过程 代码 IN类型参数存储过程调用 OUT类型参数存储过程调用 OUT类型参数的存储过程的定义如下： JDBC使用事务事务是作为单个逻辑工作单元执行的一些列操作，这些操作做为一个整体，要么都提交、要么都不执行。 JDBC中如何控制事务？ 代码演示如下： JDBC使用连接池连接池有一点像线程池的意思，作用有点类似。常用的有dbcp和c3p0。","link":"/2018/05/07/1da1a35aca2b.html"},{"title":"JUC包下同步工具类及Condition队列","text":"在上篇关于从ReentrantLock看JUC中AQS的这篇文章中，留下了一个非常重要的Condition模块，并未去分析。而这个模块，在实现BlockingQueue的过程中，用到了。因此特地回过头来，去补习一下关于Condition的实现与原理、以及JUC下面其他的同步工具类的使用。 Condition队列Condition是一个与CLH类似的队列，主要的逻辑在AQS中已经实现。 原理在ReentrantLock中，新建一个condition的入口是ReentrantLock#newCondition()方法，这里直接new了一个ConditionObject对象，它里面含有一个Node链表，与CLH队列中的Node是同一个Node。 这个队列的作用就是用来储存被暂停的线程，即调用ConditionObject的await()方法，等待条件成熟； 当代码中，条件满足之后，再调用ConditionObject的signal或signalAll方法，唤醒再ConditionObject链表上一个/所有休眠的线程。 示例因此，作用效果非常容易理解。它的应用举例的话，就直接用ArrayBlockingQueue的实现作为说明： put操作，如果队列满了，执行notFull.await()方法，将当前线程，加入到notFull这个Condition队列上，也就是语义上的等待有空间，再进行入队操作。 123456789101112public void put(E e) throws InterruptedException { Objects.requireNonNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); }} 当进行出队操作时，执行notFull.signal()，会唤醒notFull这个队列上的一条线程，进行入队操作。 123456789101112private E dequeue() { final Object[] items = this.items; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); return e;} 其实在ArrayBlockingQueue这个阻塞队列中，还有一个是否为空的Condition队列，原理与上述代码类似，在此不做过多赘述，但是可以了解下其实现的过程。 12345678910111213141516171819public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); }}private void enqueue(E e) { final Object[] items = this.items; items[putIndex] = e; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();} CountDownLatch A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. 多个线程等待计数器倒数到0，然后执行后续逻辑。 使用示例1234567891011121314151617181920212223242526272829303132class Driver { // ... void main() throws InterruptedException { CountDownLatch startSignal = new CountDownLatch(1); CountDownLatch doneSignal = new CountDownLatch(N); for (int i = 0; i &lt; N; ++i) // create and start threads new Thread(new Worker(startSignal, doneSignal)).start(); doSomethingElse(); // don't let run yet startSignal.countDown(); // let all threads proceed doSomethingElse(); doneSignal.await(); // wait for all to finish }}class Worker implements Runnable { private final CountDownLatch startSignal; private final CountDownLatch doneSignal; Worker(CountDownLatch startSignal, CountDownLatch doneSignal) { this.startSignal = startSignal; this.doneSignal = doneSignal; } public void run() { try { startSignal.await(); doWork(); doneSignal.countDown(); } catch (InterruptedException ex) {} // return; } void doWork() { ... }}} 使用示例二： 123456789101112131415161718192021222324252627282930class Driver2 { // ... void main() throws InterruptedException { CountDownLatch doneSignal = new CountDownLatch(N); Executor e = ... for (int i = 0; i &lt; N; ++i) // create and start threads e.execute(new WorkerRunnable(doneSignal, i)); doneSignal.await(); // wait for all to finish }}class WorkerRunnable implements Runnable { private final CountDownLatch doneSignal; private final int i; WorkerRunnable(CountDownLatch doneSignal, int i) { this.doneSignal = doneSignal; this.i = i; } public void run() { try { doWork(i); doneSignal.countDown(); } catch (InterruptedException ex) {} // return; } void doWork() { ... }} 实现原理内部类Sync继承自AQS await方法，检查state是否为0，为0说明已经倒数到0，可以执行，否则加入CLH队列，然后park住该线程直至唤醒，再检查state… 123456789101112131415public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1);}public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);}protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1;} countDown方法，state减1，如果state==0，那么从CLH队列尾部开始找一个正常的线程unpark以唤醒。 12345678910111213141516171819202122public void countDown() { sync.releaseShared(1);}public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false;}protected boolean tryReleaseShared(int releases) { for (;;) { int c = getState(); if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; }} CyclicBarrier A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. CyclicBarriers are useful in programs involving a fixed sized party of threads that must occasionally wait for each other. The barrier is called cyclic because it can be re-used after the waiting threads are released. 简单理解就是，多个线程执行完了之后（到达临界点），再执行最终的操作。 使用示例1234567891011121314151617181920212223242526272829303132333435363738394041class Solver { final int N; final float[][] data; final CyclicBarrier barrier; class Worker implements Runnable { int myRow; Worker(int row) { myRow = row; } public void run() { while (!done()) { processRow(myRow); try { barrier.await(); } catch (InterruptedException ex) { return; } catch (BrokenBarrierException ex) { return; } } } } public Solver(float[][] matrix) { data = matrix; N = matrix.length; Runnable barrierAction = () -&gt; mergeRows(...); barrier = new CyclicBarrier(N, barrierAction); List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(N); for (int i = 0; i &lt; N; i++) { Thread thread = new Thread(new Worker(i)); threads.add(thread); thread.start(); } // wait until done for (Thread thread : threads) thread.join(); }} 实现原理内部实现依赖ReentrantLock及Condition。 await方法，最终会调用doWait()，首先会使用ReentrantLock加锁，然后将count减1。 123456789101112131415161718192021222324252627282930313233343536373839private int dowait(boolean timed, long nanos){ final ReentrantLock lock = this.lock; lock.lock(); try { ... // count减1 int index = --count; if (index == 0) { // 到达临界条件 boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) // 执行临界操作 command.run(); ranAction = true; // 还原参数，如count，以准备下次使用 nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) // 在trip这个Condition队列上面睡眠等待 trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) {...} ... } } finally { lock.unlock(); }} 如果count为0，也就是所有的线程完成其工作，那么执行barrierCommand，并重置参数，唤醒trip条件上的线程。 如果count不为0，在Condition(trip)上面进行await操作，即进入睡眠，等待trip条件满足。 Semephore限流器。简而言之，最多允许几个线程同时执行。 使用示例123456789101112131415161718192021222324252627282930313233343536373839404142class Pool { private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException { available.acquire(); return getNextAvailableItem(); } public void putItem(Object x) { if (markAsUnused(x)) available.release(); } // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() { for (int i = 0; i &lt; MAX_AVAILABLE; ++i) { if (!used[i]) { used[i] = true; return items[i]; } } return null; // not reached } protected synchronized boolean markAsUnused(Object item) { for (int i = 0; i &lt; MAX_AVAILABLE; ++i) { if (item == items[i]) { if (used[i]) { used[i] = false; return true; } else return false; } } return false; }} 实现原理 acquire方法，如果可用数（最多允许同时执行线程数）减去想要获取数（一般为1）小于0，获取锁失败，加入CLH队列中，直到唤醒再进行尝试获取资源； release方法，可用数加上释放数，同时唤醒CLH上面的休眠的线程，让它们再次尝试获取资源。 1234567891011121314public void release() { sync.releaseShared(1);}protected final boolean tryReleaseShared(int releases) { for (;;) { int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; }} 获取资源有公平和非公平之分。公平获取时，如果发现有人在排队，那么会直接加入CLH队列中。返回-1小于0，直接入CLH队列。 1234567891011121314151617181920212223public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1);}public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);}protected int tryAcquireShared(int acquires) { for (;;) { if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }} 非公平会直接进行获取，如果数量不够，那么加入CLH队列。 123456789final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }}","link":"/2020/04/20/14e5d96312a9.html"},{"title":"JUC源码学习之AbstractQueuedSynchronizer","text":"源码基于的Oracle JDK版本为：11.0.5 什么是CLH队列简单理解是一个双向链表，链表中存放的是包含线程在内的信息，队首的是正在执行的线程，后面的是等待执行的线程，如下图所示： Node概述The wait queue is a variant of a “CLH” (Craig, Landin, and Hagersten) lock queue. CLH locks are normally used for spinlocks. We instead use them for blocking synchronizers, but use the same basic tactic of holding some of the control information about a thread in the predecessor of its node. A “status” field in each node keeps track of whether a thread should block. A node is signalled when its predecessor releases. Each node of the queue otherwise serves as a specific-notification-style monitor holding a single waiting thread. The status field does NOT control whether threads are granted locks etc though. A thread may try to acquire if it is first in the queue. But being first does not guarantee success; it only gives the right to contend. So the currently released contender thread may need to rewait. To enqueue into a CLH lock, you atomically splice it in as new tail. To dequeue, you just set the head field. 123 +------+ prev +-----+ +-----+head | | &lt;---- | | &lt;---- | | tail +------+ +-----+ +-----+ Insertion into a CLH queue requires only a single atomic operation on “tail”, so there is a simple atomic point of demarcation from unqueued to queued. Similarly, dequeuing involves only updating the “head”. However, it takes a bit more work for nodes to determine who their successors are, in part to deal with possible cancellation due to timeouts and interrupts. The “prev” links (not used in original CLH locks), are mainly needed to handle cancellation. If a node is cancelled, its successor is (normally) relinked to a non-cancelled predecessor. For explanation of similar mechanics in the case of spin locks, see the papers by Scott and Scherer at http://www.cs.rochester.edu/u/scott/synchronization/ We also use “next” links to implement blocking mechanics. The thread id for each node is kept in its own node, so a predecessor signals the next node to wake up by traversing next link to determine which thread it is. Determination of successor must avoid races with newly queued nodes to set the “next” fields of their predecessors. This is solved when necessary by checking backwards from the atomically updated “tail” when a node’s successor appears to be null. (Or, said differently, the next-links are an optimization so that we don’t usually need a backward scan.) Cancellation introduces some conservatism to the basic algorithms. Since we must poll for cancellation of other nodes, we can miss noticing whether a cancelled node is ahead or behind us. This is dealt with by always unparking successors upon cancellation, allowing them to stabilize on a new predecessor, unless we can identify an uncancelled predecessor who will carry this responsibility. CLH queues need a dummy header node to get started. But we don’t create them on construction, because it would be wasted effort if there is never contention. Instead, the node is constructed and head and tail pointers are set upon first contention. Threads waiting on Conditions use the same nodes, but use an additional link. Conditions only need to link nodes in simple (non-concurrent) linked queues because they are only accessed when exclusively held. Upon await, a node is inserted into a condition queue. Upon signal, the node is transferred to the main queue. A special value of status field is used to mark which queue a node is on. Node的内部结构如下： Node的状态代码及注释 1234567891011/** waitStatus value to indicate thread has cancelled. */static final int CANCELLED = 1;/** waitStatus value to indicate successor's thread needs unparking. */static final int SIGNAL = -1;/** waitStatus value to indicate thread is waiting on condition. */static final int CONDITION = -2;/*** waitStatus value to indicate the next acquireShared should* unconditionally propagate.*/static final int PROPAGATE = -3; 状态 简介 SIGNAL The successor of this node is (or will soon be) blocked (via park), so the current node must unpark its successor when it releases or cancels. To avoid races, acquire methods must first indicate they need a signal, then retry the atomic acquire, and then, on failure, block. CANCELLED This node is cancelled due to timeout or interrupt. Nodes never leave this state. In particular, a thread with cancelled node never again blocks. CONDITION This node is currently on a condition queue. It will not be used as a sync queue node until transferred, at which time the status will be set to 0. (Use of this value here has nothing to do with the other uses of the field, but simplifies mechanics.) PROPAGATE A releaseShared should be propagated to other nodes. This is set (for head node only) in doReleaseShared to ensure propagation continues, even if other operations have since intervened. 0 None of the above The values are arranged numerically to simplify use. Non-negative values mean that a node doesn’t need to signal. So, most code doesn’t need to check for particular values, just for sign. The field is initialized to 0 for normal sync nodes, and CONDITION for condition nodes. It is modified using CAS (or when possible, unconditional volatile writes). 具体用途可等后续结合AQS框架整体的功能来看。 ReentrantLock概览从ReentrantLock开始窥探AQS框架，其大致成员变量、方法以及内部类结构如下： ReentrantLock里面有一个抽象内部类叫做Sync，继承自AbstractQueuedSynchronizer，这个类有两个子类分别表示两种获取加锁的方式：公平锁和非公平锁。它们间的区别留待后续说面。从上面的图中的①和②可以看出，FairSync与NonfairSync的获取锁的方式不同，释放锁的方法都是一样的，即获取锁的公平与否，体现在如何获取锁上。默认是非公平锁。即如代码所言： 123456789101112131415161718// ReentrantLock.java/*** Creates an instance of {@code ReentrantLock}.* This is equivalent to using {@code ReentrantLock(false)}.*/public ReentrantLock() { sync = new NonfairSync();}/*** Creates an instance of {@code ReentrantLock} with the* given fairness policy.** @param fair {@code true} if this lock should use a fair ordering policy*/public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 这里使用默认的实现NonfairSync来进行分析。通常，使用ReentrantLock加锁的时候都会调用lock()方法，其实现如下： 1234// ReentrantLock.javapublic void lock() { sync.acquire(1);} lock()方法的执行后达到的效果如下： Acquires the lock if it is not held by another thread and returns immediately, setting the lock hold count to one.(没有线程占用此锁，占锁数+1，并立即返回) If the current thread already holds the lock then the hold count is incremented by one and the method returns immediately.(当前线程已获取此锁，占锁数+1，并立即返回) If the lock is held by another thread then the current thread becomes disabled for thread scheduling purposes and lies dormant until the lock has been acquired, at which time the lock hold count is set to one.(别的线程已占用此锁，当前线程暂停等待获取锁) sync.acquire(1)调用的是父类AQS的实现。从这里进入ASQ的源代码： AQS框架123456789101112131415161718// AbstractQueuedSynchronizer.java/*** Acquires in exclusive mode, ignoring interrupts. Implemented* by invoking at least once {@link #tryAcquire},* returning on success. Otherwise the thread is queued, possibly* repeatedly blocking and unblocking, invoking {@link* #tryAcquire} until success. This method can be used* to implement method {@link Lock#lock}.** @param arg the acquire argument. This value is conveyed to* {@link #tryAcquire} but is otherwise uninterpreted and* can represent anything you like.*/public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 尝试获取锁首先调用第一个方法tryAcquire(arg)来尝试获取锁，成功返回true。但这个方法是一个需要子类去实现的方法： 1234567891011121314151617181920212223242526272829303132// AbstractQueuedSynchronizer.java// Main exported methods/*** Attempts to acquire in exclusive mode. This method should query* if the state of the object permits it to be acquired in the* exclusive mode, and if so to acquire it.** &lt;p&gt;This method is always invoked by the thread performing* acquire. If this method reports failure, the acquire method* may queue the thread, if it is not already queued, until it is* signalled by a release from some other thread. This can be used* to implement method {@link Lock#tryLock()}.** &lt;p&gt;The default* implementation throws {@link UnsupportedOperationException}.** @param arg the acquire argument. This value is always the one* passed to an acquire method, or is the value saved on entry* to a condition wait. The value is otherwise uninterpreted* and can represent anything you like.* @return {@code true} if successful. Upon success, this object has* been acquired.* @throws IllegalMonitorStateException if acquiring would place this* synchronizer in an illegal state. This exception must be* thrown in a consistent fashion for synchronization to work* correctly.* @throws UnsupportedOperationException if exclusive mode is not supported*/protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} 也就是说具体的实现类为AQS的子类Sync的子类NonfairSync中tryAcquire()的实现。 12345678910111213141516171819202122232425262728293031// ReentrantLock.javastatic final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }}// 最终的实现方法final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 获取当前状态，volatile变量state int c = getState(); if (c == 0) { // 说明没有线程获取到该锁 // 此处可能发生有多个线程同时执行 // 通过CAS设置值，保证当前state是在为0的情况下才设置成acquires，即只有一个线程能够执行if为true时的语句 if (compareAndSetState(0, acquires)) { // 设置正在执行的线程为当前线程 setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { // 如果当前线程已获取锁 int nextc = c + acquires; // state加1 if (nextc &lt; 0) // overflow。一个线程一直获取该锁的次数超过int的最大值 throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } // 如果该锁被其他线程占有，那么直接返回获取锁失败 return false;} 获取锁失败后，将该线程等息息加入CLH队列获取锁失败后，返回false，在acquire(int arg)方法中将执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法，也就是将该线程加入到CLH队列中，首先执行的是addWaiter(Node.EXCLUSIVE)。在这方法中，先创建一个新的Node节点，这里传来的是Node.EXCLUSIVE，即null，作为其后继。即： 123456789101112/** Establishes initial head or SHARED marker. */Node() {}/** Constructor used by addWaiter. */Node(Node nextWaiter) { this.nextWaiter = nextWaiter; THREAD.set(this, Thread.currentThread());}Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread;} 接下来是一个死循环，也就是经典的for循环+CAS操作，这个操作的目的就是将当前节点，插入到CLH队列的队尾，也就是入队操作。 1234567891011121314151617181920212223242526// AbstractQueuedSynchronizer.java/*** Creates and enqueues node for current thread and given mode.** @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared* @return the new node*/private Node addWaiter(Node mode) { Node node = new Node(mode); for (;;) { Node oldTail = tail; if (oldTail != null) { // 问题1：为什么设置前驱需要CAS操作？ node.setPrevRelaxed(oldTail); if (compareAndSetTail(oldTail, node)) { oldTail.next = node; return node; } } else { // CLH队列为空 // 初始化队列 // 问题2：为什么初始化队列需要CAS操作？ initializeSyncQueue(); } }} 以上代码的作用不难理解，但是仔细思考还是存在两个问题，分别是为什么设置前驱需要CAS操作？以及为什么初始化队列需要CAS操作？。 问题1：为什么设置前驱需要CAS操作？ 1234567// 简单读写final void setPrevRelaxed(Node p) { PREV.set(this, p);}// PREV是什么private static final VarHandle PREV;PREV = l.findVarHandle(Node.class, &quot;prev&quot;, Node.class); PREV是一个VarHandle，可以用来对Node里面的prev属性执行一些操作，如简单读写操作、volatile读写操作、CAS操作等。这是一个jdk8后面的版本才出的一个用来替代Unsafe操作的一个工具。具体的用法会在后续的博客中进行信息的探讨。这里的PREV.set(this, p)并不是一个CAS操作，是一个普通的读写操作。volatile写是PREV.setVolatile()、CAS是PREV.compareAndSet()。所以这是一个误解，这里并不存在CAS操作。 问题2：为什么初始化队列需要CAS操作？ 12345678910111213141516171819/** * Initializes head and tail fields on first contention. */private final void initializeSyncQueue() { Node h; if (HEAD.compareAndSet(this, null, (h = new Node()))) tail = h;}/** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */private transient volatile Node head;private static final VarHandle HEAD;HEAD = l.findVarHandle(AbstractQueuedSynchronizer.class, &quot;head&quot;, Node.class); 既然是初始化，AQS中的head变量肯定为null。如果不为空，说明已经被别的线程初始化了，CAS操作会失败，从而跳出initializeSyncQueue()，继续进入for(;;)尝试在新的队列中将该Node入队。。这种情况会出现在两个线程同时去获得该锁，且此时该锁没有被任何线程获得（即队列为空），同时执行完了addWaiter()中的if (oldTail != null)语句，因为为null，所以两个线程都转而去执行initializeSyncQueue()的前提下。 让线程暂时停止、休息1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) { boolean interrupted = false; try { for (;;) { final Node p = node.predecessor(); // 前驱为head，尝试获取锁 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC return interrupted; } // 检查是否可以让当前线程暂时停止 if (shouldParkAfterFailedAcquire(p, node)) // 暂时停止 等被唤醒的时候，会为interrupted赋值 interrupted |= parkAndCheckInterrupt(); } } catch (Throwable t) { cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; }} 判断当前线程是否可以被暂时停止。如果前驱Node的状态被设置成了Node.SIGNAL，那么可以被停止；否则都不能被停止，返回继续执行acquireQueued()中的for(;;)代码。当不能被停止的时候，只有两种情况，如下： 前驱被取消 这时候就要一直往前找，直到状态是没有被取消的； 前驱ode状态不为Node.SIGNAL 这时候就要先通过CAS的方式将前驱的状态改成Node.SIGNAL。 123456789101112131415161718192021222324252627282930313233343536/** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) { // 前驱被取消 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 前驱ode状态不为`Node.SIGNAL` /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ pred.compareAndSetWaitStatus(ws, Node.SIGNAL); } return false;} 暂停线程，如果被唤醒，将继续执行后面的return Thread.interrupted();，然后继续返回acquireQueued()执行for(;;)里面的语句，如尝试获取锁、寻找可用的前驱、停止线程等。 123456789/** * Convenience method to park and then check if interrupted. * * @return {@code true} if interrupted */private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();} 其实后面还有一个catch语句，这里面做的事情是发生异常了，将该node从链表中移除掉，然后再抛出异常。 到这里AQS与ReentrantLock基本上上锁的流程结束了。 释放锁ReentrantLock的unlock()方法执行后，如果锁被当前线程持有，那么锁持有数将会减1；如果锁的持有数为0，将直接释放；如果当前线程不持有该锁，那么将抛出IllegalMonitorStateException异常。 123456789101112131415// ReentrantLock.java/** * Attempts to release this lock. * * &lt;p&gt;If the current thread is the holder of this lock then the hold * count is decremented. If the hold count is now zero then the lock * is released. If the current thread is not the holder of this * lock then {@link IllegalMonitorStateException} is thrown. * * @throws IllegalMonitorStateException if the current thread does not * hold this lock */public void unlock() { sync.release(1);} 释放锁与上锁的逻辑基本上类似，设计模式都是模板方法。释放锁的框架代码都写好了，具体怎么释放由子类自行实现。转入AQS的框架代码如下： 1234567891011121314151617181920// AbstractQueuedSynchronizer.java/** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} */public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 再次进入子类ReentrantLock中，调用其内部类Sync的tryRelease()方法。其中需要注意的是：没有线程持有该锁时，返回true，否则返回false。 12345678910111213141516// ReentrantLock.java -&gt; Syncprotected final boolean tryRelease(int releases) { // 持锁数减去releases int c = getState() - releases; // 非本线程持有该锁，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 没有线程持有该锁时，返回true，否则返回false if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 回到AQS的框架代码，将看到如果tryRelease()方法如果返回true，才有可能执行后面的unparkSuccessor()方法。这个方法就是找到head的可用（等待着呗唤醒的线程）后继，然后unpark()该线程，让该线程醒过来，继续执行acquireQueued()方法中的for(;;),让它获取到锁。 1234567891011121314151617// AbstractQueuedSynchronizer.javaprivate void unparkSuccessor(Node node) { int ws = node.waitStatus; if (ws &lt; 0) node.compareAndSetWaitStatus(ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node p = tail; p != node &amp;&amp; p != null; p = p.prev) if (p.waitStatus &lt;= 0) s = p; } if (s != null) LockSupport.unpark(s.thread);} 公平锁与非公平锁回过头来看FairSync与NonfairSync之间的差别。正如前面所言，他们之间的区别在于获取锁的方法不一样，上面的代码是NonfairSync的方式，现在看一下公平锁的实现： 1234567891011121314151617181920// ReentrantLock.java -&gt; NonfairSyncprotected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false;} 核心的思想大致是：查看队列中是否有存在的其他的等待线程，处于等待状态的最前面的那一个线程，如果不是本线程，那么直接返回false。 12345678910111213141516// AbstractQueuedSynchronizer.javapublic final boolean hasQueuedPredecessors() { Node h, s; if ((h = head) != null) { if ((s = h.next) == null || s.waitStatus &gt; 0) { s = null; // traverse in case of concurrent cancellation for (Node p = tail; p != h &amp;&amp; p != null; p = p.prev) { if (p.waitStatus &lt;= 0) s = p; } } if (s != null &amp;&amp; s.thread != Thread.currentThread()) return true; } return false;} 也就是说FairSync的tryAcquire()返回false，所以它将继续执行AQS里面的acquireQueued()，即准备进入等待队列。充分体现了先来后到的公平性。 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} 完 参考：https://www.cnblogs.com/waterystone/p/4920797.html","link":"/2019/10/24/71010f2a8ada.html"},{"title":"Java中的NIO学习笔记","text":"流与块的比较原来的 I/O 库(在 java.io.*中) 与 NIO 最重要的区别是数据打包和传输的方式。正如前面提到的，原来的 I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流 的 I/O 系统一次一个字节地处理数据。一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。为流式数据创建过滤器非常容易。链接几个过滤器，以便每个过滤器只负责单个复杂处理机制的一部分，这样也是相对简单的。不利的一面是，面向流的 I/O 通常相当慢。 一个 面向块 的 I/O 系统以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。按块处理数据比按(流式的)字节处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 核心组成通道和缓冲区是 NIO 中的核心对象，几乎在每一个 I/O 操作中都要使用它们。通道是对原 I/O 包中的流的模拟。到任何目的地(或来自任何地方)的所有数据都必须通过一个 Channel 对象。一个 Buffer 实质上是一个容器对象。发送给一个通道的所有对象都必须首先放到缓冲区中；同样地，从通道中读取的任何数据都要读到缓冲区中。 缓冲区(Buffer)Buffer 是一个对象， 它包含一些要写入或者刚读出的数据。 在 NIO 中加入 Buffer 对象，体现了新库与原 I/O 的一个重要区别。在面向流的 I/O 中，您将数据直接写入或者将数据直接读到 Stream 对象中。 在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。任何时候访问 NIO 中的数据，您都是将它放到缓冲区中。 缓冲区实质上是一个数组。通常它是一个字节数组，但是也可以使用其他种类的数组。但是一个缓冲区不 仅仅 是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区类型最常用的缓冲区类型是 ByteBuffer。一个 ByteBuffer 可以在其底层字节数组上进行 get/set 操作(即字节的获取和设置)。 ByteBuffer 不是 NIO 中唯一的缓冲区类型。对于每一种基本 Java 类型都有一种缓冲区类型：每一个 Buffer 类都是 Buffer 接口的一个实例。 除了 ByteBuffer，每一个 Buffer 类都有完全一样的操作，只是它们所处理的数据类型不一样。因为大多数标准 I/O 操作都使用 ByteBuffer，所以它具有所有共享的缓冲区操作以及一些特有的操作。 通道(Channel)一种可以将数据读取/写入到缓冲区中的方式 所有数据都通过 Buffer 对象来处理。不会将字节直接写入通道中，相反，将数据写入包含一个或者多个字节的缓冲区。同样，不会直接从通道中读取字节，而是将数据从通道读入缓冲区，再从缓冲区获取这个字节。 通道与流的不同之处在于通道是双向的。而流只是在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)， 而 通道 可以用于读、写或者同时用于读写。 最重要的通道的实现有： 选择器(Selector)Selector允许单线程处理多个 Channel。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便。例如，在一个聊天服务器中。 这是在一个单线程中使用一个Selector处理3个Channel的图示：要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新连接进来，数据接收等。 示例代码123456789101112131415161718// 从RandomAccessFile得到的channel可读可写RandomAccessFile raf = new RandomAccessFile(&quot;C:\\\\Users\\\\D22433\\\\Desktop\\\\DailyRecord.md&quot;, &quot;rw&quot;);// 获取channelFileChannel fileChannel = raf.getChannel();// 得到一个ByteBuffer的子类HeapByteBufferByteBuffer buffer = ByteBuffer.allocate(1024);// 从文件读数据while(fileChannel.read(buffer) != -1) { System.out.println(new String(buffer.array())); // 重置buffer buffer.clear();}// 写数据到文件buffer.put((&quot;\\n&quot;+new Date().toString()+&quot;: Hello\\n&quot;).getBytes());// 让buffer里面的数据可以被channel写入文件中buffer.flip();// 将缓冲区的内容写入文件fileChannel.write(buffer); 解析可能存在疑惑的地方有两处，一个是flip()，另外一个是clear()。要分析这两个函数，就需要先了解Buffer的内部原理。 缓冲区实际上就是美化了的数组，在从通道读取时，可以理解将所读取的数据放到底层的数组中。 在Buffer中有三个变量： position：跟踪已经写了多少数据。更准确地说，它指定了下一个字节将放到数组的哪一个元素中 limit：表明还有多少数据需要取出(在从缓冲区写入通道时)，或者还有多少空间可以放入数据(在从通道读入缓冲区时)。 capacity：可以储存在缓冲区中的最大数据容量。实际上，它指定了底层数组的大小 ― 或者至少是指定了准许我们使用的底层数组的容量。 其中三个变量恒成立的关系为(可从Buffer源码中找到)：$$mark \\leq position \\leq limit \\leq capacity$$ 状态图 ①初始状态 ②向缓冲区中写入数据 ③flip() 它将 limit 设置为当前 position。 它将 position 设置为 0。123456public final Buffer flip() { limit = position; position = 0; mark = -1; return this;} ④从缓冲区读数据(写出) ⑤clear()重置缓冲区 它将 limit 设置为与 capacity 相同。 它设置 position 为 0。123456public final Buffer clear() { position = 0; limit = capacity; mark = -1; return this;} ⑥其实还有一个compact()函数，当从缓冲区里面读取数据时，并没有读完，这是又要写入数据到缓冲区中，且不想覆盖掉未读取完的数据，此时就可以考虑使用此函数。 1234567891011121314public final int remaining() { // 处于读取模式时，将表示未读取的数据个数 return limit - position;}public ByteBuffer compact() { // 将未读取的数据，移到hb的开始处 System.arraycopy(hb, ix(position()), hb, ix(0), remaining()); // 调整当前数据位置 position(remaining()); // 设置成capacity，以用来接收数据 limit(capacity()); discardMark(); return this;} 聚集(gather)与分散(scatter)分散（scatter） 从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此，Channel将从Channel中读取的数据“分散（scatter）”到多个Buffer中。聚集（gather） 写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。scatter / gather经常用于需要将传输的数据分开处理的场合，例如传输一个由消息头和消息体组成的消息，你可能会将消息体和消息头分散到不同的buffer中，这样你可以方便的处理消息头和消息体。 Scattering Reads 12345ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = { header, body };channel.read(bufferArray); 注意buffer首先被插入到数组，然后再将数组作为channel.read() 的输入参数。read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息(译者注：消息大小不固定)。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。 Gathering Writes 123456ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);//write data into buffersByteBuffer[] bufferArray = { header, body };channel.write(bufferArray); buffers数组是write()方法的入参，write()方法会按照buffer在数组中的顺序，将数据写入到channel，注意只有position和limit之间的数据才会被写入。因此，如果一个buffer的容量为128byte，但是仅仅包含58byte的数据，那么这58byte的数据将被写入到channel中。因此与Scattering Reads相反，Gathering Writes能较好的处理动态消息。 关于Selector此段代码来自IBM的那篇文章的，可以参考来理解selector。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class MultiPortEcho { private int ports[]; private ByteBuffer echoBuffer = ByteBuffer.allocate(1024); public MultiPortEcho(int ports[]) throws IOException { this.ports = ports; go(); } private void go() throws IOException { // Create a new selector Selector selector = Selector.open(); // Open a listener on each port, and register each one // with the selector for (int i = 0; i &lt; ports.length; ++i) { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); ServerSocket ss = ssc.socket(); InetSocketAddress address = new InetSocketAddress(ports[i]); ss.bind(address); SelectionKey key = ssc.register(selector, SelectionKey.OP_ACCEPT); System.out.println(&quot;Going to listen on &quot; + ports[i]); } while (true) { int num = selector.select(); Set selectedKeys = selector.selectedKeys(); Iterator it = selectedKeys.iterator(); while (it.hasNext()) { SelectionKey key = (SelectionKey) it.next(); if ( (key.readyOps() &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT ) { // Accept the new connection ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); // Add the new connection to the selector SelectionKey newKey = sc.register(selector, SelectionKey.OP_READ); it.remove(); System.out.println(&quot;Got connection from &quot; + sc); } else if ( (key.readyOps() &amp; SelectionKey.OP_READ) == SelectionKey.OP_READ ) { // Read the data SocketChannel sc = (SocketChannel) key.channel(); // Echo data int bytesEchoed = 0; while (true) { echoBuffer.clear(); int r = sc.read(echoBuffer); if (r &lt;= 0) { break; } echoBuffer.flip(); sc.write(echoBuffer); bytesEchoed += r; } System.out.println(&quot;Echoed &quot; + bytesEchoed + &quot; from &quot; + sc); it.remove(); } } //System.out.println( &quot;going to clear&quot; ); // selectedKeys.clear(); //System.out.println( &quot;cleared&quot; ); } } public static void main(String args[]) throws Exception { if (args.length &lt;= 0) { System.err.println(&quot;Usage: java MultiPortEcho port [port port ...]&quot;); System.exit(1); } int ports[] = new int[args.length]; for (int i = 0; i &lt; args.length; ++i) { ports[i] = Integer.parseInt(args[i]); } new MultiPortEcho(ports); }} 参考：https://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.htmlhttp://ifeve.com/overview/","link":"/2018/07/07/4aa5081e79ea.html"},{"title":"Java中的Queue之概述","text":"对技术还是得有敬畏之心，总觉得Queue好像没啥，其实只是没有仔细去了解过。 不过自从上次认真地看了线程池的源代码之后，发现Queue是一个很神奇的集合类。Queue的形式有无界、有界，还有堵塞、非堵塞。初略想想，这个实现可能就不简单。 一个问题在线程池中，自定义线程池时，放入什么样的队列可以让线程数达不到maximumPoolSize？ 按照线程池的源码，线程增长有两个阶段：一个阶段是在达到corePoolSize之前，第二个阶段是在达到corePoolSize之后并且阻塞队列已经满了，才会继续增加线程，直到maximumPoolSize。 所以解决方案有如下两种： ①如果队列是无界的，那么将不会到达第二阶段的增长，也就无法到达maximumPoolSize； ②还有可以让corePoolSize在足够大的值，同时限定堆大小，保证在有限的任务数下，引发内存不足也算是一种解决方案。 在解决方案①的基础上，我给出了LinkedBlockingQueue这个答案，但是它是一个“有界”的堵塞队列，只是它的capacity默认是Integer.MAX_VALUE。因为一开始我得知它是一个无界队列，因为未做详细、深入的了解，但是后面我被指正后，引发了我对Queue的思考，因为不常用，所以了解的确不是很多；同时，Queue不仅仅是一个FIFO，还有同步操作在里面，就是生产者-消费者的同步问题的一个解决方案。综上，这让我对堵塞队列产生了强烈的兴趣。 概览找了一下BlockingQueue大致的实现类，它们的类图如下。 从中可以看出，它们都继承自AbstractQueue，并且都实现了BlockingQueue接口，只有LinkedTransferQueue还实现了TransferQueue。加上对Queue的一些操作并不是特别熟悉，比如offer、peek、poll之类，所以从Queue接口开始，逐个了解其大致的功能。 Queue这个接口定义了6个方法，功能分成3个，分别是插入、删除、获取队首元素，每个功能有2种实现，对应如下表中的关系。这两种实现的区别也很明显 Throws exception Returns special value Insert add(e) offer(e) Remove remove() poll() Examine element() peek() add(e) 和 offer(e)：添加失败时，add抛异常，offer返回false。 remove() 和 poll() ：没有元素时，remove抛异常，poll返回null。 element() 和 peek()：没有元素时，remove抛异常，peek返回null。 还有一点需要注意，虽然有的Queue的实现（LinkedList）允许插入null值，但是Queue通常不允许插入null值，因为null对peek、poll来说，是queue中没有元素。 BlockingQueue继承自Queue接口，同时在Queue的基础上，新增了堵塞插入、堵塞获取并删除、可堵塞一定时长的插入、可堵塞一定时长的获取并删除。相应关系对应下表。 Throws exception Special value Blocks Times out Insert add(e) offer(e) put(e) offer(e, time, unit) Remove remove() poll() take() poll(time, unit) Examine element() peek() not applicable not applicable put(e) 和 offer(e, time, unit)：put一直堵塞直到空间可用，offer(e, time, unit)只堵塞特定时长。 take() 和 poll(time, unit)： take一直堵塞直到元素可用，poll(time, unit)只堵塞特定时长。 BlockingQueue设计主要被用来处理生产者-消费者问题。还有一点需要注意，BlockingQueue不接受null元素。插入操作happen-before读取、移除。 AbstractQueue抽象类，继承自AbstractCollection，并实现了Queue接口，但未给出具体实现，相当于引入Queue相应方法，在自身类中使用，然后靠子类实现Queue的相关方法。 它实现的add、remove、element方法，分别依靠offer、poll、peek，具体如下： 123456789101112131415161718192021222324252627public boolean add(E e) { if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;);}public E remove() { E x = poll(); if (x != null) return x; else throw new NoSuchElementException();}public E element() { E x = peek(); if (x != null) return x; else throw new NoSuchElementException();}public void clear() { while (poll() != null) ;} 正好对应于上面Queue方法的区别。 常见实现类Java中线程安全的内置队列如下表所示。队列的底层一般分成三种：数组、链表和堆。其中，堆一般情况下是为了实现带有优先级特性的队列。 队列 有界性 锁 数据结构 ArrayBlockingQueue bounded 加锁 arraylist LinkedBlockingQueue optionally-bounded 加锁 linkedlist ConcurrentLinkedQueue unbounded 无锁 linkedlist LinkedTransferQueue unbounded 无锁 linkedlist PriorityBlockingQueue unbounded 加锁 heap DelayQueue unbounded 加锁 heap 基于数组线程安全的队列，比较典型的是ArrayBlockingQueue，它主要通过加锁的方式来保证线程安全； 基于链表的线程安全队列，分成LinkedBlockingQueue和ConcurrentLinkedQueue两大类，前者也通过锁的方式来实现线程安全，而后者以及上面表格中的LinkedTransferQueue都是通过原子变量CAS这种不加锁的方式来实现的。 通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确定的范围内）；而加锁的方式，可以实现有界队列。 在稳定性要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。 Reference： https://tech.meituan.com/2016/11/18/disruptor.html https://www.cnblogs.com/WangHaiMing/p/8798709.html https://www.cnblogs.com/stateis0/p/9062076.html","link":"/2020/04/03/5379f3c06247.html"},{"title":"Java中的Threadlocal源代码学习","text":"ThreadLocal是什么回过头，想想ThreadLocal实现了什么样的功能。举个例子，当不同的线程都去执行同样一个语句以获得当前线程的Looper时，要怎么实现？或许吧，ThreadLocal就实现了这样一个功能。 在Looper中，申明了一个如下的静态变量，说明只有一个。 1static final ThreadLocal&lt;Looper&gt; sThreadLocal = new ThreadLocal&lt;Looper&gt;(); 然后在Looper中调用myLooper()时，都执行了 123public static @Nullable Looper myLooper() { return sThreadLocal.get();} 顺手打开，看到了这个。 12345678910111213public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } return setInitialValue();} 在每个Thread中，有个ThreadLocal.ThreadLocalMap。获取到当前线程的map之后，又将sThreadLocal自身作为一个Key，去获取到相应的结果。再看set() 12345678public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);} 相同的套路，同样是先获取到当前线程的map，然后用ThreadLocal自身作为Key，存进去。 小结因此对于ThreadLocal，可以这样理解：它自身就是一个Key，然后可以以这个Key在不同的线程中存储/获取一个值，值得类型就是声明时，尖括号里面的类型。","link":"/2017/12/18/72e47e7db685.html"},{"title":"Java中的值传递","text":"在知乎上面看到的关于Java中值传递与引用传递的回答，非常赞！ 回答一作者：Intopass链接：https://www.zhihu.com/question/31203609/answer/50992895来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 首先，不要纠结于 Pass By Value 和 Pass By Reference 的字面上的意义，否则很容易陷入所谓的“一切传引用其实本质上是传值”这种并不能解决问题无意义论战中。更何况，要想知道Java到底是传值还是传引用，起码你要先知道传值和传引用的准确含义吧？可是如果你已经知道了这两个名字的准确含义，那么你自己就能判断Java到底是传值还是传引用。这就好像用大学的名词来解释高中的题目，对于初学者根本没有任何意义。 一：搞清楚基本类型和引用类型的不同之处12int num = 10;String str = &quot;hello&quot;; 如图所示，num是基本类型，值就直接保存在变量中。而str是引用类型，变量中保存的只是实际对象的地址。一般称这种变量为”引用”，引用指向实际对象，实际对象中保存着内容。 二：搞清楚赋值运算符（=）的作用12num = 20;str = &quot;java&quot;; 对于基本类型 num ，赋值运算符会直接改变变量的值，原来的值被覆盖掉。对于引用类型 str，赋值运算符会改变引用中所保存的地址，原来的地址被覆盖掉。但是原来的对象不会被改变（重要）。如上图所示，”hello” 字符串对象没有被改变。（没有被任何引用所指向的对象是垃圾，会被垃圾回收器回收） 三：调用方法时发生了什么？参数传递基本上就是赋值操作。 第一个例子：基本类型 1234void foo(int value) { value = 100;}foo(num); // num 没有被改变 第二个例子：没有提供改变自身方法的引用类型 1234void foo(String text) { text = &quot;windows&quot;;}foo(str); // str 也没有被改变 第三个例子：提供了改变自身方法的引用类型 12345StringBuilder sb = new StringBuilder(&quot;iphone&quot;);void foo(StringBuilder builder) { builder.append(&quot;4&quot;);}foo(sb); // sb 被改变了，变成了&quot;iphone4&quot;。 第四个例子：提供了改变自身方法的引用类型，但是不使用，而是使用赋值运算符。 12345StringBuilder sb = new StringBuilder(&quot;iphone&quot;);void foo(StringBuilder builder) { builder = new StringBuilder(&quot;ipad&quot;);}foo(sb); // sb 没有被改变，还是 &quot;iphone&quot;。 重点理解为什么，第三个例子和第四个例子结果不同？下面是第三个例子的图解：builder.append(“4”)之后下面是第四个例子的图解：builder = new StringBuilder(“ipad”); 之后 从局部变量/方法参数开始讲起：局部变量和方法参数在jvm中的储存方法是相同的，都是在栈上开辟空间来储存的，随着进入方法开辟，退出方法回收。以32位JVM为例，boolean/byte/short/char/int/float以及引用都是分配4字节空间，long/double分配8字节空间。对于每个方法来说，最多占用多少空间是一定的，这在编译时就可以计算好。我们都知道JVM内存模型中有，stack和heap的存在，但是更准确的说，是每个线程都分配一个独享的stack，所有线程共享一个heap。对于每个方法的局部变量来说，是绝对无法被其他方法，甚至其他线程的同一方法所访问到的，更遑论修改。当我们在方法中声明一个 int i = 0，或者 Object obj = null 时，仅仅涉及stack，不影响到heap，当我们 new Object() 时，会在heap中开辟一段内存并初始化Object对象。当我们将这个对象赋予obj变量时，仅仅是stack中代表obj的那4个字节变更为这个对象的地址。数组类型引用和对象：当我们声明一个数组时，如int[] arr = new int[10]，因为数组也是对象，arr实际上是引用，stack上仅仅占用4字节空间，new int[10]会在heap中开辟一个数组对象，然后arr指向它。当我们声明一个二维数组时，如 int[][] arr2 = new int[2][4]，arr2同样仅在stack中占用4个字节，会在内存中开辟一个长度为2的，类型为int[]的数组，然后arr2指向这个数组。这个数组内部有两个引用（大小为4字节），分别指向两个长度为4的类型为int的数组。 所以当我们传递一个数组引用给一个方法时，数组的元素是可以被改变的，但是无法让数组引用指向新的数组。 你还可以这样声明：int[][] arr3 = new int[3][]，这时内存情况如下图 你还可以这样 arr3[0] = new int [5]; arr3[1] = arr2[0]; 关于String：原本回答中关于String的图解是简化过的，实际上String对象内部仅需要维护三个变量，char[] chars, int startIndex, int length。而chars在某些情况下是可以共用的。但是因为String被设计成为了不可变类型，所以你思考时把String对象简化考虑也是可以的。String str = new String(&quot;hello&quot;)当然某些JVM实现会把”hello”字面量生成的String对象放到常量池中，而常量池中的对象可以实际分配在heap中，有些实现也许会分配在方法区，当然这对我们理解影响不大。 回答二作者：Hugo Gu链接：https://www.zhihu.com/question/20628016/answer/28970414来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 先强调这个问题前半句是真命题。说问题逻辑有问题，说一切都是值传递，都是没理解什么叫引用传递和值传递。 虽然这个问题根本就没有在问“Java是不是值传递”，但是看完其它答案发现，如果不先解释清楚到底什么是值传递，什么是引用传递，后面的好处也无从谈起。只关心好处的请拉到最后。 第一种误解是：Java是引用传递。（这么理解的人，大体会解释说Java的形参是对象的引用所以才叫引用传递。这个解释的错误在于：引用传递这个词不是这个意思，这个词是形容调用方式，而不是参数本质的类型的。所以，即使有人因为明白引用本身也是个值，然后觉得Java其实是值传递了，这种理解也是错的。你这种理解，叫“传递的是值”，而非“值传递”。后面展开。） 第二种误解是：值类型是值传递，引用类型用的是引用传递。第三种误解是：认为所有的都是值传递，因为引用本质上也是个值，本质就是个指针嘛。第四种误解是：常出现在C++程序员中，声明的参数是引用类型的，就是引用传递；声明的参数是一般类型或指针的就是值传递。（也有人把指针归为引用传递，其实它比较特殊，无论你归哪边都是错的。） 值传递与引用传递，在计算机领域是专有名词，如果你没有专门了解过，一般很难自行悟出其含义。而且在理解下面的解释时，请不要把任何概念往你所熟悉的语言功能上套。很容易产生误解。比如Reference，请当个全新的概念，它和C#引用类型中的引用，和C++的&amp;，一点儿关系都没有。 值传递和引用传递，属于函数调用时参数的求值策略(Evaluation Strategy)，这是对调用函数时，求值和传值的方式的描述，而非传递的内容的类型（内容指：是值类型还是引用类型，是值还是指针）。值类型/引用类型，是用于区分两种内存分配方式，值类型在调用栈上分配，引用类型在堆上分配。（不要问我引用类型里定义个值类型成员或反之会发生什么，这不在这个本文的讨论范畴内，而且你看完之后，你应该可以自己想明白）。一个描述内存分配方式，一个描述参数求值策略，两者之间无任何依赖或约束关系。 在函数调用过程中，调用方提供实参，这些实参可以是常量：Call(1); 也可以是变量：Call(x); 也可以是他们的组合：Call(2 * x + 1); 也可以是对其它函数的调用：Call(GetNumber()); 但是所有这些实参的形式，都统称为表达式(Expression)。求值（Evaluation）即是指对这些表达式的简化并求解其值的过程。 求值策略(值传递和引用传递)的关注的点在于，这些表达式在调用函数的过程中，求值的时机、值的形式的选取等问题。求值的时机，可以是在函数调用前，也可以是在函数调用后，由被调用者自己求值。这里所谓调用后求值，可以理解为Lazy Load或On Demand的一种求值方式。 而且，除了值传递和引用传递，还有一些其它的求值策略。这些求值策略的划分依据是：求值的时机（调用前还是调用中）和值本身的传递方式。详见下表：看到这里的名传递，可能就有人联想到C++里的别名(alias)，其实也是两码事儿。语言层直接支持名传递的语言很不主流，但是在C#中，名传递的行为可以用Func来模拟，说到这儿应该能大概猜出名传递的大致行为了。不过这不是重点，重点是值传递和引用传递。上面给出的传值方式的表述有些单薄，下表列出了一些二者在行为表象上的区别。这里的改变不是指mutate, 而是change，指把一个变量指向另一个对象，而不是指仅仅改变属性或是成员什么的（如Java，所以说Java是Pass by value，原因是它调用时Copy，实参不能指向另一个对象，而不是因为被传递的东西本质上是个Value，这么讲计算机上什么不是Value?）。 这些行为，与参数类型是值类型还是引用类型无关。对于值传递，无论是值类型还是引用类型，都会在调用栈上创建一个副本，不同是，对于值类型而言，这个副本就是整个原始值的复制。而对于引用类型而言，由于引用类型的实例在堆中，在栈上只有它的一个引用（一般情况下是指针），其副本也只是这个引用的复制，而不是整个原始对象的复制。 这便引出了值类型和引用类型（这不是在说值传递）的最大区别：值类型用做参数会被复制，但是很多人误以为这个区别是值类型的特性。其实这是值传递带来的效果，和值类型本身没有关系。只是最终结果是这样。 求值策略定义的是函数调用时的行为，并不对具体实现方式做要求，但是指针由于其汇编级支持的特性，成为实现引用传递方式的首选。但是纯理论上，你完全可以不用指针，比如用一个全局的参数名到对象地址的HashTable来实现引用传递，只是这样效率太低，所以根本没有哪个编程语言会这样做。（自己写来玩玩的不算） 综上所述，对于Java的函数调用方式最准确的描述是：参数藉由值传递方式，传递的值是个引用。（句中两个“值”不是一个意思，第一个值是evaluation result，第二个值是value content） 由于这个描述太绕，而且在字面上与Java总是传引用的事实冲突。于是对于Java，Python、Ruby、JavaScript等语言使用的这种求值策略，起了一个更贴切名字，叫Call by sharing。这个名字诞生于40年前。 前面讨论了各种求值策略的内涵。下面以C++为例： 123456789101112131415161718192021222324252627void ByValue(int a){ a = a + 1;}void ByRef(int&amp; a){ a = a + 1;}void ByPointer(int* a){ *a = *a + 1;}int main(int argv, char** args){ int v = 1; ByValue(v); ByRef(v); // Pass by Reference ByPointer(&amp;v); // Pass by Value int* vp = &amp;v; ByPointer(vp);} Main函数里的前两种方式没有什么好说，第一个是值传递，第二个函数是引用传递，但是后面两种，同一个函数，一次调用是Call by reference, 一次是Call by value。因为： ByPointer(vp); 没有改变vp，其实是无法改变。 ByPointer(&amp;v); 改变了v。（你可能会说，这传递的其实是v的地址，而ByPointer无法改变v的地址，所以这是Call by value。这听上去可以自圆其说，但是v的地址，是个纯数据，在调用的方代码中并不存在，对于调用者而言，只有v，而v的确被ByPointer函数改了，这个结果，正是Call by reference的行为。从行为考虑，才是求值策略的本意。如果把所有东西都抽象成值，从数据考虑问题，那根本就没有必要引入求值策略的概念去混淆视听。） 请体会一下，应该就明白上面一直在说的调用的行为的意思。 C语言不支持引用，只支持指针，但是如上文所见，使用指针的函数，不能通过签名明确其求值策略。C++引入了引用，它的求值策略可以确定是Pass by reference。于是C++的一个奇葩的地方来了，它语言本身（模拟的不算，什么都能模拟）支持Call by value和Call by reference两种求值策略，但是却提供了三种语法去做这俩事儿。 C#的设计就相对合理，函数声明里，有ref/out，就是引用传递，没有ref/out，就是值传递，与参数类型无关。 不过如果观察一下void ByRef(int&amp; a)和void ByPointer(int* a)所生成的汇编代码，会发现在一定条件下其实是一样的。都是这个样子： 1234567891011121314151617181920; 12 : { push ebp mov ebp, esp sub esp, 192 ; 000000c0H push ebx push esi push edi lea edi, DWORD PTR [ebp-192] mov ecx, 48 ; 00000030H mov eax, -858993460 ; ccccccccH rep stosd; 13 : *a = *a + 1; mov eax, DWORD PTR _a$[ebp] mov ecx, DWORD PTR [eax] add ecx, 1 mov edx, DWORD PTR _a$[ebp] mov DWORD PTR [edx], ecx 调用方的代码也是一样的。代码就不贴了。 这两种传递方式说完了，下面回到正题说好处。问题中“这种”指代不明，且认为是Java。 支持多种求值策略可以给语言带来更高的灵活性，但是同时也需要一个“灵活”的人来良好地驾驭。Java通过牺牲这种价值不大还可能带来问题的灵活性，带来了语言自身语法一致性、逻辑鲁棒性及更容易学习等多个好处。 不仅仅Java和C#，每个语言，在设计时都需要在这些特性间做出自己独特的取舍来体现自己的设计理念，并适应不同人，不同使用环境的要求。虽然说没有什么功能是一个语言可以做，而另一个语言做不了的。但是每个语言，都有它最适合的范畴与不适合的范畴。","link":"/2018/06/27/a0027de014ca.html"},{"title":"Java中的注解与Spring中的常用注解","text":"在Spring中，有很多的注解，比如@Controller、@Service什么的。之前对注解的了解不够，在使用SSM时，在想到底什么是注解，它的工作原理又是什么或者说它是怎么工作的，为什么注解了之后就能达到某个功能呢？带着这样的一个疑问，开始探索之旅吧！ 常见的Java内置的注解以及源代码@Override：用于标明此方法覆盖了父类的方法。在《Effective Java》中强烈建议使用此注解来注解子类覆盖父类的方法，以防没有覆盖成功。 1234567891011121314151617181920212223/** * Indicates that a method declaration is intended to override a * method declaration in a supertype. If a method is annotated with * this annotation type compilers are required to generate an error * message unless at least one of the following conditions hold: * * &lt;ul&gt;&lt;li&gt; * The method does override or implement a method declared in a * supertype. * &lt;/li&gt;&lt;li&gt; * The method has a signature that is override-equivalent to that of * any public method declared in {@linkplain Object}. * &lt;/li&gt;&lt;/ul&gt; * * @author Peter von der Ahé * @author Joshua Bloch * @jls 9.6.1.4 @Override * @since 1.5 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override {} @Deprecated：用于标明已经过时的方法或类。在使用Android Studio的时候，如果调用了被其注解过的方法或类，那么将会被IDE划上横线，表示这个方法已经不被推荐使用了。 12345678910111213141516/** * A program element annotated @Deprecated is one that programmers * are discouraged from using, typically because it is dangerous, * or because a better alternative exists. Compilers warn when a * deprecated program element is used or overridden in non-deprecated code. * * @author Neal Gafter * @since 1.5 * @jls 9.6.3.6 @Deprecated */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value={CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE})public @interface Deprecated {} @SuppressWarnnings：用于有选择的关闭编译器对类、方法、成员变量、变量初始化的警告。在《Effective Java》中，这个注解被推荐慎重使用，除非非常确定不需要这些警告信息。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Indicates that the named compiler warnings should be suppressed in the * annotated element (and in all program elements contained in the annotated * element). Note that the set of warnings suppressed in a given element is * a superset of the warnings suppressed in all containing elements. For * example, if you annotate a class to suppress one warning and annotate a * method to suppress another, both warnings will be suppressed in the method. * * &lt;p&gt;As a matter of style, programmers should always use this annotation * on the most deeply nested element where it is effective. If you want to * suppress a warning in a particular method, you should annotate that * method rather than its class. * * @author Josh Bloch * @since 1.5 * @jls 4.8 Raw Types * @jls 4.12.2 Variables of Reference Type * @jls 5.1.9 Unchecked Conversion * @jls 5.5.2 Checked Casts and Unchecked Casts * @jls 9.6.3.5 @SuppressWarnings */@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE})@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings { /** * The set of warnings that are to be suppressed by the compiler in the * annotated element. Duplicate names are permitted. The second and * successive occurrences of a name are ignored. The presence of * unrecognized warning names is &lt;i&gt;not&lt;/i&gt; an error: Compilers must * ignore any warning names they do not recognize. They are, however, * free to emit a warning if an annotation contains an unrecognized * warning name. * * &lt;p&gt; The string {@code &quot;unchecked&quot;} is used to suppress * unchecked warnings. Compiler vendors should document the * additional warning names they support in conjunction with this * annotation type. They are encouraged to cooperate to ensure * that the same names work across multiple compilers. * @return the set of warnings to be suppressed */ String[] value();} WARNING 上面为声明注解，下面为元注解！ WARNING @Documented 被修饰的注解会生成到javadoc中。 12345678910111213141516/** * Indicates that annotations with a type are to be documented by javadoc * and similar tools by default. This type should be used to annotate the * declarations of types whose annotations affect the use of annotated * elements by their clients. If a type declaration is annotated with * Documented, its annotations become part of the public API * of the annotated elements. * * @author Joshua Bloch * @since 1.5 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Documented {} @Inherited 可以让注解被继承，但这并不是真的继承，只是通过使用@Inherited，可以让子类Class对象使用getAnnotations()获取父类被@Inherited修饰的注解。 注解语法看一个简单一点的@Override的源代码，这是一个声明注解，然后其中的两个注解@Target和@Retention是元注解，就是标记其他注解的注解。@Target说明了注解的使用场景，此处是只能在方法上注解；@Retention说明了注解的生命周期，在什么阶段还存在。 1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override {} 他们的具体取值以及意义如下：@Target： 12345678910111213141516171819202122232425262728public enum ElementType { /**标明该注解可以用于类、接口（包括注解类型）或enum声明*/ TYPE, /** 标明该注解可以用于字段(域)声明，包括enum实例 */ FIELD, /** 标明该注解可以用于方法声明 */ METHOD, /** 标明该注解可以用于参数声明 */ PARAMETER, /** 标明注解可以用于构造函数声明 */ CONSTRUCTOR, /** 标明注解可以用于局部变量声明 */ LOCAL_VARIABLE, /** 标明注解可以用于注解声明(应用于另一个注解上)*/ ANNOTATION_TYPE, /** 标明注解可以用于包声明 */ PACKAGE, /** * 标明注解可以用于类型参数声明（1.8新加入） * @since 1.8 */ TYPE_PARAMETER, /** * 类型使用声明（1.8新加入) * @since 1.8 */ TYPE_USE} @Retention：用来约束注解的生命周期，分别有三个值，源码级别（source），类文件级别（class）或者运行时级别（runtime），其含有如下： SOURCE：注解将被编译器丢弃（该类型的注解信息只会保留在源码里，源码经过编译后，注解信息会被丢弃，不会保留在编译好的class文件里） CLASS：注解在class文件中可用，但会被VM丢弃（该类型的注解信息会保留在源码里和class文件里，在执行的时候，不会加载到虚拟机中），请注意，当注解未定义Retention值时，默认值是CLASS，如Java内置注解，@Override、@Deprecated、@SuppressWarnning等 RUNTIME：注解信息将在运行期(JVM)也保留，因此可以通过反射机制读取注解的信息（源码、class文件和执行的时候都有注解的信息），如SpringMvc中的@Controller、@Autowired、@RequestMapping等。 回头再看看@SuppressWarnings，声明了一个变量，叫做value，所以我们在使用这个注解的时候，可以这样写@SuppressWarnings(value=&quot;unchecked&quot;)。由此可以联想到SpringMVC中的@RequestMapping注解中的路径参数。 但是，当注解中定义了名为value的元素，并且在使用该注解时，如果该元素是唯一需要赋值的一个元素，那么此时无需使用key=value的语法，而只需在括号内给出value元素所需的值即可。这可以应用于任何合法类型的元素，这限制了元素名必须为value！ 所以@SuppressWarnings(&quot;unchecked&quot;)也是正确的。 Spring中的注解举例@Controller： 12345678910111213141516171819202122232425262728/** * Indicates that an annotated class is a &quot;Controller&quot; (e.g. a web controller). * * &lt;p&gt;This annotation serves as a specialization of {@link Component @Component}, * allowing for implementation classes to be autodetected through classpath scanning. * It is typically used in combination with annotated handler methods based on the * {@link org.springframework.web.bind.annotation.RequestMapping} annotation. * * @author Arjen Poutsma * @author Juergen Hoeller * @since 2.5 * @see Component * @see org.springframework.web.bind.annotation.RequestMapping * @see org.springframework.context.annotation.ClassPathBeanDefinitionScanner */@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller { /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;} 如何对这些注解进行操作反射 参考：https://blog.csdn.net/javazejian/article/details/71860633","link":"/2018/08/30/4c58677ac3c7.html"},{"title":"Java多线程系列（0）基础概念","text":"废话就不多说了，直接上总结吧 线程的状态(API文档翻译)看了很多网上的那些关于Java中线程的状态转换图，但是我觉得比较靠谱的还是根据源代码中所定义的状态整出来的状态图。也是看到别人的指点吧。 源代码位置：public static enum Thread.State A thread can be in only one state at a given point in time.These states are virtual machine states which do not reflect any operating system thread states. A thread can be in one of the following thread states:在某个特定的时间点上，一个线程只能处于某一个特定的状态。这些状态是指JVM中的状态，不是指任何操作系统中的线程概念（所以这可能意味着这里所讲的线程状态只是Java中的线程状态）。线程的状态如下： 状态 描述 NEW A thread that has not yet started is in this state.没有调用过start()方法的线程。或者说刚new出来的 RUNNABLE A thread executing in the Java virtual machine but it may be waiting for other resources from the operating system such as processor.正在虚拟机中运行，但可能在等待某个资源，如处理器。 BLOCKED A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling Object.wait.等待锁的释放以进入synchronized代码块/方法，或在调用wait()后再次进入synchronized代码块/方法。 WAITING A thread that is waiting indefinitely for another thread to perform a particular action is in this state.无限期地等待其他的线程执行某个特定的动作，以继续后续操作 TIMED_WAITING A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state.等待某个线程执行一个操作到某个确定的时间 TERMINATED A thread that has exited is in this state.已退出 关于TIMED_WAITING和WAITING（API文档中对其说明的翻译）： 1.一个处于WAITING状态的线程，可以在调用了下面列表中的方法后进入: Object.wait with no timeout Thread.join with no timeout LockSupport.park 处于WAITING状态的线程在等待着其他线程的某个特定的动作以继续执行。例如，当一个线程调用了 Object.wait()后，此线程便等待着其它线程调用Object.notify()/Object.notifyAll()（前后为同一个对象） ；当一个线程调用了Thread.join()后，此线程便在等待 join()方法所在对象（线程） 的终结，以继续后续操作。 2.处于TIMED_WAITING状态的线程，与WAITING状态类似，只是多了一个时间限制。可以在调用了下面的方法后进入： Thread.sleep Object.wait with timeout Thread.join with timeout LockSupport.parkNanos LockSupport.parkUntil 状态转换图 join()的源码分析1234567891011121314151617181920212223242526272829// 不带参数的join实际上运行的是一个传参数0的join()public final void join() throws InterruptedException { join(0);}// 带一个参数的joinpublic final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) { throw new IllegalArgumentException(&quot;timeout value is negative&quot;); } // 对0时特殊处理 if (millis == 0) { while (isAlive()) {//此判断的对象是当前对象，也就是另外一个线程 wait(0);// 堵塞当前运行所处的线程 } // 否则若超出了规定事件，那么将跳出循环，也就是不在阻塞 } else { while (isAlive()) { long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } }} 对于其中的wait(0)，锁是自身，所以就有一个问题，那就是何时会调用notify/notifyAll，让当前运行线程从堵塞中恢复出来，继续运行？因为锁是本身对象，这个对象也是一个线程，等这个线程运行完毕后，除了它自己，就没有看到有调用notify/notifyAll的语句。所以想了半天，可能是线程执行完毕后，会有一个回调之类的来执行同样的功能，或者是直接可以让跳出的功能吧。带着疑问看到了join(int)的注释，瞬间就明白了： As a thread terminates the this.notifyAll method is invoked. 也就是说，线程结束后，会调用this.nofityAll()。 对于为什么要在while循环中调用wait()，这是一个套路，在API中该方法的注释上面，我们可以找到相关的说明： 线程可能被除notify、interrupt、超时之外的伪唤醒唤醒。这种情况，在实际中，发生几率不大。我们需要等到其满足条件后，才不阻塞，如果不满足条件，继续阻塞。wait()要写在循环中，如下： 12345synchronized (obj) { while (&lt;condition does not hold&gt;) obj.wait(timeout); ... // Perform action appropriate to condition} JLS, 17.2.1 Wait没太理解啥时候会抛出IllegalMonitorStateException。自己写了一个，就抛出这个异常了。 异常源代码的注释：Thrown to indicate that a thread has attempted to wait on an object’s monitor or to notify other threads waiting on an object’s monitor without owning the specified monitor. 获得这个对象的锁是什么意思？ 可参考 JSL，14.19 看了这个解释越来越迷糊。既然使用synchronized就可以使得其他线程阻塞住，且其中的代码块可以保证只有一个线程在执行，那么使用wait()的意义到底在哪里呢？ 关于synchronized关键字有两个场景，一种是做为其所修饰的方法，另一种则是作为一个代码块。在JLS,8.4.3.6 synchronized Methods和JLS，14.19 The synchronized Statement中有相应的描述。所以下面来看其所修饰的方法是怎么一回事：开头的那段描述说，synchronized方法在执行前会获得一个锁。这个锁是哪来的，以及是谁的？后面的两段就已经给出了回答。按照对其的理解，尝试了将其效果体现出来，没有任何同步的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package basic.multithread;public class TestSynchronized { public static void main(String[] args) { SubClass sc1 = new SubClass(1); SubClass sc2 = new SubClass(2); // 在第一个线程中，是使用sc1的sayHello方法 new Thread(new Runnable() { @Override public void run() { sc1.sayHello(&quot;thread 1&quot;); } }).start(); // 在第二个线程中使用sc2的sayHello方法 new Thread(new Runnable() { @Override public void run() { sc2.sayHello(&quot;thread 2&quot;); } }).start(); } private static class SubClass{ private int index; public SubClass(int index) { this.index = index; } // 如果在这个方法上直接加锁，能够达到依次输出吗？ public void sayHello(String addedInfo){ for (int i = 0; i &lt; 5; i++) { System.out.println(&quot;Instance &quot; + index + &quot; say Hello from &quot; + addedInfo); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } } }}/**某一次的输出Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1*/ 按照对其的理解，可以猜测如果只是在SubClass.sayHello()方法加上synchronized是不能达到让线程1执行完毕后再执行线程2的。为什么呢？因为在这两个线程中，执行sayHello()方法的实例不是同一个，也就是说，不是同一把锁，也就没有阻塞的效果。要怎么改？换成同一个实例或者**将sayHello()中的代码用synchronized代码块包裹住，其中的参数填写SubClass.class**，即可达到让线程1或线程2执行完毕后再执行另外一个线程的效果。当然也可以直接用join，这里只是验证一下对synchronized关键字的理解。 先看实际操作中，只添加关键字的做法： 1234567891011121314151617181920212223// 接上述代码，其余不变，只加上synchronized关键字public synchronized void sayHello(String addedInfo){ for (int i = 0; i &lt; 5; i++) { System.out.println(&quot;Instance &quot; + index + &quot; say Hello from &quot; + addedInfo); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } }}/**运行结果：Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2Instance 1 say Hello from thread 1Instance 2 say Hello from thread 2*/ 在加上关键字后（接上面的代码），调用同一个实例的sayHello()方法： 1234567891011121314151617181920212223242526272829303132// 将sc2改成了sc1，即使用同一个实例public static void main(String[] args) { SubClass sc1 = new SubClass(1); SubClass sc2 = new SubClass(2); new Thread(new Runnable() { @Override public void run() { sc1.sayHello(&quot;thread 1&quot;); } }).start(); new Thread(new Runnable() { @Override public void run() { // 修改点在这里 sc1.sayHello(&quot;thread 2&quot;); } }).start();}/*运行结果：Instance 1 say Hello from thread 1Instance 1 say Hello from thread 1Instance 1 say Hello from thread 1Instance 1 say Hello from thread 1Instance 1 say Hello from thread 1Instance 1 say Hello from thread 2Instance 1 say Hello from thread 2Instance 1 say Hello from thread 2Instance 1 say Hello from thread 2Instance 1 say Hello from thread 2*/ 由结果看来，理解是不存在偏差的，不需要负责。还有一种方法，是在原始代码的基础上，将sayHello()方法中的代码，全部包裹在synchronized代码块中，即： 123synchronized (SubClass.class) { ……} 为什么呢？这得说一下普通类和 Class类 之间的关系。Class类是用来描述一些普通类的信息；每一个普通类都会有一个Class类，不管有多少个实例，不同实例中获取到的相应Class类都是同一个，如下： 123SubClass sc1 = new SubClass(1);SubClass sc2 = new SubClass(2);System.out.println(sc1.getClass() == sc2.getClass()); 经验证效果也是没问题的，结果和代码就不贴了。 关于sleep与yield(JLS, 17.3) http://www.importnew.com/21136.htmlhttps://www.cnblogs.com/trust-freedom/p/6606594.html","link":"/2018/07/16/2832d1a0f212.html"},{"title":"Java中的线程池从精通到入门","text":"说真的，我一直认为线程池很简单，也没去看过它的实现，大概了解过其中的原理，但是并未深入学习。一方面，了解过之后很长时间不去看，非常容易忘；另一方面，还是深入源码得到的信息才会比较深刻，还能避免背书式学习。 继承结构说明 在Executors中，有几个静态方法，预设了几个ThreadPoolExecutor，其实主要的区别在于new一个实例的时候，传入的参数不一样。关于这几个预设的ThreadPoolExecutor可以在了解其参数详细的定义后，再进行分析。 用法简介 - 注释ThreadPoolExecutor的类前注释，当阅读理解随便看看，看个大概，都比网上的文章要优质。 An ExecutorService that executes each submitted task using one of possibly several pooled threads, normally configured using Executors factory methods. Thread pools address two different problems: they usually provide improved performance when executing large numbers of asynchronous tasks, due to reduced per-task invocation overhead, and they provide a means of bounding and managing the resources, including threads, consumed when executing a collection of tasks. Each ThreadPoolExecutor also maintains some basic statistics, such as the number of completed tasks. To be useful across a wide range of contexts, this class provides many adjustable parameters and extensibility hooks. However, programmers are urged to use the more convenient Executors factory methods Executors.newCachedThreadPool (unbounded thread pool, with automatic thread reclamation), Executors.newFixedThreadPool (fixed size thread pool) and Executors.newSingleThreadExecutor (single background thread), that preconfigure settings for the most common usage scenarios. Otherwise, use the following guide when manually configuring and tuning this class: Core and maximum pool sizes A ThreadPoolExecutor will automatically adjust the pool size (see getPoolSize) according to the bounds set by corePoolSize (see getCorePoolSize) and maximumPoolSize (see getMaximumPoolSize). When a new task is submitted in method execute(Runnable), if fewer than corePoolSize threads are running, a new thread is created to handle the request, even if other worker threads are idle. Else if fewer than maximumPoolSize threads are running, a new thread will be created to handle the request only if the queue is full. By setting corePoolSize and maximumPoolSize the same, you create a fixed-size thread pool. By setting maximumPoolSize to an essentially unbounded value such as Integer.MAX_VALUE, you allow the pool to accommodate an arbitrary number of concurrent tasks. Most typically, core and maximum pool sizes are set only upon construction, but they may also be changed dynamically using setCorePoolSize and setMaximumPoolSize. 当一个新任务通过execute()方法执行时，如果当前运行的线程数小于核心数，那么会新开一个线程处理这个任务，即使别的线程在闲置；如果当前在跑的线程数大于等于核心数但小于最大线程数，若Queue没有满，那么会将改任务加入Queue中，若Queue满了，那么会新增一个线程去处理改任务；如果大于等于最大线程数，会触发决绝策略。 On-demand construction By default, even core threads are initially created and started only when new tasks arrive, but this can be overridden dynamically using method prestartCoreThread or prestartAllCoreThreads. You probably want to prestart threads if you construct the pool with a non-empty queue. 可以预先初始化好线程数，不用一次次execute时慢慢增加。 Creating new threads New threads are created using a ThreadFactory. If not otherwise specified, a Executors.defaultThreadFactory is used, that creates threads to all be in the same ThreadGroup and with the same NORM_PRIORITY priority and non-daemon status. By supplying a different ThreadFactory, you can alter the thread’s name, thread group, priority, daemon status, etc. If a ThreadFactory fails to create a thread when asked by returning null from newThread, the executor will continue, but might not be able to execute any tasks. Threads should possess the “modifyThread” RuntimePermission. If worker threads or other threads using the pool do not possess this permission, service may be degraded: configuration changes may not take effect in a timely manner, and a shutdown pool may remain in a state in which termination is possible but not completed. 创建新线程是通过ThreadFactory的newThread()方法，默认实现是Executors.defaultThreadFactory。可自定义线程的名称、是否为守护进程、优先级等。 Keep-alive times If the pool currently has more than corePoolSize threads, excess threads will be terminated if they have been idle for more than the keepAliveTime (see getKeepAliveTime(TimeUnit)). This provides a means of reducing resource consumption when the pool is not being actively used. If the pool becomes more active later, new threads will be constructed. This parameter can also be changed dynamically using method setKeepAliveTime(long, TimeUnit). Using a value of Long.MAX_VALUE TimeUnit.NANOSECONDS effectively disables idle threads from ever terminating prior to shut down. By default, the keep-alive policy applies only when there are more than corePoolSize threads, but method allowCoreThreadTimeOut(boolean) can be used to apply this time-out policy to core threads as well, so long as the keepAliveTime value is non-zero. 当线程数超过核心数，如果线程闲置超过keepAliveTime ，那么该线程将会被关闭。也可以通过 allowCoreThreadTimeOut(boolean)，回收核心线程。可拓展啊，牛逼。 Queuing Any BlockingQueue may be used to transfer and hold submitted tasks. The use of this queue interacts with pool sizing: If fewer than corePoolSize threads are running, the Executor always prefers adding a new thread rather than queuing. If corePoolSize or more threads are running, the Executor always prefers queuing a request rather than adding a new thread. If a request cannot be queued, a new thread is created unless this would exceed maximumPoolSize, in which case, the task will be rejected. 大于核心数，存储到queue；如果queue满了，新建线程，直到到达maximumPoolSize。 There are three general strategies for queuing: Direct handoffs. A good default choice for a work queue is a SynchronousQueue that hands off tasks to threads without otherwise holding them. Here, an attempt to queue a task will fail if no threads are immediately available to run it, so a new thread will be constructed. This policy avoids lockups when handling sets of requests that might have internal dependencies. Direct handoffs generally require unbounded maximumPoolSizes to avoid rejection of new submitted tasks. This in turn admits the possibility of unbounded thread growth when commands continue to arrive on average faster than they can be processed. Unbounded queues. Using an unbounded queue (for example a LinkedBlockingQueue without a predefined capacity) will cause new tasks to wait in the queue when all corePoolSize threads are busy. Thus, no more than corePoolSize threads will ever be created. (And the value of the maximumPoolSize therefore doesn’t have any effect.) This may be appropriate when each task is completely independent of others, so tasks cannot affect each others execution; for example, in a web page server. While this style of queuing can be useful in smoothing out transient bursts of requests, it admits the possibility of unbounded work queue growth when commands continue to arrive on average faster than they can be processed. Bounded queues. A bounded queue (for example, an ArrayBlockingQueue) helps prevent resource exhaustion when used with finite maximumPoolSizes, but can be more difficult to tune and control. Queue sizes and maximum pool sizes may be traded off for each other: Using large queues and small pools minimizes CPU usage, OS resources, and context-switching overhead, but can lead to artificially low throughput. If tasks frequently block (for example if they are I/O bound), a system may be able to schedule time for more threads than you otherwise allow. Use of small queues generally requires larger pool sizes, which keeps CPUs busier but may encounter unacceptable scheduling overhead, which also decreases throughput. 队列的三种策略。第一种，不让存储到到queue，一有存储动作，就新建线程，最大线程数设置成无限制；第二种，队列的长度无限，这样会导致最大线程数失效；第三种，有界队列。 Rejected tasks New tasks submitted in method execute(Runnable) will be rejected when the Executor has been shut down, and also when the Executor uses finite bounds for both maximum threads and work queue capacity, and is saturated. In either case, the execute method invokes the RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor) method of its RejectedExecutionHandler. Four predefined handler policies are provided: In the default ThreadPoolExecutor.AbortPolicy, the handler throws a runtime RejectedExecutionException upon rejection. In ThreadPoolExecutor.CallerRunsPolicy, the thread that invokes execute itself runs the task. This provides a simple feedback control mechanism that will slow down the rate that new tasks are submitted. In ThreadPoolExecutor.DiscardPolicy, a task that cannot be executed is simply dropped. In ThreadPoolExecutor.DiscardOldestPolicy, if the executor is not shut down, the task at the head of the work queue is dropped, and then execution is retried (which can fail again, causing this to be repeated.) It is possible to define and use other kinds of RejectedExecutionHandler classes. Doing so requires some care especially when policies are designed to work only under particular capacity or queuing policies. 拒绝任务发生在线程池已经处于SHUT_DOWN 状态，或最大线程数以及队列长度有限，并处于饱和状态时。预置的拒绝策略有4种，分别为：第一种，直接抛异常；第二种，调用者在自己的线程中执行该任务；第三种，直接抛弃；第四种，丢弃等待时间最久的那个任务。 自己可以自定义拒绝策略。 Hook methods This class provides protected overridable beforeExecute(Thread, Runnable) and afterExecute(Runnable, Throwable) methods that are called before and after execution of each task. These can be used to manipulate the execution environment; for example, reinitializing ThreadLocals, gathering statistics, or adding log entries. Additionally, method terminated can be overridden to perform any special processing that needs to be done once the Executor has fully terminated.If hook, callback, or BlockingQueue methods throw exceptions, internal worker threads may in turn fail, abruptly terminate, and possibly be replaced. 有钩子函数可以做到AOP的效果，分别在执行前，执行后。具体用途可以根据自己需求来进行自定义。 Queue maintenance Method getQueue() allows access to the work queue for purposes of monitoring and debugging. Use of this method for any other purpose is strongly discouraged. Two supplied methods, remove(Runnable) and purge are available to assist in storage reclamation when large numbers of queued tasks become cancelled. 可获取 Reclamation A pool that is no longer referenced in a program AND has no remaining threads may be reclaimed (garbage collected) without being explicitly shutdown. You can configure a pool to allow all unused threads to eventually die by setting appropriate keep-alive times, using a lower bound of zero core threads and/or setting allowCoreThreadTimeOut(boolean). 可以通过设置让线程被回收掉。 Extension example Most extensions of this class override one or more of the protected hook methods. For example, here is a subclass that adds a simple pause/resume feature: 1234567891011121314151617181920212223242526272829303132333435363738class PausableThreadPoolExecutor extends ThreadPoolExecutor { private boolean isPaused; private ReentrantLock pauseLock = new ReentrantLock(); private Condition unpaused = pauseLock.newCondition(); public PausableThreadPoolExecutor(...) { super(...); } protected void beforeExecute(Thread t, Runnable r) { super.beforeExecute(t, r); pauseLock.lock(); try { while (isPaused) unpaused.await(); } catch (InterruptedException ie) { t.interrupt(); } finally { pauseLock.unlock(); } } public void pause() { pauseLock.lock(); try { isPaused = true; } finally { pauseLock.unlock(); } } public void resume() { pauseLock.lock(); try { isPaused = false; unpaused.signalAll(); } finally { pauseLock.unlock(); } }} 线程池的状态 状态 说明 RUNNING Accept new tasks and process queued tasks SHUTDOWN Don’t accept new tasks, but process queued tasks STOP Don’t accept new tasks, don’t process queued tasks, and interrupt in-progress tasks TIDYING All tasks have terminated, workerCount is zero, the thread transitioning to state TIDYING will run the terminated() hook method TERMINATED terminated() has completed 状态变换： RUNNING -&gt; SHUTDOWNOn invocation of shutdown() (RUNNING or SHUTDOWN) -&gt; STOPOn invocation of shutdownNow() SHUTDOWN -&gt; TIDYINGWhen both queue and pool are empty STOP -&gt; TIDYINGWhen pool is empty TIDYING -&gt; TERMINATEDWhen the terminated() hook method has completed 关键属性 名称 含义 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程最大空闲时间 workQueue 线程等待队列 threadFactory 线程创建工厂 handler 拒绝策略 参数最多的一个构造函数： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;} 项目中用到的线程池，在MDC中加入了追踪每一个请求的traceId，通过log输出： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SysThreadPool { private ThreadPoolExecutor threadPoolExecutor; private SysThreadPool(ThreadPoolExecutor threadPoolExecutor) { this.threadPoolExecutor = threadPoolExecutor; } public static void doExecute(Runnable task) { Map&lt;String, String&gt; context = MDC.getCopyOfContextMap(); getInstance().threadPoolExecutor.execute(() -&gt; { // 将父线程的MDC内容传给子线程 if(context != null){ MDC.setContextMap(context); } try { task.run(); } catch (Exception e){ e.printStackTrace(); }finally { // 清空MDC内容 MDC.clear(); } }); } private static SysThreadPool getInstance() { return InstanceHolder.threadPool; } // 单例模式的容器实现方式 private static class InstanceHolder { private static final Integer CORE_POOL_SIZE = 50; private static final Integer MAX_POOL_SIZE = 500; private static final Long KEEP_ALIVE_TIME = 2L; private static final TimeUnit TIME_UNIT = TimeUnit.MINUTES; private static final LinkedTransferQueue QUEUE = new LinkedTransferQueue(); private static final ThreadFactory FACTORY = new ThreadFactory() { private final AtomicInteger integer = new AtomicInteger(); @Override public Thread newThread(Runnable r) { return new Thread(r, &quot;SysThreadPool thread: &quot; + integer.getAndIncrement()); } }; public static final SysThreadPool threadPool = new SysThreadPool( new ThreadPoolExecutor(CORE_POOL_SIZE, MAX_POOL_SIZE, KEEP_ALIVE_TIME, TIME_UNIT, QUEUE, FACTORY)); }} 貌似有点问题，MAX_POOL_SIZE应该没有生效，因为队列是无界队列。 JDK预置线程池打开Executors.java，里面很多static方法，且它的构造方法时私有的，所以这个类的用处也很明显，只是作为一个Facade。 12/** Cannot instantiate. */private Executors() {} newCachedThreadPool。这种Queue的策略，对应前面所描述的第一种，Direct Handsoff。 12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());} 核心数为0，最大线程数相当于无界，而SynchronousQueue则是一个空队列，不能存放任务，所以会直接创建线程，直到达到最大的线程数。所有闲置60s之后的线程会被回收，因此执行完之后不会占用任何资源。 newFixedThreadPool。这种Queue策略，对应前面所描述的第二种，Unbounded queues。 12345public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} 核心数等于最大线程数，因为LinkedBlockingQueue无界，所以最大线程数无实际意义。所以这种线程池保证最大线程数为nThreads，且由于keepAliveTime为0，所以不对线程进行回收；后来的任务全部扔进queue里面，等待空闲的线程来执行。 newSingleThreadExecutor。这种Queue策略，对应前面描述的第二种，Unbounded queues。 1234567public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));} 在FixThreadPool的基础上，保证线程数最大为1。 线程池如何工作一般通过线程池的execute方法执行任务，在execute方法中，变浓缩了上面 内容的处理逻辑。 1234567891011121314151617181920/* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ 主要分三步：①与corePoolSize比较大小，小就新建线程运行任务。②大于corePoolSize，放入队列。③放入队列失败，再次尝试新建线程执行任务，上限是maximumPoolSize。④创建新线程失败，那么调用拒绝策略。 1234567891011121314151617181920212223public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // ①与corePoolSize比较大小，小就新建线程运行任务。 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } // ②大于corePoolSize，放入队列。 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } // ③放入队列失败，再次尝试新建线程执行任务，上限是maximumPoolSize。 else if (!addWorker(command, false)) // ④创建新线程失败，那么调用拒绝策略。 reject(command);} 其中比较关键的一个步骤可能是addWorker这个方法，在这其中，会调用threadFactory新建线程，并调用Thread的start()方法来开启线程。 其中有一段标号与break、continue的使用，之前都没见过、没用过。 ①可以给语句块加标号赋予它们名称，标号位于语句之前，且语句前只允许加一个标号，标号后面不能跟大括号，且后面只能跟for.while.do-while等循环。 ②标号只能被continue和break引用。通过用标号，我们可以对外层循环进行控制。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273private boolean addWorker(Runnable firstTask, boolean core) { retry: for (int c = ctl.get();;) { // Check if queue empty only if necessary. if (runStateAtLeast(c, SHUTDOWN) &amp;&amp; (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; for (;;) { if (workerCountOf(c) &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) return false; // 通过CAS更新工作线程数量 if (compareAndIncrementWorkerCount(c)) // break外层循环 break retry; c = ctl.get(); // Re-read ctl if (runStateAtLeast(c, SHUTDOWN)) // continue外层循环 continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 调用threadFactory新建线程 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); if (isRunning(c) || (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { // 启动线程 t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted;}Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this);} reject即直接调用rejectedExecution方法。 123final void reject(Runnable command) { handler.rejectedExecution(command, this);} 线程池如何拉取队列中的任务并执行？这里有一个细节，需要注意，Worker这个私有内部类，它实现了Runnable，并且通过threadFactory创建线程的时候，将自己作为Runnable，传给了创建的线程，而同时传进去的task被专门用firstTask保存起来。 12345Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this);} 所以，上面的t.start()： 12345if (workerAdded) { // 启动线程 t.start(); workerStarted = true;} 实际上是执行了Worker的run方法，也就是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public void run() { runWorker(this);}final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 第一次执行时，会首先执行之前传入的task。 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // getTask()会堵塞线程，直到能拿到数据。 while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); try { task.run(); afterExecute(task, null); } catch (Throwable ex) { afterExecute(task, ex); throw ex; } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); }} 其中还包含beforeExecute、afterExecute函数的执行。 Reference: https://www.jianshu.com/p/f030aa5d7a28 https://www.cnblogs.com/dolphin0520/p/3932921.html","link":"/2020/03/17/fc3d3a908eba.html"},{"title":"Java多线程系列（1）对一个多线程同步代码的分析","text":"注意synchronized关键字使用的是实例锁即可。即m1()与m2()是按照某个次序执行，所以在m1()中，一定会输出b = 1000。至于主线程中的输出，则需要考虑执行顺序。 1234567891011121314151617181920212223242526272829303132333435363738394041package basic.multithread;public class TestSync2 implements Runnable { int b = 100; synchronized void m1() throws InterruptedException { b = 1000; Thread.sleep(500); System.out.println(Thread.currentThread().getName() + &quot; b = &quot; + b); } synchronized void m2() throws InterruptedException { Thread.sleep(250); b = 2000; } public static void main(String[] args) throws InterruptedException { TestSync2 tt = new TestSync2(); Thread t = new Thread(tt); t.start(); tt.m2(); System.out.println(Thread.currentThread().getName() + &quot; b = &quot; + tt.b); } @Override public void run(){ try { m1(); } catch (InterruptedException e){ e.printStackTrace(); } }}/* 我的输出是:main b = 1000Thread-0 b = 1000*/ 多次运行，可能会有不同的结果，但是子线程的输出，我认为一定是1000。对于这样的输出，可能的执行次序是这样的： 主线程开启子线程后，便获得了实例tt的锁，然后等m1()执行完后，再执行m2()，在m2()中，首先改变b的值到1000，然后进行休眠。注意，此时的主线程是可以继续执行的，然后转到主线程，输出main b = 1000，因为使用了同步，所以修改对主线程可见。然后子线程再输出Thread-0 b = 1000。","link":"/2018/07/17/b1c1fc966e44.html"},{"title":"Java多线程系列（2）同步器的使用与解析","text":"CountDownLatchA synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. A CountDownLatch is initialized with a given count. The await methods block until the current count reaches zero due to invocations of the countDown() method, after which all waiting threads are released and any subsequent invocations of await return immediately. This is a one-shot phenomenon – the count cannot be reset. If you need a version that resets the count, consider using a CyclicBarrier. A CountDownLatch is a versatile synchronization tool and can be used for a number of purposes. A CountDownLatch initialized with a count of one serves as a simple on/off latch, or gate: all threads invoking await wait at the gate until it is opened by a thread invoking countDown(). A CountDownLatch initialized to N can be used to make one thread wait until N threads have completed some action, or some action has been completed N times. A useful property of a CountDownLatch is that it doesn’t require that threads calling countDown wait for the count to reach zero before proceeding, it simply prevents any thread from proceeding past an await until all threads could pass. Sample usage: Here is a pair of classes in which a group of worker threads use two countdown latches: The first is a start signal that prevents any worker from proceeding until the driver is ready for them to proceed;The second is a completion signal that allows the driver to wait until all workers have completed. 123456789101112131415161718192021222324252627282930313233class Driver { // ... void main() throws InterruptedException { CountDownLatch startSignal = new CountDownLatch(1); CountDownLatch doneSignal = new CountDownLatch(N); for (int i = 0; i &lt; N; ++i) // create and start threads new Thread(new Worker(startSignal, doneSignal)).start(); doSomethingElse(); // don't let run yet startSignal.countDown(); // let all threads proceed doSomethingElse(); doneSignal.await(); // wait for all to finish } } class Worker implements Runnable { private final CountDownLatch startSignal; private final CountDownLatch doneSignal; Worker(CountDownLatch startSignal, CountDownLatch doneSignal) { this.startSignal = startSignal; this.doneSignal = doneSignal; } public void run() { try { startSignal.await(); doWork(); doneSignal.countDown(); } catch (InterruptedException ex) {} // return; } void doWork() { ... } } Another typical usage would be to divide a problem into N parts, describe each part with a Runnable that executes that portion and counts down on the latch, and queue all the Runnables to an Executor. When all sub-parts are complete, the coordinating thread will be able to pass through await. (When threads must repeatedly count down in this way, instead use a CyclicBarrier.) 1234567891011121314151617181920212223242526272829class Driver2 { // ... void main() throws InterruptedException { CountDownLatch doneSignal = new CountDownLatch(N); Executor e = ... for (int i = 0; i &lt; N; ++i) // create and start threads e.execute(new WorkerRunnable(doneSignal, i)); doneSignal.await(); // wait for all to finish }} class WorkerRunnable implements Runnable { private final CountDownLatch doneSignal; private final int i; WorkerRunnable(CountDownLatch doneSignal, int i) { this.doneSignal = doneSignal; this.i = i; } public void run() { try { doWork(i); doneSignal.countDown(); } catch (InterruptedException ex) {} // return; } void doWork() { ... } } Memory consistency effects: Until the count reaches zero, actions in a thread prior to calling countDown() happen-before actions following a successful return from a corresponding await() in another thread. CyclicBarrierA synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. CyclicBarriers are useful in programs involving a fixed sized party of threads that must occasionally wait for each other. The barrier is called cyclic because it can be re-used after the waiting threads are released.A CyclicBarrier supports an optional Runnable command that is run once per barrier point, after the last thread in the party arrives, but before any threads are released. This barrier action is useful for updating shared-state before any of the parties continue. Sample usage: Here is an example of using a barrier in a parallel decomposition design: 123456789101112131415161718192021222324252627282930313233343536373839404142class Solver { final int N; final float[][] data; final CyclicBarrier barrier; class Worker implements Runnable { int myRow; Worker(int row) { myRow = row; } public void run() { while (!done()) { processRow(myRow); try { barrier.await(); } catch (InterruptedException ex) { return; } catch (BrokenBarrierException ex) { return; } } } } public Solver(float[][] matrix) { data = matrix; N = matrix.length; Runnable barrierAction = new Runnable() { public void run() { mergeRows(...); }}; barrier = new CyclicBarrier(N, barrierAction); List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(N); for (int i = 0; i &lt; N; i++) { Thread thread = new Thread(new Worker(i)); threads.add(thread); thread.start(); } // wait until done for (Thread thread : threads) thread.join(); }} Here, each worker thread processes a row of the matrix then waits at the barrier until all rows have been processed. When all rows are processed the supplied Runnable barrier action is executed and merges the rows. If the merger determines that a solution has been found then done() will return true and each worker will terminate.If the barrier action does not rely on the parties being suspended when it is executed, then any of the threads in the party could execute that action when it is released. To facilitate this, each invocation of await() returns the arrival index of that thread at the barrier. You can then choose which thread should execute the barrier action, for example: 123if (barrier.await() == 0) { // log the completion of this iteration} The CyclicBarrier uses an all-or-none breakage model for failed synchronization attempts: If a thread leaves a barrier point prematurely because of interruption, failure, or timeout, all other threads waiting at that barrier point will also leave abnormally via BrokenBarrierException (or InterruptedException if they too were interrupted at about the same time). Memory consistency effects: Actions in a thread prior to calling await() happen-before actions that are part of the barrier action, which in turn happen-before actions following a successful return from the corresponding await() in other threads. SemaphoreA counting semaphore. Conceptually, a semaphore maintains a set of permits. Each acquire() blocks if necessary until a permit is available, and then takes it. Each release() adds a permit, potentially releasing a blocking acquirer. However, no actual permit objects are used; the Semaphore just keeps a count of the number available and acts accordingly.Semaphores are often used to restrict the number of threads than can access some (physical or logical) resource. For example, here is a class that uses a semaphore to control access to a pool of items: 123456789101112131415161718192021222324252627282930313233343536373839404142class Pool { private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException { available.acquire(); return getNextAvailableItem(); } public void putItem(Object x) { if (markAsUnused(x)) available.release(); } // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() { for (int i = 0; i &lt; MAX_AVAILABLE; ++i) { if (!used[i]) { used[i] = true; return items[i]; } } return null; // not reached } protected synchronized boolean markAsUnused(Object item) { for (int i = 0; i &lt; MAX_AVAILABLE; ++i) { if (item == items[i]) { if (used[i]) { used[i] = false; return true; } else return false; } } return false; }} Before obtaining an item each thread must acquire a permit from the semaphore, guaranteeing that an item is available for use. When the thread has finished with the item it is returned back to the pool and a permit is returned to the semaphore, allowing another thread to acquire that item. Note that no synchronization lock is held when acquire() is called as that would prevent an item from being returned to the pool. The semaphore encapsulates the synchronization needed to restrict access to the pool, separately from any synchronization needed to maintain the consistency of the pool itself. A semaphore initialized to one, and which is used such that it only has at most one permit available, can serve as a mutual exclusion lock. This is more commonly known as a binary semaphore, because it only has two states: one permit available, or zero permits available. When used in this way, the binary semaphore has the property (unlike many Lock implementations), that the “lock” can be released by a thread other than the owner (as semaphores have no notion of ownership). This can be useful in some specialized contexts, such as deadlock recovery. The constructor for this class optionally accepts a fairness parameter. When set false, this class makes no guarantees about the order in which threads acquire permits. In particular, barging is permitted, that is, a thread invoking acquire() can be allocated a permit ahead of a thread that has been waiting - logically the new thread places itself at the head of the queue of waiting threads. When fairness is set true, the semaphore guarantees that threads invoking any of the acquire methods are selected to obtain permits in the order in which their invocation of those methods was processed (first-in-first-out; FIFO). Note that FIFO ordering necessarily applies to specific internal points of execution within these methods. So, it is possible for one thread to invoke acquire before another, but reach the ordering point after the other, and similarly upon return from the method. Also note that the untimed tryAcquire methods do not honor the fairness setting, but will take any permits that are available. Generally, semaphores used to control resource access should be initialized as fair, to ensure that no thread is starved out from accessing a resource. When using semaphores for other kinds of synchronization control, the throughput advantages of non-fair ordering often outweigh fairness considerations. This class also provides convenience methods to acquire and release multiple permits at a time. Beware of the increased risk of indefinite postponement when these methods are used without fairness set true. Memory consistency effects: Actions in a thread prior to calling a “release” method such as release() happen-before actions following a successful “acquire” method such as acquire() in another thread. ExchangerA synchronization point at which threads can pair and swap elements within pairs. Each thread presents some object on entry to the exchange method, matches with a partner thread, and receives its partner’s object on return. An Exchanger may be viewed as a bidirectional form of a SynchronousQueue. Exchangers may be useful in applications such as genetic algorithms and pipeline designs.Sample Usage: Here are the highlights of a class that uses an Exchanger to swap buffers between threads so that the thread filling the buffer gets a freshly emptied one when it needs it, handing off the filled one to the thread emptying the buffer. 123456789101112131415161718192021222324252627282930313233343536class FillAndEmpty { Exchanger&lt;DataBuffer&gt; exchanger = new Exchanger&lt;DataBuffer&gt;(); DataBuffer initialEmptyBuffer = ... a made-up type DataBuffer initialFullBuffer = ... class FillingLoop implements Runnable { public void run() { DataBuffer currentBuffer = initialEmptyBuffer; try { while (currentBuffer != null) { addToBuffer(currentBuffer); if (currentBuffer.isFull()) currentBuffer = exchanger.exchange(currentBuffer); } } catch (InterruptedException ex) { ... handle ... } } } class EmptyingLoop implements Runnable { public void run() { DataBuffer currentBuffer = initialFullBuffer; try { while (currentBuffer != null) { takeFromBuffer(currentBuffer); if (currentBuffer.isEmpty()) currentBuffer = exchanger.exchange(currentBuffer); } } catch (InterruptedException ex) { ... handle ...} } } void start() { new Thread(new FillingLoop()).start(); new Thread(new EmptyingLoop()).start(); }} Memory consistency effects: For each pair of threads that successfully exchange objects via an Exchanger, actions prior to the exchange() in each thread happen-before those subsequent to a return from the corresponding exchange() in the other thread. 还可参考下列博客：http://www.importnew.com/21889.html","link":"/2018/07/31/363fd694f6d3.html"},{"title":"Java进程周期性自动退出的原因排查","text":"一个java -jar服务在被CI启动后，过一段时间，进程就被消失了，不见了。日志没有关于出错的相关信息。对日志中记录的最后一条请求，进行压力测试，但该进程却没有自己消失。个人觉得这个问题很有意思，但是我也明白，找到这其中的原因可能需要很长的时间。 Update(2019-3-15 )最近公司的其他项目上，又遇到了一个进程老是无缘无故就挂的现象，按照之前的那种场景来排查，并没有发现有那种CI的出现。顿时又陷入了困境之中。不过我还是按部就班的做了三件事： 用root权限启动改服务 做好对jvm的监控 用strace对进程做好监控顺便了解了一下strace的含义，发现其中的字段确实是有很大的意义。监控命令如下：1nohup strace -T -tt -e trace=all -p \\`pgrep -f algorithm-work-1.0.0.jar\\ ` &gt; trace.\\`pgrep -f algorithm-work-1.0.0.jar\\`.log &amp;\\ 监控日志如下：12345678webapp@ecs-f1c4-0003:/opt/webapp/logs$ cat trace.26077.log strace: Process 26077 attached11:22:43.117920 futex(0x7f631a5fb9d0, FUTEX_WAIT, 26078, NULL) = ? ERESTARTSYS (To be restarted if SA_RESTART is set) &lt;1238.653416&gt;11:43:21.776222 --- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=26158, si_uid=0} ---11:43:21.777278 futex(0x7f63199c0540, FUTEX_WAKE_PRIVATE, 1) = 1 &lt;0.004217&gt;11:43:21.786583 rt_sigreturn({mask=[]}) = 202 &lt;0.005049&gt;11:43:21.796220 futex(0x7f631a5fb9d0, FUTEX_WAIT, 26078, NULL &lt;unfinished ...&gt;11:43:23.605244 +++ exited with 143 +++ 从上面看来，uid=0说明操作者是root，但是kill -9不一定有，不过至少是可以看出来是什么时候被干掉的。 转机发现是被别人用来挖矿了==详细的情况与下面链接的描述一模一样。本来还有一个进程叫做crond64，在top中看到占用的CPU非常高，各个核的都占到了90%+。执行的挖矿脚本的目录在~/.ttp下，打包好了，准备研究研究。https://askubuntu.com/questions/1115770/crond64-tsm-virus-in-ubuntu 压力测试首先想到的是：是不是某一个接口出现了问题，所以根据日志中所记录的最后一条请求，对其进行压力测试。脚本如下： 1234567#!/bin/bash# 获取工单详情for i in {1..100000}do curl --header &quot;token:71e8e4dd40dd65f645ceb214397f578e&quot; --url &quot;192.168.31.117:9997/workorder/mine/orders?id=79&quot; &amp; echo &quot;&quot;done 结果被认为遭到了ddos攻击，囧！该服务进程扛过了这些请求，没有死亡。 排查CI因为整个项目通过gitlab管理，而gitlab中有一项叫做CI，可以通过ci脚本来执行一些脚本达到发布、部署最新的服务到相应服务器上。这里面可能会存在问题，比如说，另外一个ci脚本在执行的时候，会把该服务的进程kill掉，只是会有这种可能，因为CI脚本大部分是通过copy的，但是可能性不高，因为所有的CI脚本都能够顺利执行，所以kill掉的肯定是自身服务的进程，不然CI脚本对应的服务可能起不来，但目前所有的CI脚本都能顺利执行完。但是还是去排查一下CI脚本，没毛病。 是谁kill掉了该进程？这个进程消失的原因，可以想到的情况为：jvm崩溃、被操作系统的oom_killer杀掉、被某个脚本杀掉？ 是否为操作系统所终结？由于outofmemory被kill掉的进程，会在/var/log下的某个文件中留下最终的遗迹。但是在整个/var/log下、都没有搜索kill的痕迹，如下：如果没有/var/log/messages这个文件，可以通过设置，将这个log文件开启。 root身份打开 /etc/rsyslog.d/50-default.conf 把注释#去掉 1234#*.=info;*.=notice;*.=warn;\\# auth,authpriv.none;\\# cron,daemon.none;\\# mail,news.none -/var/log/messages 重启后oksudo restart rsyslog 并没有发现这个oom_killer的痕迹 JVM自己崩溃？在该服务的启动参数中加入了对崩溃日志的指定：java -jar -Xms512m -Xmx512m -XX:MaxPermSize=126m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/webapp/xxx-server/ -XX:ErrorFile=/opt/webapp/xxx-server/hs_err_pid_%p.log xxx-server.jar但是在该进程被终结后，并没有发现相应目录下的日志文件。所以这种情况下，同样也没有对其进行内存分析的先决条件、jdk自带的一系列工具并没有发挥出作用的余地。 到底是谁杀掉了这个进程？使用nohup strace -T -tt -e trace=all -p 21715 &gt; trace.log &amp;监控该pid的情况，如果是被kill -9，会出现一个log，大致如下： 结果通过strace命令的跟踪、最终发现trace.log的内容如下所示：出现这个的原因基本上是两个、一个是人为的kill -9、或者就是被系统kill -9。系统杀掉该进程的原因、被逐一排除，结果只剩下人为的因素。关于人为的因素、首先查看命令，并没有相关的kill记录。然后发现开发环境与测试环境的该进程基本上同时挂掉、并且都点了这两个环境的某个CI，然后这两个环境上的该进程都挂掉了，因此基本断定是CI操作杀掉了该进程。被杀掉的进程名字为：java -jar workorder-server.jar，通过CI发布&amp;启动的进程名字为：java -jar order-server.jar。然后在点击order相关的CI时会执行如下操作： 12345script: - mvn clean package -pl order-server -am -Dmaven.test.skip=true - scp order-server/target/order-server.jar ${user_dev}@${nemt_host_dev}:/opt/webapp/order-server/. - ssh ${user_dev}@${nemt_host_dev} 'kill -9 `pgrep -f order-server\\.jar` ; echo 1' - ssh ${user_dev}@${nemt_host_dev} '. /etc/profile ; cd /opt/webapp/order-server/ ; nohup java -jar order-server.jar &gt;&gt; /dev/null 2&gt;&amp;1 &amp;' 问题就在kill -9上面，pgrep查出来的进程号有两个，所以执行order相关的CI时，顺带也把workorder干掉了。 解决办法修改shell语句，让pgrep order-server时，只显示出order-server的进程号即可。","link":"/2019/02/03/8d333a46d643.html"},{"title":"Kubernetes 中 apiserver 加载 schema 流程","text":"在 apiserver 初始化、启动时，会加载所有能识别的 schema。加载的过程通过 import pkg 后，触发对应包下 init() 方法来加载。 入口cmd/kube-apiserver/apiserver.go： 初始化 apiserver 命令行，并运行。 12345func main() { command := app.NewAPIServerCommand() code := cli.Run(command) os.Exit(code)} 在 app.NewAPIServerCommand() 中，有一长串 import，其中这两条 import 语句完成了 schema 的加载。 123456import ( ... &quot;k8s.io/kubernetes/pkg/api/legacyscheme&quot; &quot;k8s.io/kubernetes/pkg/controlplane&quot; ...) 初始化导入 k8s.io/kubernetes/pkg/api/legacyscheme 后，此包下只有一个文件，名为 scheme.go ，该文件中会初始化 3 个变量。其中 Scheme 中会存储 k8s 默认能识别的 scheme。 123456789101112131415161718192021package legacyschemeimport ( &quot;k8s.io/apimachinery/pkg/runtime&quot; &quot;k8s.io/apimachinery/pkg/runtime/serializer&quot;)var ( // Scheme is the default instance of runtime.Scheme to which types in the Kubernetes API are already registered. // NOTE: If you are copying this file to start a new api group, STOP! Copy the // extensions group instead. This Scheme is special and should appear ONLY in // the api group, unless you really know what you're doing. // TODO(lavalamp): make the above error impossible. Scheme = runtime.NewScheme() // Codecs provides access to encoding and decoding for the scheme Codecs = serializer.NewCodecFactory(Scheme) // ParameterCodec handles versioning of objects that are converted to query parameters. ParameterCodec = runtime.NewParameterCodec(Scheme)) 导入 k8s.io/kubernetes/pkg/controlplane 后，在该包下的 import_known_versions.go 文件中，导入了所有 apiserver 支持的 API groups。 123456789101112131415161718192021222324252627package controlplaneimport ( // These imports are the API groups the API server will support. _ &quot;k8s.io/kubernetes/pkg/apis/admission/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/admissionregistration/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/apiserverinternal/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/apps/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/authentication/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/authorization/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/autoscaling/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/batch/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/certificates/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/coordination/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/core/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/discovery/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/events/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/extensions/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/flowcontrol/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/imagepolicy/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/networking/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/node/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/policy/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/rbac/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/scheduling/install&quot; _ &quot;k8s.io/kubernetes/pkg/apis/storage/install&quot;) 它们 import 后的行为是基本一致的，以 k8s.io/kubernetes/pkg/apis/apps/install 为例。该包下只有一个文件，名叫 install.go，其中有一个 init() 方法，会在包导入时执行。 1234567891011121314151617181920212223242526// Package install installs the apps API group, making it available as// an option to all of the API encoding/decoding machinery.package installimport ( &quot;k8s.io/apimachinery/pkg/runtime&quot; utilruntime &quot;k8s.io/apimachinery/pkg/util/runtime&quot; &quot;k8s.io/kubernetes/pkg/api/legacyscheme&quot; &quot;k8s.io/kubernetes/pkg/apis/apps&quot; &quot;k8s.io/kubernetes/pkg/apis/apps/v1&quot; &quot;k8s.io/kubernetes/pkg/apis/apps/v1beta1&quot; &quot;k8s.io/kubernetes/pkg/apis/apps/v1beta2&quot;)func init() { Install(legacyscheme.Scheme)}// Install registers the API group and adds types to a schemefunc Install(scheme *runtime.Scheme) { utilruntime.Must(apps.AddToScheme(scheme)) utilruntime.Must(v1beta1.AddToScheme(scheme)) utilruntime.Must(v1beta2.AddToScheme(scheme)) utilruntime.Must(v1.AddToScheme(scheme)) utilruntime.Must(scheme.SetVersionPriority(v1.SchemeGroupVersion, v1beta2.SchemeGroupVersion, v1beta1.SchemeGroupVersion))} 这里可以这样简单理解（以 utilruntime.Must(apps.AddToScheme(scheme)) 为例）： apps 这个 gv 下所有的资源，通过 apps 包中的 AddToScheme 方法，都注册到了 legacyscheme.Scheme 中，即前面初始化的 Scheme 变量中。这样 k8s 就能识别该 gv 下资源。 对于仅仅了解大致过程，上述的流程已经足够。但是如果点开 apps.AddToScheme(scheme) 方法，会有一种非常熟悉的感觉——在开发operator，通过k8s提供的脚本，来为 CRD 生成对应 yaml 时，会生成相应的代码。 那么，这一套模板到底是怎么将 Scheme 加载进 legacyscheme.Scheme 去的呢？ One more step forward apps.AddToScheme() 方法在 pkg/apis/apps/register.go 文件中，它有 3 个变量加上一个方法，即表示这些资源（Kind）同属于这个 GV： 1234567891011121314151617181920212223242526272829303132var ( // SchemeBuilder stores functions to add things to a scheme. SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) // AddToScheme applies all stored functions t oa scheme. AddToScheme = SchemeBuilder.AddToScheme)// GroupName is the group name use in this packageconst GroupName = &quot;apps&quot;// SchemeGroupVersion is group version used to register these objectsvar SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: runtime.APIVersionInternal}// Adds the list of known types to the given scheme.func addKnownTypes(scheme *runtime.Scheme) error { // TODO this will get cleaned up with the scheme types are fixed scheme.AddKnownTypes(SchemeGroupVersion, &amp;DaemonSet{}, &amp;DaemonSetList{}, &amp;Deployment{}, &amp;DeploymentList{}, &amp;DeploymentRollback{}, &amp;autoscaling.Scale{}, &amp;StatefulSet{}, &amp;StatefulSetList{}, &amp;ControllerRevision{}, &amp;ControllerRevisionList{}, &amp;ReplicaSet{}, &amp;ReplicaSetList{}, ) return nil} 其中执行添加操作的方式是 scheme.AddKnownTypes()，对每种资源，将会在 legacyscheme.Scheme 的 gvkToType、typeToGVK 添加对应的值，如下： 12s.gvkToType[gvk] = ts.typeToGVK[t] = append(s.typeToGVK[t], gvk) 方法 addKnownTypes(scheme *runtime.Scheme) 是如何绕了一大圈才执行的？ 变量 SchemeBuilder 的类型是 []func(*Scheme) error ，也就是说它本身是一个数组，元素类型为一个函数。即： 12345// SchemeBuilder collects functions that add things to a scheme. It's to allow// code to compile without explicitly referencing generated types. You should// declare one in each package that will have generated deep copy or conversion// functions.type SchemeBuilder []func(*Scheme) error 变量 SchemeBuilder 通过 runtime.NewSchemeBuilder(addKnownTypes) 初始化之后，它（数组）含有一个元素，即 addKnownTypes() 方法。 12345678910111213// Register adds a scheme setup function to the list.func (sb *SchemeBuilder) Register(funcs ...func(*Scheme) error) { for _, f := range funcs { *sb = append(*sb, f) }}// NewSchemeBuilder calls Register for you.func NewSchemeBuilder(funcs ...func(*Scheme) error) SchemeBuilder { var sb SchemeBuilder sb.Register(funcs...) return sb} 当执行 utilruntime.Must(apps.AddToScheme(scheme)) 时，会执行 SchemeBuilder.AddToScheme 方法，这个方法中会依次取 SchemeBuilder 中的每个元素，然后执行该元素（方法），如下： 12345678910// AddToScheme applies all the stored functions to the scheme. A non-nil error// indicates that one function failed and the attempt was abandoned.func (sb *SchemeBuilder) AddToScheme(s *Scheme) error { for _, f := range *sb { if err := f(s); err != nil { return err } } return nil} 为什么要这样设计 SchemeBuilder 核心思想是让执行加载 Scheme 的逻辑不用知道具体的类型是什么。 将 SchemeBuilder 设计成数组的形式，可以提高加载时的灵活性？虽然绝大多数场景下，SchemeBuilder 只有一个元素，但是有一些场景下会有两个以上的元素。 SchemeBuilder 的 3 个方法 AddToScheme()、Register()、NewSchemeBuilder() 都是基于 SchemeBuilder 是数组形式时的应有做法，分别对应执行元素（方法）、添加（数组 append()）、初始化（数组）。","link":"/2022/07/14/7a73b54f4876.html"},{"title":"Kubernetes 如何关闭一个 Pod","text":"本文主要求证一个问题：Pod 生命周期中执行 preStop 的时长是否计入 terminationGracePeriodSeconds 中。这个问题在 https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination 中有描述，但是未能清楚地 get 到计时的方式，所以期望从源码中能找到答案。 求证从 kubectl delete pod xxxx 开始，kubectl 最终会向 apiserver 发送 DELETE 请求，如下代码所示 当对 apiserver 的请求经过若干处理后，最终写入 etcd 后，kubelet 监测到该 Pod 状态的变更，最终执行 Pod 的删除操作。此处过滤掉 kublet 冗长的启动后，直接进入 Pod 删除的代码逻辑。 可以看到先删除容器、再删除 PodSandbox 容器的列表在一个 for 循环中，各开一个协程进行删除操作 当开始删除容器时，会先计算 gracePeriod 的时长，它的值未必会一定等于 terminationGracePeriodSeconds，有若干条件，简单而言，若由于 reasonLivenessProbe 检测失败的原因导致的容器删除，它的 gracePeriod 会取 LivenessProbe 里面配置的 TerminationGracePeriodSeconds 时长。 12345678910111213141516171819// From this point, pod and container must be non-nil.gracePeriod := int64(minimumGracePeriodInSeconds)switch {case pod.DeletionGracePeriodSeconds != nil: gracePeriod = *pod.DeletionGracePeriodSecondscase pod.Spec.TerminationGracePeriodSeconds != nil: gracePeriod = *pod.Spec.TerminationGracePeriodSeconds switch reason { case reasonStartupProbe: if containerSpec.StartupProbe != nil &amp;&amp; containerSpec.StartupProbe.TerminationGracePeriodSeconds != nil { gracePeriod = *containerSpec.StartupProbe.TerminationGracePeriodSeconds } case reasonLivenessProbe: if containerSpec.LivenessProbe != nil &amp;&amp; containerSpec.LivenessProbe.TerminationGracePeriodSeconds != nil { gracePeriod = *containerSpec.LivenessProbe.TerminationGracePeriodSeconds } }} 因此此处假设 gracePeriod 为 terminationGracePeriodSeconds 的情况。 当配有 preStop 时，会从 gracePeriod 中减去执行 preStop 的用时，即执行 preStop 的用时是计算在 gracePeriod 中。preStop 的最大执行时长为 gracePeriod。当执行 preStop 的时长比 gracePeriod 2s 时，会直接将 gracePeriod 置为 2s。重新获得额外的 2s 时间。 接着给容器发送停止信号，此处的超时时长为 gracePeriod，已减去 preStop 执行所用时长。 结论preStop 的执行时长，会被纳入 terminationGracePeriodSeconds 的倒计时中 Reference https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination","link":"/2022/04/20/1cd28b1299d9.html"},{"title":"Kubernetes如何创建一个Pod","text":"","link":"/2023/01/07/b7e46d224c2f.html"},{"title":"LeetCode 第 241 场周赛题解报告","text":"好菜啊。只做了一个出来、还是看了生成子集的方法后、调了半天才做出来。 比赛链接：https://leetcode-cn.com/contest/weekly-contest-241/ 5759. 找出所有子集的异或总和再求和这个问题的关键在于子集的生成方式，可参考此链接","link":"/2021/05/17/538170d6075f.html"},{"title":"LeetCode 罗马字相关","text":"https://leetcode.com/problems/integer-to-roman/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657char ONE[5] = {' ', 'I', 'X', 'C', 'M'};char FIVE[4] = {' ', 'V', 'L', 'D'};char strr[100];int judgeByte(int num, int * byte) { int ten = 10, tmp = 1; while (1) { if (num / ten == 0) { *byte = tmp; return ten; } else { ten *= 10; tmp ++; } }}void produceRomanSymbol(int num, int ten, int byte, char * result) { if (byte == 0) { //sprintf(result + strlen(result), &quot;\\n&quot;); return ; } int target = num / (ten/10); //printf(&quot;num = %d, ten = %d, target = %d, byte = %d\\n&quot;, num, ten, target, byte); if (target == 5) { sprintf(result + strlen(result), &quot;%c&quot;, FIVE[byte]); } else if (target &gt; 5) { if (target == 9) { sprintf(result + strlen(result), &quot;%c%c&quot;, ONE[byte], ONE[byte + 1]); } else { int i = 1; sprintf(result + strlen(result), &quot;%c&quot;, FIVE[byte]); for (; i &lt;= (target - 5); i ++) { sprintf(result + strlen(result), &quot;%c&quot;, ONE[byte]); } } } else { if (target == 4) { sprintf(result + strlen(result), &quot;%c%c&quot;, ONE[byte], FIVE[byte]); } else { int i = 1; for (; i &lt;= target; i ++) { sprintf(result + strlen(result), &quot;%c&quot;, ONE[byte]); } } } produceRomanSymbol(num % (ten/10), ten / 10, byte - 1, result);}char* intToRoman(int num) { int byte; int ten = judgeByte(num, &amp;byte); memset(strr, 0, 100); produceRomanSymbol(num, ten, byte, strr); return strr;} https://leetcode.com/problems/roman-to-integer/ 1234567891011121314151617181920212223242526272829303132333435363738394041int getRomanValue(char ch) { switch (ch) { case 'I': return 1; case 'V': return 5; case 'X': return 10; case 'L': return 50; case 'C': return 100; case 'D': return 500; case 'M': return 1000; } return -1;}int romanToInt(char* s) { int cnt = 0, tmp = 0, i; for (i = 0; i &lt; strlen(s); i ++) {// printf(&quot;i = %d, &quot;, i); if (i == 0) { tmp = getRomanValue(s[i]); } else { int diff = getRomanValue(s[i]) - getRomanValue(s[i - 1]); if (diff == 0) { tmp += getRomanValue(s[i]);// printf(&quot;** tmp = %d, pos = %c\\n&quot;, tmp, s[i]); //cnt += tmp; } else if(diff &gt; 0) { cnt += (getRomanValue(s[i]) - tmp);// printf(&quot;cnt = %d, pos = %c\\n&quot;, cnt, s[i]); tmp = 0; } else { cnt += tmp; tmp = 0; tmp += getRomanValue(s[i]);// printf(&quot;tmp = %d, pos = %c\\n&quot;, tmp, s[i]); } } } if (tmp != 0) cnt += tmp; return cnt;}","link":"/2019/02/27/5ba82e56096a.html"},{"title":"Leetcode数据库无锁题答题记录","text":"175. Combine Two Tables 123# Write your MySQL query statement belowselect FirstName, LastName, City, Statefrom Person left join Address on Person.PersonId = Address.PersonId; 176. Second Highest Salary 1234# Write your MySQL query statement belowselect max(Salary) as SecondHighestSalaryfrom Employeewhere Salary != (select max(Salary) from Employee); 177. Nth Highest Salary 12345678CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INTBEGINset N = N - 1; RETURN ( # Write your MySQL query statement below. select IFNULL((select distinct salary from employee order by salary desc limit N,1),NULL) );END 178. Rank Scores 12345# Write your MySQL query statement belowselect b.Score, cast(b.Rank as UNSIGNED) as Rankfrom (select id, score, if(@prev = score, @rank, @rank := @rank + 1) as Rank, @prev := score as tmpfrom scores, (select @rank := 0, @prev := null) as aorder by score desc) b; 180. Consecutive Numbers 1234# Write your MySQL query statement belowselect distinct a.num as ConsecutiveNumsfrom logs as a, logs as b, logs as cwhere (a.id &lt;&gt; b.id and b.id &lt;&gt; c.id) and (b.id = a.id + 1 and c.id = b.id + 1) and (a.num = b.num and b.num = c.num); 181. Employees Earning More Than Their Managers 123# Write your MySQL query statement belowselect name as Employee from employee as ewhere e.salary &gt; ifnull((select salary from employee where id=e.managerid), e.salary + 1); 182. Duplicate Emails 12# Write your MySQL query statement belowselect Email from Person group by Email having count(Email) &gt; 1; 183. Customers Who Never Order 12# Write your MySQL query statement belowselect name as Customers from Customers where id not in (select distinct CustomerId from Orders); 184. Department Highest Salary 1234567# Write your MySQL query statement belowselect Department, e.Name as Employee, Salaryfrom (select DepartmentId as did, Department.Name as Department, max(Salary) maxsalaryfrom Employee join Department on Department.Id = DepartmentIdgroup by DepartmentId) as maxtable, Employee ewhere e.DepartmentId = maxtable.did and maxsalary = e.Salary; 185. Department Top Three Salaries 123456789101112# Write your MySQL query statement belowselect Department, Employee, Salaryfrom (select d1.Name as Department, e1.name as Employee, e1.Salary, ( select count(distinct e2.salary) from Employee as e2 where e2.salary &gt; e1.salary and e2.departmentId = e1.departmentId) as Rankkfrom Employee e1, Department d1where e1.departmentId = d1.id) as dddwhere Rankk &lt; 3order by ddd.Department, ddd.Salary desc; 196. Delete Duplicate Emails 123# Write your MySQL query statement belowdelete p1.* from Person p1, Person p2where p1.email = p2.email and p1.id &gt; p2.id; 197. Rising Temperature 1234# Write your MySQL query statement belowselect w2.Idfrom Weather w1, Weather w2where datediff(w2.RecordDate, w1.RecordDate) = 1 and w2.Temperature &gt; w1.Temperature; 262. Trips and Users题目所需的建表语句如下： user表 12345678910111213141516171819202122232425262728293031323334353637383940414243/* Navicat Premium Data Transfer Source Server : LocalMySQL Source Server Type : MySQL Source Server Version : 80011 Source Host : localhost:3306 Source Schema : test Target Server Type : MySQL Target Server Version : 80011 File Encoding : 65001 Date: 30/07/2018 13:38:27*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for users-- ----------------------------DROP TABLE IF EXISTS `users`;CREATE TABLE `users` ( `user_id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, `banned` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `role` enum('client','driver','partner') CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, PRIMARY KEY (`user_id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of users-- ----------------------------INSERT INTO `users` VALUES (1, 'No', 'client');INSERT INTO `users` VALUES (2, 'Yes', 'client');INSERT INTO `users` VALUES (3, 'No', 'client');INSERT INTO `users` VALUES (4, 'No', 'client');INSERT INTO `users` VALUES (10, 'No', 'driver');INSERT INTO `users` VALUES (11, 'No', 'driver');INSERT INTO `users` VALUES (12, 'No', 'driver');INSERT INTO `users` VALUES (13, 'No', 'driver');SET FOREIGN_KEY_CHECKS = 1; trips表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* Navicat Premium Data Transfer Source Server : LocalMySQL Source Server Type : MySQL Source Server Version : 80011 Source Host : localhost:3306 Source Schema : test Target Server Type : MySQL Target Server Version : 80011 File Encoding : 65001 Date: 30/07/2018 13:38:43*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for trips-- ----------------------------DROP TABLE IF EXISTS `trips`;CREATE TABLE `trips` ( `id` int(10) UNSIGNED NOT NULL AUTO_INCREMENT, `client_id` int(10) UNSIGNED NOT NULL, `driver_id` int(10) UNSIGNED NOT NULL, `city_id` int(11) NOT NULL, `status` enum('completed','cancelled_by_driver','cancelled_by_client') CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `request_at` date NOT NULL, PRIMARY KEY (`id`) USING BTREE, INDEX `client_fk`(`client_id`) USING BTREE, INDEX `driver_fk`(`driver_id`) USING BTREE, CONSTRAINT `client_fk` FOREIGN KEY (`client_id`) REFERENCES `users` (`user_id`) ON DELETE RESTRICT ON UPDATE RESTRICT, CONSTRAINT `driver_fk` FOREIGN KEY (`driver_id`) REFERENCES `users` (`user_id`) ON DELETE RESTRICT ON UPDATE RESTRICT) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;-- ------------------------------ Records of trips-- ----------------------------INSERT INTO `trips` VALUES (1, 1, 10, 1, 'completed', '2013-10-01');INSERT INTO `trips` VALUES (2, 2, 11, 1, 'cancelled_by_driver', '2013-10-01');INSERT INTO `trips` VALUES (3, 3, 12, 6, 'completed', '2013-10-01');INSERT INTO `trips` VALUES (4, 4, 13, 6, 'cancelled_by_client', '2013-10-01');INSERT INTO `trips` VALUES (5, 1, 10, 1, 'completed', '2013-10-02');INSERT INTO `trips` VALUES (6, 2, 11, 6, 'completed', '2013-10-02');INSERT INTO `trips` VALUES (7, 3, 12, 6, 'completed', '2013-10-02');INSERT INTO `trips` VALUES (8, 2, 12, 12, 'completed', '2013-10-03');INSERT INTO `trips` VALUES (9, 3, 10, 12, 'completed', '2013-10-03');INSERT INTO `trips` VALUES (10, 4, 13, 12, 'cancelled_by_driver', '2013-10-03');SET FOREIGN_KEY_CHECKS = 1; Accepted Solution 1234567891011# Write your MySQL query statement belowselect date as Day, cast(format(sum(valid) / count(date), 2) as decimal(10, 2)) as 'Cancellation Rate'from ( select t.id, t.client_id, c.banned cb, t.driver_id, d.banned db, t.status, t.request_at as date, if (status in ('cancelled_by_driver', 'cancelled_by_client'), 1, 0) as valid from trips t, users c, users d where t.client_id = c.users_id and t.driver_id = d.users_id and c.banned != 'Yes' and d.banned != 'Yes' and t.request_at between '2013-10-01' and '2013-10-03') as tmpgroup by date; 595. Big Countries 1234# Write your MySQL query statement belowselect name, population, areafrom Worldwhere population &gt; 25000000 or area &gt; 3000000; 596. Classes More Than 5 Students 12345# Write your MySQL query statement belowselect classfrom coursesgroup by classhaving count(distinct student) &gt;= 5; 620. Not Boring Movies 12345# Write your MySQL query statement belowselect *from cinemawhere id % 2 &lt;&gt; 0 and description not like '%boring%'order by rating desc; 626. Exchange Seats 123456# Write your MySQL query statement belowselect b.id, a.studentfrom seat a, seat b, (select max(id) as id from seat) as maxidwhere ((maxid.id % 2 &lt;&gt; 0 and a.id = maxid.id and a.id = b.id)) or(a.id &lt;&gt; maxid.id and a.id % 2 &lt;&gt; 0 and b.id = a.id + 1) or(b.id &lt;&gt; maxid.id and a.id % 2 = 0 and a.id = b.id + 1); 627. Swap Salary 1234567# Write your MySQL query statement belowupdate salaryset sex=case sexwhen 'm' then 'f'else 'm'end;","link":"/2018/07/31/6232ece6b7b7.html"},{"title":"LinkedList源码阅分析","text":"LinkedList里面涉及到的一些操作，非常细致，以避免出现的空指针，理解后对于其优点与缺点会有一个更加整体的认识吧。 继承关系图(对比ArrayList) 元素的存储结构在LinkedList中，每一个元素都是Node存储，Node拥有一个存储值的item与一个前驱prev和一个后继next，如下： 1234567891011// 典型的链表结构private static class Node&lt;E&gt; { E item;// 存储元素 Node&lt;E&gt; next;// 指向上一个元素 Node&lt;E&gt; prev;// 指向下一个元素 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { this.item = element; this.next = next; this.prev = prev; }} 构造函数与成员变量变量主要有3个： 12345678910111213transient int size = 0;//当前列表的元素个数/** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */transient Node&lt;E&gt; first;// 第一个元素/** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */transient Node&lt;E&gt; last;// 最后一个元素 在LinkedList中的构造函数有两个，一个是无参的，另一个是带Collection参数的。 12345public LinkedList() {}//无参构造函数public LinkedList(Collection&lt;? extends E&gt; c) { this(); addAll(c);//将c中的元素都添加到此列表中} 其添加的过程中，此时size = 0，如下： 123public boolean addAll(Collection&lt;? extends E&gt; c) { return addAll(size, c);//此时 size == 0} 如果index==size，则添加c中的元素到列表的尾部；否则，添加的第index个元素的前面； 123456789101112131415161718192021222324252627282930313233343536373839404142public boolean addAll(int index, Collection&lt;? extends E&gt; c) { // 检查位置是否合法 位置是[0,size]，注意是闭区间 否则报异常 checkPositionIndex(index); Object[] a = c.toArray();// 得到一个元素数组 int numNew = a.length;// c中元素的数量 if (numNew == 0) return false;// 没有元素，添加失败 // 主要功能是找到第size个元素的前驱和后继。得到此元素需要分情况讨论。 // 这段代码是各种情况的总和，可能有一点点容易懵逼。 Node&lt;E&gt; pred, succ;// 前驱与后继 if (index == size) {// 如果位置与当前的size相同 succ = null;// 无后继 pred = last;// 前驱为last，即第size个元素(最后一个元素) } else {// 若与size不同，即index位于[0, size)之间 succ = node(index);// 后继为第index个元素 pred = succ.prev;// 前驱为后继的前驱 }// 后文有详细的图片说明 // 开始逐个插入 for (Object o : a) { @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o; // 新建一个以pred为前驱、null为后继、值为e的节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null)// 前驱为空，则此节点被当做列表的第一个节点 first = newNode; else// 规避掉了NullPointerException，感觉又达到了目的，又实现了逻辑 pred.next = newNode;// 不为空，则将前驱的后继改成当前节点 pred = newNode;// 将前驱改成当前节点，以便后续添加c中其它的元素 } // 至此，c中元素已添加到链表上，但链表中从size开始的那些元素还没有链接到列表上 // 此时就需要利用到之前找出来的succ值，它是作为这个c的整体后继 if (succ == null) {// 如果后继为空，说明无整体后继 last = pred;// c的最后一个元素应当作为列表的尾元素 } else {// 有整体后继 pred.next = succ;// pred即c中的最后一个元素，其后继指向succ，即整体后继 succ.prev = pred;// succ的前驱指向c中的最后一个元素 } // 添加完毕，修改参数 size += numNew; modCount++; return true;} 返回序号为index的元素节点。 看这段代码中的if语句，真的是佩服，这样写代码，都可以这样减少查找次数。 1234567891011121314151617Node&lt;E&gt; node(int index) { // assert isElementIndex(index); // 这个地方很有意思。视其与中值的差距，觉得从前遍历还是从后遍历。 if (index &lt; (size &gt;&gt; 1)) { Node&lt;E&gt; x = first; // 循环index次 迭代到所需要的元素 for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E&gt; x = last; // 循环size-1-index次 for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; }} 测试代码以及验证输出如下： 1234567891011121314public class Main { public static void main(String[] args) { List&lt;String&gt; list = new LinkedList&lt;&gt;(Arrays.asList(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)); System.out.println(list.toString()); list.addAll(2, Arrays.asList(&quot;4&quot;, &quot;5&quot;)); System.out.println(list.toString()); list.addAll(0, Arrays.asList(&quot;6&quot;, &quot;7&quot;)); System.out.println(list.toString()); }}---[1, 2, 3][1, 2, 4, 5, 3][6, 7, 1, 2, 4, 5, 3] 增加元素对于向列表中添加元素，先看一组基本的添加操作，具体如下： 将e链接成列表的第一个元素源代码以及相应的分析如下： 12345678910111213private void linkFirst(E e) { final Node&lt;E&gt; f = first; // 前驱为空，值为e，后继为f final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode;// first指向newNode // 此时的f有可能为null if (f == null)// 若f为空，则表明列表中还没有元素 last = newNode;// last也应该指向newNode else f.prev = newNode;// 否则，前first的前驱指向newNode size++; modCount++;} 其过程大致如下两图所示：初始状态：后续状态：添加元素作为第一个元素时，所需要做的工作，有下列所述：首先，获取第一个节点，然后将该节点的前驱指向新添加的元素所在的节点；接着，将新添加的节点的后继指向前第一个节点；最后，将first指向新添加的元素的节点。添加完毕。 将e链接为最后一个元素源代码以及相应的解释如下： 123456789101112void linkLast(E e) { final Node&lt;E&gt; l = last;// 找到最后一个节点 // 前驱为前last，值为e，后继为null final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode;// last一定会指向此节点 if (l == null)// 最后一个节点为空，说明列表中无元素 first = newNode;// first同样指向此节点 else l.next = newNode;// 否则，前last的后继指向当前节点 size++; modCount++;} 其操作过程与前述linkFirst()的过程类似，因此其替换后的示意图如下： 将e链接到节点succ前源代码以及相应的解析如下： 1234567891011121314void linkBefore(E e, Node&lt;E&gt; succ) { // assert succ != null; final Node&lt;E&gt; pred = succ.prev; // 找到succ的前驱 // 前驱为pred，值为e，后继为succ final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 将succ的前驱指向当前节点 succ.prev = newNode; if (pred == null)// pred为空，说明此时succ为首节点 first = newNode;// 指向当前节点 else pred.next = newNode;// 否则，将succ之前的前驱的后继指向当前节点 size++; modCount++;} 这个操作有点类似将上述的两个操作整合到一起。其操作简图如下： 有了上述的分析，我们再来看一些添加的操作，这些操作基本上是做了一些逻辑判断，然后再调用上述三个方法去实现添加功能，这里略过就好。 123456789101112131415161718public boolean add(E e) { linkLast(e); return true;}// 只有这个是有一点逻辑的public void add(int index, E element) { checkPositionIndex(index); if (index == size)// 为最后一个节点，当然是添加到最后一个~ linkLast(element); else linkBefore(element, node(index));}public void addFirst(E e) { linkFirst(e);}public void addLast(E e) { linkLast(e);} 删除元素删除就是添加过程的逆过程。同样，在分析我们使用的接口前，先分析几个我们看不到的方法，如下： 删除首节点123456789101112131415private E unlinkFirst(Node&lt;E&gt; f) { // assert f == first &amp;&amp; f != null;别忽略这里的断言 final E element = f.item;// 取出首节点中的元素 final Node&lt;E&gt; next = f.next;// 取出首节点中的后继 f.item = null; f.next = null; // help GC first = next;// first指向前first的后继，也就是列表中的2号位 if (next == null)// 如果此时2号位为空，那么列表中此时已无节点 last = null;// last指向null else next.prev = null;// 首节点无前驱 size--; modCount++; return element;// 返回首节点保存的元素值} 删除尾节点此处的操作与删除首节点的操作类似。 123456789101112131415private E unlinkLast(Node&lt;E&gt; l) {// assert l == last &amp;&amp; l != null;别忽略这里的断言final E element = l.item;// 取出尾节点中的元素final Node&lt;E&gt; prev = l.prev;// 取出尾节点中的后继l.item = null;l.prev = null; // help GClast = prev;// last指向前last的前驱，也就是列表中的倒数2号位if (prev == null)// 如果此时倒数2号位为空，那么列表中已无节点 first = null;// first指向nullelse prev.next = null;// 尾节点无后继size--;modCount++;return element;// 返回尾节点保存的元素值} 删除某个非空节点这个也类似添加元素时的第三个基本操作，与结合了上述两个操作有点类似。 1234567891011121314151617181920212223242526// x即为要删除的节点E unlink(Node&lt;E&gt; x) {// assert x != null;final E element = x.item;// 保存x的元素值final Node&lt;E&gt; next = x.next;// 保存x的后继final Node&lt;E&gt; prev = x.prev;// 保存x的前驱if (prev == null) {// 前驱为null，说明x为首节点 first = next;// first指向x的后继} else { prev.next = next;// x的前驱的后继指向x的后继，即略过了x x.prev = null;// x.prev已无用处，置空引用}if (next == null) {// 后继为null，说明x为尾节点 last = prev;// last指向x的前驱} else { next.prev = prev;// x的后继的前驱指向x的前驱，即略过了x x.next = null;// x.next已无用处，置空引用}x.item = null;// 引用置空size--;modCount++;return element;// 返回所删除的节点的元素值} 有了上面的几个函数作为支撑，我们再来看下面的几个我们能用来删除节点的方法，他们也基本上是在一些逻辑判断的基础之上，再调用上述的基本操作： 1234567891011121314151617181920212223242526272829303132333435public E removeFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);}public E removeLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);}// 遍历列表中所有的节点，找到相同的元素，然后删除它public boolean remove(Object o) { if (o == null) { for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (x.item == null) { unlink(x); return true; } } } else { for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) { unlink(x); return true; } } } return false;}public E remove(int index) { checkElementIndex(index); return unlink(node(index));} 修改元素通过遍历，循环index次，获取到相应的节点后，再通过节点来修改元素值。 1234567public E set(int index, E element) { checkElementIndex(index); Node&lt;E&gt; x = node(index);// 获取到需要修改元素的节点 E oldVal = x.item;// 保存之前的值 x.item = element;// 修改 return oldVal;// 返回修改前的值} 查询元素通过位置，循环index次，获取到节点，然后返回该节点中元素的值 1234public E get(int index) { checkElementIndex(index); return node(index).item;// 获取节点，并返回节点中的元素值} 还有两个获取首尾节点的元素的方法： 123456789101112public E getFirst() { final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;}public E getLast() { final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;} 获取元素位置从0开始往后遍历 1234567891011121314151617public int indexOf(Object o) { int index = 0; if (o == null) {// null时分开处理 for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (x.item == null)// 说明找到 return index;// 返回下标 index++; } } else { for (Node&lt;E&gt; x = first; x != null; x = x.next) { if (o.equals(x.item))// 说明找到 return index;// 返回下标 index++; } } return -1;// 未找到，返回-1} 从size - 1开始遍历。基本操作与上述操作类似，只是起始位置不同。 1234567891011121314151617public int lastIndexOf(Object o) { int index = size; if (o == null) { for (Node&lt;E&gt; x = last; x != null; x = x.prev) { index--; if (x.item == null) return index; } } else { for (Node&lt;E&gt; x = last; x != null; x = x.prev) { index--; if (o.equals(x.item)) return index; } } return -1;} 额外的话在上面的诸多函数中，有许多是需要进行位置判断的。在源码中，位置判断有两个函数，一个是下标，一个是位置。看到这两个函数，确实是有一些感触，这确实是需要比较强的总结能力以及仔细的观察能力。 12345678// 下标，保证数组访问不越界。private boolean isElementIndex(int index) { return index &gt;= 0 &amp;&amp; index &lt; size;}// 位置private boolean isPositionIndex(int index) { return index &gt;= 0 &amp;&amp; index &lt;= size;} 后记LinkedList还实现了Queue这个接口，在实现这些接口时，仍然是做一些逻辑处理，然后调用上面所描述的基本操作，如link()、unlink()之类的，因此不再分析。还有其中的关于序列化、Iterator这两块，与ArrayList的实现也是不尽相同的，故在此可参考ArrayList中的解析。","link":"/2018/06/04/c7de834a7b74.html"},{"title":"Linux 系统 IO 多路复用模型","text":"select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。 select 时间复杂度O(n) 它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。 select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是： 1、 单个进程可监视的fd数量被限制，即能监听端口的大小有限。 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048. 2、 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低： ​ 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。 3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大 poll 时间复杂度O(n) poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的. poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点： 1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 2、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 epoll 时间复杂度O(1) epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)） epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。 为什么要有EPOLLET触发模式如果采用EPOLLLT模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.。而采用EPOLLET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符 优点 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）； 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 区别 select poll epoll 进程的最大连接数 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 FD剧增带来的IO效率问题 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 同 select 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 消息传递方式 内核需要将消息传递到用户空间，都需要内核拷贝动作 同 select epoll通过内核和用户空间共享一块内存来实现的。 总结： 综上，在选择select，p****oll，epoll时要根据具体的使用场合以及这三种方式的自身特点。 1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 实现select 使用copy_from_user从用户空间拷贝fd_set到内核空间 注册回调函数__pollwait 遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） 以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 __pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 把fd_set从内核空间拷贝到用户空间。 select的几大缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 pollpoll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多,管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 epollepoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 总结 select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。 参考 IO多路复用之select总结 IO多路复用之poll总结 IO多路复用之epoll总结 linux下select/poll/epoll机制的比较 select、poll、epoll之间的区别总结 epoll 源码解读","link":"/2021/05/30/4bfeb873647c.html"},{"title":"Linux中的特殊符号以及特殊语法","text":"辨别||、&amp;&amp;、;、$*等符号在linux中的含义 与或123456789101112131415161718# 将&amp;&amp;前后的两个命令当做一个表达式，如果表达式出错，那么可以认为该表达式为false➜ ~ ls / &amp;&amp; datebin boot dev etc home initrd.img initrd.img.old lastore lib lib64 lost+found media mnt opt proc root run sbin snap srv sys tmp usr var vmlinuz vmlinuz.oldThu Mar 21 14:18:44 HKT 2019# 第一个命令失败，后面的命令不再执行。短路，因为表达式整体的值已经可以通过第一个表达式获得。➜ ~ ls /hello &amp;&amp; datels: cannot access '/hello': No such file or directory# 与&amp;&amp;恰好相反➜ ~ ls /hello || datels: cannot access '/hello': No such file or directoryThu Mar 21 14:19:03 HKT 2019# 第一个执行成功，已经可以获得整个表达式的值，所以不执行第二个表达式。短路。➜ ~ ls / || date bin boot dev etc home initrd.img initrd.img.old lastore lib lib64 lost+found media mnt opt proc root run sbin snap srv sys tmp usr var vmlinuz vmlinuz.old 分号；表示过程，不计算值，因此按顺序执行。 123456➜ ~ ls / ; date bin boot dev etc home initrd.img initrd.img.old lastore lib lib64 lost+found media mnt opt proc root run sbin snap srv sys tmp usr var vmlinuz vmlinuz.oldThu Mar 21 14:23:48 HKT 2019➜ ~ ls /hello ; datels: cannot access '/hello': No such file or directoryThu Mar 21 14:23:52 HKT 2019 $相关表达式$0, $1, $2, $3, $4, $5, $6, $7, $8, $9, ${10}, ${11}…..指令本身为0。后面为传入参数。个位数的，可直接使用数字，但两位数以上，则必须使用 {} 符号来括住。 12345678910111213141516171819202122232425262728293031#!/bin/bashecho $#echo $*echo $@echo $0echo $1echo $2echo &quot;--------&quot;# 当 $* 和 $@ 不被双引号&quot; &quot;包围时，它们之间没有任何区别，都是将接收到的每个参数看做一份数据，彼此之间以空格来分隔。for a in $*do echo ${a}donefor a in $@do echo ${a}doneecho &quot;--------&quot;# 但是当它们被双引号&quot; &quot;包含时，就会有区别了：# &quot;$*&quot;会将所有的参数从整体上看做一份数据，而不是把每个参数都看做一份数据。# &quot;$@&quot;仍然将每个参数都看作一份数据，彼此之间是独立的。for a in &quot;$*&quot;do echo ${a} # 这 2 个参数会合并到一起形成一份数据，它们之间是无法分割的donefor a in &quot;$@&quot;do echo ${a} # 这 2 个参数是相互独立的，它们是 2 份数据done 输出如下： 12345678910111213141516➜ Documents ./shell.sh hello world 2hello worldhello world./shell.shhelloworld--------helloworldhelloworld--------hello worldhelloworld $? 获取上一个命令的退出状态 123➜ ~ pkill -f xxxxoooo➜ ~ echo $?1 $!和$$ 12345678910111213# Shell最后运行的后台Process的PID ➜ ~ ping www.baidu.com &gt; /dev/null &amp;[1] 14025➜ ~ echo $!14025# Shell本身的PID（ProcessID）➜ ~ ps -ef | grep -v grep | grep zsh sasurai 9143 9122 0 09:48 pts/1 00:00:00 /usr/bin/zshsasurai 11946 5190 0 14:32 pts/4 00:00:00 /usr/bin/zshsasurai 19350 19085 0 10:52 pts/0 00:00:00 /usr/bin/zsh -i➜ ~ echo $$9143 输出/输入重导向 文件描述符 名称 常用缩写 默认值 0 标准输入 stdin 键盘 1 标准输出 stdout 屏幕 2 标准错误输出 stderr 屏幕 我们在简单地用&lt;或&gt;时，相当于使用 0&lt; 或 1&gt;（下面会详细介绍）。* cmd &gt; file把cmd命令的输出重定向到文件file中。如果file已经存在，则清空原有文件，使用bash的noclobber选项可以防止复盖原有文件。* cmd &gt;&gt; file把cmd命令的输出重定向到文件file中，如果file已经存在，则把信息加在原有文件後面。* cmd &lt; file使cmd命令从file读入 cmd &lt;&lt; text从命令行读取输入，直到一个与text相同的行结束。除非使用引号把输入括起来，此模式将对输入内容进行shell变量替换。如果使用&lt;&lt;- ，则会忽略接下来输入行首的tab，结束行也可以是一堆tab再加上一个与text相同的内容，可以参考後面的例子。 cmd &lt;&lt;&lt; word把word（而不是文件word）和後面的换行作为输入提供给cmd。 cmd &lt;&gt; file以读写模式把文件file重定向到输入，文件file不会被破坏。仅当应用程序利用了这一特性时，它才是有意义的。 cmd &gt;| file功能同&gt;，但即便在设置了noclobber时也会复盖file文件，注意用的是|而非一些书中说的!，目前仅在csh中仍沿用&gt;!实现这一功能。 : &gt; filename 把文件”filename”截断为0长度.# 如果文件不存在, 那么就创建一个0长度的文件(与’touch’的效果相同). cmd &gt;&amp;n 把输出送到文件描述符n cmd m&gt;&amp;n 把输出 到文件符m的信息重定向到文件描述符n cmd &gt;&amp;- 关闭标准输出 cmd &lt;&amp;n 输入来自文件描述符n cmd m&lt;&amp;n m来自文件描述各个n cmd &lt;&amp;- 关闭标准输入 cmd &lt;&amp;n- 移动输入文件描述符n而非复制它。（需要解释） cmd &gt;&amp;n- 移动输出文件描述符 n而非复制它。（需要解释）注意： &gt;&amp;实际上复制了文件描述符，这使得cmd &gt; file 2&gt;&amp;1与cmd 2&gt;&amp;1 &gt;file的效果不一样。 for循环1234for var in 集合do cmd1...done while循环1234while [ 条件 ]do echo &quot;hello&quot;done if条件语句1234567if [ 条件 ]; then cmd1elif [ 条件 ]; then cmd2else cmd3fi case语句1234567891011121314151617case 值 in 模式1) command1 command2 command3 ;; 模式2） command1 command2 command3 ;; *) command1 command2 command3 ;;esac","link":"/2019/03/22/22c744900f73.html"},{"title":"Linux中的运行级别以及修改","text":"什么是运行级别0： 关机1： 单用户2： 无网络的多用户3： 命令行模式4： 未用5： GUI（图形桌面 模式）6 ： 重启一般默认是5，也就是图形模式。在这里作为一个服务器，不怎么需要图形界面，通过ssh来连接，然后做一些服务器的部署应该是足够了。所以需要将默认的5改成3即可。 如何切换运行级别使用init 数字这个命令来切换运行级别。比如说要切换成GUI，可以输入命令init 5。注意，这个只是暂时的修改运行级别，当重启后，将恢复成默认的运行级别。 如何修改默认运行级别找到/etc/inittab，打开后，发现如下注释。也就是说，修改默认的运行级别的方式可以通过如下的命令进行systemctl set-default TARGET.target，在这里需要将虚拟机中的CentOS系统的默认运行级别改成3，也就是multi-user.target，然后重启。 12345678910111213141516# inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses 'targets' instead of runlevels. By default, there are two main targets:## multi-user.target: analogous to runlevel 3# graphical.target: analogous to runlevel 5## To view current default target, run:# systemctl get-default## To set a default target, run:# systemctl set-default TARGET.target","link":"/2018/08/30/44063bc2d2d6.html"},{"title":"Linux撤销挂载home分区后保数据不丢失","text":"WARNINGS: 这个操作，在一定程度上可行，毕竟我已经成功做到了。但是这个操作有一定的风险，请慎重！没有图，因为过去的时间比较久了，但大体流程是正确的。 问题引入Linux磁盘分区大致如下表所示，因为当前分区A的容量大于（/的实际容量 + /home的实际容量），所以想把/home挂载的分区B取消，空闲出分区B的容量挪作他用，然后让/home使用/的容量，并且保证home分区数据不丢失。 挂载点 分区 / 分区A /home 分区B 解决过程如果你要按照我的操作去做，请确保你了解你的每一步操作会产生什么效果！ 最重要的部分：使用rsync备份好home分区的数据到某个不会丢失的地方。使用这个命令时，注意权限，权限在这里如果不恰当的话，会引发不太必要的问题。 接着，在/etc/fstab文件里面注释掉/home的挂载信息，保存。这里使用注释，是为了给自己后悔药吃。此时，如果重启，一定是登录不进去桌面的。重启之后，默认从/分区找家目录，找不到，所以会在登录器里面，输入密码后，进入不了系统界面。 重启。正如预期，进入了桌面。这个时候我们使用tty1-5，打开类似于黑窗口的界面，进行登录，然后在home分区下，创建属于我们的目录，注意权限。 再次使用rsync，将备份的数据，还原到home分区下。 最后，切换到登录器，输入密码，成功进入，并且数据未丢失。并且分区B可以挪作他用了。 后记这个操作，在一定程度上可行，毕竟我已经成功做到了。但是这个操作有一定的风险，请慎重!没有图，因为过去的时间比较久了，但大体流程是正确的。 参考：https://www.cnblogs.com/saszhuqing/p/8716644.html","link":"/2019/01/28/47ee8df3706c.html"},{"title":"Linux日常使用之软件安装失败的处理方式","text":"从古董系统Ubuntu12.04一路升级到较新的16.04，发现有些软件，如samba，不能用了。用一般的处理方式如apt -f install也没办法处理。一直放着，今天还是觉得samba有一些方便，便花了一点时间去看这个问题。 错误详情➜ ~ sudo apt install samba Reading package lists… DoneBuilding dependency treeReading state information… DoneSome packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: samba : Depends: python-samba but it is not going to be installed Depends: samba-common (= 2:4.3.8+dfsg-0ubuntu1) but 2:4.3.11+dfsg-0ubuntu0.14.04.11 is to be installed Depends: samba-common-bin (= 2:4.3.8+dfsg-0ubuntu1) but it is not going to be installed Depends: libwbclient0 (= 2:4.3.8+dfsg-0ubuntu1) but 2:4.3.11+dfsg-0ubuntu0.14.04.11 is to be installed Depends: samba-libs (= 2:4.3.8+dfsg-0ubuntu1) but it is not going to be installed Recommends: attr Recommends: samba-dsdb-modules but it is not going to be installed Recommends: samba-vfs-modules but it is not going to be installedE: Unable to correct problems, you have held broken packages. 原因我觉得大致如下：提示是packages have unmet dependencies，再仔细看一下下面的描述，这种问题其实就是软件所依赖的包的版本不对，基本一可以通过sudo apt -f install解决，但是该包被以为是最新的，无法被替换掉。 解决办法先把这些依赖包全部卸载掉，然后再安装回来。 过程如下： ➜ ~ sudo apt install python-samba Reading package lists… DoneBuilding dependency treeReading state information… DoneSome packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: python-samba : Depends: samba-libs (= 2:4.3.8+dfsg-0ubuntu1) but it is not going to be installedE: Unable to correct problems, you have held broken packages. ➜ ~ sudo apt install samba-libs Reading package lists… DoneBuilding dependency treeReading state information… DoneSome packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: samba-libs : Depends: libwbclient0 (= 2:4.3.8+dfsg-0ubuntu1) but 2:4.3.11+dfsg-0ubuntu0.14.04.11 is to be installedE: Unable to correct problems, you have held broken packages. ➜ ~ sudo apt install libwbclient0 Reading package lists… DoneBuilding dependency treeReading state information… Donelibwbclient0 is already the newest version (2:4.3.11+dfsg-0ubuntu0.14.04.11).0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. ➜ ~ sudo apt remove libwbclient0:amd64 Reading package lists… DoneBuilding dependency treeReading state information… DoneThe following packages will be REMOVED: libwbclient00 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.After this operation, 209 kB disk space will be freed.Do you want to continue? [Y/n](Reading database … 318410 files and directories currently installed.)Removing libwbclient0:amd64 (2:4.3.11+dfsg-0ubuntu0.14.04.11) …Processing triggers for libc-bin (2.23-0ubuntu3) … ➜ ~ sudo apt install libwbclient0 Reading package lists… DoneBuilding dependency treeReading state information… DoneThe following NEW packages will be installed: libwbclient00 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.Need to get 30.4 kB of archives.After this operation, 186 kB of additional disk space will be used.Get:1 http://mirrors.aliyun.com/ubuntu xenial/main amd64 libwbclient0 amd64 2:4.3.8+dfsg-0ubuntu1 [30.4 kB]Fetched 30.4 kB in 0s (146 kB/s)Selecting previously unselected package libwbclient0:amd64.(Reading database … 318404 files and directories currently installed.)Preparing to unpack …/libwbclient0_2%3a4.3.8+dfsg-0ubuntu1_amd64.deb …Unpacking libwbclient0:amd64 (2:4.3.8+dfsg-0ubuntu1) …Processing triggers for libc-bin (2.23-0ubuntu3) …Setting up libwbclient0:amd64 (2:4.3.8+dfsg-0ubuntu1) …Processing triggers for libc-bin (2.23-0ubuntu3) … ➜ ~ sudo apt install libwbclient0 Reading package lists… DoneBuilding dependency treeReading state information… Donelibwbclient0 is already the newest version (2:4.3.8+dfsg-0ubuntu1).0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. 其它的依赖包按照此方法去一一操作，操作完成了之后便可以安装好之前想安装的软件了。","link":"/2018/02/03/f8169c1576cb.html"},{"title":"Linux修改hostname和用户名","text":"Reference SSH允许root远程登录 Linux：修改Hostname Linux 下如何修改用户名（同时修改用户组名和家目录）","link":"/2020/08/18/763356a713b2.html"},{"title":"Manjaro的安装以及使用记录","text":"只想要一个linux环境、不用太折腾、软件安装方便的一个版本。起初只是对它的名声吸引，然后再使用了一段时间后，确确实实被它所折服了。其实主要就是在软件的安装、数量上面，比Ubuntu之类要强得多。 笔记本型号小米Pro 15.6” i7 Manjaro初识依次尝试了KDE、XFCE、DEEPIIN，最终还是皈依在deepin版的manjaro下。总体的印象有3个：0、刻录到U盘当做启动盘时的问题。根据官网推荐，选择使用Rufus刻录。在使用Rufus刻录过程中，选择以DD镜像模式写入。当时我以第一种方式刻录，从U盘无法启动Manjaro。1、安装的过程中，需要手动挂在esp分区为/boot/efi，如果不主动挂载，安装会有问题。2、Xfce版安装到90%左右时，会卡死，表现为鼠标不动、键盘无输入，同样需要长按电源键关机。解决办法为在进入U盘启动的初始界面，drivers选项选择non-free。3、KDE版在锁屏界面选择关机，系统会卡死，需要长按电源键才能关机。 安装软件&amp;设置源设置中科大源说明链接：http://mirrors.ustc.edu.cn/help/manjaro.html 12sudo pacman-mirrors -i -c China -m ranksudo pacman -Syy 安装yaourt一个软件安装工具、与mac中的homebrew有点类似。sudo pacman -S yaourt 更新源的配置： sudo nano /etc/pacman.conf。添加 CN 仓库（这里使用了 USTC 镜像），在上述文件末尾新增以下容： 123[archlinuxcn]SigLevel = Optional TrustedOnlyServer = https://mirrors.ustc.edu.cn/archlinuxcn/$arch 然后保存，同步 123456# 同步sudo pacman -Syy # 新增 CN 仓库的 Keyringsudo pacman -S archlinuxcn-keyring`# 更新sudo pacman -Syu 为什么？: 导入 GPG Key，否则通过 Yaourt 安装软件会经常出错。例子 : 如果不导入Key，yaourt安装lantern时会报错 安装google-chromeyaourt -S google-chrome 安装SwitchyOmegahttps://github.com/FelisCatus/SwitchyOmega/releaseshttps://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt shadowsockssudo pacman -S shadowsocks-qt5 vimsudo pacman -S vim CodeBlockssudo pacman -S codeblocks Java配置环境变量123456# sudo vim /etc/profile #编辑文件# 在文件末尾处追加下列几行export JAVA_HOME=/home/asahi/devtools/jdk1.8.0_191export JRE_HOME=${JAVA_HOME}/jreexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/libexport PATH=${JAVA_HOME}/bin:$PATH zsh12sudo pacman -S zshsh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 搜狗输入法1234yaourt -S fcitxyaourt -S fcitx-im # 安装fcitx 选择全部安装yaourt -S fcitx-configtool # fcitx 配置界面yaourt -S fcitx-sogoupinyin # 安装sogoupinyin 上述安装完成后，在.xprofile中添加如下脚本，然后重启，即可在部分应用中使用搜狗输入法。 12345sudo vim ~/.xprofile # 打开编辑.xprofile文件# 在文件中加入以下两行代码export GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=&quot;@im=fcitx&quot; JetBrains全家桶官网主页：http://www.jetbrains.com/products.html破解教程：http://idea.lanyus.com/如果在安装过程中，没有看见生成Desktop Entry的选项，那么可以在Tools中找到，如下：也可以在打开IDE的最开始地方，选择Configure，如下：再来一张全家福： 数据库相关工具1234# Redis缓存查看IDEyaourt -S redis-desktop-manager# MySQL自带的IDEyaourt -S mysql-workbench 如何让linux全局能够访问Google？网上的解法很多，我感觉我找到了一种更加快速的办法： lantern 在Android手机中打开Shadowsocks，设置代理，然后使用USB共享网络给linux，此时整个linux都具备了自由访问的能力，这在安装软件，需要访问一些被Qiang的网站时，能发挥出意想不到的作用。值得尝试。 参考：https://servernotfound.net/archlinux_note_2.htmlhttps://linuxtoy.org/archives/archlinux-pkgbuild-aur-and-abs.htmlhttp://www.cnblogs.com/bluestorm/p/5929478.html","link":"/2019/01/06/e279c499d1b3.html"},{"title":"Maven 使用笔记","text":"安装下载 maven 包，然后 1234curl -LO https://downloads.apache.org/maven/maven-3/3.8.1/binaries/apache-maven-3.8.1-bin.zipunzip apache-maven-3.8.1-bin.zipmv apache-maven-3.8.1 /usr/local/Cellar/mavenln -s /usr/local/Cellar/maven/bin/mvn /usr/local/bin/mvn","link":"/2021/07/23/996c3d13e540.html"},{"title":"Microsoft Visual Studio 2017配置OpenCV开发环境简要操作","text":"参考博客：https://blog.csdn.net/sinat_36264666/article/details/73135823 有机会接触这个是因为公司的某个项目，有时候需要使用到OpenCV处理图片，在JNI层操作有诸多不便，还不如使用Visual Studio来进行相应操作的验证，得到的结果会更快更有说服力。Visual Studio是传说中的神器，说真的菜单还真看着有点不知道说什么，虽然都是汉字。配置这种东西，博客太多了，但是有一些是2015的或者更低，当然也有2017的。这里就做个简要的记录，多余的都删除。 下载并安装Visual Studio 2017下载安装器后，选择安装。如果是第一次安装，可以先勾上这两个选项（从网上看到的操作，并且我之前没勾全了，配置好了也跑不起来）；如果是已经安装了，并且上图中的两个勾没选上的话，那么可以按照下述步骤去勾上并进行组件的安装。控制面板-&gt;程序与应用-&gt;Visual Studio 2017-&gt;右键-&gt;修改 下载并安装OpenCV3.4.1说是安装，其实是解压到某个地方，先记着这个地方 配置OpenCV环境变量添加到环境变量后如下 新建项目并配置项目我选了这“Windows控制台应用程序”建立好了之后，配置项目中OpenCV相关信息。 打开属性管理窗口。操作路径为视图-&gt;其他窗口-&gt;属性管理窗口。 在此配置Debug X64,操作右键-&gt;属性。 配置VC++目录 包含目录 库目录 4.配置链接器-&gt;输入这个名字中的数字表示OpenCV的版本号，此处我的版本号为3.4.1，后面的d表示为Debug。 测试运行1234567891011// ConsoleApplication3.cpp: 定义控制台应用程序的入口点。#include &quot;stdafx.h&quot;#include &lt;opencv2/opencv.hpp&gt;int main(){ cv::Mat img = cv::imread(&quot;C:\\\\Users\\\\xxxxxx\\\\Desktop\\\\1.png&quot;); cv::imshow(&quot;测试&quot;, img); cv::waitKey(0); return 0;} 前面配置的是Debug X64的，所以现在选择这个，运行后如下：","link":"/2018/05/20/21d022a35c60.html"},{"title":"MongoDB原生脚本的CURD--官方文档阅读笔记","text":"安装&amp;登录0、Windows下使用从MongoDB官网下载MSI安装文件，感觉比zip的安装包使用便捷。Ubuntu Linux下使用sudo apt install mongodb-server安装、其配置文件路径为/etc/mongodb.conf、可以通过在其中配置数据库路径。Mac下使用brew install mongodb，其配置信息可参考如下：1、mongod --bind_all 默认只能本机访问MongoDB、使用此选项可以让别的机器通过网络访问2、如果不能访问，检查端口是否开放，默认为27017。AWS的EC2需要在入站规则中加入该端口才会生效。3、使用mongo进入数据库后、创建用户与密码。 Mongo Shellinsert12345678910db.collection.insert( &lt;document or array of documents&gt;, { writeConcern: &lt;document&gt;, // ordered: &lt;boolean&gt; // 按顺序插入 })db.inventory.insertOne( { item: &quot;canvas&quot;, qty: 100, tags: [&quot;cotton&quot;], size: { h: 28, w: 35.5, uom: &quot;cm&quot; } }) saveUpdates an existing document or inserts a new document, depending on its document parameter. query一般查询： 12db.inventory.find( {} )db.inventory.find( { status: &quot;D&quot; } ) 使用查询操作符查询：更多查询操作符：https://docs.mongodb.com/manual/reference/operator/query/ 12// 格式：{ &lt;field1&gt;: { &lt;operator1&gt;: &lt;value1&gt; }, ... }db.inventory.find( { status: { $in: [ &quot;A&quot;, &quot;D&quot; ] } } ) 使用AND 12// status==‘A’ &amp;&amp; qty &lt; 30db.inventory.find( { status: &quot;A&quot;, qty: { $lt: 30 } } ) 使用OR 12345678// status==‘A’ || qty &lt; 30db.inventory.find( { $or: [ { status: &quot;A&quot; }, { qty: { $lt: 30 } } ] } )// status=='A' &amp;&amp; (qty &lt; 30 || item like 'p%')db.inventory.find( { status: &quot;A&quot;, $or: [ { qty: { $lt: 30 } }, { item: /^p/ } ]} ) 正则表达式详细可参考：https://docs.mongodb.com/manual/reference/operator/query/regex/ 123456789101112/* 格式：{ &lt;field&gt;: { $regex: /pattern/, $options: '&lt;options&gt;' } }{ &lt;field&gt;: { $regex: 'pattern', $options: '&lt;options&gt;' } }{ &lt;field&gt;: { $regex: /pattern/&lt;options&gt; } }-----{ &lt;field&gt;: /pattern/&lt;options&gt; }*/----------------------------------------------------------// 查询title以h开头的文档，options里面有i说明大小写不敏感db.bizQuestion.find( { title : {$regex : /^h/, $options:'i'}} ) 两种格式的使用场景存在差异，具体可参考上述链接： 1{ name: { $in: [ /^acme/i, /^ack/ ] } } // 这里只能使用第二种格式 如果文档中的某个字段的值是文档 1234567891011// 插入--注意size的结构db.inventory.insertMany( [ { item: &quot;journal&quot;, qty: 25, size: { h: 14, w: 21, uom: &quot;cm&quot; }, status: &quot;A&quot; }, { item: &quot;notebook&quot;, qty: 50, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, status: &quot;A&quot; }, { item: &quot;paper&quot;, qty: 100, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, status: &quot;D&quot; }, { item: &quot;planner&quot;, qty: 75, size: { h: 22.85, w: 30, uom: &quot;cm&quot; }, status: &quot;D&quot; }, { item: &quot;postcard&quot;, qty: 45, size: { h: 10, w: 15.25, uom: &quot;cm&quot; }, status: &quot;A&quot; }]);// 接着上面的进行查询。db.inventory.find( { size: { h: 14, w: 21, uom: &quot;cm&quot; } } ) // OKdb.inventory.find( { size: { w: 21, h: 14, uom: &quot;cm&quot; } } ) // X, 注意顺序，这里匹配不到任何东西 执行效果如下：如果只以size中的某一个字段为查询域 123db.inventory.find( { &quot;size.uom&quot;: &quot;in&quot; } )db.inventory.find( { &quot;size.h&quot;: { $lt: 15 } } )db.inventory.find( { &quot;size.h&quot;: { $lt: 15 }, &quot;size.uom&quot;: &quot;in&quot;, status: &quot;D&quot; } ) 其中的字段还可以为一个数组，数组中的数据可以是一个简单的类型，如整数、字符串等，也可以还是一个文档。对于这些情况，其查询方式存在或多或少的差异，可以在需要的时候参考官方文档。 如何返回自己想要的字段前面查询得到的结果都是全部的字段，如果不需要返回所有的字段，可以通过设置projection来达到目的，projection的解释： A document given to a query that specifies which fields MongoDB returns in the result set. 其中还包括字段为数组以及数组中的字段为文档的多种情况。 123456789101112131415161718// 初始数据结构db.inventory.insertMany( [ { item: &quot;journal&quot;, status: &quot;A&quot;, size: { h: 14, w: 21, uom: &quot;cm&quot; }, instock: [ { warehouse: &quot;A&quot;, qty: 5 } ] }, { item: &quot;notebook&quot;, status: &quot;A&quot;, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, instock: [ { warehouse: &quot;C&quot;, qty: 5 } ] }, { item: &quot;paper&quot;, status: &quot;D&quot;, size: { h: 8.5, w: 11, uom: &quot;in&quot; }, instock: [ { warehouse: &quot;A&quot;, qty: 60 } ] }, { item: &quot;planner&quot;, status: &quot;D&quot;, size: { h: 22.85, w: 30, uom: &quot;cm&quot; }, instock: [ { warehouse: &quot;A&quot;, qty: 40 } ] }, { item: &quot;postcard&quot;, status: &quot;A&quot;, size: { h: 10, w: 15.25, uom: &quot;cm&quot; }, instock: [ { warehouse: &quot;B&quot;, qty: 15 }, { warehouse: &quot;C&quot;, qty: 35 } ] }]);// 返回结果显示item,status，不显示_iddb.inventory.find( { status: &quot;A&quot; }, { item: 1, status: 1, _id: 0 } )// 如果字段的值也是一个文档db.inventory.find( { status: &quot;A&quot; }, { item: 1, status: 1, &quot;size.uom&quot;: 1 })// 字段为数组，数组的类型是文档db.inventory.find( { status: &quot;A&quot; }, { item: 1, status: 1, &quot;instock.qty&quot;: 1 } ) update1234567891011121314151617181920212223242526272829303132333435363738394041424344db.books.update( { _id: 1 }, { $inc: { stock: 5 }, $set: { item: &quot;ABC123&quot;, &quot;info.publisher&quot;: &quot;2222&quot;, tags: [ &quot;software&quot; ], &quot;ratings.1&quot;: { by: &quot;xyz&quot;, rating: 3 } } })-------------------------------------------------------------------try { db.restaurant.updateMany( { violations: { $gt: 4 } }, { $set: { &quot;Review&quot; : true } } );} catch (e) { print(e);}-------------------------------------------------------------------// The following operation updates a single document where name: &quot;Central Perk Cafe&quot; with the violations field:try { db.restaurant.updateOne( { &quot;name&quot; : &quot;Central Perk Cafe&quot; }, { $set: { &quot;violations&quot; : 3 } } );} catch (e) { print(e);}-------------------------------------------------------------------// The following operation attempts to update the document with name : &quot;Pizza Rat's Pizzaria&quot;, while upsert: true :// 对于这个upsert：true这个参数，update--insert。如果为true并且前面的query没有匹配到，则会进行插入，否则更新。try { db.restaurant.updateOne( { &quot;name&quot; : &quot;Pizza Rat's Pizzaria&quot; }, { $set: {&quot;_id&quot; : 4, &quot;violations&quot; : 7, &quot;borough&quot; : &quot;Manhattan&quot; } }, { upsert: true } );} catch (e) { print(e);}","link":"/2018/11/15/f3827fe969b1.html"},{"title":"MTK和Qualcomm刷机备忘录","text":"这两个处理器厂商的刷机方式有一些不一样，然而很久不刷的我还是有些迷。还是总结一下，不要再用错误的方式，来刷机了～ MTK刷机从服务器上面下载target_files-package.zip的编译包，然后解压；也可以选择使用自己编译源代码出来得到的rom。烧录的时候：1、Download agent选择路径（默认一般已经选好）：MTK_driver_and_flashtool\\SP_Flash_Tool_exe_Windows_v5.1612.00.000 \\MTK_AllInOne_DA.bin。2、Scatter-loading选择编译出来的android目录中的scatter文件，路径如下：\\out\\target\\product\\*****\\*****_Android_scatter.txt选择完成，之后按download开始，这个时候，将手机关机，插入USB即可开始烧录，等待烧录完成，然后重启(扣电池也行)手机，即可。 Qualcomm刷机高通用QFILE，不论在edl模式还是在开机状态都可以。第一栏选择好相应的.mbn文件后，第二栏的配置文件一般做如下选择： 第一次选择： rawprogram_unsparse.xml || rawprogram_unsparse_without_QCN.xml rawprogram2.xml 第二次选择：两个都选上。","link":"/2018/01/21/50280c094198.html"},{"title":"Maven构建项目","text":"Maven常见的打包方式有： jarjar工程，很显然就是pom工程的子工程，由pom工程来管理。 warwar工程是一个web工程，是可以直接放到tomcat下运行的工程。 pompom工程一般都是父工程，管理jar包的版本、maven插件的版本、统一的依赖管理，它是一个聚合工程。其实说白了它只有一个pom.xml文件，一般是作为父工程出现的，只是定义了一些依赖、插件、还有一些版本号等等。 使用maven的好处 依赖管理、jar包、工程之间的依赖。Maven定义了软件开发的整套流程体系，并进行了封装，开发人员只需要指定项目的构建流程，无需针对每个流程编写自己的构建脚本。 项目构建。实现项目的一步构建。除了项目构建，Maven最核心的功能是软件包的依赖管理，能够自动分析项目所需要的依赖软件包，并到Maven中心仓库去下载。管理Jar包的依赖。管理工程之间的依赖关系，即可使用Maven依赖其他的工程。 工程聚合、继承、依赖。 构建父工程父工程应该是一个pom工程。在父工程中定义依赖的jar包的版本信息。Maven插件的版本。即其它项目通过依赖父工程项目，来统一版本号及其他信息。 聚合该项目中可以聚合几个其它的项目，然后打包成一个war包。","link":"/2018/08/03/ad3983496d35.html"},{"title":"MyEclipse中Maven的配置与使用","text":"Maven可以帮你搞定一些项目上的包依赖，与Android Studio中的Gradle有点类似，当然也有很大的不一样。目前认识还是有点粗浅，期待后续的深入。 配置虽然MyEclipse上面也集成了Maven，但是版本比官网上的低一些。从官网上面下载最新的软件包，找个合适的位置解压，然后在环境变量中加入所解压目录下的bin目录。 具体的配置方式，视不同的Shell，修改不同的配置文件。再此处为zsh，修改了~/.zshrc的内容如下：检查配置是否成功还需要修改conf目录下的setting.xml文件的localRepository的路径。从注释我们可以看到，如果不设置的话，默认是在~/.m2/repository目录下。该目录的主要功能就是存放Maven从仓库里面下下来的包。 接下来在MyEclipse中集成我们下载后解压的Maven。打开Preference，依次选择Maven中的Installations与User Settings，添加Maven的路径以及配置文件后如下： 到此基本配置完成。 创建Maven项目看网上的博客，创建Maven项目的方式有很多，尚不清楚它们会不会有什么差异。不过能达到使用Maven的功能就没差了吧。 第一次创建Maven项目时，它从服务器上面下载jar包会花费很长的时间，请耐心等待 方法一：创建JavaWeb项目同时添加Maven支持感觉这种方法流程较简单。创建流程如下：New一个Web Project，然后勾上Add Maven Support选项重复选择下一步，直到出现Maven的相关设置。这里被建议选择Standard Maven JEE project structure。其实就是项目的目录结构不一样。之后，选择到Finish即可完成创建。创建后如下，但是请注意啊，这已经是第二次创建了。所以再重复一下：第一次创建Maven项目时，它从服务器上面下载jar包会花费很长的时间，请耐心等待 方法二：创建Maven Web项目选择创建一个Maven Project选择创建后续按实际需求填写即可 使用在该项目的pom.xml中添加依赖信息，然后点击Build Project，Maven就会把相关的依赖信息都找齐到本项目中。","link":"/2018/04/15/f50fde222d04.html"},{"title":"MyBatis中的#与$符号的区别","text":"Mybatis中有很多可以学习的地方，#和$是两种常见的值替换方式，今天站在源码的角度去分析其解析过程。 关键源码因为这段代码功能单一，对后续的流程影响不大，搞清楚这段代码的作用，基本上#{}和${}的区别，在源代码上已经是清楚了。了解了这段代码之后，再进行后续的解析流程，就不会陷入这段代码的逻辑中，将整个视野投入到流程当中。 位置：GenericTokenParser.java –&gt; parse() 12345678910private final String openToken;private final String closeToken;// 当匹配到#{}或${}后，对其中的文本进行的操作。private final TokenHandler handler;public GenericTokenParser(String openToken, String closeToken, TokenHandler handler) { this.openToken = openToken; this.closeToken = closeToken; this.handler = handler;} 首先它有3个成员变量，可以理解成：当匹配到已openToken开头，closeToken结尾的字符串后，对其中的字符串执行handler.handleToken()方法。 这个handler就是一个典型的策略模式。它是一个只含有``函数的接口： 123public interface TokenHandler { String handleToken(String content);} 也就是说#{}和${}的处理逻辑都是封装到handleToken中。 寻找是否含有#{}和${}的逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class GenericTokenParser { public String parse(String text) { if (text == null || text.isEmpty()) { return &quot;&quot;; } // search open token int start = text.indexOf(openToken, 0); if (start == -1) { return text; } char[] src = text.toCharArray(); int offset = 0; final StringBuilder builder = new StringBuilder(); StringBuilder expression = null; while (start &gt; -1) { if (start &gt; 0 &amp;&amp; src[start - 1] == '\\\\') { // this open token is escaped. remove the backslash and continue. builder.append(src, offset, start - offset - 1).append(openToken); offset = start + openToken.length(); } else { // found open token. let's search close token. if (expression == null) { expression = new StringBuilder(); } else { expression.setLength(0); } builder.append(src, offset, start - offset); offset = start + openToken.length(); int end = text.indexOf(closeToken, offset); while (end &gt; -1) { if (end &gt; offset &amp;&amp; src[end - 1] == '\\\\') { // this close token is escaped. remove the backslash and continue. expression.append(src, offset, end - offset - 1).append(closeToken); offset = end + closeToken.length(); end = text.indexOf(closeToken, offset); } else { expression.append(src, offset, end - offset); offset = end + closeToken.length(); break; } } if (end == -1) { // close token was not found. builder.append(src, start, src.length - start); offset = src.length; } else { builder.append(handler.handleToken(expression.toString())); offset = end + closeToken.length(); } } start = text.indexOf(openToken, offset); } if (offset &lt; src.length) { builder.append(src, offset, src.length - offset); } return builder.toString(); }} 用到GenericTokenParser的地方如下图所示： 仔细看一看上面的图片，会有一个疑问，那就是为什么#{}和${}分别有2种不同的解析方法？这个可以在后面的分析中得出答案。这里直接给出我们平常所认为的那种处理方式的源代码，即#变成？，然后$直接变成相应的值，如下： #{}的处理方式 位置：SqlSourceBuidler.java –&gt; ParameterMappingTokenHandler 12345@Overridepublic String handleToken(String content) { parameterMappings.add(buildParameterMapping(content)); return &quot;?&quot;;} ${}的处理方式 位置：PropertyParser.java –&gt; VariableTokenHandler 123456789101112131415161718192021@Overridepublic String handleToken(String content) { if (variables != null) { String key = content; if (enableDefaultValue) { final int separatorIndex = content.indexOf(defaultValueSeparator); String defaultValue = null; if (separatorIndex &gt;= 0) { key = content.substring(0, separatorIndex); defaultValue = content.substring(separatorIndex + defaultValueSeparator.length()); } if (defaultValue != null) { return variables.getProperty(key, defaultValue); } } if (variables.containsKey(key)) { return variables.getProperty(key); } } return &quot;${&quot; + content + &quot;}&quot;;} 从上面的代码来看，基本上的问题已经解决了。下面是MyBatis对XML中SQL语句的解析流程的分析。 示例代码12345678public static void main(String[] args) throws IOException { SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;)); SqlSession session = sqlSessionFactory.openSession(); BizDriverMapper mapper = session.getMapper(BizDriverMapper.class); List&lt;BizDriver&gt; list = mapper.getByNameOrNumber(&quot;hello&quot;); System.out.println(list.size());} 构建SqlSessionFactory阶段SqlSessionFactoryBuilder.java –&gt; build(InputStream, String, Properties) 1234567public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) { try { XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); } ...} XMLConfigBuilder.java –&gt; parse() 12345678public Configuration parse() { if (parsed) { throw new BuilderException(&quot;Each XMLConfigBuilder can only be used once.&quot;); } parsed = true; parseConfiguration(parser.evalNode(&quot;/configuration&quot;)); return configuration;} XMLConfigBuilder.java –&gt; parseConfiguration() 123456789101112131415161718192021private void parseConfiguration(XNode root) { try { //issue #117 read properties first propertiesElement(root.evalNode(&quot;properties&quot;)); Properties settings = settingsAsProperties(root.evalNode(&quot;settings&quot;)); loadCustomVfs(settings); typeAliasesElement(root.evalNode(&quot;typeAliases&quot;)); pluginElement(root.evalNode(&quot;plugins&quot;)); objectFactoryElement(root.evalNode(&quot;objectFactory&quot;)); objectWrapperFactoryElement(root.evalNode(&quot;objectWrapperFactory&quot;)); reflectorFactoryElement(root.evalNode(&quot;reflectorFactory&quot;)); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode(&quot;environments&quot;)); databaseIdProviderElement(root.evalNode(&quot;databaseIdProvider&quot;)); typeHandlerElement(root.evalNode(&quot;typeHandlers&quot;)); mapperElement(root.evalNode(&quot;mappers&quot;)); } catch (Exception e) { throw new BuilderException(&quot;Error parsing SQL Mapper Configuration. Cause: &quot; + e, e); }} XMLConfigBuilder.java –&gt; mapperElement() 123456789101112131415161718192021222324252627282930private void mapperElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { if (&quot;package&quot;.equals(child.getName())) { String mapperPackage = child.getStringAttribute(&quot;name&quot;); configuration.addMappers(mapperPackage); } else { String resource = child.getStringAttribute(&quot;resource&quot;); String url = child.getStringAttribute(&quot;url&quot;); String mapperClass = child.getStringAttribute(&quot;class&quot;); if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(resource); InputStream inputStream = Resources.getResourceAsStream(resource); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(url); InputStream inputStream = Resources.getUrlAsStream(url); XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) { Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); } else { throw new BuilderException(&quot;A mapper element may only specify a url, resource or class, but not more than one.&quot;); } } } }} XMLMapperBuilder.java –&gt; parse() 1234567891011public void parse() { if (!configuration.isResourceLoaded(resource)) { configurationElement(parser.evalNode(&quot;/mapper&quot;)); configuration.addLoadedResource(resource); bindMapperForNamespace(); } parsePendingResultMaps(); parsePendingCacheRefs(); parsePendingStatements();} XMLMapperBuilder.java –&gt; configurationElement() 123456789101112131415161718private void configurationElement(XNode context) { try { String namespace = context.getStringAttribute(&quot;namespace&quot;); if (namespace == null || namespace.equals(&quot;&quot;)) { throw new BuilderException(&quot;Mapper's namespace cannot be empty&quot;); } builderAssistant.setCurrentNamespace(namespace); cacheRefElement(context.evalNode(&quot;cache-ref&quot;)); cacheElement(context.evalNode(&quot;cache&quot;)); parameterMapElement(context.evalNodes(&quot;/mapper/parameterMap&quot;)); resultMapElements(context.evalNodes(&quot;/mapper/resultMap&quot;)); sqlElement(context.evalNodes(&quot;/mapper/sql&quot;)); // 处理sql的入口 buildStatementFromContext(context.evalNodes(&quot;select|insert|update|delete&quot;)); } catch (Exception e) { throw new BuilderException(&quot;Error parsing Mapper XML. The XML location is '&quot; + resource + &quot;'. Cause: &quot; + e, e); }} 处理sql的入口 1234567891011121314151617private void buildStatementFromContext(List&lt;XNode&gt; list) { if (configuration.getDatabaseId() != null) { buildStatementFromContext(list, configuration.getDatabaseId()); } buildStatementFromContext(list, null);}private void buildStatementFromContext(List&lt;XNode&gt; list, String requiredDatabaseId) { for (XNode context : list) { final XMLStatementBuilder statementParser = new XMLStatementBuilder(configuration, builderAssistant, context, requiredDatabaseId); try { statementParser.parseStatementNode(); } catch (IncompleteElementException e) { configuration.addIncompleteStatement(statementParser); } }} XMLStatementBuilder.java –&gt; parseStatementNode() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public void parseStatementNode() { String id = context.getStringAttribute(&quot;id&quot;); String databaseId = context.getStringAttribute(&quot;databaseId&quot;); if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) { return; } Integer fetchSize = context.getIntAttribute(&quot;fetchSize&quot;); Integer timeout = context.getIntAttribute(&quot;timeout&quot;); String parameterMap = context.getStringAttribute(&quot;parameterMap&quot;); String parameterType = context.getStringAttribute(&quot;parameterType&quot;); Class&lt;?&gt; parameterTypeClass = resolveClass(parameterType); String resultMap = context.getStringAttribute(&quot;resultMap&quot;); String resultType = context.getStringAttribute(&quot;resultType&quot;); String lang = context.getStringAttribute(&quot;lang&quot;); LanguageDriver langDriver = getLanguageDriver(lang); Class&lt;?&gt; resultTypeClass = resolveClass(resultType); String resultSetType = context.getStringAttribute(&quot;resultSetType&quot;); StatementType statementType = StatementType.valueOf(context.getStringAttribute(&quot;statementType&quot;, StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); String nodeName = context.getNode().getNodeName(); SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = context.getBooleanAttribute(&quot;flushCache&quot;, !isSelect); boolean useCache = context.getBooleanAttribute(&quot;useCache&quot;, isSelect); boolean resultOrdered = context.getBooleanAttribute(&quot;resultOrdered&quot;, false); // Include Fragments before parsing XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: &lt;selectKey&gt; and &lt;include&gt; were parsed and removed) SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(&quot;resultSets&quot;); String keyProperty = context.getStringAttribute(&quot;keyProperty&quot;); String keyColumn = context.getStringAttribute(&quot;keyColumn&quot;); KeyGenerator keyGenerator; String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) { keyGenerator = configuration.getKeyGenerator(keyStatementId); } else { keyGenerator = context.getBooleanAttribute(&quot;useGeneratedKeys&quot;, configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; } builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets);} 其中createSqlSource()的对象langDriver来自XMLLanguageDriver XMLLanguageDriver.java –&gt; createSqlSource() 12345@Overridepublic SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType) { XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); return builder.parseScriptNode();} 关键步骤：XMLScriptBuilder.java –&gt; parseScriptNode() 这里面的每一行代码都可以仔细去看、并理解它的意思 12345678910111213public SqlSource parseScriptNode() { // 判定是否含有${},如果有，isDynamic--&gt;true MixedSqlNode rootSqlNode = parseDynamicTags(context); SqlSource sqlSource = null; if (isDynamic) { // 有${}不做任何处理 sqlSource = new DynamicSqlSource(configuration, rootSqlNode); } else { // 没有${}，把#{}都替换成? sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); } return sqlSource;} 通过上面的分析可知，会有两种情况，即是否为动态。一条语句开始的时候都被包装成MixedSqlNode，然后再通过判断是否为动态，将其封装成DynamicSqlSource和RawSqlSource。这两种的含义是：DynamicSqlSource有${}不做任何处理，RawSqlSource没有${}，把#{}都替换成?。是如何分配的呢？是通过GenericTokenParser来寻找$符号，然后在handler中，将isDynamic标记为true，代码如下： 123456789101112131415161718192021222324252627protected MixedSqlNode parseDynamicTags(XNode node) { List&lt;SqlNode&gt; contents = new ArrayList&lt;SqlNode&gt;(); NodeList children = node.getNode().getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) { XNode child = node.newXNode(children.item(i)); if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) { String data = child.getStringBody(&quot;&quot;); TextSqlNode textSqlNode = new TextSqlNode(data); // isDynamic()中封装了对GenericTokenParser的调用 if (textSqlNode.isDynamic()) { contents.add(textSqlNode); isDynamic = true; } else { contents.add(new StaticTextSqlNode(data)); } } else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) { // issue #628 String nodeName = child.getNode().getNodeName(); XMLScriptBuilder.NodeHandler handler = nodeHandlerMap.get(nodeName); if (handler == null) { throw new BuilderException(&quot;Unknown element &lt;&quot; + nodeName + &quot;&gt; in SQL statement.&quot;); } handler.handleNode(child, contents); isDynamic = true; } } return new MixedSqlNode(contents);} isDynamic()中封装了对GenericTokenParser的调用 123456789101112131415161718192021222324public boolean isDynamic() { DynamicCheckerTokenParser checker = new DynamicCheckerTokenParser(); GenericTokenParser parser = createParser(checker); parser.parse(text); return checker.isDynamic();}private static class DynamicCheckerTokenParser implements TokenHandler { private boolean isDynamic; public DynamicCheckerTokenParser() { // Prevent Synthetic Access } public boolean isDynamic() { return isDynamic; } // 将本对象的变量置为true @Override public String handleToken(String content) { this.isDynamic = true; return null; }} 在处理RawSqlSource时的初始化过程如下： 123456789101112131415161718public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) { this(configuration, getSql(configuration, rootSqlNode), parameterType);}public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) { SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType; // 所有的#{}都将被替换成？ sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;String, Object&gt;());}// SqlSourceBuilder.javapublic SqlSource parse(String originalSql, Class&lt;?&gt; parameterType, Map&lt;String, Object&gt; additionalParameters) { ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); GenericTokenParser parser = new GenericTokenParser(&quot;#{&quot;, &quot;}&quot;, handler); String sql = parser.parse(originalSql); return new StaticSqlSource(configuration, sql, handler.getParameterMappings());} 其中ParameterMappingTokenHandler的handleToken()方法，也就是匹配成功后的回调，实现如下： 12345@Overridepublic String handleToken(String content) { parameterMappings.add(buildParameterMapping(content)); return &quot;?&quot;;} 在处理RawSqlSource时，没有这方面的处理，因此在这里就不贴其代码流程。反思：因为这是初始化阶段，可以理解成开机启动脚本，所以#{}的值是确定的，也就是说要变成？，而${}的值在这个阶段就是未知的，因为还没有具体的SQL语句要生成，直接替换的数据还不确定，所以含有${}的语句，在初始化阶段是先不处理。 参考： https://blog.csdn.net/xu1916659422/article/details/77918175 在此基础上进行了校正，并加入了自己的理解 http://www.mybatis.org/mybatis-3/zh/getting-started.html 进行基本的配置","link":"/2019/05/22/282f6dc55840.html"},{"title":"MyBatis分页插件PageHelper封装以及遇到的bug","text":"PageHelper链接：https://github.com/pagehelper/Mybatis-PageHelper项目中使用到了一个注解，叫做PageAble，这是一个对PageHelper的封装注解。这个注解有一个非常显著的问题就是，不能在这个方法里面执行两次SQL查询（原因将在后续中慢慢分析）。使用方法如下： 1234@PageAblepublic Object method(int page, int size) { 。。。} 注解的内容比较简单，就是定义了两个参数，分别为这两个参数设置了默认的名字、以及默认值。 12345678@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface PageAble { String pageSizeName() default &quot;size&quot;; String pageNumName() default &quot;page&quot;; int pageSize() default 20; int pageNum() default 1;} 然后得到的返回值是一个叫做ResultPageView的类，是对分页情况的一个封装，其中的内容如下： 1234567public class ResultPageView&lt;T&gt; { private Long total = 0l; private Integer current = 1; private Integer pageCount = 0; private List&lt;T&gt; list; // 省略一些构造方法、getter/setter方法} 所以，最重要的问题当然是被@PageAble注解的方法是怎样执行的。显然这里是利用了Spring AOP，在这个方法的前后，加上了自定义的处理方法，如下： 1234567891011121314151617181920private static final String PAGE_ABLE = &quot;@annotation(com.xxxxxo0o0.baseservice.annotation.PageAble)&quot;;@Around(PAGE_ABLE)public Object doAroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { logger.info(&quot;execute method : &quot; + proceedingJoinPoint.getSignature().getName()); try { // 准备开始分页 prepare(proceedingJoinPoint); // 执行被注解的方法 Object obj = proceedingJoinPoint.proceed(); // 装饰被注解方法返回的值 Object result = after(obj); return result; } catch (Throwable throwable) { logger.error(&quot;aspect execute error : &quot;, throwable); throw throwable; } finally { // 先忽略这个finally里面的内容 //PageHelper.clearPage(); }} 在被注解方法执行前的准备活动中，执行了什么操作？代码如下： 12345678910111213141516171819202122232425262728293031private void prepare(ProceedingJoinPoint point) throws Exception { Signature signature = point.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); PageAble pageAble = targetMethod.getAnnotation(PageAble.class); // 获取参数名称 String numName = pageAble.pageNumName(); String sizeName = pageAble.pageSizeName(); // 先获取page和size的默认值 int pageNo = pageAble.pageNum(); int pageSize = pageAble.pageSize(); // 获取参数值列表 Object[] paramValues = point.getArgs(); // 获取参数名列表 String[] paramNames = methodSignature.getParameterNames(); int length = paramNames.length; // 对参数列表进行遍历 for (int i = 0; i &lt; length; i++) { // 如果参数名 == 注解中写入的页数参数名 if (paramNames[i].equals(numName)) { // 从参数值列表中取出值，赋值给页数 pageNo = (Integer) paramValues[i]; // 如果参数名 == 注解中写入的每页数量的参数名 } else if (paramNames[i].equals(sizeName)) { // // 从参数值列表中取出值，赋值为每页尺寸 pageSize = (Integer) paramValues[i]; } } // 调用PageHelper的分页 PageHelper.startPage(pageNo, pageSize);} 先忽略其中的细节，看看被注解方法后面执行的方法做了什么事情，代码如下： 12345678910111213141516171819202122232425262728293031323334private Object after(Object obj) { assert obj instanceof List; PageInfo&lt;?&gt; pageInfo = new PageInfo((List&lt;?&gt;) obj); // 从某个地方获取的分页的信息。（其实是ThreadLocal，先忽略） Page&lt;Object&gt; localPage = PageHelper.getLocalPage(); // 获取分页参数 long total = localPage.getTotal(); int pageNum = localPage.getPageNum(); int pages = localPage.getPages(); List&lt;?&gt; list = (List&lt;?&gt;) obj; try { List&lt;Map&gt; mapList = new ArrayList&lt;&gt;(); for (Object o : list) { // 将一个对象按照原来的字段名转成map HashMap&lt;String, Object&gt; map = MapUtil.convertObj2Map(o); if (o instanceof BaseModel) { BaseModel baseModel = (BaseModel) o; map.put(&quot;id&quot;, baseModel.getId()); } ReflectionUtils .doWithFields(o.getClass(), new InnerFieldCallback(map, o), new InnerFieldFilter()); mapList.add(map); } list = mapList; } catch (Exception e) { logger.error(&quot;convert obj to map occurred error &quot;, e); } pageInfo = new PageInfo((list)); ResultPageView&lt;?&gt; resultPageView; resultPageView = new ResultPageView&lt;&gt;(total, pageNum, pages, pageInfo.getList()); // 清除分页信息 PageHelper.clearPage(); return resultPageView; } PageHelper.start()做了什么一路往父类翻到start()的实现代码如下： 123456789101112131415161718192021/** * 开始分页 * * @param pageNum 页码 * @param pageSize 每页显示数量 * @param count 是否进行count查询 * @param reasonable 分页合理化,null时用默认配置 * @param pageSizeZero true且pageSize=0时返回全部结果，false时分页,null时用默认配置 */public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count, Boolean reasonable, Boolean pageSizeZero) { Page&lt;E&gt; page = new Page&lt;E&gt;(pageNum, pageSize, count); page.setReasonable(reasonable); page.setPageSizeZero(pageSizeZero); //当已经执行过orderBy的时候 Page&lt;E&gt; oldPage = getLocalPage(); if (oldPage != null &amp;&amp; oldPage.isOrderByOnly()) { page.setOrderBy(oldPage.getOrderBy()); } setLocalPage(page); return page;} setLocalPage()与之前的after()中的getLocalPage()是一对get/set方法，他们的目的是从当前线程中获取/设置分页信息。其实现如下（关于ThreadLocal的具体实现，可以去参考其他博客）:既然startPage()只是在线程中塞了一个关于分页的信息，那么真正读取这个分页信息的动作一定是在处理SQL语句的地方，也就是Interceptor。PageHelper的官方使用文档链接：https://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md其中也有一块，是对不安全分页的说明： PageHelper 方法使用了静态的 ThreadLocal 参数，分页参数和线程是绑定的。只要你可以保证在 PageHelper 方法调用后紧跟 MyBatis 查询方法，这就是安全的。因为 PageHelper 在 finally 代码段中自动清除了 ThreadLocal 存储的对象。如果代码在进入 Executor 前发生异常，就会导致线程不可用，这属于人为的 Bug（例如接口方法和 XML 中的不匹配，导致找不到 MappedStatement 时），这种情况由于线程不可用，也不会导致 ThreadLocal 参数被错误的使用。但是如果你写出下面这样的代码，就是不安全的用法： 1234567PageHelper.startPage(1, 10);List&lt;Country&gt; list;if(param1 != null){ list = countryMapper.selectIf(param1);} else { list = new ArrayList&lt;Country&gt;();} 这种情况下由于 param1 存在 null 的情况，就会导致 PageHelper 生产了一个分页参数，但是没有被消费，这个参数就会一直保留在这个线程上。当这个线程再次被使用时，就可能导致不该分页的方法去消费这个分页参数，这就产生了莫名其妙的分页。 因此打开项目中的MyPageInterceptor，它的功能就是充当Mybatis的拦截器，还有一部分自定义的功能，比如说输出sql执行时间、打印sql语句。这个类与PageHelper的拦截器关键的代码基本一致，可以说是copy吧，其中关键的一个地方是intercept()方法中，有一个进行判断，是否需要分页的语句。在查询完毕后，finally方法回执行一次清除动作：这个dialect是一个本地的类，继承自PageHelper这个类，覆盖了其中的afterAll()方法，如下： 12345678910111213public class MyPageHelper extends PageHelper { @Override public void afterAll() { // 获取分页信息 Page&lt;Object&gt; localPage = getLocalPage(); // 调用父类方法，即清除分页信息 super.afterAll(); // 又将分页信息塞回线程中。 // 为什么要这样做？为了让在切面中，加入分页的详细信息。 setLocalPage(localPage); }} 这里的代码执行完成后，不论查询的结果是成功还是失败，分页信息都会存在当前线程中（如果直接调用父类的方法，不自定义这个方法，就能保证执行完一次查询，分页信息不会保存在当前线程中）。问题就出在这里。因为interceptor处理过后，当前线程中还存在分页的信息，并且这个分页的信息需要以来切面的处理方法来完成。 1234567891011121314151617@Overridepublic boolean skip(MappedStatement ms, Object parameterObject, RowBounds rowBounds) { if(ms.getId().endsWith(MSUtils.COUNT)){ throw new RuntimeException(&quot;在系统中发现了多个分页插件，请检查系统配置!&quot;); } Page page = pageParams.getPage(parameterObject, rowBounds); if (page == null) { return true; } else { //设置默认的 count 列 if(StringUtil.isEmpty(page.getCountColumn())){ page.setCountColumn(pageParams.getCountColumn()); } autoDialect.initDelegateDialect(ms); return false; }} 其中获取Page的代码是这样的，说到底还是从当前线程中去取： bug描述与分析执行一个分页查询，让查询故意报错，多执行几次，然后再进行一次普通查询，得到ClassCastException异常。因此，问题已经出来了。 解决因此加上finally后，无论是否报错，那么分页信息都将会被在线程中清除。问题就解决了，所以把涂掉的finally加上清除分页信息的处理，即可解决此问题。 后记批量发送请求的脚本，用来引发bug用：main.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344import requestsimport jsonhost1 = 'localhost:9999'host2 = 'xxxxxxxx'host = host1MAX = 100def vehicle(): parse_response(send_get_req('http://'+host+'/nemt/driver/get')) parse_response(send_get_req('http://'+host+'/nemt/vehicles?page=1&amp;size=20')) parse_response(send_get_req('http://'+host+'/nemt/vehicleType/all')) passdef app_version(): parse_response(send_get_req('http://'+host+'/nemt/driver-apps'))def parse_response(resp): s = json.loads(resp[0].content) if s['code'] == 500: # print() print(&quot;x &quot; + s['message'] + ' --&gt; ' + resp[1]) else: print(&quot;o&quot;) passdef send_get_req(url): # print('url --&gt; '+url) return requests.get(url), urldef main(): i = 0 while i &lt;= MAX: app_version() vehicle() i = i + 1if __name__ == '__main__': main() crack.sh 1234567891011#!/usr/bin/env bash#if [$1 -eq &quot;&quot;]; then# max=1#else# max=$1#fifor i in $(seq 1 $1):docurl 'http://localhost:9999/nemt/orders?page=1&amp;size=20' -H 'Accept-Encoding: gzip, deflate' -H 'Accept-Language: zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5' -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36' -H 'Accept: application/json, text/plain, */*' -H 'userId: 453' -H 'Connection: keep-alive' -H 'token: 48143d9154e7c42face53855826f5ffa' --compressedecho ''done","link":"/2019/03/23/14909257ac39.html"},{"title":"MySQL中插入emoji表情报错的问题解决方案","text":"操作：在内容中输入表情，然后点击查询，报错。其中这个请求的处理代码如下：请求的内容为： 1/feedbacks?page=1&amp;size=20&amp;content=%F0%9F%98%AF%F0%9F%98%A2 日志如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702018-12-21 10:11:49,731 [http-nio-8889-exec-10] INFO c.h.d.a.SystemAdvice - execute method : getFeedbacks2018-12-21 10:11:49,733 [http-nio-8889-exec-10] ERROR c.h.d.a.SystemAdvice - aspect execute error :org.springframework.jdbc.UncategorizedSQLException:### Error querying database. Cause: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'### The error may exist in class path resource [mappers/BizFeedbackMapper.xml]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT count(0) FROM biz_feedback WHERE content LIKE ? AND deleted = ?### Cause: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'; uncategorized SQLException; SQL state [HY000]; error code [1267]; Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'; nested exception is java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like' at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy77.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy101.getSortedResultByConditionList(Unknown Source) at com.haylion.dynamicbus.service.FeedbackService.getFeedbacks(FeedbackService.java:40) at com.haylion.dynamicbus.service.FeedbackService$$FastClassBySpringCGLIB$$298f5809.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.haylion.dynamicbus.advice.SystemAdvice.doAroundAdvice(SystemAdvice.java:44) at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.haylion.dynamicbus.service.FeedbackService$$EnhancerBySpringCGLIB$$ab8db9b2.getFeedbacks(&lt;generated&gt;) at com.haylion.dynamicbus.controller.FeedbackController.getFeedbacks(FeedbackController.java:69) at com.haylion.dynamicbus.controller.FeedbackController$$FastClassBySpringCGLIB$$825dd925.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.validation.beanvalidation.MethodValidationInterceptor.invoke(MethodValidationInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.haylion.dynamicbus.controller.FeedbackController$$EnhancerBySpringCGLIB$$f311ce89.getFeedbacks(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.haylion.dynamicbus.facade.filter.TraceCopyFilter.doFilter(TraceCopyFilter.java:30) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)Caused by: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like' at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:964) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2487) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1197) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:498) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:63) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at com.haylion.dynamicbus.interceptor.sql.MyPageInterceptor.executeAutoCount(MyPageInterceptor.java:211) at com.haylion.dynamicbus.interceptor.sql.MyPageInterceptor.intercept(MyPageInterceptor.java:114) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy154.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at sun.reflect.GeneratedMethodAccessor116.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 90 common frames omitted2018-12-21 10:11:49,734 [http-nio-8889-exec-10] ERROR c.h.d.f.e.ExceptionHandle - Exception for handleorg.springframework.jdbc.UncategorizedSQLException:### Error querying database. Cause: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'### The error may exist in class path resource [mappers/BizFeedbackMapper.xml]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT count(0) FROM biz_feedback WHERE content LIKE ? AND deleted = ?### Cause: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'; uncategorized SQLException; SQL state [HY000]; error code [1267]; Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like'; nested exception is java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like' at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:73) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:446) at com.sun.proxy.$Proxy77.selectList(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:230) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59) at com.sun.proxy.$Proxy101.getSortedResultByConditionList(Unknown Source) at com.haylion.dynamicbus.service.FeedbackService.getFeedbacks(FeedbackService.java:40) at com.haylion.dynamicbus.service.FeedbackService$$FastClassBySpringCGLIB$$298f5809.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:88) at com.haylion.dynamicbus.advice.SystemAdvice.doAroundAdvice(SystemAdvice.java:44) at sun.reflect.GeneratedMethodAccessor348.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:644) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:633) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:175) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.haylion.dynamicbus.service.FeedbackService$$EnhancerBySpringCGLIB$$ab8db9b2.getFeedbacks(&lt;generated&gt;) at com.haylion.dynamicbus.controller.FeedbackController.getFeedbacks(FeedbackController.java:69) at com.haylion.dynamicbus.controller.FeedbackController$$FastClassBySpringCGLIB$$825dd925.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.validation.beanvalidation.MethodValidationInterceptor.invoke(MethodValidationInterceptor.java:119) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.haylion.dynamicbus.controller.FeedbackController$$EnhancerBySpringCGLIB$$f311ce89.getFeedbacks(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:215) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:142) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:800) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1038) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:942) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:998) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:890) at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:875) at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.haylion.dynamicbus.facade.filter.TraceCopyFilter.doFilter(TraceCopyFilter.java:30) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:92) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:93) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:490) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:408) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:770) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1415) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)Caused by: java.sql.SQLException: Illegal mix of collations (utf8mb4_general_ci,IMPLICIT) and (utf8_general_ci,COERCIBLE) for operation 'like' at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:964) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2487) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1858) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1197) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:498) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:63) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:79) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109) at com.haylion.dynamicbus.interceptor.sql.MyPageInterceptor.executeAutoCount(MyPageInterceptor.java:211) at com.haylion.dynamicbus.interceptor.sql.MyPageInterceptor.intercept(MyPageInterceptor.java:114) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61) at com.sun.proxy.$Proxy154.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141) at sun.reflect.GeneratedMethodAccessor116.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:433) ... 90 common frames omitted2018-12-21 10:11:49,734 [http-nio-8889-exec-10] INFO c.h.d.f.a.ResponseAdvice - Trace log is ====&gt; {&quot;url&quot;:&quot;/bus/feedbacks&quot;,&quot;httpMethod&quot;:&quot;GET&quot;,&quot;reqHeader&quot;:{&quot;x-real-ip&quot;:&quot;10.10.0.195&quot;,&quot;referer&quot;:&quot;https://xxxxxxx.cn/&quot;,&quot;accept-language&quot;:&quot;zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6&quot;,&quot;host&quot;:&quot;10.10.0.103&quot;,&quot;connection&quot;:&quot;close&quot;,&quot;x-forwarded-for&quot;:&quot;10.10.0.195&quot;,&quot;userid&quot;:&quot;435&quot;,&quot;accept-encoding&quot;:&quot;gzip, deflate, br&quot;,&quot;accept&quot;:&quot;application/json, text/plain, */*&quot;,&quot;user-agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&quot;,&quot;token&quot;:&quot;67f7df9448dd691c71f57bcb95891bcf&quot;},&quot;reqParams&quot;:&quot;page=1&amp;size=20&amp;content=%F0%9F%98%AF%F0%9F%98%A2&quot;,&quot;requestBody&quot;:&quot;&quot;,&quot;respParams&quot;:&quot;{\\&quot;code\\&quot;:500,\\&quot;message\\&quot;:\\&quot;system is busy\\&quot;,\\&quot;data\\&quot;:{}}&quot;,&quot;startTime&quot;:1545358309731,&quot;spendTime&quot;:3} 从网上搜了一个解决方案，生效了：然后重启MySQL，service mysql restart链接地址为：https://dba.stackexchange.com/questions/89355/unable-to-insert-utf8mb4-characters-in-mysql-5-6 以下关于MySQL中的字符相关的知识来自链接：https://www.cnblogs.com/chyingp/p/mysql-character-set-collation.html 通过分析，得出一下结论：like里面填写的数据的编码格式为utf8，为character_set_server的值，而表里面的编码为utf8mb4，所以他们的值的字符序列是不一样的，因此造成了上述问题的出现。所以解决的办法是将服务器的字符改成utf8mb4，这样like的值就是utf8mb4编码格式，字符序就与表中的字段一致，问题解决。","link":"/2018/12/26/37c3f433edda.html"},{"title":"MySQL中的日期操作","text":"获取当前时间 now() 1234567mysql&gt; select now();+---------------------+| now() |+---------------------+| 2018-07-26 15:58:46 |+---------------------+1 row in set (0.00 sec) sysdate() 1234567mysql&gt; select sysdate()+---------------------+| sysdate() |+---------------------+| 2018-07-26 15:59:19 |+---------------------+1 row in set (0.00 sec) 两者之间的区别在于：**sysdate()是实时获取的**。 123456789101112131415mysql&gt; select now(), sleep(3), now();+---------------------+----------+---------------------+| now() | sleep(3) | now() |+---------------------+----------+---------------------+| 2018-07-26 16:00:14 | 0 | 2018-07-26 16:00:14 |+---------------------+----------+---------------------+1 row in set (3.00 sec)mysql&gt; select sysdate(), sleep(3), sysdate();+---------------------+----------+---------------------+| sysdate() | sleep(3) | sysdate() |+---------------------+----------+---------------------+| 2018-07-26 16:00:30 | 0 | 2018-07-26 16:00:33 |+---------------------+----------+---------------------+1 row in set (3.00 sec) current_timestamp, current_timestamp() 1234567mysql&gt; select current_timestamp, current_timestamp();+---------------------+---------------------+| current_timestamp | current_timestamp() |+---------------------+---------------------+| 2018-07-26 16:04:01 | 2018-07-26 16:04:01 |+---------------------+---------------------+1 row in set (0.00 sec) 日期、时间转换感觉时间与日期这块有挺多操作的，包括与字符串的相互转换等。 日期/时间转字符串 date_format()/time_format()将日期/时间转换成字符串123456789101112131415mysql&gt; select date_format('2018-7-26 16:05:11', '%Y%m%d%H%i%s')+---------------------------------------------------+| date_format('2018-7-26 16:05:11', '%Y%m%d%H%i%s') |+---------------------------------------------------+| 20180726160511 |+---------------------------------------------------+1 row in set (0.00 sec)mysql&gt; select time_format('16:05:11', '%H%i%s');+-----------------------------------+| time_format('16:05:11', '%H%i%s') |+-----------------------------------+| 160511 |+-----------------------------------+1 row in set (0.00 sec) str_to_date() 将字符串转成日期类型。123456789101112131415mysql&gt; select str_to_date('07/26/2018', '%m/%d/%Y');+---------------------------------------+| str_to_date('07/26/2018', '%m/%d/%Y') |+---------------------------------------+| 2018-07-26 |+---------------------------------------+1 row in set (0.00 sec)mysql&gt; select str_to_date('2018/7/26 16:23:33','%Y/%m/%d %H:%i:%s');+-------------------------------------------------------+| str_to_date('2018/7/26 16:23:33','%Y/%m/%d %H:%i:%s') |+-------------------------------------------------------+| 2018-07-26 16:23:33 |+-------------------------------------------------------+1 row in set (0.00 sec) 日期时间计算函数为日期增加一个时间间隔：date_add() 12345678910111213set @dt = now();select date_add(@dt, interval 1 day); -- add 1 dayselect date_add(@dt, interval 1 hour); -- add 1 hourselect date_add(@dt, interval 1 minute); -- ...select date_add(@dt, interval 1 second);select date_add(@dt, interval 1 microsecond);select date_add(@dt, interval 1 week);select date_add(@dt, interval 1 month);select date_add(@dt, interval 1 quarter);select date_add(@dt, interval 1 year);select date_add(@dt, interval -1 day); -- sub 1 day 为日期减去一个时间间隔：date_sub()日期、时间相减函数：datediff(date1,date2), timediff(time1,time2)","link":"/2018/07/31/b890da07a04b.html"},{"title":"MySQL备份记录","text":"备份命令行下具体用法如下： mysqldump -u用戶名 -p密码 -d 数据库名 表名 &gt; 脚本名; 导出整个数据库结构和数据mysqldump -h localhost -uroot -p123456 database &gt; dump.sql 导出单个数据表结构和数据mysqldump -h localhost -uroot -p123456 database table &gt; dump.sql 导出整个数据库结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database &gt; dump.sql 导出单个数据表结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database table &gt; dump.sql 数据还原1、还原使用mysqldump命令备份的数据库的语法如下：mysql -u root -p [dbname] &lt; backup.sq 示例：mysql -u root -p &lt; C:\\backup.sql","link":"/2019/12/16/cbd6ae13640b.html"},{"title":"MySQL数据库使用笔记","text":"索引失效问题https://www.jianshu.com/p/d5b2f645d657 基本使用操作 查看数据库：show databases; 选择某个数据库：use 数据库名 查看某个数据库内有哪些表：show tables; 显示数据表的属性：show columns from 表名; 12345678910mysql&gt; show index from user;+-------+------------+-------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible |+-------+------------+-------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+| user | 0 | PRIMARY | 1 | user_id | A | 0 | NULL | NULL | | BTREE | | | YES || user | 0 | PRIMARY | 2 | phone | A | 0 | NULL | NULL | | BTREE | | | YES || user | 0 | user_phone_uindex | 1 | phone | A | 0 | NULL | NULL | | BTREE | | | YES || user | 0 | user_id_uindex | 1 | user_id | A | 0 | NULL | NULL | | BTREE | | | YES |+-------+------------+-------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+4 rows in set (0.15 sec) 外键约束在建表添加外键约束的时候，需要选择on delete/update时的操作。大致知道这是怎么回事，无非是主表的内容删除或者更新的时候，对从表的相应的字段进行什么样的操作。但是具体的内容，忘记了，在这里特地找出来，给自己一个参考，顺便温习一下外键。 外键约束对子表的含义:如果在父表中找不到候选键,则不允许在子表上进行insert/update 外键约束对父表的含义:在父表上进行update/delete以更新或删除在子表中有一条或多条对应匹配行的候选键时,父表的行为取决于：在定义子表的外键时指定的on update/on delete子句。 MySQL中的InnoDB有5中方式，如下： 方式 描述 cascade 在父表上update/delete记录时，同步update/delete掉子表的匹配记录 set null 在父表上update/delete记录时，将子表上匹配记录的列设为null,要注意子表的外键列不能为not null no action 如果子表中有匹配的记录,则不允许对父表对应候选键进行update/delete操作 restrict 同no action, 都是立即检查外键约束 缺省 解析器认识这个action,但Innodb不能识别，不知道是什么意思 常见错误 1022 can't write duplicate key in table #‘sql_XXXXX’外键重名导致，另起一个名字即可解决。（mysql）","link":"/2018/07/16/c2b6878a6508.html"},{"title":"MySQL查询卡死、无返回结果问题解决","text":"现象①在Navicat中，修改表结构，点击保存，然后发现Navicat卡住，无法正常退出，且MySQL无数据返回。②在任务管理器中强制关闭了Navicat后，重复在Navicat中尝试几次，结果仍然一样。③在MySQL CLI中进行select查询，同样卡住。 分析起初认为是网络问题，但是想到可能是被堵塞住了。 解决查询MySQL中的进程：show processlist。 打开正在进行中的进程列表，发现有Waiting for table metadata lock，所以初步判定是因为某个操作被堵塞，然后后续操作无法执行，从而引起了这个问题。 从网上的资料看来，可能的原因是有未提交事物，阻塞DDL，继而阻塞所有同表的后续操作；结合自己对此数据库的操作，初步认为是在自己的小项目里面，可能存在上述情况。 查看未提交的事务：select trx_state, trx_started, trx_mysql_thread_id, trx_query from information_schema.innodb_trx\\G 执行后，发现确实存在未提交的事务。 kill掉未提交的事务，返回到Navicat，发现 之前卡住的操作已完成。 【参考】https://blog.csdn.net/benben683280/article/details/78799010https://blog.csdn.net/u013235478/article/details/68062939https://www.cnblogs.com/digdeep/p/4892953.html","link":"/2019/04/20/f6a218b8160a.html"},{"title":"MySQL简易入门","text":"MySQL 是一个互联网绕不过去的坎，总觉得很简单，一切似乎都围绕着 CURD，但是不能脱离这个核心，本次的博客其 MySQL 的一些基本概念作为主题，力求用自己的语言，将其中的概念说清楚。 今天是在银川的第二天，第一次坐完飞机，现在在见家长的过程中，偷得片刻悠闲，写点东西作为总结~ 一条SQL的执行流程MySQL 可以分为 Server 层和存储引擎层两部分。 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB。 连接器用户端与 MySQL 服务器建立 TCP 连接后，连接器对连接信息进行权限校验、维持和管理连接。 当校验用户名和密码通过后，再进行权限的获取。所以当连接建立后，修改权限，不会对已存在的连接产生影响，需要重新连接后，才生效。 连接长时间没有执行指令，连接器会断开连接。这个值默认为 8 小时，由 wait_timeout 控制。 常用指令 show processlist","link":"/2020/10/04/8af25a958664.html"},{"title":"M系列MacBook连接l2tp时失败的问题修复","text":"启用基于预共享秘钥的l2tp连接功能 12345#!/bin/sh[ -d /etc/ppp ] || mkdir /etc/pppecho '''plugin L2TP.pppl2tpnoipsec''' &gt; /etc/ppp/optionschmod 777 /etc/ppp/options 解决连接lt2p后能ping但是所有端口都无法访问的问题，关闭网络checksum功能。ip-up是会在lt2p连接建立时自动运行的脚本 1234echo '''#!/bin/sh/usr/sbin/sysctl net.link.generic.system.hwcksum_tx=0/usr/sbin/sysctl net.link.generic.system.hwcksum_rx=0''' &gt; /etc/ppp/ip-upchmod 755 /etc/ppp/ip-up 在断开l2tp连接后会将相关配置还原为系统默认。ip-down是会在l2tp连接断开时自动运行的脚本 1234echo '''#!/bin/sh/usr/sbin/sysctl net.link.generic.system.hwcksum_tx=1/usr/sbin/sysctl net.link.generic.system.hwcksum_rx=1''' &gt; /etc/ppp/ip-downchmod 755 /etc/ppp/ip-down","link":"/2024/12/09/249b2dc63505.html"},{"title":"MySQL中的常用关键字","text":"很久不用MySQL，感觉又是一个新的玩意儿了，写起SQL语句来感觉好陌生，确实是很久了！ distinct查询出某个字段不重复的记录。可用distinct来返回不重复字段的条数count(distinct id)。 limit记得这个可以用来做分页。它后面可以接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。 12345678//初始记录行的偏移量是 0(而不是 1)：mysql&gt; SELECT * FROM table LIMIT 5,10; //检索记录行6-15//为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：mysql&gt; SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last//如果只给定一个参数，它表示返回最大的记录行数目。换句话说，LIMIT n 等价于 LIMIT 0,n：mysql&gt; SELECT * FROM table LIMIT 5; //检索前 5 个记录行 limit的效率高？常说的Limit的执行效率高，是对于一种特定条件下来说的：即数据库的数量很大，但是只需要查询一部分数据的情况。高效率的原理是：避免全表扫描，提高查询效率。比如：每个用户的email是唯一的，如果用户使用email作为用户名登陆的话，就需要查询出email对应的一条记录。SELECT * FROM t_user WHERE email=?;上面的语句实现了查询email对应的一条用户信息，但是由于email这一列没有加索引，会导致全表扫描，效率会很低。SELECT * FROM t_user WHERE email=? LIMIT 1;加上LIMIT 1，只要找到了对应的一条记录，就不会继续向下扫描了，效率会大大提高。 limit的效率低？在一种情况下，使用limit效率低，那就是：只使用limit来查询语句，并且偏移量特别大的情况。做以下实验：语句1：select * from table limit 150000,1000;语句2:select * from table while id&gt;=150000 limit 1000;语句1为0.2077秒；语句2为0.0063秒。两条语句的时间比是：语句1/语句2＝32.968 比较以上的数据时，我们可以发现采用where…limit….性能基本稳定，受偏移量和行数的影响不大，而单纯采用limit的话，受偏移量的影响很大，当偏移量大到一定后性能开始大幅下降。不过在数据量不大的情况下，两者的区别不大。所以应当先使用where等查询语句，配合limit使用，效率才高。在sql语句中，limt关键字是最后才用到的。以下条件的出现顺序一般是：**where-&gt;group by-&gt;having-order by-&gt;limit** OFFSET为了与 PostgreSQL 兼容，MySQL 也支持句法： LIMIT # OFFSET #。经常用到在数据库中查询中间几条数据的需求比如下面的sql语句： ① selete * from testtable limit 2,1;② selete * from testtable limit 2 offset 1; 注意：1.数据库数据计算是从0开始的2.offset X是跳过X个数据，limit Y是选取Y个数据3.limit X,Y 中X表示跳过X个数据，读取Y个数据 这两个都是能完成需要，但是他们之间是有区别的：①是从数据库中第三条开始查询，取一条数据，即第三条数据读取，一二条跳过②是从数据库中的第二条数据开始查询两条数据，即第二条和第三条。 UNION &amp; UNION ALLunion all是直接连接，取到得是所有值，记录可能有重复 union 是取唯一值，记录没有重复。 1、UNION 的语法如下： [SQL 语句 1] UNION [SQL 语句 2] 2、UNION ALL 的语法如下： [SQL 语句 1] UNION ALL [SQL 语句 2] 效率UNION和UNION ALL关键字都是将两个结果集合并为一个，但这两者从使用和效率上来说都有所不同。 1、对重复结果的处理：UNION在进行表链接后会筛选掉重复的记录，Union All不会去除重复记录。 2、对排序的处理：Union将会按照字段的顺序进行排序；UNION ALL只是简单的将两个结果合并后就返回。 从效率上说，UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复数据且不需要排序时的话，那么就使用UNION ALL。 简单应用将一个表的内容弄成两份到一个输出中： 1234select * from(select * from players) bUNION all(select * from players) ; join相关left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录inner join(等值连接) 只返回两个表中联结字段相等的行 参考：https://www.cnblogs.com/acm-bingzi/p/msqlLimit.html","link":"/2018/07/31/5061116eb624.html"},{"title":"Netty源码学习系列④接收消息","text":"有点开始怀疑人生。为什么我说不清楚netty的工作方式？博客基本上是自己一个字一个字敲出来的，也能在一定程度上说明，我当时确实是懂了，但为什么会说不出来呢？回顾了自己的博客，有些过程的细节确实忘了，但是可怕的是，我需要想半天才能想起来，有些还想不起来。我觉得方式有问题，单纯的文字记录，缺少指导性的图画，不利于理解整个流程。 接收客户端的消息，很明显是从Main Reactor所在的EventLoop的for循环中，通过select()获取到了OP_READ事件。 Update - 2020.3.23 Netty整个系列先暂停学习，我觉得目前应该学习的是Spring的一些更加深入的知识，不然有一种眼高手低的感觉，踏踏实实地把web的那一套先搞清楚。","link":"/2020/03/17/be07bc5263e8.html"},{"title":"OpenCV使用遇到的问题","text":"图像翻转 The example scenarios of using the function are the following: Vertical flipping of the image (flipCode == 0) to switch between top-left and bottom-left image origin. This is a typical operation in video processing on Microsoft Windows* OS. Horizontal flipping of the image with the subsequent horizontal shift and absolute difference calculation to check for a vertical-axis symmetry (flipCode &gt; 0). Simultaneous horizontal and vertical flipping of the image with the subsequent shift and absolute difference calculation to check for a central symmetry (flipCode &lt; 0). Reversing the order of point arrays (flipCode &gt; 0 or flipCode == 0). 简而言之，就是：flipCode &gt;0: 沿y轴翻转；==0: 沿x轴翻转； &lt;0: x、y轴同时翻转 。图片中的坐标系，原点在左上角，向右为x轴，向下为y轴。效果图如下： x轴翻转 y轴翻转 x，y都翻转 图片旋转transpose()：相当于逆时针旋转90°，然后取镜像。效果如下： 顺时针旋转90°123transpose(img2, img2);flip(img2, img3, 1);imshow(&quot;先转置，再y轴翻转&quot;, img3); 顺时针旋转270°（逆时针旋转90°）123transpose(img2, img2);flip(img2, img3, 0);imshow(&quot;先转置，再x轴翻转&quot;, img3); 旋转180° 方法1： 123flip(img2, img3, 0);flip(img3, img3, 1);imshow(&quot;先x轴翻转，再y轴翻转&quot;, img3); 方法2：先顺时针旋转90°，再顺时针旋转90°。略 遇到的错误描述：OpenCV Error: Assertion failed (0 &lt;= roi.x &amp;&amp; 0 &lt;= roi.width &amp;&amp; roi.x + roi.width &lt;= m.cols &amp;&amp; 0 &lt;= roi.y &amp;&amp; 0 &lt;= roi.height &amp;&amp; roi.y + roi.height &lt;= m.rows) in cv::Mat::Mat 在使用OpenCV的裁剪功能时，传入了cv::Rect，遇到如上错误。后来经过检查，错误来源自传给cv::Rect的四个参数。在JNI中获得的来自Java层的floag[]在转化过程中出现了错误，让原本的参数，变成了其它的莫名其妙的负数，致使如上错误出现。后面经过对参数的修正，错误就未出现了，裁剪图片成功。 大致理解，此错误来源自所需要裁剪的区域，应该是超过了原本图片大小。","link":"/2018/05/22/c48880302b58.html"},{"title":"Oracle安装&amp;实用过程中遇到的问题","text":"安装ORACLE 11G 出现：“[INS-32025] 所选安装与指定 Oracle 主目录中已安装的软件冲突” 的问题参考了网上的一些教程，但是没有在C:\\Program Files (x86)下面找到相关文件，但是却在C:\\Program Files下找到了相关文件，可能与我之前安装。如下：删除Oracle\\Inventory\\ContentsXML目录下的inventory.xml 文件即可。 Oracle中的分页查询oracle中的分页没有mysql容易，mysql只需要实用limit关键字就行，oracle中需要使用隐含列rownum，来进行分页。其中rownum是指：符合要求的列数的序号，从1开始，即先进行了where语句后，赛选出来的行数。如下： 123456789select * from ( SELECT rownum rn, &lt;include refid=&quot;Haylion_Column_List&quot;/&gt; FROM m_qr_offline_consume_reg_hay WHERE TRANS_DATE &gt; to_date(#{date}, #{template}) and trans_date &lt; (sysdate - 1 / (25 * 60) * #{delay}))where rn between #{startIdx} and #{endIdx} Oracle查看版本12select * from v$version;select * from product_component_version; Oracle中基本概念数据库名什么是数据库名？ 数据库名就是一个数据库的标识，就像人的身份证号一样。他用参数DB_NAME表示，如果一台机器上装了多全数据库，那么每一个数据库都有一个数据库名。在数据库安装或创建完成之后，参数DB_NAME被写入参数文件之中。格式如下： DB_NAME=myorcl … 在 创建数据库时就应考虑好数据库名，并且在创建完数据库之后，数据库名不宜修改，即使要修改也会很麻烦。因为，数据库名还被写入控制文件中，控制文件是以 二进制型式存储的，用户无法修改控制文件的内容。假设用户修改了参数文件中的数据库名，即修改DB_NAME的值。但是在Oracle启动时，由于参数文 件中的DB_NAME与控制文件中的数据库名不一致，导致数据库启动失败，将返回ORA-01103错误。 数据库名的作用 数据库名是在安装数据库、创建新的数据库、创建数据库控制文件、修改数据结构、备份与恢复数据库时都需要使用到的。 有很多Oracle安装文件目录是与数据库名相关的，如： winnt: d:/oracle/product/10.1.0/oradata/DB_NAME/… Unix: /home/app/oracle/product/10.1.0/oradata/DB_NAME/… pfile: winnt: d:/oracle/product/10.1.0/admin/DB_NAME/pfile/ini.ora Unix: /home/app/oracle/product/10.1.0/admin/DB_NAME/pfile/init$ORACLE_SID.ora 跟踪文件目录： winnt: /home/app/oracle/product/10.1.0/admin/DB_NAME/bdump/… 另外，在创建数据时，careate database命令中的数据库名也要与参数文件中DB_NAME参数的值一致，否则将产生错误。 同样，修改数据库结构的语句alter database， 当然也要指出要修改的数据库的名称。 如果控制文件损坏或丢失，数据库将不能加载，这时要重新创建控制文件，方法是以nomount方式启动实例，然后以create controlfile命令创建控制文件，当然这个命令中也是指指DB_NAME。 还有在备份或恢复数据库时，都需要用到数据库名。 总之，数据库名很重要，要准确理解它的作用。 查询当前数据名 方法一:select name from v$database; 方法二：show parameter db 方法三：查看参数文件。 修改数据库名 前面建议：应在创建数据库时就确定好数据库名，数据库名不应作修改，因为修改数据库名是一件比较复杂的事情。那么现在就来说明一下，如何在已创建数据之后，修改数据库名。步骤如下：1.关闭数据库。2.修改数据库参数文件中的DB_NAME参数的值为新的数据库名。3.以NOMOUNT方式启动实例，修建控制文件(有关创建控制文件的命令语法，请参考oracle文档) 数据库实例名什么是数据库实例名？ 数据库实例名是用于和操作系统进行联系的标识，就是说数据库和操作系统之间的交互用的是数据库实例名。实例名也被写入参数文件中，该参数为instance_name，在winnt平台中，实例名同时也被写入注册表。 数据库名和实例名可以相同也可以不同。 在一般情况下，数据库名和实例名是一对一的关系，但如果在oracle并行服务器架构(即oracle实时应用集群)中，数据库名和实例名是一对多的关系。这一点在第一篇中已有图例说明。 查询当前数据库实例名方法一：select instance_name from v$instance;方法二：show parameter instance方法三：在参数文件中查询。 数据库实例名与ORACLE_SID 虽 然两者都表是oracle实例，但两者是有区别的。instance_name是oracle数据库参数。而ORACLE_SID是操作系统的环境变 量。 ORACLD_SID用于与操作系统交互，也就是说，从操作系统的角度访问实例名，必须通过ORACLE_SID。在winnt不台， ORACLE_SID还需存在于注册表中。 且ORACLE_SID必须与instance_name的值一致，否则，你将会收到一个错误，在unix平台，是“ORACLE not available”,在winnt平台，是“TNS:协议适配器错误”。 数据库实例名与网络连接 数据库实例名除了与操作系统交互外，还用于网络连接的oracle服务器标识。当你配置oracle主机连接串的时候，就需要指定实例名。当然8i以后版本的网络组件要求使用的是服务名SERVICE_NAME。这个概念接下来说明 。 数据库域名什么是数据库域名？ 在分布工数据库系统中，不同版本的数据库服务器之间，不论运行的操作系统是unix或是windows，各服务器之间都可以通过数据库链路进行远程复制，数据库域名主要用于oracle分布式环境中的复制。举例说明如： 全国交通运政系统的分布式数据库，其中： 福建节点： fj.jtyz 福建厦门节点： xm.fj.jtyz 江西： jx.jtyz 江西上饶：sr.jx.jtyz 这就是数据库域名。 数据库域名在存在于参数文件中，他的参数是db_domain. 查询数据库域名 方法一：select value from v$parameter where name = 'db_domain'; 方法二：show parameter domain 方法三：在参数文件中查询。 全局数据库名 全局数据库名=数据库名+数据库域名，如前述福建节点的全局数据库名是：oradb.fj.jtyz 数据库服务名什么是数据库服务名？ 从oracle9i版本开始，引入了一个新的参数，即数据库服务名。参数名是SERVICE_NAME。 如果数据库有域名，则数据库服务名就是全局数据库名；否则，数据库服务名与数据库名相同。 查询数据库服务名 方法一：select value from v$parameter where name = ‘service_name’; 方法二：show parameter service_name 方法三：在参数文件中查询。 数据库服务名与网络连接 从oracle8i开如的oracle网络组件，数据库与客户端的连接主机串使用数据库服务名。之前用的是ORACLE_SID,即数据库实例名","link":"/2019/01/01/ad599b882728.html"},{"title":"ProjectA 项目辅助脚本档案","text":"本文主要记录在做 ProjectA 时用到的 Python 脚本，因为用得频繁，所以做成了脚本，避免重复输命令。 项目树状结构图如下： 123456.├── CommonTips.py├── DumpPhotos.py├── FallWithMask.py├── OfflineSoRunner.py└── main.py 它主要的功能是： 从 Android 手机拉取照片（需要手机连接到电脑并且安装好 adb 命令） 在 Android 手机上以 shell 的形式跑 so 库算法，一般是在 apk 上运行 这个带 mask 分析已经看不懂是什么意思了 入口：main.py1234567891011121314151617181920212223242526272829303132import CommonTipsimport DumpPhotosimport OfflineSoRunnerimport FallWithMasksub_model_name = 'Main Menu'op_info = '''\\n--------------Main Menu--------------| 【0】：Dump照片| 【1】：离线跑算法库| 【2】：带mask分析跌倒视频''' + CommonTips.tip_ops+'-------------------------------------\\n'print(op_info)while True: cmd = input('（'+sub_model_name+'）'+CommonTips.tip_input_cmd) if cmd.isdigit(): cmd = int(cmd) if cmd == 0: DumpPhotos.main() elif cmd == 1: OfflineSoRunner.main() elif cmd == 2: FallWithMask.main() else: print(CommonTips.tip_arg_error) else: if 'h' == cmd.lower(): print(op_info) elif 'q' == cmd.lower(): print(CommonTips.tip_quit) break else: print(CommonTips.tip_arg_error) 提示输出：CommonTips.py123456789tip_arg_error = '''--------------------------| X 参数错误，请重新输入！ |--------------------------\\n'''tip_quit = &quot;已退出子模块&quot;tip_input_cmd = &quot;请输入命令：&quot;tip_ops = '''\\n|************************************| 【h】：打印本帮助| 【q】：退出本模块''' 拉取照片：DumpPhotos.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import osimport CommonTipssub_model_name = 'Dump照片'save_path = &quot;C:\\\\Users\\\\D22433\\\\Desktop\\\\DumpPhotos\\\\&quot;remote_path = &quot;/sdcard/AlgoTest/&quot;pull_photo_2_local = &quot;adb pull &quot;+remote_path+&quot; &quot;+save_pathdel_local_photos = &quot;del /Q &quot;+save_path+&quot;\\\\*&quot;del_remote_photos = 'adb shell &quot;rm -rf '+remote_path+'/*&quot;'op_info = '''--------------Dump照片--------------| 【0】：从安卓端拉取dump照片至本地| 【1】：删除本地dump照片| 【2】：删除安卓dump照片| 【3】：删除本地&amp;安卓dump照片''' + CommonTips.tip_ops+'-----------------------------------'def main(): print(op_info) while True: cmd = input('（'+sub_model_name+'）'+CommonTips.tip_input_cmd) if cmd.isdigit(): cmd = int(cmd) if cmd == 0: os.system(pull_photo_2_local) elif cmd == 1: os.system(del_local_photos) elif cmd == 2: os.system(del_remote_photos) elif cmd == 3: os.system(del_local_photos) os.system(del_remote_photos) else: print(CommonTips.tip_arg_error) else: if 'h' == cmd.lower(): print(op_info) elif 'q' == cmd.lower(): print(CommonTips.tip_quit) break else: print(CommonTips.tip_arg_error)if __name__ == '__main__': main() 离线跑 so 库：OfflineSoRunner.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# -*- coding:utf-8 -*-import osimport CommonTipssub_model_name = '跑离线算法库'model_path_local = 'E:\\\\ProjectA\\\\latestModel'model_path_remote = '/sdcard/apache/model/'exe_path_local = 'E:\\\\projects\\\\Android\\\\projectA_app\\\\app\\\\build\\\\intermediates\\\\cmake\\\\debug\\\\obj\\\\arm64-v8a\\\\executor'exe_path_remote = '/system/app/'so_path_local = 'E:\\\\ProjectA\\\\latestLib'so_path_remote = '/system/lib64/'cmd_push_model = 'adb push ' + model_path_local + ' ' + model_path_remotecmd_push_exe = 'adb push ' + exe_path_local + ' ' + exe_path_remotecmd_grant_permission = 'adb shell chmod 777 /system/app/executor'cmd_push_so = 'adb push ' + so_path_local + ' ' + so_path_remoteop_info = '''--------------跑离线算法库--------------| 【0】：推送算法库所需要的数据文件| 【1】：推送算法库so文件| 【2】：推送可执行文件并授予运行权限| 【3】：执行可执行文件| 1 for testing checkFall| 2 for testing detectFaceNumber| 3 for testing extractFaceFeature| others for quit.''' + CommonTips.tip_ops + '----------------------------------------'def main(): print(op_info) while True: cmd = input('（'+sub_model_name+'）'+CommonTips.tip_input_cmd) if cmd.isdigit(): cmd = int(cmd) if cmd == 0: os.system(cmd_push_model) elif cmd == 1: os.system(cmd_push_so) elif cmd == 2: os.system(cmd_push_exe) os.system(cmd_grant_permission) elif cmd == 3: while True: choice = input(&quot;测试选项：&quot;) if choice == '1' or choice == '2' or choice == '3': # do something about checkFall command = 'adb shell &quot;/system/app/executor ' + choice + ' `ls /sdcard/TestData' + choice + '`&quot;' print(command) os.system(command) else: break else: print(CommonTips.tip_arg_error) else: if 'h' == cmd.lower(): print(op_info) elif 'q' == cmd.lower(): print(CommonTips.tip_quit) break else: print(CommonTips.tip_arg_error)if __name__ == '__main__': main() 带 mask 分析：FallWithMask.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import osimport CommonTipssub_model_name = '带mask跌倒检测'exe_path = 'E:\\\\ProjectA\\\\TestVideoWithMask\\\\TestVideoWithMask.exe'video_path = 'E:\\\\ProjectA\\\\videos'remote_path = '/sdcard/LuPingDaShi/Rec/'op_info = '--------------带mask跌倒检测--------------'def main(): # pull videos pull = input(&quot;是否要从Android拉取视频(y/N):&quot;) if pull == 'y': os.system('adb pull '+remote_path+' '+video_path+' ') os.system('adb shell rm '+remote_path+'* ') files = os.listdir(video_path) print(&quot;可用来测试的视频 :&quot;) for f in range(0, len(files)): print('【'+str(f)+'】 : '+files[f]) while True: idx = input('（' + sub_model_name + '）' + &quot;请选择序号：&quot;) if idx.isdigit(): idx = int(idx) if idx &gt;= len(files) or idx &lt; 0: print(CommonTips.tip_arg_error+&quot;---数组越界&quot;) else: os.system(exe_path + ' ' + video_path + '\\\\' + files[idx]+' &gt;&gt; log.txt') else: if 'h' == idx.lower(): print(op_info) elif 'q' == idx.lower(): print(CommonTips.tip_quit) break elif 'r' == idx.lower(): files = os.listdir(video_path) print(&quot;可用来测试的视频 :&quot;) for f in range(0, len(files)): print('【' + str(f) + '】 : ' + files[f]) else: print(CommonTips.tip_arg_error)if __name__ == '__main__': main()","link":"/2018/04/17/acdc45f57935.html"},{"title":"PV、PVC、StorageClass 概览","text":"为何如此设计 解耦对存储的使用与维护 拓展不同的存储需求 定义PV 描述的是持久化存储数据卷。这个 API 对象主要定义的是⼀个持久化存储在宿主机上的⽬录，⽐如⼀个 NFS 的挂载⽬录。通常情况下，PV 对象是由运维⼈员事先创建在 Kubernetes 集群⾥待⽤的。_类似于接口的具体实现，干活的打工人。PVC 描述的是 Pod 所希望使⽤的持久化存储的属性。PVC 对象通常由开发⼈员创建；或者以 PVC 模板的⽅式成为 StatefulSet 的⼀部分，然后由 StatefulSet 控制器负责创建带编号的 PVC。类似于接口，不提供具体实现_。 PV与PVC匹配绑定规则 两者的 spec 字段匹配 两者的 storageClassName 字段必须相同 过程通过 operator 机制，为每个未处于 Bound 状态的 PVC，遍历所有可用的 PV，来匹配到合适的 PV。 结果在 PVC 的 spec.volumeName 字段上填写上 PV 的名称 两阶段处理 Attach 调用存储系统的 API 将存储挂载到 Pod 将要调度到的 Node 上； 由 AttachDetachController 管理。它不断地检查每⼀个 Pod 对应的 PV，和 这个 Pod 所在宿主机之间挂载情况。从⽽决定，是否需要对这个 PV 进⾏ Attach（或者 Dettach）操作。作为⼀个 Kubernetes 内置的控制器，Volume Controller ⾃然是 kube-controller-manager 的⼀部分。所以，AttachDetachController 也⼀定是运⾏在 Master 节点上的。当然，Attach 操作只需要调⽤公有云或者具体存储项⽬的 API，并不需要在具体的宿主机上执⾏操作。 Mount 格式化存储设备 绑定挂载到 Pod 中 由 VolumeManagerReconciler 管理。它必须发⽣在 Pod 对应的宿主机上，所以必须是 kubelet 组件的⼀部分。它运⾏起来之后，是⼀个独⽴于 kubelet 主循环的 Goroutine（不堵塞 kubelet 主控循环）。 PV 管理方式 Static Provisioning 创建 PVC 之后，由运维人员手动创建 PV 的方式 Dynamic Provisioning 创建 PVC 时指定 StorageClass，由 StorageClass 中指定的 provisioner 来创建对应的 PV。 StorageClass当 PVC 中指定的 StorageClass 存在时，调用对应的 provisioner 来创建 PV；否则去匹配带有相同 StorageClass 的 PV。如果 PVC 中未指定 StorageClass，当集群已经开启了名叫 DefaultStorageClass 的 Admission Plugin时，它就会为 PVC 和 PV ⾃动添加⼀个默认的 StorageClass；否则，PVC 的 storageClassName 的值就是“”，这也意味着它只能够跟 storageClassName 也是“”的 PV 进⾏绑定。 本地持久化卷的实现延迟绑定：当使用本地存储后，需要延迟 PV 与 PVC 之间的绑定时机到 Pod 调度时，避免出现 PV 与 Pod 不在同一节点上面的问题。 123456kind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: local-storageprovisioner: kubernetes.io/no-provisionervolumeBindingMode: WaitForFirstConsumer","link":"/2023/06/12/e1999bb16b6a.html"},{"title":"PageAble分页注解在并发环境下遇到的bug","text":"数据库结构及数据说明结构 数据 对应类 接口详细说明获取分页数据接口 12345678910111213@AnonymousSupport@GetMapping(&quot;get-system-busy&quot;)public Object getPageableUsers(@RequestParam Integer page, @RequestParam Integer size) { return testService.getSystemBusy(page, size);}@PageAblepublic Object getSystemBusy(Integer page, Integer size) { return testMapper.getSystemBusy();}@Select(&quot;select gender from user&quot;)List&lt;User&gt; getSystemBusy(); 根据id获取用户详情 123456789101112@AnonymousSupport@GetMapping(&quot;get-one-user&quot;)public Object getOneUserById(@RequestParam Integer id) { return testService.getOneUser(id);}public Object getOneUser(Integer id) { return testMapper.getOneUser(id);}@Select(&quot;select * from user where id = #{id}&quot;)User getOneUser(Integer id); 获取所有司机列表 123456789101112@AnonymousSupport@GetMapping(&quot;get-all-drivers&quot;)public Object getAllDrivers() { return testService.getAllDrivers();}public Object getAllDrivers() { return testMapper.getAllDrivers();}@Select(&quot;select * from driver&quot;)List&lt;Driver&gt; getAllDrivers(); 获取所有用户的名字 1234567891011121314151617@AnonymousSupport@GetMapping(&quot;get-username-list&quot;)public Object getUsernameList() { return testService.getUsernameList();}public Object getUsernameList() { List&lt;User&gt; users = testMapper.getAllUsers(); List&lt;String&gt; names = new ArrayList&lt;&gt;(); for (User user : users) { names.add(user.getUsername()); } return names;}@Select(&quot;select * from user&quot;)List&lt;User&gt; getAllUsers(); 分页相关文件说明12345678910111213141516171819202122base-service├── pom.xml└── src └── main └── java └── com └── haylion └── realTimeBus ├── advice │ └── SystemAdvice.java # 分页注解实现 ├── annotation │ └── PageAble.java # 分页注解 ├── bean │ ├── BaseModel.java # 含有id熟悉的基础bean │ ├── Condition.java # 条件查询时的条件 │ ├── ResultPageView.java # 被分页注解标记后，改函数返回的对象，将被包装成该对象(一个普通的bean类) │ └── Sort.java # 查询时排序方式 ├── interceptor └── sql ├── MyPageHelper.java # 覆盖afterAll后的PageHelper，在MyPageInterceptor中进行调用 ├── MyPageInterceptor.java # PageHelper中拦截器PageInterceptor的源码，有自定义修改 └── SqlLogHandler.java # 把将要执行的SQL打印出来，集成在MyPageInterceptor中 前言这个注解主要是对PageHelper插件的封装，这个插件的工作流程可参考：此链接。 需要做的是在mybatis的配置文件中加入一个拦截器（拦截器的源代码链接）。MyBatis在执行query语句时，会触发该拦截器，然后得到的数据是处理过的分页后的数据。 在上述链接中有一个注意事项，如下： 什么时候会导致不安全的分页？ PageHelper 方法使用了静态的 ThreadLocal 参数，分页参数和线程是绑定的。只要你可以保证在 PageHelper 方法调用后紧跟 MyBatis 查询方法，这就是安全的。因为 PageHelper 在 finally 代码段中自动清除了 ThreadLocal 存储的对象。如果代码在进入 Executor 前发生异常，就会导致线程不可用，这属于人为的 Bug（例如接口方法和 XML 中的不匹配，导致找不到 MappedStatement 时），这种情况由于线程不可用，也不会导致 ThreadLocal 参数被错误的使用。但是如果你写出下面这样的代码，就是不安全的用法： 1234567PageHelper.startPage(1, 10);List&lt;Country&gt; list;if(param1 != null){ list = countryMapper.selectIf(param1);} else { list = new ArrayList&lt;Country&gt;();} 这种情况下由于 param1 存在 null 的情况，就会导致 PageHelper 生产了一个分页参数，但是没有被消费，这个参数就会一直保留在这个线程上。当这个线程再次被使用时，就可能导致不该分页的方法去消费这个分页参数，这就产生了莫名其妙的分页。上面这个代码，应该写成下面这个样子： 1234567List&lt;Country&gt; list;if(param1 != null){ PageHelper.startPage(1, 10); list = countryMapper.selectIf(param1);} else { list = new ArrayList&lt;Country&gt;();} 这种写法就能保证安全。如果你对此不放心，你可以手动清理 ThreadLocal 存储的分页参数，可以像下面这样使用： 1234567891011List&lt;Country&gt; list;if(param1 != null){ PageHelper.startPage(1, 10); try{ list = countryMapper.selectAll(); } finally { PageHelper.clearPage(); }} else { list = new ArrayList&lt;Country&gt;();} 这么写很不好看，而且没有必要。 用法直接在方法上加上@PageAble注解，并在该方法中传入两个参数，分别为page和size，在该方法返回后，会得到一个ResultPageView封装对象，其中包含分页相关信息。 工作流程 SystemAdvice定义一个切面，切点是@annotation(com.haylion.realTimeBus.annotation.PageAble)。也就是说，每个被@PageAble注解过的方法，都将执行下面的代码： 123456789101112131415161718private static final String PAGE_ABLE = &quot;@annotation(com.haylion.realTimeBus.annotation.PageAble)&quot;;@Around(PAGE_ABLE)public Object doAroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { logger.info(&quot;execute method : &quot; + proceedingJoinPoint.getSignature().getName()); try { // 进入被@PageAble注解的方法前的准备工作 prepare(proceedingJoinPoint); // 执行被@PageAble注解的方法 Object obj = proceedingJoinPoint.proceed(); // 执行被@PageAble注解的方法后，执行扫尾工作 Object result = after(obj); return result; } catch (Throwable throwable) { logger.error(&quot;aspect execute error : &quot;, throwable); throw throwable; }} 准备工作：主要是获取page和size的值，然后调用PageHelper的startPage方法，初始化分页信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// PageAble中page和size的默认值分别是1和20@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface PageAble { String pageSizeName() default &quot;size&quot;; String pageNumName() default &quot;page&quot;; int pageSize() default 20; int pageNum() default 1;}// 准备分页private void prepare(ProceedingJoinPoint point) throws Exception { Signature signature = point.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); PageAble pageAble = targetMethod.getAnnotation(PageAble.class); String numName = pageAble.pageNumName(); String sizeName = pageAble.pageSizeName(); // 先获取默认的page和size值 int pageNo = pageAble.pageNum(); int pageSize = pageAble.pageSize(); Object[] paramValues = point.getArgs(); String[] paramNames = methodSignature.getParameterNames(); int length = paramNames.length; // 遍历该方法中的所有参数，如果有page和size信息，那么就覆盖默认值为用户传入的值 for (int i = 0; i &lt; length; i++) { if (paramNames[i].equals(numName)) { pageNo = (Integer) paramValues[i]; } else if (paramNames[i].equals(sizeName)) { pageSize = (Integer) paramValues[i]; } } // 该方法利用ThreadLocal在本线程中插入一个分页信息的对象Page PageHelper.startPage(pageNo, pageSize);}// startPage()方法的最终实现public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count, Boolean reasonable, Boolean pageSizeZero) { Page&lt;E&gt; page = new Page&lt;E&gt;(pageNum, pageSize, count); page.setReasonable(reasonable); page.setPageSizeZero(pageSizeZero); //当已经执行过orderBy的时候 Page&lt;E&gt; oldPage = getLocalPage(); if (oldPage != null &amp;&amp; oldPage.isOrderByOnly()) { page.setOrderBy(oldPage.getOrderBy()); } setLocalPage(page); return page;}protected static void setLocalPage(Page page) { LOCAL_PAGE.set(page);}protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal&lt;Page&gt;(); 进入SQL拦截器（即MyPageInterceptor）：这个拦截器中主要是PageHelper执行分页的步骤，相关步骤可分为： 判断是否需要进行分页。判断的条件为!dialect.skip(ms, parameter, rowBounds)，其实现为： 1234567891011121314151617@Overridepublic boolean skip(MappedStatement ms, Object parameterObject, RowBounds rowBounds) { if(ms.getId().endsWith(MSUtils.COUNT)){ throw new RuntimeException(&quot;在系统中发现了多个分页插件，请检查系统配置!&quot;); } Page page = pageParams.getPage(parameterObject, rowBounds); if (page == null) { return true; } else { //设置默认的 count 列 if(StringUtil.isEmpty(page.getCountColumn())){ page.setCountColumn(pageParams.getCountColumn()); } autoDialect.initDelegateDialect(ms); return false; }} 也就是说，通过判断Page是否为空来决定是否进行分页，Page则从本线程中获取，如下： 1234567891011121314// PageHelper.javaPage page = pageParams.getPage(parameterObject, rowBounds);//PageParams.javapublic Page getPage(Object parameterObject, RowBounds rowBounds) { Page page = PageHelper.getLocalPage(); ...}// PageMethod.javapublic static &lt;T&gt; Page&lt;T&gt; getLocalPage() { return LOCAL_PAGE.get();}protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal&lt;Page&gt;(); 获取数据的总条数。在进入此项前，会进行判断是否需要进行总数查询。这里假设进行总数查询。从源SQL解析出获取数据总条数的代码调试如下： log如下所示： 123456789101112132019-06-14 09:37:31.475 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Preparing: SELECT count(0) FROM advertising 2019-06-14 09:37:31.490 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Parameters: 2019-06-14 09:37:31.507 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - &lt;== Total: 12019-06-14 09:37:31.508 INFO [http-nio-8880-exec-1] c.h.r.i.s.SqlLogHandler - com.haylion.realTimeBus.dao.AdvertisingMapper.getByConditionList_COUNT:select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising&lt;cost time is :45 ms &gt;2019-06-14 09:37:31.512 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Preparing: select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising LIMIT ? 2019-06-14 09:37:31.512 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Parameters: 1(Integer)2019-06-14 09:37:31.519 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - &lt;== Total: 12019-06-14 09:37:31.520 INFO [http-nio-8880-exec-1] c.h.r.i.s.SqlLogHandler - com.haylion.realTimeBus.dao.AdvertisingMapper.getByConditionList:select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising LIMIT 1 &lt;cost time is :8 ms &gt;2019-06-14 09:37:31.591 INFO [http-nio-8880-exec-1] c.h.r.f.a.ResponseAdvice - Trace log is ====&gt; {&quot;url&quot;:&quot;/advertising/getAdvertisingList&quot;,&quot;httpMethod&quot;:&quot;GET&quot;,&quot;reqHeader&quot;:{&quot;host&quot;:&quot;192.168.12.39:8880&quot;,&quot;content-type&quot;:&quot;application/json&quot;,&quot;user-agent&quot;:&quot;curl/7.54.0&quot;,&quot;accept&quot;:&quot;*/*&quot;,&quot;token&quot;:&quot;fe20027352f8250571436f471a988b4d&quot;},&quot;reqParams&quot;:&quot;page=1&amp;size=1&quot;,&quot;requestBody&quot;:&quot;&quot;,&quot;respParams&quot;:&quot;{\\&quot;code\\&quot;:200,\\&quot;message\\&quot;:\\&quot;success\\&quot;,\\&quot;data\\&quot;:{\\&quot;total\\&quot;:9,\\&quot;current\\&quot;:1,\\&quot;pageCount\\&quot;:9,\\&quot;list\\&quot;:[{\\&quot;settlementType\\&quot;:0,\\&quot;imagesUrl\\&quot;:\\&quot;xxxxxxx\\&quot;,\\&quot;advertisingName\\&quot;:\\&quot;hello kitty 111\\&quot;,\\&quot;advertiserName\\&quot;:\\&quot;暁\\&quot;,\\&quot;advertiserId\\&quot;:0,\\&quot;createTimeymdhm_Str\\&quot;:\\&quot;2019-06-10 17:27\\&quot;,\\&quot;advertisingType\\&quot;:0,\\&quot;createTime\\&quot;:1560158854000,\\&quot;advertisingPosition\\&quot;:0,\\&quot;auditStatus\\&quot;:4,\\&quot;createUser\\&quot;:1,\\&quot;id\\&quot;:0,\\&quot;advertiserUrl\\&quot;:\\&quot;xxxxx\\&quot;,\\&quot;createTimeStr\\&quot;:\\&quot;2019-06-10 17:27:34\\&quot;}]}}&quot;,&quot;startTime&quot;:1560476250978,&quot;spendTime&quot;:592} 获取完总数后，会进行判断是否有分页的必要。 分页查询。这里假设有分页的必要。 12345678910111213141516171819//调用方言获取分页 sqlString pageSql = dialect.getPageSql(ms, boundSql, parameter, rowBounds, pageKey);@Overridepublic String getPageSql(MappedStatement ms, BoundSql boundSql, Object parameterObject, RowBounds rowBounds, CacheKey pageKey) { String sql = boundSql.getSql(); Page page = getLocalPage(); //支持 order by String orderBy = page.getOrderBy(); if (StringUtil.isNotEmpty(orderBy)) { pageKey.update(orderBy); sql = OrderByParser.converToOrderBySql(sql, orderBy); } if (page.isOrderByOnly()) { return sql; } // 这是一个抽象方法，会根据具体的数据库，调用不同的实现方法，来在原SQL语句上，加上对应的分页语句 return getPageSql(sql, page, pageKey);} 具体支持的数据库如下： Oracle的分页实现如下： 1234567891011//@Overridepublic String getPageSql(String sql, Page page, CacheKey pageKey) { StringBuilder sqlBuilder = new StringBuilder(sql.length() + 120); sqlBuilder.append(&quot;SELECT * FROM ( &quot;); sqlBuilder.append(&quot; SELECT TMP_PAGE.*, ROWNUM ROW_ID FROM ( &quot;); sqlBuilder.append(sql); sqlBuilder.append(&quot; ) TMP_PAGE WHERE ROWNUM &lt;= ? &quot;); sqlBuilder.append(&quot; ) WHERE ROW_ID &gt; ? &quot;); return sqlBuilder.toString();} MySQL的分页实现如下： 123456789101112@Overridepublic String getPageSql(String sql, Page page, CacheKey pageKey) { StringBuilder sqlBuilder = new StringBuilder(sql.length() + 14); sqlBuilder.append(sql); if (page.getStartRow() == 0) { sqlBuilder.append(&quot; LIMIT ? &quot;); } else { sqlBuilder.append(&quot; LIMIT ?, ? &quot;); } pageKey.update(page.getPageSize()); return sqlBuilder.toString();} 保存分页查询后的结果。 1234567891011121314151617181920212223242526272829303132// resultList是分页查询后的数据列表// afterPage的返回值是有两种情况，但是都可以被转成Listreturn dialect.afterPage(resultList, parameter, rowBounds);// dialect.afterPage()方法@Overridepublic Object afterPage(List pageList, Object parameterObject, RowBounds rowBounds) { //这个方法即使不分页也会被执行，所以要判断 null AbstractHelperDialect delegate = autoDialect.getDelegate(); if(delegate != null){ return delegate.afterPage(pageList, parameterObject, rowBounds); } return pageList;}// delegate.afterPage()方法@Overridepublic Object afterPage(List pageList, Object parameterObject, RowBounds rowBounds) { Page page = getLocalPage(); if (page == null) { return pageList; } page.addAll(pageList); if (!page.isCount()) { page.setTotal(-1); } else if ((page.getPageSizeZero() != null &amp;&amp; page.getPageSizeZero()) &amp;&amp; page.getPageSize() == 0) { page.setTotal(pageList.size()); } else if(page.isOrderByOnly()){ page.setTotal(pageList.size()); } return page;} 其实这里有一个问题是，如果delegate不为空，那么返回的是Page，但是我们在调用xxxxxMapper的查询方法之后，返回值基本上是List，与我们的常识并不符合。那Page是什么呢？它不只是包含分页信息的基本类，它继承自ArrayList。 123public class Page&lt;E&gt; extends ArrayList&lt;E&gt; implements Closeable { // ...} 在return后，还会执行finally中的处理代码，即com.haylion.realTimeBus.interceptor.sql.MyPageHelper的afterAll()方法。其中实现如下： 123456789101112131415161718192021222324252627// com.haylion.realTimeBus.interceptor.sql.MyPageHelper.afterAll()// 这个方法是我们自定义的方法，用来处理执行完前面所述的切点后，保留分页信息，进行再次封装@Overridepublic void afterAll() { Page&lt;Object&gt; localPage = getLocalPage(); // 删除分页信息 super.afterAll(); // 设置回本线程中 setLocalPage(localPage);}// super.afterAll()。这个方法可以简单理解成，清楚掉本线程中的分页信息@Overridepublic void afterAll() { //这个方法即使不分页也会被执行，所以要判断 null AbstractHelperDialect delegate = autoDialect.getDelegate(); if (delegate != null) { delegate.afterAll(); autoDialect.clearDelegate(); } clearPage();}// 移除本地变量public static void clearPage() { LOCAL_PAGE.remove();} 经过上述的过程，MyPageInterceptor执行完毕，分页信息存储在本线程中，然后回到切面处理。 切面收尾工作（回到SystemAdvice）： 12345678910111213private Object after(Object obj) { // ... PageInfo&lt;?&gt; pageInfo; Page&lt;Object&gt; localPage = PageHelper.getLocalPage(); long total = localPage.getTotal(); int pageNum = localPage.getPageNum(); int pages = localPage.getPages(); List&lt;?&gt; list = (List&lt;?&gt;) obj; // ... pageInfo = new PageInfo((list)); ResultPageView&lt;?&gt; resultPageView = new ResultPageView&lt;&gt;(total, pageNum, pages, pageInfo.getList()); return resultPageView;} 至此，备注解方法将返回ResultPageView对象，经过包装后，也就是我们常看到的分页格式： 12345678910{ &quot;code&quot;: 200, &quot;message&quot;: &quot;success&quot;, &quot;data&quot;: { &quot;total&quot;: 17, &quot;current&quot;: 1, &quot;pageCount&quot;: 9, &quot;list&quot;: [] }} 局限这就限定了在一个被PageAble注解了的方法上，只能执行一条查询。如果对于一个到来的请求，需要进行两次或以上的查询，并且某一条查询需要分页的情况，如果所有的查询都放在被PageAble注解的方法下，执行会出现问题（出现不必要的分页操作）。但是可以通过组装的形式，完成该项需求。 bug说明 当一条线程，执行被PageAble注解过的方法时，线程中会保存Page信息。 如果切面没有执行完，会导致Page在处理完改请求后，继续留存在该线程中。 当一条含有Page对象的线程，处理某个不分页、但需进行查询的请求时，会导致该查询进行分页，并且会将Page对象中的之前查询得到的数据一并返回。 四个请求的各自功能 在线程中留下分页标志。 curl -s localhost:8880/test/get-system-busy\\?page=1\\&amp;size=2 | jq --indent 4 在分页后的数据列表中，加入数据。curl -s localhost:8880/test/get-all-drivers | jq --indent 4 出错情况1：TooManyResultsException。curl -s localhost:8880/test/get-one-user\\?id=1 | jq --indent 4 出错情况2 &amp; 3：ClassCastException &amp; 数据累积。curl -s localhost:8880/test/get-username-list | jq --indent 4 PPT内容略","link":"/2019/07/22/10be91c35e3d.html"},{"title":"Python爬虫环境搭建（Mac）","text":"这是一篇对此教程视频的笔记。看视频太磨叽了，安装都是分成了win、linux、mac三种，再看视频的话怕是没那个耐心看。 Homebrew与AnacondaHomebrew充当的角色是mac下的apt-get，是一种包管理工具。先把Homebrew安装到mac上。然后用它安装python3，最后验证python3与pip3是否安装成功。 可以参考 Anaconda墙内教程。 数据库 安装MongoDB1brew install mongodb 验证：开启MongoDB数据库，mongod，然后使用mongo去链接数据库。 由于之前已经安装过MongoDB，很久没有用过了，启动时出现错误，错误如下：exception in initAndListen: 29 Data directory /data/db not found., terminating解决办法有两种：一种是在启动时指定一个其他的db文件所在的目录： 1mongod --dbpath ~/Documents/mongo/db 另一种是，创建/data/db并授予相应的权限： 12sudo mkdir -p /data/dbsudo chmod ugo+rwx /data/db 成功执行后如下： 使用mongo连接： 测试几个命令： 1234567&gt; show dbsadmin 0.000GBlocal 0.000GB&gt; use localswitched to db local&gt; db.test.insert({'a':1})WriteResult({ &quot;nInserted&quot; : 1 }) Redis分布式爬虫中，维护爬虫队列。1brew install redis 安装完成后，输入redis-cli即可连接上redis，如果失败，可以尝试使用redis-server打开数据库服务。 redis的配置文件位置：/usr/local/etc/redis.conf远程访问：注释掉bind 127.0.0.1设置密码：取消注释# requirepass foobared重启即可生效。 使用brew查看services 1brew services list 使用brew启动/重启动service 1brew services start/restart redis MySQL 1brew install mysql Python多版本共存配置使用软链接对不同的版本，进行命名的简化。如生成python3.6的软链接为python，按照需求，把不同的版本链接到此文件名上。注意将软连接文件放在PATH中，或加入其中也可。 安装Python爬虫库 requests：Python发送请求所用到的库 selenium：模拟浏览器访问 beautifulsoup4：解析网页 pyquery：网页解析库。接收网页源代码，然后通过与jQuery类似的语法获取相应的数据。 pymysql/pymongo：使用Python访问MySQL/MongoDB数据库 django/flask：Python Web框架 其中有一个非常有意思的工具jupyter，它是一款网页端的笔记本，可以在其中运行代码等，它的启动方式是在终端输入：jupyter notebook。","link":"/2018/06/11/ffc13320b7a2.html"},{"title":"Python爬虫常用库的使用","text":"builtwith的使用 Requests库的使用 实例引入12345678import requestsresponse = requests.get('https://www.baidu.com/')print(type(response))print(response.status_code)print(type(response.text))print(response.text)print(response.cookies) 各种请求方式123456import requestsrequests.post('http://httpbin.org/post')requests.put('http://httpbin.org/put')requests.delete('http://httpbin.org/delete')requests.head('http://httpbin.org/get')requests.options('http://httpbin.org/get') 基本GET请求基本写法1234import requestsresponse = requests.get('http://httpbin.org/get')print(response.text) 带参数GET请求123import requestsresponse = requests.get(&quot;http://httpbin.org/get?name=germey&amp;age=22&quot;)print(response.text) 12345678import requestsdata = { 'name': 'germey', 'age': 22}response = requests.get(&quot;http://httpbin.org/get&quot;, params=data)print(response.text) 解析json12345678import requestsimport jsonresponse = requests.get(&quot;http://httpbin.org/get&quot;)print(type(response.text))print(response.json())print(json.loads(response.text))print(type(response.json())) 获取二进制数据123456import requestsresponse = requests.get(&quot;https://github.com/favicon.ico&quot;)print(type(response.text), type(response.content))print(response.text)print(response.content) 123456import requestsresponse = requests.get(&quot;https://github.com/favicon.ico&quot;)with open('favicon.ico', 'wb') as f: f.write(response.content) f.close() 添加headers1234import requestsresponse = requests.get(&quot;https://www.zhihu.com/explore&quot;)print(response.text) 1234567import requestsheaders = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}response = requests.get(&quot;https://www.zhihu.com/explore&quot;, headers=headers)print(response.text) 基本POST请求12345import requestsdata = {'name': 'germey', 'age': '22'}response = requests.post(&quot;http://httpbin.org/post&quot;, data=data)print(response.text) 12345678import requestsdata = {'name': 'germey', 'age': '22'}headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}response = requests.post(&quot;http://httpbin.org/post&quot;, data=data, headers=headers)print(response.json()) reponse属性12345678import requestsresponse = requests.get('http://www.jianshu.com')print(type(response.status_code), response.status_code)print(type(response.headers), response.headers)print(type(response.cookies), response.cookies)print(type(response.url), response.url)print(type(response.history), response.history) 状态码判断1234import requestsresponse = requests.get('http://www.jianshu.com/hello.html')exit() if not response.status_code == requests.codes.not_found else print('404 Not Found') 1234import requestsresponse = requests.get('http://www.jianshu.com')exit() if not response.status_code == 200 else print('Request Successfully') 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475100: ('continue',),101: ('switching_protocols',),102: ('processing',),103: ('checkpoint',),122: ('uri_too_long', 'request_uri_too_long'),200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\\\o/', '✓'),201: ('created',),202: ('accepted',),203: ('non_authoritative_info', 'non_authoritative_information'),204: ('no_content',),205: ('reset_content', 'reset'),206: ('partial_content', 'partial'),207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),208: ('already_reported',),226: ('im_used',),# Redirection.300: ('multiple_choices',),301: ('moved_permanently', 'moved', '\\\\o-'),302: ('found',),303: ('see_other', 'other'),304: ('not_modified',),305: ('use_proxy',),306: ('switch_proxy',),307: ('temporary_redirect', 'temporary_moved', 'temporary'),308: ('permanent_redirect', 'resume_incomplete', 'resume',), # These 2 to be removed in 3.0# Client Error.400: ('bad_request', 'bad'),401: ('unauthorized',),402: ('payment_required', 'payment'),403: ('forbidden',),404: ('not_found', '-o-'),405: ('method_not_allowed', 'not_allowed'),406: ('not_acceptable',),407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),408: ('request_timeout', 'timeout'),409: ('conflict',),410: ('gone',),411: ('length_required',),412: ('precondition_failed', 'precondition'),413: ('request_entity_too_large',),414: ('request_uri_too_large',),415: ('unsupported_media_type', 'unsupported_media', 'media_type'),416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),417: ('expectation_failed',),418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),421: ('misdirected_request',),422: ('unprocessable_entity', 'unprocessable'),423: ('locked',),424: ('failed_dependency', 'dependency'),425: ('unordered_collection', 'unordered'),426: ('upgrade_required', 'upgrade'),428: ('precondition_required', 'precondition'),429: ('too_many_requests', 'too_many'),431: ('header_fields_too_large', 'fields_too_large'),444: ('no_response', 'none'),449: ('retry_with', 'retry'),450: ('blocked_by_windows_parental_controls', 'parental_controls'),451: ('unavailable_for_legal_reasons', 'legal_reasons'),499: ('client_closed_request',),# Server Error.500: ('internal_server_error', 'server_error', '/o\\\\', '✗'),501: ('not_implemented',),502: ('bad_gateway',),503: ('service_unavailable', 'unavailable'),504: ('gateway_timeout',),505: ('http_version_not_supported', 'http_version'),506: ('variant_also_negotiates',),507: ('insufficient_storage',),509: ('bandwidth_limit_exceeded', 'bandwidth'),510: ('not_extended',),511: ('network_authentication_required', 'network_auth', 'network_authentication'), 文件上传12345import requestsfiles = {'file': open('favicon.ico', 'rb')}response = requests.post(&quot;http://httpbin.org/post&quot;, files=files)print(response.text) 获取cookie123456import requestsresponse = requests.get(&quot;https://www.baidu.com&quot;)print(response.cookies)for key, value in response.cookies.items(): print(key + '=' + value) 会话维持模拟登录 12345import requestsrequests.get('http://httpbin.org/cookies/set/number/123456789')response = requests.get('http://httpbin.org/cookies')print(response.text) 123456import requestss = requests.Session()s.get('http://httpbin.org/cookies/set/number/123456789')response = s.get('http://httpbin.org/cookies')print(response.text) 证书验证1234import requestsresponse = requests.get('https://www.12306.cn')print(response.status_code) 12345import requestsfrom requests.packages import urllib3urllib3.disable_warnings()response = requests.get('https://www.12306.cn', verify=False)print(response.status_code) 1234import requestsresponse = requests.get('https://www.12306.cn', cert=('/path/server.crt', '/path/key'))print(response.status_code) 代理设置123456789import requestsproxies = { &quot;http&quot;: &quot;http://127.0.0.1:9743&quot;, &quot;https&quot;: &quot;https://127.0.0.1:9743&quot;,}response = requests.get(&quot;https://www.taobao.com&quot;, proxies=proxies)print(response.status_code) 1234567import requestsproxies = { &quot;http&quot;: &quot;http://user:password@127.0.0.1:9743/&quot;,}response = requests.get(&quot;https://www.taobao.com&quot;, proxies=proxies)print(response.status_code) 1pip3 install 'requests[socks]' 12345678import requestsproxies = { 'http': 'socks5://127.0.0.1:9742', 'https': 'socks5://127.0.0.1:9742'}response = requests.get(&quot;https://www.taobao.com&quot;, proxies=proxies)print(response.status_code) 超时设置1234567import requestsfrom requests.exceptions import ReadTimeouttry: response = requests.get(&quot;http://httpbin.org/get&quot;, timeout = 0.5) print(response.status_code)except ReadTimeout: print('Timeout') 认证设置12345import requestsfrom requests.auth import HTTPBasicAuthr = requests.get('http://120.27.34.24:9001', auth=HTTPBasicAuth('user', '123'))print(r.status_code) 1234import requestsr = requests.get('http://120.27.34.24:9001', auth=('user', '123'))print(r.status_code) 异常处理1234567891011import requestsfrom requests.exceptions import ReadTimeout, ConnectionError, RequestExceptiontry: response = requests.get(&quot;http://httpbin.org/get&quot;, timeout = 0.5) print(response.status_code)except ReadTimeout: print('Timeout')except ConnectionError: print('Connection error')except RequestException: print('Error') Connection error Urllib库的使用 urllib.urlopenget请求 123import urllib.requestresponse = urllib.request.urlopen('http://asahii.cn')print(response.read().decode('utf-8')) &lt;html&gt; &lt;script&gt; window.location.href=&quot;http://blog.csdn.net/asahinokawa&quot; &lt;/script&gt; &lt;/html&gt; post请求 123456import urllib.parseimport urllib.requestdata = bytes(urllib.parse.urlencode({'word':'hello'}), encoding='utf8')response = urllib.request.urlopen('http://httpbin.org/post', data=data)print(response.read().decode('utf-8')) { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: {}, &quot;form&quot;: { &quot;word&quot;: &quot;hello&quot; }, &quot;headers&quot;: { &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Content-Length&quot;: &quot;10&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Python-urllib/3.6&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;14.154.29.216&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } 超时时限设置。超过此值将抛出异常。 1234import urllib.requestresponse = urllib.request.urlopen('http://httpbin.org/get?data=haha', timeout=1)print(response.read().decode('utf-8')) { &quot;args&quot;: { &quot;data&quot;: &quot;haha&quot; }, &quot;headers&quot;: { &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Python-urllib/3.6&quot; }, &quot;origin&quot;: &quot;14.154.29.216&quot;, &quot;url&quot;: &quot;http://httpbin.org/get?data=haha&quot; } 捕捉异常 123456789import socketimport urllib.requestimport urllib.errortry: response = urllib.request.urlopen('http://httpbin.org/get', timeout=0.1)except urllib.error.URLError as e: if isinstance(e.reason, socket.timeout): print('Time Out') Time Out 响应响应类型 1234567891011import urllib.requestresp = urllib.request.urlopen('http://asahii.cn')print(type(resp))#resp = urllib.request.urlopen('https://www.python.org')#print(type(resp))print(resp.status)print(resp.getheaders())print(resp.getheader('Server')) &lt;class 'http.client.HTTPResponse'&gt; 200 [('Server', 'GitHub.com'), ('Content-Type', 'text/html; charset=utf-8'), ('Last-Modified', 'Sat, 20 Jan 2018 04:10:07 GMT'), ('Access-Control-Allow-Origin', '*'), ('Expires', 'Mon, 22 Jan 2018 13:32:43 GMT'), ('Cache-Control', 'max-age=600'), ('X-GitHub-Request-Id', '71A8:11832:91183A:9A71F6:5A65E5A3'), ('Content-Length', '106'), ('Accept-Ranges', 'bytes'), ('Date', 'Mon, 22 Jan 2018 14:26:04 GMT'), ('Via', '1.1 varnish'), ('Age', '480'), ('Connection', 'close'), ('X-Served-By', 'cache-hnd18748-HND'), ('X-Cache', 'HIT'), ('X-Cache-Hits', '1'), ('X-Timer', 'S1516631164.467386,VS0,VE0'), ('Vary', 'Accept-Encoding'), ('X-Fastly-Request-ID', 'f3adc99bea78d082bc4447a4a04f427731a40dad')] GitHub.com Request构造请求，包括增添一些请求头部信息等。 12345678910111213141516171819from urllib import request, parsereq = urllib.request.Request('http://asahii.cn')resp = urllib.request.urlopen(req)print(resp.read().decode('utf-8'))########################## 分隔线 ##########################url = 'http://httpbin.org/post'headers = { 'User-Agent':'Mozilla/4.0(compatible;MSIE 5.5;Windows NT)', 'Host':'httpbin.org'}dict = { 'name':'Germey'}data = bytes(parse.urlencode(dict), encoding='utf8')req = request.Request(url=url, data=data, headers=headers, method='POST')resp = request.urlopen(req)print(resp.read().decode('utf-8')) &lt;html&gt; &lt;script&gt; window.location.href=&quot;http://blog.csdn.net/asahinokawa&quot; &lt;/script&gt; &lt;/html&gt; { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: {}, &quot;form&quot;: { &quot;name&quot;: &quot;Germey&quot; }, &quot;headers&quot;: { &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Content-Length&quot;: &quot;11&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Mozilla/4.0(compatible;MSIE 5.5;Windows NT)&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;14.154.29.0&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } 1234567891011from urllib import request,parseurl = 'http://httpbin.org/post'dict = { 'name':'China'}data = bytes(parse.urlencode(dict), encoding='utf8')req = request.Request(url=url, data=data, method='POST')req.add_header('User-Agent', 'Mozilla/4.0(compatible;MSIE 5.5;Windows NT)')resp = request.urlopen(req)print(resp.read().decode('utf-8')) { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: {}, &quot;form&quot;: { &quot;name&quot;: &quot;China&quot; }, &quot;headers&quot;: { &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Content-Length&quot;: &quot;10&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Mozilla/4.0(compatible;MSIE 5.5;Windows NT)&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;14.154.28.26&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } Handler设置代理。可以通过来回切换代理，以防止服务器禁用我们的IP。 12345678910import urllib.requestproxy_handler = urllib.request.ProxyHandler({ 'http':'http://127.0.0.1:9743', 'https':'https://127.0.0.1:9743'})opener = urllib.request.build_opener(proxy_handler)resp = opener.open('http://www.baidu.com')print(resp.read()) Cookie相关操作用来维持登录状态。可以在遇到需要登录的网站使用。 12345678# 获取cookieimport http.cookiejar, urllib.requestcookie = http.cookiejar.CookieJar()handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)resp = opener.open('http://www.baidu.com')for item in cookie: print(item.name+&quot;=&quot;+item.value) BAIDUID=417382BEB774A45EA7FC2C374C846E04:FG=1 BIDUPSID=417382BEB774A45EA7FC2C374C846E04 H_PS_PSSID=25639_1446_21107_20930 PSTM=1516632429 BDSVRTM=0 BD_HOME=0 保存cookie到本地文件中 1234567import http.cookiejar, urllib.requestfilename = &quot;cookie.txt&quot;cookie = http.cookiejar.MozillaCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)resp = opener.open('http://www.baidu.com')cookie.save(ignore_discard=True, ignore_expires=True) 另一种cookie保存格式 1234567import http.cookiejar, urllib.requestfilename = &quot;cookie.txt&quot;cookie = http.cookiejar.LWPCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)resp = opener.open('http://www.baidu.com')cookie.save(ignore_discard=True, ignore_expires=True) 加载本地cookie到请求中去。用什么样的方式存cookie，就用什么样的方式去读。 1234567import http.cookiejar, urllib.requestcookie = http.cookiejar.LWPCookieJar()cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)resp = opener.open('http://httpbin.org/get')print(resp.read().decode('utf8')) { &quot;args&quot;: {}, &quot;headers&quot;: { &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Python-urllib/3.6&quot; }, &quot;origin&quot;: &quot;14.154.29.0&quot;, &quot;url&quot;: &quot;http://httpbin.org/get&quot; } 页面请求时的异常处理 12345from urllib import request, errortry: resp = request.urlopen('http://asahii.cn/index.htm')except error.URLError as e: print(e.reason)#可考虑进行重拾 Not Found 详细的错误类型 1234567from urllib import request, errortry: resp = request.urlopen('http://asahii.cn/index.htm')except error.HTTPError as ee: print(ee.reason, ee.code, ee.headers, sep='\\n')except error.URLError as e: print(e.reason) Not Found 404 Server: GitHub.com Content-Type: text/html; charset=utf-8 ETag: &quot;5a62c123-215e&quot; Access-Control-Allow-Origin: * X-GitHub-Request-Id: F758:1D9CC:916D4F:9B5FD5:5A65FE22 Content-Length: 8542 Accept-Ranges: bytes Date: Mon, 22 Jan 2018 15:09:43 GMT Via: 1.1 varnish Age: 148 Connection: close X-Served-By: cache-hnd18733-HND X-Cache: HIT X-Cache-Hits: 1 X-Timer: S1516633784.646920,VS0,VE0 Vary: Accept-Encoding X-Fastly-Request-ID: fb6b42a4706a17c3de8bd318b76be3513b68c49b 加上原因判断 12345678import socketfrom urllib import request, errortry: resp = request.urlopen('http://asahii.cn/index.html', timeout=0.01)except error.URLError as e: print(type(e.reason)) if isinstance(e.reason, socket.timeout): print('TIME OUT') &lt;class 'socket.timeout'&gt; TIME OUT 网页解析解析URL 123456789101112131415from urllib.parse import urlparseresult = urlparse('http://www.baidu.com/index.html;user?id=5#comment')print(type(result), result, sep='\\n')result = urlparse('www.baidu.com/index.html;user?id=5#comment', scheme='https')print(result)result = urlparse('http://www.baidu.com/index.html;user?id=5#comment', scheme='https')print(result)result = urlparse('http://www.baidu.com/index.html;user?id=5#comment', allow_fragments=False)print(result)result = urlparse('http://www.baidu.com/index.html#comment', allow_fragments=False)print(result) &lt;class 'urllib.parse.ParseResult'&gt; ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user', query='id=5', fragment='comment') ParseResult(scheme='https', netloc='', path='www.baidu.com/index.html', params='user', query='id=5', fragment='comment') ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user', query='id=5', fragment='comment') ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user', query='id=5#comment', fragment='') ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html#comment', params='', query='', fragment='') URL拼装 123from urllib.parse import urlunparsedata=['http', 'www.baidu.com', 'index.html', 'user', 'a=6', 'comment']print(urlunparse(data)) http://www.baidu.com/index.html;user?a=6#comment 12345678from urllib.parse import urlencodeparams = { 'name':'germey', 'age':22}base_url = 'http://www.baidu.com?'url = base_url+urlencode(params)print(url) http://www.baidu.com?name=germey&amp;age=22","link":"/2018/06/11/f3af4577337e.html"},{"title":"RestTemplate如何发送带headers的GET请求","text":"需求：发送自定义header的GET请求，header中需要插入一个签名。 发送自定义header的POST请求之前写过一个类似的请求，但是是POST的。这个也摸了一段时间，自己看参数整了出来。代码如下： 12345678910111213// header填充LinkedMultiValueMap&lt;String, String&gt; headers = new LinkedMultiValueMap&lt;&gt;();headers.put(&quot;Content-Type&quot;, Collections.singletonList(&quot;application/json;charset=UTF-8&quot;));headers.put(&quot;signature&quot;, Collections.singletonList(makeSignature(form.getNewMobile())));// body填充JSONObject json = new JSONObject();json.put(&quot;oldMobile&quot;, mobile);json.put(&quot;newMobile&quot;, form.getNewMobile());HttpEntity&lt;String&gt; request = new HttpEntity&lt;String&gt;(json.toString(), headers);// 一个单例的restTemplateRestTemplate restTemplate = HttpInvoker.getRestTemplate();// 发送请求ResponseEntityTemplate.postForEntity(whiteListURL, request, String.class); 很简单的想着，只需要把上面的postForEntity()改成get的就行，但不是这样的。 发送自定义header的GET请求Update: 2019/12/11 从链接学到了一种比较友好的写法： 1234567891011121314private static void getEmployees(){ final String uri = &quot;http://localhost:8080/springrestexample/employees&quot;; RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setAccept(Arrays.asList(MediaType.APPLICATION_JSON)); HttpEntity&lt;String&gt; entity = new HttpEntity&lt;String&gt;(&quot;parameters&quot;, headers); ResponseEntity&lt;String&gt; result = restTemplate.exchange(uri, HttpMethod.GET, entity, String.class); System.out.println(result);} 粗略看了看postForEntity()和getForEntity()这两个方法的实现，都是准备参数，然后调用execute()方法，如下： 123456789101112131415161718// POST@Overridepublic &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException { RequestCallback requestCallback = httpEntityCallback(request, responseType); ResponseExtractor&lt;ResponseEntity&lt;T&gt;&gt; responseExtractor = responseEntityExtractor(responseType); return nonNull(execute(url, HttpMethod.POST, requestCallback, responseExtractor, uriVariables));}// GET@Override@Nullablepublic &lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables) throws RestClientException { RequestCallback requestCallback = acceptHeaderRequestCallback(responseType); HttpMessageConverterExtractor&lt;T&gt; responseExtractor = new HttpMessageConverterExtractor&lt;&gt;(responseType, getMessageConverters(), logger); return execute(url, HttpMethod.GET, requestCallback, responseExtractor, uriVariables);} 区别就在于RequestCallback实例化的时候，传的参数不一样。POST的时候，是将header做为参数传给了RequestCallback。再然后就是execute()中的GET和POST参数不一样。到这个时候，发送自定义header的GET请求，已经很明显了。实例化的函数，都是public的。如果不是public的，或者说我们不能直接访问到，还可以考虑通过反射的方式去调用相关的方法，但这里不需要用反射了。 结果123456789101112// header填充LinkedMultiValueMap&lt;String, String&gt; headers = new LinkedMultiValueMap&lt;&gt;();headers.put(&quot;Content-Type&quot;, Collections.singletonList(&quot;application/json;charset=UTF-8&quot;));headers.put(&quot;signature&quot;, Collections.singletonList(makeSignature(mobile)));// 获取单例RestTemplateRestTemplate restTemplate = HttpInvoker.getRestTemplate();HttpEntity request = new HttpEntity(headers);// 构造execute()执行所需要的参数。RequestCallback requestCallback = restTemplate.httpEntityCallback(request, JSONObject.class);ResponseExtractor&lt;ResponseEntity&lt;JSONObject&gt;&gt; responseExtractor = restTemplate.responseEntityExtractor(JSONObject.class);// 执行execute()，发送请求ResponseEntity&lt;JSONObject&gt; response = restTemplate.execute(apiAddress + &quot;/xxx/whitelist/check?phone=&quot; + mobile, HttpMethod.GET, requestCallback, responseExtractor); 虽然很简单，但是看似不可能，自己却做到了、完成了，就很有成就感。","link":"/2019/01/16/0f02cb67d2f4.html"},{"title":"Rust学习笔记","text":"学习资料📚书单 Rust For Rustaceans The Rust Programming Language, 2nd Edition Programming Rust, 2nd Edition Creative Projects for Rust Programmers 官方资料 The Rust Programming Language - The Rust Programming Language (rust-lang.org) Rust 语言圣经 - Rust语言圣经(Rust Course) 关于 pracitce.rs - Rust By Practice( Rust 练习实践 ) 进阶 - Rust 秘典（死灵书） (purewhite.io) std - Rust 其他 Rust Playground rust-lang/rustlings: Small exercises to get you used to reading and writing Rust code! (github.com) async_task - Rust (docs.rs) smol/examples at master · smol-rs/smol (github.com) 安装12curl https://sh.rustup.rs -sSf | shrustc Hello WorldTab：用4个空格替换； 分号：可要可不要，但 Rust 风格是需要； 代码文件命名：用下划线分割不同单词； 123fn main() { println!(&quot;hello world!&quot;)} 编译与运行 12rustc main.rs./main cargo使用cargo比rustc的优势 依赖管理 编译大型项目 常用命令 cargo new cargo build cargo run cargo check","link":"/2024/12/09/e9036e8500f6.html"},{"title":"Python语法简要概览","text":"很久没用过Python了，熟悉一下用法准备ms。 输入和输出1234&gt;&gt;&gt; var=input('input:')input:sjdf asdkjf 123 adsf ;dfa--..&gt;&gt;&gt; print(var)sjdf asdkjf 123 adsf ;dfa--.. 暂时理解input()读入一行数据，且可以加入提示信息。读入一个整数： 12s = input('birth: ')birth = int(s) 基本注意事项# 注释某行中其后的内容。缩进代替C系列语言中的大括号。大小写敏感。字符串可用''或&quot;&quot;包裹, \\可用于转义。\\n\\t等r’’表示’’内部的字符串默认不转义'''表示多行输入 1234567891011&gt;&gt;&gt; print(r'\\\\\\t\\\\')\\\\\\t\\\\&gt;&gt;&gt; print('''hi... hi... hi... hello,py... ''')hihihihello,py 空值是一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。用全部大写的变量名表示常量。三种除法，//地板除，/整除，得到浮点数，%取余。在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。ord()函数获取字符的整数表示，chr()函数把编码转换为对应的字符。格式化： 1234567891011121314151617&gt;&gt;&gt; 'Hi, %s, you have $%d.' % ('Michael', 1000000)'Hi, Michael, you have $1000000.'``` ## 有意思的数据类型#### list```python&gt;&gt;&gt; fruits = ['apple', 'banana', 'orange']&gt;&gt;&gt; fruits['apple', 'banana', 'orange']&gt;&gt;&gt; len(fruits)3&gt;&gt;&gt; fruits[1]'banana'&gt;&gt;&gt; fruits[6]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range 倒数12345678&gt;&gt;&gt; fruits[-1]'orange'&gt;&gt;&gt; fruits[-2]'banana'&gt;&gt;&gt; fruits[-6]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range append()insert(1, ‘hi’)pop()list中的元素类型可以不同 tuple不可更改的list，声明用()当你定义一个tuple时，在定义的时候，tuple的元素就必须被确定下来。t = (1)定义的是自然数1，要定义成tuple需要加‘,’，规则。t = (‘a’, ‘b’, [‘A’, ‘B’])其中的list是可变的。 dict123456&gt;&gt;&gt; d = {'Michael': 95, 'Bob': 75, 'Tracy': 85}&gt;&gt;&gt; d['Michael']95&gt;&gt;&gt; d['Adam'] = 67&gt;&gt;&gt; d['Adam']67 判断是否存在dict中的两个方法一是通过in判断key是否存在；二是通过dict提供的get()方法，如果key不存在，可以返回None，或者自己指定的value。12345&gt;&gt;&gt; 'Thomas' in dFalse&gt;&gt;&gt; d.get('Thomas')&gt;&gt;&gt; d.get('Thomas', -1)-1 删除用pop(‘Bob’)。 set123s = set([1, 2, 3])s.add(4)s.remove(4) 可以对集合进行&amp;和|操作。 判断&amp;循环if1234567891011121314age = 3if age &gt;= 18: print('adult')elif age &gt;= 6: print('teenager')else: print('kid')s = input('birth: ')birth = int(s)if birth &lt; 2000: print('00前')else: print('00后') for…in可打印list、tuple中的数据。 12345678names = ['Michael', 'Bob', 'Tracy']for name in names: print(name)sum = 0for x in range(101): sum = sum + xprint(sum) while123456sum = 0n = 99while n &gt; 0: sum = sum + n n = n - 2print(sum) break&amp;continue同C系列语言 函数内置函数 abs() int() max() hex() isinstance()函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，相当于给这个函数起了一个“别名”：123&gt;&gt;&gt; a = abs # 变量a指向abs函数&gt;&gt;&gt; a(-1) # 所以也可以通过a调用abs函数1 自定义函数12345def my_abs(x): if x &gt;= 0: return x else: return -x pass什么都不做,作为占位符 返回多个值在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，Python的函数返回多值其实就是返回一个tuple 函数参数 默认参数 123456def power(x, n=2): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 可变参数 12345678def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum&gt;&gt;&gt; nums = [1, 2, 3]&gt;&gt;&gt; calc(*nums)14 *nums表示把nums这个list的所有元素作为可变参数传进去。 关键字参数 1234567891011121314def person(name, age, **kw): print('name:', name, 'age:', age, 'other:', kw)&gt;&gt;&gt; person('Michael', 30)name: Michael age: 30 other: {}&gt;&gt;&gt; person('Bob', 35, city='Beijing')name: Bob age: 35 other: {'city': 'Beijing'}&gt;&gt;&gt; person('Adam', 45, gender='M', job='Engineer')name: Adam age: 45 other: {'gender': 'M', 'job': 'Engineer'}&gt;&gt;&gt; extra = {'city': 'Beijing', 'job': 'Engineer'}&gt;&gt;&gt; person('Jack', 24, city=extra['city'], job=extra['job'])name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'}&gt;&gt;&gt; extra = {'city': 'Beijing', 'job': 'Engineer'}&gt;&gt;&gt; person('Jack', 24, **extra)name: Jack age: 24 other: {'city': 'Beijing', 'job': 'Engineer'} **extra表示把extra这个dict的所有key-value用关键字参数传入到函数的**kw参数，kw将获得一个dict，注意kw获得的dict是extra的一份拷贝，对kw的改动不会影响到函数外的extra 命名关键字参数 命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了。 命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错 12345678910def person(name, age, *, city, job): print(name, age, city, job)&gt;&gt;&gt; person('Jack', 24, city='Beijing', job='Engineer')Jack 24 Beijing Engineerdef person(name, age, *args, city, job): print(name, age, args, city, job)def person(name, age, *, city='Beijing', job): print(name, age, city, job)&gt;&gt;&gt; person('Jack', 24, job='Engineer')Jack 24 Beijing Engineer 限定了kw中的关键字只能为city,job 参数组合参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 支持递归 高级特性切片12345678L = ['Michael', 'Sarah', 'Tracy', 'Bob', 'Jack']L[0:3]L[:3]L[-2:]L[-2:-1]L[:10:2]L[::5]L[:] 迭代12345678910111213141516171819202122232425&gt;&gt;&gt; d = {'a': 1, 'b': 2, 'c': 3}&gt;&gt;&gt; for key in d:... print(key)...abc&gt;&gt;&gt; for k, v in d.items():... print(k,v)...a 1b 2c 3&gt;&gt;&gt; for value in d.values():... print(value)...123&gt;&gt;&gt; for i, value in enumerate(['A', 'B', 'C']):... print(i, value)...0 A1 B2 C 列表生成式12345678910111213&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&gt;&gt;&gt; [m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ']&gt;&gt;&gt; import os # 导入os模块，模块的概念后面讲到&gt;&gt;&gt; [d for d in os.listdir('.')] # os.listdir可以列出文件和目录['.emacs.d', '.ssh', '.Trash', 'Adlm', 'Applications', 'Desktop', 'Documents', 'Downloads', 'Library', 'Movies', 'Music', 'Pictures', 'Public', 'VirtualBox VMs', 'Workspace', 'XCode']&gt;&gt;&gt; d = {'x': 'A', 'y': 'B', 'z': 'C' }&gt;&gt;&gt; [k + '=' + v for k, v in d.items()]['y=B', 'x=A', 'z=C']&gt;&gt;&gt; L = ['Hello', 'World', 'IBM', 'Apple']&gt;&gt;&gt; [s.lower() for s in L]['hello', 'world', 'ibm', 'apple'] 生成器1234567def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return 'done' 函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 小结生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。 把list、dict、str等Iterable变成Iterator可以使用iter()函数： 凡是可作用于for循环的对象都是Iterable类型； 凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列； 集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。 Python的for循环本质上就是通过不断调用next()函数实现的，例如： 123456789101112for x in [1, 2, 3, 4, 5]: pass# 首先获得Iterator对象:it = iter([1, 2, 3, 4, 5])# 循环:while True: try: # 获得下一个值: x = next(it) except StopIteration: # 遇到StopIteration就退出循环 break 函数式编程高阶函数 传入函数12def add(x, y, f): return f(x) + f(y) map/reduce map123456&gt;&gt;&gt; def f(x):... return x * x...&gt;&gt;&gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])&gt;&gt;&gt; list(r)[1, 4, 9, 16, 25, 36, 49, 64, 81] reducereduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 两者综合 12345678from functools import reduceDIGITS = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}def str2int(s): def fn(x, y): return x * 10 + y def char2num(s): return DIGITS[s] return reduce(fn, map(char2num, s)) filter12345678def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15]def not_empty(s): return s and s.strip()list(filter(not_empty, ['A', '', 'B', None, 'C', ' ']))# 结果: ['A', 'B', 'C'] sorted123456&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36]&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)['about', 'bob', 'Credit', 'Zoo']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)['Zoo', 'Credit', 'bob', 'about']","link":"/2017/12/18/13e08688297f.html"},{"title":"SSH使用config管理多个会话配置","text":"参考：https://www.cnblogs.com/zhonghuasong/p/7236989.html最终效果图示如下：这种配置我在虚拟机（固定了IP）CentOS中还尚未成功配置好，每一次都还需要输入密码，原因还没找到，等找到了再把原因贴过来。原文如下： 配置账号与密码大致的配置文件的路径为：~/.ssh/config，内容如下（大小写不敏感）： 使用秘钥登录1identityfile ~/.ssh/keys/id_rsa","link":"/2018/11/22/a5a56d8df187.html"},{"title":"Service 中的几个 port 的区别","text":"Service: This directs the traffic to a pod.TargetPort: This is the actual port on which your application is running inside the container.Port: Some times your application inside container serves different services on a different port. Example: The actual application can run 8080 and health checks for this application can run on 8089 port of the container. So if you hit the service without port it doesn’t know to which port of the container it should redirect the request. Service needs to have a mapping so that it can hit the specific port of the container. 1234567891011121314151617181920212223kind: ServiceapiVersion: v1metadata: name: my-servicespec: selector: app: MyApp ports: - name: http nodePort: 30475 port: 8089 protocol: TCP targetPort: 8080 - name: metrics nodePort: 31261 port: 5555 protocol: TCP targetPort: 5555 - name: health nodePort: 30013 port: 8443 protocol: TCP targetPort: 8085 if you hit the my-service:8089 the traffic is routed to 8080 of the container(targetPort). Similarly, if you hit my-service:8443 then it is redirected to 8085 of the container(targetPort). But this myservice:8089 is internal to the kubernetes cluster and can be used when one application wants to communicate with another application. So to hit the service from outside the cluster someone needs to expose the port on the host machine on which kubernetes is running so that the traffic is redirected to a port of the container. This is node port(port exposed on the host machine). From the above example, you can hit the service from outside the cluster(Postman or any rest-client) by host_ip:nodePort Say your host machine ip is 10.10.20.20 you can hit the http, metrics, health services by 10.10.20.20:30475, 10.10.20.20:31261, 10.10.20.20:30013. Edits: Edited as per Raedwald comment.","link":"/2023/06/12/6352c36d7c20.html"},{"title":"Service使用笔记","text":"看过好几回了，但是还是好像每次都忘，可能是用得少，但是工作中看的一些源代码中用的太多了，可是每次用的时候都看一遍，有点浪费时间，还是自己做一个简单的总结，这样可能以后会快一些。 这篇在草稿箱里实在是存太久了。。。 Service的分类 启动型通过调用startService() 启动，一旦启动，服务即可在后台无限期运行，即使启动服务的组件已被销毁也不受影响。 已启动的服务通常是执行单一操作，而且不会将结果返回给调用方。 绑定型通过调用bindService() 绑定到服务，服务即处于“绑定”状态。绑定服务提供了一个客户端-服务器接口，允许组件与服务进行交互、发送请求、获取结果，甚至是利用进程间通信 (IPC) 跨进程执行这些操作。 仅当与另一个应用组件绑定时，绑定服务才会运行; 多个组件可以同时绑定到该服务，但全部取消绑定后，该服务即会被销毁。 服务在其托管进程的主线程中运行，它既不创建自己的线程，也不在单独的进程中运行（除非另行指定）。 Service的生命周期因为其分两类,所以它的生命周期也有两种: 左边为启动型, 右边为绑定型. Service在清单文件中的属性 android:exported: 顾名思义,是否可以被导出,即是否可以被绑定用做服务端. false:确保服务仅适用于您的应用.true: 与false相反. 请始终使用显式 Intent 启动或绑定 Service，且不要为服务声明 Intent 过滤器。 启动型Service继承Service若使用这种方法,则需要注意一个问题,那就是**Service默认的线程是主线程**, 不要在其中做耗时的事情. 继承IntentService使用这种方法, 就不需要担心线程的问题.因为其做为一个对Service的简单封装,它内部已经将所有的事件都放在了子线程中.不妨对其做一个简单的分析来加深对Service的理解. 12345678910@Overridepublic void onCreate() { super.onCreate(); HandlerThread thread = new HandlerThread(&quot;IntentService[&quot; + mName + &quot;]&quot;); thread.start(); mServiceLooper = thread.getLooper(); mServiceHandler = new ServiceHandler(mServiceLooper);} 在其onCreate()中,将开启一个初始化好Looper的子线程. 并为这个Looper的消息队列添加一个Handler. 123456789101112131415//IntentService.javaprivate final class ServiceHandler extends Handler { public ServiceHandler(Looper looper) { super(looper); } @Override public void handleMessage(Message msg) { onHandleIntent((Intent)msg.obj); stopSelf(msg.arg1); }}@WorkerThreadprotected abstract void onHandleIntent( @Nullable Intent intent); 其中的Handler用来处理在这个子线程中的事务,其中的onHandleIntent()正是我们在继承IntentService时所需要实现的一个方法, 也就是说我们在其中写的方法都是在子线程中执行. 12345678910111213141516171819@Overridepublic void onStart(@Nullable Intent intent, int startId) { Message msg = mServiceHandler.obtainMessage(); msg.arg1 = startId; msg.obj = intent; mServiceHandler.sendMessage(msg);}/** * You should not override this method for your IntentService. Instead, * override {@link #onHandleIntent}, which the system calls when the IntentService * receives a start request. * @see android.app.Service#onStartCommand */@Overridepublic int onStartCommand(@Nullable Intent intent, int flags, int startId) { onStart(intent, startId); return mRedelivery ? START_REDELIVER_INTENT : START_NOT_STICKY;} onStart()并没有太大的意义，只是一个普通的函数，重要的是它里面做的事情。它将从onStartCommand()里面得到的intent，通过message传递给handler，然后再是自己，对不同intent的处理。 对onStartCommand()的返回值，有下面三种： START_NOT_STICKY如果系统在 onStartCommand() 返回后终止服务，则除非有挂起 Intent 要传递，否则系统不会重建服务。这是最安全的选项，可以避免在不必要时以及应用能够轻松重启所有未完成的作业时运行服务。 START_STICKY如果系统在 onStartCommand() 返回后终止服务，则会重建服务并调用 onStartCommand()，但不会重新传递最后一个 Intent。相反，除非有挂起 Intent 要启动服务（在这种情况下，将传递这些 Intent ），否则系统会通过空 Intent 调用 onStartCommand()。这适用于不执行命令、但无限期运行并等待作业的媒体播放器（或类似服务）。 START_REDELIVER_INTENT如果系统在 onStartCommand() 返回后终止服务，则会重建服务，并通过传递给服务的最后一个 Intent 调用 onStartCommand()。任何挂起 Intent 均依次传递。这适用于主动执行应该立即恢复的作业（例如下载文件）的服务。 如何停止启动服务必须管理自己的生命周期。也就是说，除非系统必须回收内存资源，否则系统不会停止或销毁服务，而且服务在 onStartCommand() 返回后会继续运行。因此，服务必须通过调用stopSelf() 自行停止运行，或者由另一个组件通过调用 stopService() 来停止它。一旦请求使用 stopSelf() 或 stopService() 停止服务，系统就会尽快销毁服务。 http://blog.csdn.net/baidu_31405631/article/details/52469093 绑定型Service对于此种类型的，感觉自己用得到的地方并不是很多，但是要能够看得懂这这种类型的Service的代码，尤其是AIDL，在Android中非常常见。 AIDL的大致使用步骤如下： 编写包含接口的aidl文件，make project，生成同名的java文件 AIDL是一种可跨进程的，就是说可以在进程A中，调用进程B中的方法，所以要首先要实现该方法类。实现其中的方法，只需要继承同名java文件中的Stub类，并实现其中的方法，即可。","link":"/2018/04/08/3ddbaba2d194.html"},{"title":"Set的常用实现类源码分析","text":"Set的实现基本上是依靠于相应的Map实现，从某种意义上来说，了解Set，只需要去分析相应的Map就可以了。 Set实现类的继承关系图 HashSet 源码简要分析翻开源码我们我可以清楚地看到HashSet中有一个变量map，它的类型是HashMap。不难想到，HashMap的键值是一个不可重复的集合，它恰好可以作为一个Set，也不难理解为什么要叫HashSet。 12345private transient HashMap&lt;E,Object&gt; map;public HashSet() { //在构造方法中，new一个HaskMap对象 map = new HashMap&lt;&gt;();} 在HashSet中，总共有5个构造方法（包括上面的构造方法）。在其他的构造方法中，也同样是new一个HashMap或LinkedHashMap。 使用HashMap的场景 12345678910public HashSet(Collection&lt;? extends E&gt; c) { map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);}public HashSet(int initialCapacity, float loadFactor) { map = new HashMap&lt;&gt;(initialCapacity, loadFactor);}public HashSet(int initialCapacity) { map = new HashMap&lt;&gt;(initialCapacity);} 使用LinkedHashMap的场景 123HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);} 增删改查 基本上是调用HashMap所对应的操作方法。增加元素的时候，值传PRESENT给HashMap。 1234567891011121314151617181920212223// 用来充当Map键值对中的值private static final Object PRESENT = new Object();public boolean contains(Object o) { return map.containsKey(o);}public boolean add(E e) {// 值传PRESENT return map.put(e, PRESENT)==null;}public boolean remove(Object o) { return map.remove(o)==PRESENT;}public boolean isEmpty() { return map.isEmpty();}public int size() { return map.size();}public Iterator&lt;E&gt; iterator() { return map.keySet().iterator();}public void clear() { map.clear();} 从整体上面来看，HashSet是对HashMap的二次封装。关键还是在于HashMap的实现之上。 LinkedHashSet 源码简要分析它的所有方法以及成员变量如下图所示：LinkedHashSet继承自HashSet。因此它是一个对HashSet的再次封装。它有5个函数，4个是构造函数。而且这些构造函数都将调用HashSet中的HashSet(int initialCapacity, float loadFactor, boolean dummy) 方法。如下： 12345678910111213public LinkedHashSet(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor, true);}public LinkedHashSet(int initialCapacity) { super(initialCapacity, .75f, true);}public LinkedHashSet() { super(16, .75f, true);}public LinkedHashSet(Collection&lt;? extends E&gt; c) { super(Math.max(2*c.size(), 11), .75f, true); addAll(c);} TreeSet 源码简要分析先再来单独看看其继承关系：再来看其构造函数与重要的成员变量： 123456789101112131415161718// 应该与上面的HashSet类似，用来存储private transient NavigableMap&lt;E,Object&gt; m;// 应该是用来填充键值对中的值private static final Object PRESENT = new Object();// 这个方法对我们来说不可见TreeSet(NavigableMap&lt;E,Object&gt; m) { this.m = m;}public TreeSet() { this(new TreeMap&lt;E,Object&gt;());}public TreeSet(Comparator&lt;? super E&gt; comparator) { this(new TreeMap&lt;&gt;(comparator));}public TreeSet(Collection&lt;? extends E&gt; c) { this(); addAll(c);} 从4个构造方法中，我们可以大致看出，这个NavigableMap是一个接口，而TreeMap实现了此接口，并在此处为元素的实际存储载体。 增删改查方面，TreeSet与HashSet的实现类似: 12345678910111213public int size() { return m.size();}public boolean isEmpty() { return m.isEmpty();}public boolean contains(Object o) { return m.containsKey(o);}public boolean add(E e) { return m.put(e, PRESENT)==null;}//后续不再列举... 后记Set 相关的源码基本对应这样的一个关系：XxxSet 需要去学习、研究 XxxMap。 相关 Map 的分析待后续文章分析、记录。","link":"/2018/06/05/743343ad8129.html"},{"title":"Spinnaker orca 禁止流水线并发执行的 bug 修复记录","text":"orca 是 Spinnaker 这个开源 CD 服务的心脏模块，负责 CD 流水线的编排、执行，是大脑一般的存在。 在 Spinnaker 这个产品中，每次部署操作都可以抽象成一条 流水线，当 流水线 触发时，会产生一次 执行。当该 流水线 已存在一次正在运行中的 执行 时，新的 执行 是否能够执行，取决于 流水线 中的一个配置项：limitConcurrent。 当此选项为 true 时，新的 执行 将进入等待状态，待正在运行的 执行 完成后，才会继续执行；当次选项为 false 时，新的 执行 将立刻执行 用法 &amp; 产生此问题的前提在 coding.net 的部署控制台中，点击应用，进入流水线编辑，在基础配置中： 勾选 禁止本流程并行执行 选项，打钩则意味着同一时间一个流水线只能有一个执行在运行。 勾选 不要自动取消在排队状态的部署执行任务，如果由于勾选 禁止本流程并行执行 而产生的处于排队等待状态的执行，不会被自动取消，直至进入运行状态或手动取消。 现象流水线在多次触发后，由于禁止本流程并行执行，所以有一些 执行 进入等待状态 但当正在运行的 执行 跑完后，后触发的 执行 并未进入运行状态，一直处于等待中。 此时如果再触发一次流水线 可以看到最新的一次执行完成后，之前处于等待状态的执行进入了运行中的状态。 原因禁止并发执行依赖于 Redis 中一个叫做 orca.pipeline.queue.${pipeline_config_id} 的 key，它是 list 类型，其中存储的内容（部分）是 StartExecution 类型的 Message，如下： 该 list 在 orca 代码中主要由 PendingExecutionService 来操作。主要涉及下面两个操作： enqueue（左入，头插） popOldest（右出，尾取） 往该 list 存东西的时机只有 2 处： 其中在 startExecution 时，会判断 如果禁用并行执行 &amp; 该流水线有在执行的 execution ，如果满足要求，就会安排入队，其中入队的信息是 StartExecution Message。 12345678910111213141516override fun handle(message: StartExecution) { message.withExecution { execution -&gt; if (execution.status == NOT_STARTED &amp;&amp; !execution.isCanceled) { if (execution.shouldQueue()) { execution.pipelineConfigId?.let { log.info(&quot;Queueing {} {} {}&quot;, execution.application, execution.name, execution.id) pendingExecutionService.enqueue(it, message) } } else { start(execution) } } else { terminate(execution) } }} 这里的 enqueue 不会做任何校验，会直接入队。 12345override fun enqueue(pipelineConfigId: String, message: Message) { pool.resource.use { redis -&gt; redis.lpush(listName(pipelineConfigId), mapper.writeValueAsString(message)) }} 如果存在两个一模一样的 StartExecution 被送到 StartExectionHandler 执行，那么就会入队两次。 往该 list 中取东西的时机只有 1 处，即在 StartWaitingExecutionsHandler 中，如下： 123456override fun popOldest(pipelineConfigId: String): Message? = pool.resource.use { redis -&gt; redis .rpop(listName(pipelineConfigId)) ?.let { mapper.readValue(it) } } StartWaitingExecutions Message 被插入 Redis 中的时机主要看 CompleteExecutionHandler 中，如下： 也就是说，当一次 execution 完成后，会尝试执行因并发策略而排队的执行。 至此，完整的逻辑链路梳理完毕。 客户问题日志验证此次 execution 01FSC58BRQW5GH19AM8D45SN9E，用户等待了 30min 以上，再真正被执行，期间还进行了多次触发。此次 execution 的日志如下： 可以看出此次 execution 在 2022-01-14 19:23:39 被提交，但在 2022-01-14 19:23:41 之后，就再也没有任何动静了，直到 2022-01-14 20:00:54 才真正执行。提交后没有动静，是因为此时有流水线正在执行。可以看到查询数据库获得此时的执行记录如下： 按照前面的逻辑，当正在执行的 execution 完成后，会依次执行排队在中的 execution，直到此次 execution 01FSC58BRQW5GH19AM8D45SN9E。但是可以观察到，在此次 execution 01FSC58BRQW5GH19AM8D45SN9E 的前面，有 3 次 execution，其中出现异常的是第 2 次，即 01FSC3YKGFYX68X2DDXT3W9MD6，它在 2022-01-14 19:45:49 执行完之后，并没有去执行后续队列中的 execution，直到 2022-01-14 19:59:52 开始了一次新的 execution 01FSC7AMB7SDMT3KE2SNER4KBT，注意它是用户在发现很久没有触发后，再一次手动触发的。它触发完成后，才轮到 01FSC58BRQW5GH19AM8D45SN9E 执行，此时已过去 30 min 多。 出现问题的 execution 可以通过日志发现他被入队了两次。 可以从上面的代码中发现，只要是打了 Queueing xxx 日志的地方，那次 execution 一定会入队。所以出现两次，会入队两次。且上面的日志，来自于两个不同的 pod。 为啥不能入队两次假设入队了两次，就会在获取到第一个消息时，成功/失败执行该 execution，等到该 execution 执行失败后，会再次从该队列中去取，取到了，但是是同一个流水线，且启动流水线时，对流水线的状态时有要求的，正常执行需要 execution.status == NOT_STARTED &amp;&amp; !execution.isCanceled 即： 12345678910111213141516override fun handle(message: StartExecution) { message.withExecution { execution -&gt; if (execution.status == NOT_STARTED &amp;&amp; !execution.isCanceled) { if (execution.shouldQueue()) { execution.pipelineConfigId?.let { log.info(&quot;Queueing {} {} {}&quot;, execution.application, execution.name, execution.id) pendingExecutionService.enqueue(it, message) } } else { start(execution) } } else { terminate(execution) } }} 如果不满足状态要求，会执行终止该 execution，即： 123456789101112private fun terminate(execution: Execution) { if (execution.status == CANCELED || execution.isCanceled) { publisher.publishEvent(ExecutionComplete(this, execution.type, execution.id, execution.status)) execution.pipelineConfigId?.let { queue.push(StartWaitingExecutions(it, purgeQueue = !execution.isKeepWaitingPipelines)) } } else { log.warn(&quot;Execution (type: ${execution.type}, id: {}, status: ${execution.status}, application: {})&quot; + &quot; cannot be started unless state is NOT_STARTED. Ignoring StartExecution message.&quot;, value(&quot;executionId&quot;, execution.id), value(&quot;application&quot;, execution.application)) } 这里最主要的问题是不会再从 orca.pipeline.queue.${pipeline_config_id} 中取，也就是说，如果队列中还有排队的 execution，将得不到执行。所以可以从日志中看到，01FSC3YKGFYX68X2DDXT3W9MD6 执行完成后，又从队列中取到了一模一样的消息，再次启动该流水线时发现状态不符合要求，也不再执行等待队列中的其他 execution。 修复思路在尝试启动排队的 execution 时，对该 execution 的状态做判断，不满足要求，直接 push(StartWaitExecution)，此时，后续的执行又会从 StartWaitExecutionHandler 的入口开始，类似于一个 for 循环；满足要求的 execution，直接 push(StartExecution)，尝试执行下一个 execution。 修复后的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Componentclass StartWaitingExecutionsHandler( override val queue: Queue, override val repository: ExecutionRepository, private val pendingExecutionService: PendingExecutionService) : OrcaMessageHandler&lt;StartWaitingExecutions&gt; { private val log: Logger get() = LoggerFactory.getLogger(javaClass) override val messageType = StartWaitingExecutions::class.java override fun handle(message: StartWaitingExecutions) { if (message.purgeQueue) { // when purging the queue, run the latest message and discard the rest pendingExecutionService.popNewest(message.pipelineConfigId) .also { _ -&gt; pendingExecutionService.purge(message.pipelineConfigId) { purgedMessage -&gt; when (purgedMessage) { is StartExecution -&gt; { log.info(&quot;Dropping queued pipeline {} {}&quot;, purgedMessage.application, purgedMessage.executionId) queue.push(CancelExecution(purgedMessage)) } is RestartStage -&gt; { log.info(&quot;Cancelling restart of {} {}&quot;, purgedMessage.application, purgedMessage.executionId) // don't need to do anything else } } } } } else { // when not purging the queue, run the messages in the order they came in pendingExecutionService.popOldest(message.pipelineConfigId) } ?.let { when (it) { is StartExecution -&gt; { try { val startedExecution: Execution = repository.retrieve(it.executionType, it.executionId) if (startedExecution.status != ExecutionStatus.NOT_STARTED || startedExecution.isCanceled) { log.info( &quot;Dropping queued pipeline {} {}, because its status was {}, which can not be stated&quot;, startedExecution.application, startedExecution.id, startedExecution.status ) queue.push(message) return } } catch (enfe: ExecutionNotFoundException) { log.debug(&quot;queued pipeline {} {} not found, and can be started later&quot;, it.application, it.executionId) } } } // spoiler, it always is! if (it is ExecutionLevel) { log.info(&quot;Starting queued pipeline {} {} {}&quot;, it.application, it.executionId) } queue.push(it) } }}","link":"/2022/04/20/beca913cb6e2.html"},{"title":"SmartRefreshLayout使用记录","text":"之前在简书上面的一篇文章，挪到CSDN上来。 前言此开源控件高度省力、美观，理应不会有太多的问题。奈何该项目的主页上面的说明并不能满足我的需求，因此大致翻看了其中的源码，得到了满足自己需求的用法。因此特意地记录下来自己对其的理解，算是对此控件使用的一个小小笔记吧。 需求所涉及的需求很简单，也是非常常见的一种用法。下拉刷新，刷新完毕之后关闭刷新动画。 开始分析为了达到这个小小的需求，首先翻看了其的说明文件。并没有与我的需求对应的说明，其上的说明也没有详细说明每个函数的更多用法，多的只是一笔带过的感觉。也许是作者相信我们的能力吧！这一番得到的结果是： autoRefresh()应该可以让刷新的动画显示；finishRefresh()应该可以让正在显示的刷新动画停止并消失；下拉刷新类似。 可以通过SmartRefreshLayout.setDefaultRefreshFooterCreater()设置默认的刷新时的动画；下拉加载类似。除此之外，还可以通过其的setRefreshHeader()方法，来设置；下拉加载类似。 可以通过setOnRefreshListener设置监听事件。这是说明中给的一段代码：12345678910111213RefreshLayout refreshLayout = (RefreshLayout)findViewById(R.id.refreshLayout);refreshLayout.setOnRefreshListener(new OnRefreshListener() { @Override public void onRefresh(RefreshLayout refreshlayout) { refreshlayout.finishRefresh(2000); }});refreshLayout.setOnLoadmoreListener(new OnLoadmoreListener() { @Override public void onLoadmore(RefreshLayout refreshlayout) { refreshlayout.finishLoadmore(2000); }}); 但是当时并没有仔细看这个，才导致了我后来使用时有点摸不着方向啊！其实在使用过程中对此也是有疑问的，这个监听事件到底是什么时候触发的？所以接下来的一段曲折的经历都是基于此上，谁让我没仔细看这个代码~ 其实我一直以为在onRefresh中调用的是finishRefresh()，onLoadMore()中调用的是finishLoadmore()， 所以这根本就说不通啊，啥时候触发这监听事件的都不知道。 由一个小小的不仔细引发的旅程 虽然缘由是无厘头的，但是我喜欢接下来的这个过程。 首先，从autoRefresh()看起 这个函数的用法到底是怎么样的？它到底是用来干什么的？为了回答自己心中的这个问题，只能习惯性地按着Ctrl点开这个函数。 开源库中的源码为： 1234567/** * 自动刷新 */@Overridepublic boolean autoRefresh() { return autoRefresh(400);} 这个400是什么，看了这个兄弟函数之后，发现是delay，也就是延迟。为啥要这个？很是疑惑，但是心中想到的也就是，在过完了400/1000秒之后，可能会显示刷新的动画吧。接着看， 1234567/** * 自动刷新 */@Overridepublic boolean autoRefresh(int delayed) { return autoRefresh(delayed, 1f * (mHeaderHeight + mHeaderExtendHeight / 2) / mHeaderHeight);} 大致的意思也就是，说句实话不太想知道这个到底是干啥的，感觉与我想知道的无关。接着看， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 * 自动刷新 */@Overridepublic boolean autoRefresh(int delayed, final float dragrate) { if (mState == RefreshState.None &amp;&amp; mEnableRefresh) { if (reboundAnimator != null) { reboundAnimator.cancel(); } Runnable runnable = new Runnable() { @Override public void run() { reboundAnimator = ValueAnimator.ofInt(mSpinner, (int) (mHeaderHeight * dragrate)); reboundAnimator.setDuration(mReboundDuration); reboundAnimator.setInterpolator(new DecelerateInterpolator()); reboundAnimator.addUpdateListener(new AnimatorUpdateListener() { @Override public void onAnimationUpdate(ValueAnimator animation) { moveSpinner((int) animation.getAnimatedValue(), false); } }); reboundAnimator.addListener(new AnimatorListenerAdapter() { @Override public void onAnimationStart(Animator animation) { mLastTouchX = getMeasuredWidth() / 2; setStatePullDownToRefresh(); } @Override public void onAnimationEnd(Animator animation) { reboundAnimator = null; if (mState != RefreshState.ReleaseToRefresh) { setStateReleaseToRefresh(); } overSpinner(); } }); reboundAnimator.start(); } }; if (delayed &gt; 0) { reboundAnimator = new ValueAnimator(); postDelayed(runnable, delayed); } else { runnable.run(); } return true; } else { return false; }} 中间一大堆是初始化了一个Runnable对象，关键的代码在下面： 123456if (delayed &gt; 0) { reboundAnimator = new ValueAnimator(); postDelayed(runnable, delayed);} else { runnable.run();} 如果delayed是小于等于0的数，就直接运行刚才初始化的Runnable对象的run()方法。否则又看到了delayed，很明显，小于等于0就会直接执行Runnable对象的run()，也就是会立刻显示刷新动画。因此只需要调用autoRefresh(0)方法，便可立刻开启刷新动画。抱着试试看的心态，好奇地点开了当delayed大于0时会执行的postDelayed()。源码如下： 123456789@Overridepublic boolean postDelayed(Runnable action, long delayMillis) { if (handler == null) { mDelayedRunables = mDelayedRunables == null ? new ArrayList&lt;DelayedRunable&gt;() : mDelayedRunables; mDelayedRunables.add(new DelayedRunable(action, delayMillis)); return false; } return handler.postDelayed(new DelayedRunable(action), delayMillis);} 果然将Runnable对象交给了handler，然后是handler进行的一些延时执行的操作。至此，autoRefresh()的用法便了然于心。 再者，finishRefresh()是到底干啥的？它竟然和上者基本上是同样的套路！了然！ 那么，setOnRefreshListener到底是个什么??在阅读该项目的WiKi时，看见过默认3秒的说法。可是，我了解到的是，持续3秒，没办法实现啊！我了解到的是，延迟3秒之后再进行某个操作啊！ 突然，翻到了源码中的一段代码，一语惊醒梦中人： 12345678910111213141516if (mRefreshListener == null) { mRefreshListener = new OnRefreshListener() { @Override public void onRefresh(RefreshLayout refreshlayout) { refreshlayout.finishRefresh(3000); } };}if (mLoadmoreListener == null) { mLoadmoreListener = new OnLoadmoreListener() { @Override public void onLoadmore(RefreshLayout refreshlayout) { refreshlayout.finishLoadmore(2000); } };} 如果监听事件为空，也就是我们没有设置默认的监听事件，那么它就会为我们创建一个监听事件，而且执行的是3000，这不就是3秒吗！所以啊，原来这个监听事件就是下拉的时候就会触发的啊。等等， 这不是finishRefresh()吗？就是延迟3秒钟之后，关闭刷新动画的显示。那么，也就是说，autoRefresh()就只会（延迟）开启动画咯。我还特意去验证了，真是可爱?。突然间看到了说明中的那段设置监听事件的代码，瞬间笑得哭了起来。 结论所以，如果设置监听事件的话，并且它为空的话，那么就会一直显示刷新动画。因此，我只需要在开启刷新动画之后，在其中的监听事件的某个时间点关闭刷新动画即可！坑了我的人就只有自己啊！为自己的一时sb买单。附上成功地完成了需求之后的动图：","link":"/2018/05/04/646a784dbfca.html"},{"title":"SpringBoot上传文件失败报The temporary upload location xxx is not valid","text":"现象上传文件接口并没有问题，突然有一天上传文件失败，查看日志提示抛出异常，原因为The temporary upload location xxx is not valid。 分析都明白，上传文件的时候，会先上传到Tomcat建的某个目录下，现在这个目录不见了。貌似之前清除了/tmp目录。到/tmp目录下面，并没有找到xxx文件夹。因此新增一个xxx目录或重新启动该服务可以解决此问题。还有一种办法，从网上找的，大致的思想就是指定一个目录，然后上传文件的时候，临时存在在此处。 指定目录123456 @Bean MultipartConfigElement multipartConfigElement() { MultipartConfigFactory factory = new MultipartConfigFactory(); factory.setLocation(&quot;/data/tmp&quot;); return factory.createMultipartConfig();} 参考：http://wuzhaoyang.me/2017/06/07/spring-multipartexception-location-not-valid.html","link":"/2019/03/31/e7def79eb9d6.html"},{"title":"Spring Data Mongo DB去掉插入的_class字段分析","text":"大致的框架是从网上找来的资源。但是遇到了两个问题： 运行代码后，MongoDB数据库没有收到改变。想起了在yaml中配置的mongodb参数，那些参数，data的上一层是spring，如下：spring boot在加载这些数据时，会得到一个MongoProperties。按住Ctrl，然后点在那些值上，然后点进去后，就出来了。该类的属性如下：所以Spring Boot的加载过程中，会产生这样一个bean，通过注入的方式，拿到该类，便可以拿到相应的mongo db配置。再通过一定的分析，将配置信息传给自定义的MongoTemplate。 其中使用@Deprecated方法。这里换成了其中的没有@Deprecated的构造方法。 先给出可以忽略掉_class字段的配置如下： 12345678910111213141516171819@Configurationpublic class SpringMongoConfig { @Autowired public MongoProperties mongoProperties; public @Bean MongoDbFactory mongoDbFactory() throws Exception { // MongoClientURI uri = new MongoClientURI(&quot;mongodb://&quot;+mongoProperties.getUsername()+&quot;:&quot;+new String(mongoProperties.getPassword())+&quot;@&quot;+mongoProperties.getHost()+&quot;/&quot;+mongoProperties.getDatabase()); return new SimpleMongoDbFactory(mongoProperties.createMongoClient(null, null), mongoProperties.getDatabase()); } public @Bean MongoTemplate mongoTemplate() throws Exception { //remove _class MappingMongoConverter converter = new MappingMongoConverter(new DefaultDbRefResolver(mongoDbFactory()), new MongoMappingContext()); converter.setTypeMapper(new DefaultMongoTypeMapper(null)); return new MongoTemplate(mongoDbFactory(), converter); }} 从源代码去分析这个过程从save()开始： 1234567891011121314151617181920212223242526272829303132333435// 从MongoTemplate的save方法开始public void save(Object objectToSave) { Assert.notNull(objectToSave, &quot;Object to save must not be null!&quot;); save(objectToSave, determineEntityCollectionName(objectToSave));}// 获取到集合的名字后，再存储public void save(Object objectToSave, String collectionName) { Assert.notNull(objectToSave, &quot;Object to save must not be null!&quot;); Assert.hasText(collectionName, &quot;Collection name must not be null or empty!&quot;); MongoPersistentEntity&lt;?&gt; mongoPersistentEntity = getPersistentEntity(objectToSave.getClass()); // No optimistic locking -&gt; simple save if (mongoPersistentEntity == null || !mongoPersistentEntity.hasVersionProperty()) { doSave(collectionName, objectToSave, this.mongoConverter); return; } doSaveVersioned(objectToSave, mongoPersistentEntity, collectionName);}// 存储的主要步骤protected &lt;T&gt; void doSave(String collectionName, T objectToSave, MongoWriter&lt;T&gt; writer) { maybeEmitEvent(new BeforeConvertEvent&lt;T&gt;(objectToSave, collectionName)); assertUpdateableIdIfNotSet(objectToSave); // 加上_class的语句在这里 DBObject dbDoc = toDbObject(objectToSave, writer); // 执行词语后，debug显示的数据如下图 maybeEmitEvent(new BeforeSaveEvent&lt;T&gt;(objectToSave, dbDoc, collectionName)); Object id = saveDBObject(collectionName, dbDoc, objectToSave.getClass()); populateIdIfNecessary(objectToSave, id); maybeEmitEvent(new AfterSaveEvent&lt;T&gt;(objectToSave, dbDoc, collectionName));} 执行toDbObject(objectToSave, writer);后，debug显示的数据如下：所以继续toDbObject(objectToSave, writer);里面走：所以进入MappingMongoConverter的write(final Object obj, final DBObject dbo)方法： 123456789101112131415161718public void write(final Object obj, final DBObject dbo) { if (null == obj) { return; } Class&lt;?&gt; entityType = obj.getClass(); boolean handledByCustomConverter = conversions.getCustomWriteTarget(entityType, DBObject.class) != null; TypeInformation&lt;? extends Object&gt; type = ClassTypeInformation.from(entityType); // typeMapper在MappingMongoConverter的构造函数中初始化 if (!handledByCustomConverter &amp;&amp; !(dbo instanceof BasicDBList)) { typeMapper.writeType(type, dbo); } Object target = obj instanceof LazyLoadingProxy ? ((LazyLoadingProxy) obj).getTarget() : obj; writeInternal(target, dbo, type);} 与typeMapper初始化相关的代码如下：因此，打开DefaultMongoTypeMapper，找到writeType方法，但是发现并没有，所以从它的父类DefaultTypeMapper&lt;DBObject&gt;中找。再看accessor.writeTypeTo()。这里的accessor在该类初始化的构造器中就已经被初始化，所以我们可以从继承该类的子类DefaultMongoTypeMapper中找到该类的实现，这里的accessor就是DefaultMongoTypeMapper的一个静态内部类。这个时候，再回想一下之前的修改，有一种豁然开朗的感觉，哈哈。","link":"/2018/11/10/e37c525d3ae8.html"},{"title":"SpringBoot中全局异常的捕获与包装","text":"@ControllerAdvice从Spring3.2开始，引入了一个叫做@ControllerAdvice的注解，这个注解用来编写含有 @ExceptionHandler, @InitBinder, or @ModelAttribute这三个注解的类。官方文档注释如下：这个注解有几个参数，可以用来限定该类对哪些Controller起作用：所以比起上面的参数，我们更需要关心的是被该注解注解过得类里面的其他三个注解。 @ExceptionHandler当Controller捕捉到异常后，若异常类型匹配，将执行被该注解注解的方法。其中，value值为异常的类型，表示该注解处理该类型，如下：该被注解方法的入参和出参： 实践项目中使用到的编码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@ControllerAdvicepublic class ExceptionHandle { public static final Logger logger = LoggerFactory.getLogger(ExceptionHandle.class); private static final Map&lt;String, String&gt; EMPTY_DATA = new HashMap&lt;&gt;(); @ResponseBody @ExceptionHandler(value = Exception.class) // 处理所有异常 public JsonView exceptionGet(Exception e) { logger.error(&quot;Exception for handle &quot;, e); // 自定义类，项目中用作API统一响应模板 JsonView jsonView; if (e instanceof ApplicationException) { // 项目中用到的自定义异常 jsonView = new JsonView(); jsonView.setData(EMPTY_DATA); ApplicationException applicationException = (ApplicationException) e; jsonView.setCode(applicationException.getRetStub().getCode()); jsonView.setMessage(applicationException.getRetStub().getMsg()); } else if (e instanceof ConstraintViolationException) { ConstraintViolationException applicationException = (ConstraintViolationException) e; Set&lt;ConstraintViolation&lt;?&gt;&gt; violations = applicationException.getConstraintViolations(); StringBuilder stringBuilder = new StringBuilder(); for (ConstraintViolation&lt;?&gt; item : violations) { stringBuilder.append(&quot;[&quot; + item.getMessage() + &quot;]&quot;); } String msg = stringBuilder.toString(); logger.error(&quot;ConstraintViolation msg is : &quot; + msg); jsonView = new JsonView(SysStubInfo.PARAMETER_TYPE_INVALID, msg, EMPTY_DATA); } else if (e instanceof MethodArgumentNotValidException) { MethodArgumentNotValidException applicationException = (MethodArgumentNotValidException) e; List&lt;ObjectError&gt; allErrors = applicationException.getBindingResult().getAllErrors(); StringBuilder stringBuilder = new StringBuilder(); for (ObjectError error : allErrors) { stringBuilder.append(&quot;[&quot; + error.getDefaultMessage() + &quot;]&quot;); } String msg = stringBuilder.toString(); logger.error(&quot;ArgumentNotValid msg is : &quot; + msg); jsonView = new JsonView(SysStubInfo.PARAMETER_TYPE_INVALID, msg, EMPTY_DATA); } else if (e instanceof MissingServletRequestParameterException) { MissingServletRequestParameterException applicationException = (MissingServletRequestParameterException) e; String parameterName = applicationException.getParameterName(); String parameterType = applicationException.getParameterType(); StringBuilder stringBuilder = new StringBuilder(); stringBuilder .append(&quot;parameter &quot; + parameterName + &quot; is null &quot; + &quot; , expect: &quot; + parameterType); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.PARAMETER_IS_NULL, msg, EMPTY_DATA); } else if (e instanceof HttpMediaTypeNotSupportedException) { HttpMediaTypeNotSupportedException applicationException = (HttpMediaTypeNotSupportedException) e; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(applicationException.getContentType().getSubtype()); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.CONTENT_TYPE_INVALID, msg, EMPTY_DATA); } else if (e instanceof HttpRequestMethodNotSupportedException) { HttpRequestMethodNotSupportedException applicationException = (HttpRequestMethodNotSupportedException) e; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(applicationException.getMethod()); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.METHOD_INVALID, msg, EMPTY_DATA); } else if (e instanceof NoHandlerFoundException) { NoHandlerFoundException applicationException = (NoHandlerFoundException) e; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append( applicationException.getHttpMethod() + &quot; --&gt; &quot; + applicationException.getRequestURL()); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.RESOURCE_INVALID, msg, EMPTY_DATA); } else if (e instanceof MethodArgumentTypeMismatchException) { MethodArgumentTypeMismatchException applicationException = (MethodArgumentTypeMismatchException) e; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append( &quot;parameter &quot; + applicationException.getName() + &quot; is not type of &quot; + applicationException .getRequiredType().getSimpleName()); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.PARAMETER_TYPE_INVALID, msg, EMPTY_DATA); } else if (e instanceof HttpMessageNotReadableException) { HttpMessageNotReadableException applicationException = (HttpMessageNotReadableException) e; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(applicationException.getMessage()); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.REQUEST_BODY_INVALID, msg, EMPTY_DATA); } else if (e instanceof BindException) { BindException applicationException = (BindException) e; BindingResult bindingResult = applicationException .getBindingResult(); FieldError fieldError = bindingResult.getFieldError(); String field = fieldError.getField(); // String code = fieldError.getCode(); StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(field); String msg = stringBuilder.toString(); jsonView = new JsonView(SysStubInfo.PARAMETER_IS_NULL, msg, EMPTY_DATA); } else { jsonView = new JsonView(SysStubInfo.DEFAULT_FAIL, EMPTY_DATA); } return jsonView; }} 希望自己能够对正在进行中的项目的架构有一个比较清晰的认识。 参考：https://www.cnblogs.com/magicalSam/p/7198420.html","link":"/2019/01/28/efadb81e2673.html"},{"title":"SpringBoot启动logo配置","text":"起始每次打开Spring Boot的应用的main方法时，都会出现下面如下所示Spring的Logo。 之前没有注意过这个Logo的配置，直到看到一个Spring Cloud的开源示例项目时，看到了一个配置如下： 有一个问题：为什么放在classpath下且名字为banner.txt就能够配置成功？ 源码中的配置入口 123public static void main(String[] args) { SpringApplication.run(CustomerStarter.class, args);} 最终执行的逻辑为：public ConfigurableApplicationContext run(String... args)这个方法， 如下所示： 首先是设置不同的打印Logo的模式，模式包括日志、标准输出、关闭三种。 获取banner的步骤来了 12345678910public Banner print(Environment environment, Class&lt;?&gt; sourceClass, Log logger) { Banner banner = getBanner(environment); try { logger.info(createStringFromBanner(banner, environment, sourceClass)); } catch (UnsupportedEncodingException ex) { logger.warn(&quot;Failed to create String for banner&quot;, ex); } return new PrintedBanner(banner, sourceClass);} 实际的获取都是在getBanner()这个方法里面，如下： 123456789101112private Banner getBanner(Environment environment) { Banners banners = new Banners(); banners.addIfNotNull(getImageBanner(environment)); banners.addIfNotNull(getTextBanner(environment)); if (banners.hasAtLeastOneBanner()) { return banners; } if (this.fallbackBanner != null) { return this.fallbackBanner; } return DEFAULT_BANNER;} 由上可知，存在两种banner，一种是文字类型的，一种是图片类型的。这两个banner都会被加载到banners中。获取文字和图片banner的源码如下： 12345678910111213141516171819202122232425// 文字Logoprivate Banner getImageBanner(Environment environment) { String location = environment.getProperty(BANNER_IMAGE_LOCATION_PROPERTY); if (StringUtils.hasLength(location)) { Resource resource = this.resourceLoader.getResource(location); return resource.exists() ? new ImageBanner(resource) : null; } for (String ext : IMAGE_EXTENSION) { Resource resource = this.resourceLoader.getResource(&quot;banner.&quot; + ext); if (resource.exists()) { return new ImageBanner(resource); } } return null;}// 图片Logoprivate Banner getTextBanner(Environment environment) { String location = environment.getProperty(BANNER_LOCATION_PROPERTY, DEFAULT_BANNER_LOCATION); Resource resource = this.resourceLoader.getResource(location); if (resource.exists()) { return new ResourceBanner(resource); } return null;} 其中environment.getProperty()有两个参数，第一个是配置在yaml中的路径，第二个就是默认值，分别为： 123static final String BANNER_LOCATION_PROPERTY = &quot;spring.banner.location&quot;;static final String BANNER_IMAGE_LOCATION_PROPERTY = &quot;spring.banner.image.location&quot;;static final String DEFAULT_BANNER_LOCATION = &quot;banner.txt&quot;; 至此，分析完毕。 这里还有一个问题，如何进行配置不同的打印方式？ 12345678910111213141516// bannerMode的设置方法public void setBannerMode(Banner.Mode bannerMode) { this.bannerMode = bannerMode;}// 调用setBannerMode的方法public SpringApplicationBuilder bannerMode(Banner.Mode bannerMode) { this.application.setBannerMode(bannerMode); return this;}// 因此需要通过构建者模式来构建出一个SpringApplication,然后通过这个实例来运行run方法// 构建的步骤可以参考如下代码public static void main(String[] args) { SpringApplicationBuilder builder = new SpringApplicationBuilder(CustomerStarter.class); builder.bannerMode(Banner.Mode.OFF); builder.build(args).run(args);} 配置效果如下图所示：","link":"/2019/10/22/94c04f50732d.html"},{"title":"SpringBoot启动的Tomcat不接收特殊字符而报400Bad Request错误","text":"现象GET请求中输入*[ \\ ] ^ ` { | }*符号，服务器报400错误。 123456789curl 'http://localhost:9999/xxxx/drivers?page=1&amp;size=20&amp;realname=\\xxxx' \\-H 'Accept-Encoding: gzip, deflate' \\-H 'Accept-Language: zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5' \\-H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36' \\-H 'Accept: application/json, text/plain, */*' \\-H 'userId: 453' \\-H 'Connection: keep-alive' \\-H 'token: 1e6966ec2fafdbbd53ef53124cc3e5ae' \\--compressed 错误如下，也就是400： 1&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;title&gt;HTTP Status 400 – Bad Request&lt;/title&gt;&lt;style type=&quot;text/css&quot;&gt;h1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} h2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} h3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} body {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} b {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} p {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;} a {color:black;} a.name {color:black;} .line {height:1px;background-color:#525D76;border:none;}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;HTTP Status 400 – Bad Request&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 原因根据RFC7230中2.3.6的规定，字符\\充当是不允许出现在HTTP header field values中。还根据Tomcat的doc文档中关于relaxedQueryChars与relaxedPathChars 的描述，默认情况下，字符“&lt; &gt; [ \\ ] ^ ` { | }”是不允许出现在相应地方。因此服务器返回400错误，也就是请求包含了不允许的字符，所以是个Bad Request。 解决办法 在项目中、对Tomcat服务器进行自定义设置，允许出现某些字符。 对URL进行转义。改动量可能有点大。 在SpringBoot中设置可接收\\的方法如下： 1234567891011121314151617import org.springframework.boot.web.embedded.tomcat.TomcatConnectorCustomizer;import org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory;import org.springframework.boot.web.server.WebServerFactoryCustomizer;import org.springframework.stereotype.Component;@Componentpublic class CustomContainer implements WebServerFactoryCustomizer&lt;TomcatServletWebServerFactory&gt; { @Override public void customize(TomcatServletWebServerFactory factory) { factory.addConnectorCustomizers((TomcatConnectorCustomizer) connector -&gt; { connector.setAttribute(&quot;relaxedQueryChars&quot;, &quot;\\\\&quot;); connector.setAttribute(&quot;relaxedPathChars&quot;, &quot;\\\\&quot;);// connector.setPort(8888); }); }} 结论上面的代码可行，可以解决所提及的bug，但是此问题严格意义上来说不能算作一个bug，因此先不做修改，只当做一个备用解决方案。 参考：https://stackoverflow.com/questions/41053653/tomcat-8-is-not-able-to-handle-get-request-with-in-query-parameters/51212677#51212677https://stackoverflow.com/questions/51703746/setting-relaxedquerychars-for-embedded-tomcat","link":"/2019/03/26/0dc6f9376a15.html"},{"title":"SpringBoot配置双数据库源","text":"最近遇到一个需要在项目中配置双数据源的需求，虽然在同一个项目中使用两个独立的数据库，听起来有点扯，但是本着试一试的想法，尝试着在项目中进行了双数据源的配置。成功配置，但是遇到了比较多的坑，感觉还挺有意思的。后面成功配置好了之后，经过商讨，在此项目中配置双数据源并不合适，于是直接revert掉了。 大致流程如果是只有一个数据源，我们在需要使用数据库的时候，只需要调用Mapper相关方法即可。这里使用的ORM框架是MyBatis。也就是说框架自动会给我们配置好MyBatis相关的参数，让我们可以直接使用。直接使用MyBatis进行数据库操作的的流程，可以参看其官网的教程。 目前在yaml中的配置如下： 所以肯定会有一个解析spring.datasource、并将其配置成连接数据库所需信息的地方。因此我们也需要将第二个数据库信息配置到yaml文件中。如下： 然后让Spring为我们生成一个数据库源信息相关的bean。再为不同的数据源设置不同的MyBatis配置。 成功实现版本主数据源的配置信息如下代码所示。此处为了更清晰的描述，特意为bean加上了相应的名字。 12345678910111213141516171819202122232425262728293031323334353637@Configuration@MapperScan(basePackages = {&quot;相应包名&quot;}, sqlSessionTemplateRef = &quot;sqlSessionTemplate&quot;)public class MainDataSourceConfig { // 未指明bean的名称时，优先使用该bean @Primary @Bean(name = &quot;dataSource&quot;) // 设置数据库属性来源 @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) public DataSource dataSource(){ // 默认是Hikari return DataSourceBuilder.create().type(DruidDataSource.class).build(); } @Primary @Bean(name = &quot;sqlSessionFactory&quot;) public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;dataSource&quot;)DataSource dataSource) throws Exception { SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); // 设置Mapper.xml文件的扫描处 bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mappers/*.xml&quot;)); // mybatis相关设置 bean.setConfigLocation(new ClassPathResource(&quot;mybatis-config.xml&quot;)); bean.setDataSource(dataSource); return bean.getObject(); } @Primary @Bean public DataSourceTransactionManager transactionManager(@Qualifier(&quot;dataSource&quot;) DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } @Primary @Bean public SqlSessionTemplate sqlSessionTemplate(@Qualifier(&quot;sqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) { return new SqlSessionTemplate(sqlSessionFactory); }} 第二数据库配置信息，基本与上面类似，如下： 123456789101112131415161718192021222324@Configuration@MapperScan(basePackages = &quot;相应包名&quot;, sqlSessionTemplateRef = &quot;secondSqlSessionTemplate&quot;)public class CustomDataSourceConfig { @Bean(name = &quot;secondDataSource&quot;) @ConfigurationProperties(prefix = &quot;spring.second-db&quot;) public DataSource secondDataSource() { return DataSourceBuilder.create().type(DruidDataSource.class).build(); } @Bean(name = &quot;secondSqlSessionFactory&quot;) public SqlSessionFactory firstSqlSessionFactory(@Qualifier(&quot;secondDataSource&quot;) DataSource dataSource) throws Exception{ SqlSessionFactoryBean bean=new SqlSessionFactoryBean(); bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:phdsun-mappers/*.xml&quot;)); bean.setConfigLocation(new ClassPathResource(&quot;mybatis-config.xml&quot;)); bean.setDataSource(dataSource); return bean.getObject(); } @Bean(name = &quot;secondSqlSessionTemplate&quot;) public SqlSessionTemplate secondSqlSessionTemplate(@Qualifier(&quot;secondSqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception{ return new SqlSessionTemplate(sqlSessionFactory); }} 使用直接调用相关的mapper","link":"/2019/07/01/268ad906f8cb.html"},{"title":"SpringBoot快速入门笔记","text":"咨询了老哥，做一个系统用哪些东西比较好，给我推荐了Spring Boot。说真的，以前知道有Spring、SpringMVC，虽然还有一大堆东西，但是对Spring Boot还是略为陌生。所以，去搜了搜它的主要功能。总结网上所说，即最大的功能就是简化Spring应用的配置，让上手更容易。 使用Maven构建项目 使用http://start.spring.io/里面的SPRING INITIALIZR生成Maven项目。选择生成项目，会下载项目压缩包到本地。然后解压之。如下图： 接下来比较关键吧，导了好几次，才导成功。感觉参考的教程上写得流程与当前最新版本的IDEA不太相符，在这里补充完整，给自己做个笔记。 1）先打开IntelliJ IDEA的欢迎界面，选择Import Project。 2）找到解压的目录，点击Open 3）选择以Maven模板打开，后续根据需要一路选择Next即可。 4）导入成功后如下所示： 通过上面步骤完成了基础项目的创建，如上图所示，Spring Boot的基础结构共三个文件（具体路径根据用户生成项目时填写的Group所有差异）。HelloController.java请忽略，这是我后面添加的：src/main/java下的程序入口：DdggApplicationsrc/main/resources下的配置文件：application.propertiessrc/test/下的测试入口：DdggApplicationTests生成的DdggApplication和DdggApplicationTests类都可以直接运行来启动当前创建的项目，由于目前该项目未配合任何数据访问或Web模块，程序会在加载完Spring之后结束运行。 引入Web模块当前的pom.xml内容如下，仅引入了两个模块，还不能跑Web应用：spring-boot-starter：核心模块，包括自动配置支持、日志和YAMLspring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito 要跑Web应用需要引入spring-boot-starter-web 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; HelloWorld在src/main/java下创建HelloController.java类 123456789101112package cn.asahi.ddgg;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController { @RequestMapping(&quot;/hello&quot;) public String index(){ return &quot;Hello world&quot;; }} 启动程序，打开浏览器访问http://localhost:8080/hello。 编写测试用例修改src/test/下的DdggApplicationTests，最后如下所示： 12345678910111213141516171819202122232425262728293031323334package cn.asahi.ddgg;import org.junit.Before;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import static org.hamcrest.Matchers.equalTo;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;@RunWith(SpringRunner.class)@SpringBootTestpublic class DdggApplicationTests { private MockMvc mvc; @Before public void setUp() throws Exception { mvc = MockMvcBuilders.standaloneSetup(new HelloController()).build(); } @Test public void contextLoads() throws Exception { mvc.perform(MockMvcRequestBuilders.get(&quot;/hello&quot;).accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk()) .andExpect(content().string(equalTo(&quot;Hello Xorld&quot;))); }} 在@Test所注解的方法中，它模拟请求了前面的/hello页面的内容，并对其的内容与Hello Xorld做对比。但是它与/hello的内容不同。在该类中，点击右键：选择运行该测试类，结果如下：修改之成为Hello world，即设置期望的返回值为它，再与/hello的返回值做比较，期望与实际的一致，则运行正常，无错误提示。 测试的一种方式吧，对某个URL的内容，与所期望的内容做对比，这样就不需要在浏览器中打开，也不需要肉眼对比期望与实际的差别。 参考：http://blog.didispace.com/spring-boot-learning-1/","link":"/2018/04/16/b7c1af5684ce.html"},{"title":"SpringMVC添加拦截器笔记","text":"没有登录时，有些页面是不能让用户访问的，标准的ServletAPI中提供了一个接口，叫做过滤器Filter。但在SpringMVC中，用到的是org.springframework.web.servlet.HandlerInterceptor。 首先写一个类，实现HandlerInterceptor接口的三个方法，如下： 123456789101112131415161718192021222324252627282930313233343536package com.asahi.ddgg.common;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;public class LoginInterceptor implements HandlerInterceptor{ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String token = request.getParameter(&quot;token&quot;); System.out.println(&quot;token = &quot; + token); if (token != null &amp;&amp; !token.equals(&quot;&quot;)) { return true; } // 否则会重定向到首页 response.sendRedirect(request.getContextPath()+&quot;/index.jsp&quot;); return false; } } 如何才能使这个拦截器被应用呢？在spring的配置文件中加入下面配置（按需求删减）即可： 123456789101112&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/error/*&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/index.jsp&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/css/*&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/images/*&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/js/*&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/fonts/*&quot;/&gt; &lt;bean class=&quot;com.asahi.ddgg.common.LoginInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 首先上面的流程没有问题，但是遇到了坑。下面来说是怎么解决这些遇到的坑的。 首先是404错误。这里报错的是所拦截的URL报错。 这里报错，说明SpringMVC没有找到对应的servlet，然后将也没办法被拦截器拦截。这里出错在spring-mvc.xml扫描@Controller的配置处，错误地将&lt;context:component-scan base-package=&quot;com.asahi.ddgg.controller&quot; /&gt;改成了&lt;context:component-scan base-package=&quot;com.asahi.ddgg.controller.*&quot; /&gt;，引发报错。这里就需要弄清楚这之间的差距，就明白原因了。其实之前是前者，误改成了后者。对于这之间的区别，可以参考关于component-scan中base-package包含通配符的问题探究，写得挺详细的。改成正常的后，发现虽然同样是404错误，但是URL不同了。所以接下来看下面的错误排查。 然后还是404错误。这里报错的是重定向之后的URL报错。 这个是因为重定向后的URL，没有加上项目名。所以在跳转的URL前面，加上request.getContextPath()即可跳转成功。","link":"/2018/07/17/e25c4c2747d0.html"},{"title":"SpringMVC源码探索之RequestBody的工作原理","text":"遇到一个很奇怪的问题，后面发现了问题所在，原因是自己太过匆忙、连快捷键都被复制粘贴省略了。虽然出现问题的原因有点傻逼，但是之所以出现这种问题的原因却更加引人入胜。 问题现象描述Controller中没有逻辑，只有一个@RequestBody注释的form表单然而这个TestBean有点特殊，非一般的get/set方法按照常理，发送post请求，body中塞入{&quot;param&quot;:&quot;hello&quot;}即可成功注入到TestBean的实例中高潮在后面，如果我改成{&quot;paramA&quot;:&quot;hello&quot;}，结果却能成功接收：综上所述，paramA为之前定义的一个变量，我把它改成了新的变量param，然后顺便把paramA的get/set方法中的this.paramA改成了this.param。然后就出现了上面的情况。要知道，这个现象很反常，并且不常见。非常想知道为什么！ 怎么通向背后的原因从源码中看spring是如何处理@RequestBody 站在巨人肩膀上从网上的参考资料来看，处理相关内容的源码可能位于一个叫做readWithMessageConverters()方法中。打开该方法所在的类（双击shift，然后输入方法名），大致是八九不离十的，如下：打开至该方法后，使用debug模式，在可能的地方打上断点，发送postman请求，等待请求的到来：接着往下看，寻找到一个能将JSON转换成对象的方法：此时的messageConverters和body内容如下：这里的read()，才是真正的开始。 向着jackson-databind的源码出发跟着上面的read()方法，一路打断点达到了这里，这可以说是最终setter方法的执行处，代码如下：所以，为什么setter方法会变成setParamA()呢？ 目前为止，可行的解释为：jackson是根据已解析的出来的json的键，去寻找对应键的setter方法，与对应的Form表单类中的成员变量的值无关，因此也解释了刚开头那一幕戏剧性的现象。但是，源代码在哪里？ 如何寻找对应的setter方法经过一次又一次的打断点、跟踪代码运行，终于将规则锁定在了POJOPropertiesCollector.java这个类上了。这里面还涉及到了打断点、跟踪代码的一些技巧，一定要分清F7、F8、F9呀，不然就很容易就要从头再来。从上面的代码来看，对TestForm的解析，变成了只有一个变量为paramA的bean类。所以，按照paramA的键，去JSON中取数据，然后调用对应的setter方法，最后赋值给了param，过程就是这样。 总结对这个流程的跟踪，发现：只有第一次请求的时候，会初始化一个把JSON转化成对象的这样一个类，缓存使用的是LRUMap。其中desc是一个解析器，包含了变量与getter/setter方法之间的映射关系。关键的代码如下：调试跟踪的过程中，主要的时间都花在了desc的初始化上。因为后续的调用，就是根据desc的映射关系去执行。 如何根据getter/setter去解析出成员变量名称？其实这个流程并不难，我们自己也很容易想到，但是就是想看框架里面是怎么写的。在传给这个函数之前，已经保证了basename是以get开头，且此时的offset为3。 什么情况下删除param？param即没有setter/getter方法的那个属性。这里因为param被private修饰，然后也未找到setter/getter方法。具体判断是否可见的代码如下： 以上。于2019/01/31 00:51完成全部内容。","link":"/2019/01/31/10076998b027.html"},{"title":"Spring系中常见注解用法说明","text":"@PathVariable与@RequestParm在spring mvc中，有@requestparm, @requestbody和@pathvariable 三种注解来获得浏览器端的参数，其中@requestparm是取自url中“?”之后的a=b&amp;c=d，@requestbody 来自于请求体，而@pathvariable 则是从网址中取得参数； 感谢评论区@comeoon的订正，浏览器的get/put/delete/post方法都可以使用上述参数，但是由于浏览器get方法不能提供body，所以RequestBody实际获取的是一个map，参数来自于url中“？”之后的参数（实际上是request parameters） 假设代码如下： 123456@Requestmapping（value=&quot;/{category}/{brand}/{id},method=RequestMethod.POST）public void getbyid(@PathVariable(&quot;category&quot;) String category @PathVariable(&quot;brand&quot;) String brand @PathVariable(&quot;id&quot;) String id){ //具体代码略} @Controller与@RestController@restcontroller为@controller和@responsebody的结合。在@controller注解中，返回的是字符串，或者是字符串匹配的模板名称，即直接渲染视图，与html页面配合使用的，在这种情况下，前后端的配合要求比较高，java后端的代码要结合html的情况进行渲染,使用model对象（或者modelandview）将user的属性渲染到页面。 12345678@Controller@RequestMapping(method = RequestMethod.GET, value = &quot;/&quot;)public String getuser(Model model) throws IOException { model.addAttribute(&quot;name&quot;,bob); model.addAttribute(&quot;sex&quot;,boy); return &quot;user&quot;;} 前端取数据： 12345678&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;body&gt; &lt;div&gt; &lt;p&gt;&quot;${name}&quot;&lt;/p&gt; &lt;p&gt;&quot;${sex}&quot;&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 而在@restcontroller中，返回的应该是一个对象，即return一个user对象，这时，在没有页面的情况下，也能看到返回的是一个user对象对应的json字符串，而前端的作用是利用返回的json进行解析渲染页面，java后端的代码比较自由。 12345678@RestController@RequestMapping(method = RequestMethod.GET, value = &quot;/&quot;)public User getuser( ) throws IOException { User bob=new User(); bob.setName(&quot;bob&quot;); bob.setSex(&quot;boy&quot;); return bob;}","link":"/2019/12/16/108e8f49b029.html"},{"title":"StringBuffer与StringBuilder源代码分析","text":"背景想了解StringBuffer与StringBuilder之间的差别以及他们是通过何种方式去实现其功能的。差别大致了解，线程安全与不安全。更感兴趣的是其实现方式。 AbstractStringBuilder两者都继承自此抽象类。该类提供了一些StringBuffer与StringBuilder公用的方法。 StringBuffer1234567891011121314151617public StringBuffer() { super(16);}public StringBuffer(int capacity) { super(capacity);}public StringBuffer(String str) { super(str.length() + 16); append(str);}public StringBuffer(CharSequence seq) { this(seq.length() + 16); append(seq);} 一般常用到的两个构造函数为第一、三个。从上面来看，其默认的长度为16。这个16是一个什么的值呢，查看其super，如下： 123456/*** Creates an AbstractStringBuilder of the specified capacity.*/AbstractStringBuilder(int capacity) { value = new char[capacity];} 其背后的实现只是一个char[]，没有其他了吗？回头继续往下看其如何进行append()，由于该方法有很多个重载方法，因此选择一个经常用的其参数为String的来看，如下： 1234567891011121314151617// StringBuffer.java@Overridepublic synchronized StringBuffer append(String str) { toStringCache = null; super.append(str); return this;}// AbstractStringBuilder.javapublic AbstractStringBuilder append(String str) { if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;} 其中count为当前StringBuffer中已存在的字符数，len为当前String的长度。很显然ensureCapacityInternal(count + len);是为了不让之前的字符数组溢出。获取这算是其核心之一吧，很值得去看看。如下： 123456789101112131415161718192021222324252627282930313233343536373839404142// AbstractStringBuilder.javaprivate void ensureCapacityInternal(int minimumCapacity) { // overflow-conscious code if (minimumCapacity - value.length &gt; 0) { value = Arrays.copyOf(value, newCapacity(minimumCapacity)); }}private int newCapacity(int minCapacity) { // overflow-conscious code int newCapacity = (value.length &lt;&lt; 1) + 2; if (newCapacity - minCapacity &lt; 0) { newCapacity = minCapacity; } return (newCapacity &lt;= 0 || MAX_ARRAY_SIZE - newCapacity &lt; 0) ? hugeCapacity(minCapacity) : newCapacity;}private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private int hugeCapacity(int minCapacity) { if (Integer.MAX_VALUE - minCapacity &lt; 0) { // overflow throw new OutOfMemoryError(); } return (minCapacity &gt; MAX_ARRAY_SIZE) ? minCapacity : MAX_ARRAY_SIZE;}// Integer.javapublic static final int MAX_VALUE = 0x7fffffff;// Arrays.javapublic static char[] copyOf(char[] original, int newLength) { char[] copy = new char[newLength]; System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;}// 再往下就是native方法了public static native void arraycopy( Object src, int srcPos, Object dest, int destPos,int length); 也就是说，每次append都会返回一个新的包含此前char[]中数据的char[]数组，此时的数组长度已经被x2+2。 然后调用String的getChars(int srcBegin, int srcEnd, char dst[], int dstBegin)方法，将此字符串，添加到目标数组中。在此有个困惑，每次返回来的数组长度已经变了，可是在StringBuffer中调用capacity()方法显示长度只是变成了添加了字符串之后的长度。是因为那个native方法吗？应该是吧。 线程安全这大概就是append的过程了。仔细想想，如果是这样操作的话，多线程的环境下可能会出现一些问题。因此，大部分的StringBuffer中的方法都加上了synchronized关键字，因此它就是线程安全的了。在看StringBuilder，没有。其操作基本上是使用AbstractStringBuilder类的方法。在两者的对应方法中，只是加了/没加同步关键字的差别吧。StringBuilder的代码就不贴了。","link":"/2017/12/26/8bb4530fbcdd.html"},{"title":"TCP协议的三次握手与四次挥手","text":"TCP提供面向连接的服务，在传送数据之前必须先建立连接，数据传送完成后要释放连接。因此TCP是一种可靠的的运输服务，但是正因为这样，不可避免的增加了许多的开销，比如确认，流量控制等。 字段含义 序号seq，占4个字节，TCP连接中传送的字节流中的每个字节都按顺序编号。例如，一段报文的序号字段值是 301 ，而携带的数据共有100字段，显然下一个报文段（如果还有的话）的数据序号应该从401开始 确认号ack，占4个字节，是期望收到对方下一个报文的第一个数据字节的序号。例如，B收到了A发送过来的报文，其序列号字段是501，而数据长度是200字节，这表明B正确的收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701 确认ACK，仅当ACK=1时，确认号字段才有效。TCP规定，在连接建立后所有报文的传输都必须把ACK置1 同步SYN，在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1 终止FIN，用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放 三次握手过程最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。 TCP服务端B先创建传输控制块TCB，时刻准备接受客户A连接请求，此时服务端B就进入了LISTEN（监听）状态； TCP客户端A也是先创建传输控制块TCB，然后向服务端B发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端A进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务端B收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务端进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户端A到确认后，还要向服务端B给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务端B收到客户端A的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 为什么client还要再发送一次确认关于三次握手的目的，谢希仁的《计算机网络》中这么说： 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误 在另一部经典的《计算机网络》一书中讲： 三次握手的目的是为了解决“网络中存在延迟的重复分组”的问题。这两种不用的表述其实阐明的是同一个问题。 谢希仁版《计算机网络》中的例子是这样的： 已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。 SYN攻击在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了 其他TCP“三次握手” 这个问题的本质是, 信道不可靠, 但是通信双发需要就某个问题达成一致. 而要解决这个问题, 无论你在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足”在不可靠信道上可靠地传输信息”这一需求所导致的. 请注意这里的本质需求,信道不可靠, 数据传输要可靠. 三次达到了, 那后面你想接着握手也好, 发数据也好, 跟进行可靠信息传输的需求就没关系了. 因此,如果信道是可靠的, 即无论什么时候发出消息, 对方一定能收到, 或者你不关心是否要保证对方收到你的消息, 那就能像UDP那样直接发送消息就可以了.”。这可视为对“三次握手”目的的另一种解答思路。 后面一段话意思就是如果想确定双通道通畅，必须使用三个包的发送接收，也就是三次握手 四次挥手 数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。 客户端A发出连接释放报文，并且停止发送数据。A把释放数据报文段首部的终止控制位FIN置为1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端A进入FIN-WAIT-1（终止等待1）状态。TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务器B收到连接释放报文即发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v（v等于前面已传送过得数据的最后一个字节的序号加1），此时，服务端B就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端A向服务器B方向的连接释放了，这时候处于半关闭状态，即客户端A已经没有数据要发送了，但是服务器B若发送数据，客户端A依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。也就是说：A-&gt;B方向的连接已关闭，但是B-A方向的连接还未关闭。 客户端A收到服务器B的确认请求后，此时，客户端A就进入FIN-WAIT-2（终止等待2）状态，等待服务器B发送连接释放报文（在这之前还需要接受服务器B发送的最后的数据）。 服务器B将最后的数据发送完毕后，就向客户端A发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器B很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器B就进入了LAST-ACK（最后确认）状态，等待客户端A的确认。 客户端A收到服务器B的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端A就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，当客户端A撤销相应的TCB后，才进入CLOSED状态。 服务器B只要收到了客户端A发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器B结束TCP连接的时间要比客户端A早一些。 为什么要等待2MSLMSL（Maximum Segment Lifetime），RFC793建议设置为2分钟，但TCP允许不同的实现可以设置不同的MSL值。 第一，保证客户端发送的最后一个ACK报文能够到达服务器。因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器，如果没有这个2MSL的等待时间，那么在最后一次挥手的报文段丢失后，服务器B将无法按照正常步骤进入CLOSED状态。 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 为什么需要四次挥手建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。 连接双方中任意一方意外断开连接如何处理TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 TCP连接建立与断开状态机 参考： 谢希仁·《计算机网络》 https://mp.weixin.qq.com/s?__biz=MzI3NjU2ODA5Mg==&amp;mid=2247483881&amp;idx=1&amp;sn=321fcb1d995feb17be3b703c5dfb2201 https://blog.csdn.net/qzcsu/article/details/72861891 https://www.jianshu.com/p/65605622234b","link":"/2019/12/16/4e7fa8a51a3f.html"},{"title":"System.loadLibrary()进程不断重启","text":"解决这个问题花费了最近很长的一段时间，所以觉得非常有写出来分享的必要。其实这个问题，主要还是需要考虑细心！因为说到底是权限的问题，但是又与平常所说的权限问题有很大的差别。网上遇到的一些关于加载so库的问题都是什么连接问题、什么又找不到了的之类，都是可以正常吐出Exception的情况，这个连个Exception都没有打印出来。 问题描述主要的log为Process xxxxx (pid xxxxx) has died : fore BFGS。前面的TAG是在System.loadLibrary(xxxx)之前的一条语句。 原因所加载的so库进行了外部存储的访问，但是加载so库的时候并没有获得到访问外部存储的权限。因此崩溃得连一句像样的有点用处的log都没有。 吐槽真的是奇了怪了。都没听说过so库访问外部存储还需要访问权限的！但是，它是在一个App中，所以它的行为也可以看成是App的行为，因此需要权限也是可以理解的。但是为什么会在加载的时候，就会去检测这些权限呢？而且没有权限的时候，一个像样的错误都爆不出来，好生苦找啊！","link":"/2018/04/29/a88c4e43cd3d.html"},{"title":"Ubuntu爬坑指南","text":"从接触Ubuntu以来，就在不断地爬坑，也有过一些记录，但是都不集中，现在都找不到了，这着实是一个不小的遗憾。为了让自己不再遗憾，能够更快地提升自己，写下这往篇博客。 Ubuntu开启root用户登录系统以及关闭guest用户 开启root用户登录打开/usr/share/lightdm/lightdm.conf.d/50-ubuntu.conf，加入下面这条语句，然后注销，就可以看见使用用户名和密码登录的选项,。greeter-show-manual-login=true 关闭guest用户对于关闭Guest用户，只需要在这个文件中添加上下面这条语句即可。allow-guest=false 开机登录后显示”System program problem detected”如下图所示。虽然这个提示并不影响对OS的使用，但是做为一个强迫症患者，相信还是有办法解决的。出现这种情况，是因为一些应用在使用过程中出现了一些错误，然后系统将这些错误记录了下来，然后就是每次登录都来提示你。。。 这些冲突（错误）都在/var/crash下，只需要将其下的所有文件全部删除，提示就不会再出现了。但是，如果某些应用又运行时出现了问题，那么提示还是会继续出现的，需要再重复以上操作。因此，可以进行下面的捷足操作来永久地关闭这种通知。 Turn off apport After removing the old crash reports, if you still get the same error message, then you can completely turn off apport to get rid. Edit the configuration file at /etc/default/apport. $ gksudo gedit /etc/default/apportThe file would contain something like this 1234# set this to 0 to disable apport, or to 1 to enable it# you can temporarily override this with# sudo service apport start force_start=1enabled=1 Just set the value of enabled to 0, and this will disable apport.enabled=0Save the file and close it. From the next boot onwards, there should be no error messages ever. If you do not want to restart the system then restart apport from the command line.$ sudo restart apport JetBrains系列IDE全局菜单菜单栏在标题下面，看起来特别别扭，还是全局的、统一的高大上～１. Install Jayatana package: 123sudo add-apt-repository ppa:danjaredg/jayatanasudo apt-get updatesudo apt-get install jayatana ２. Append line to bin/idea64.vmoptions: 1-javaagent:/usr/share/java/jayatanaag.jar 注：JetBrains全系（以及基于IDEA的Android Studio）都可以通过在安装目录下的bin/xxxxxx.vmoptions添加２中代码来开启全局菜单。 其实2还可以用下面的操作，都是导入了那个选项吧。之前成功过，但是目前并没有，是感觉是因为.desktop文件原因。不过可以当做是一个参考吧！ export _JAVA_OPTIONS=&quot;-javaagent:/usr/share/java/jayatanaag.jar&quot;在运行bin/****.sh前让它生效应该就好了吧。 参考 http://www.binarytides.com/ubuntu-fix-system-program-problem-error/","link":"/2018/01/21/74bbd954ed41.html"},{"title":"VMware Fusion 固定 IP","text":"编辑 DHCP 配置文件1sudo vim /Library/Preferences/VMware\\ Fusion/vmnet8/dhcpd.conf 做如下修改 1234567891011121314151617####### VMNET DHCP Configuration. End of &quot;DO NOT MODIFY SECTION&quot; #######host Ubuntu-20.04-Master { hardware ethernet 00:0c:29:bd:f2:22; fixed-address 172.16.214.2;}host Ubuntu-20.04-Node01 { hardware ethernet 00:0c:29:67:a7:0b; fixed-address 172.16.214.3;}host Ubuntu-20.04-Node02 { hardware ethernet 00:0c:29:27:8c:0a; fixed-address 172.16.214.4;}host Ubuntu-20.04-Node03 { hardware ethernet 00:0c:29:ee:fe:e0; fixed-address 172.16.214.5;} 刷新网络配置1sudo /Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --configure 验证是否生效1sudo dhclient -v -r ens33","link":"/2021/10/11/5b3beaa77008.html"},{"title":"WebSocket多实例部署时的一种解决方案","text":"需要用到k8s进行扩展，在变更容器数量的时候，希望达到不改动代码。 遇到的问题 Client与哪一个WS服务建立连接是不知道的 当需要发送WS消息时，使用URL发送给所有的WS模块不可取（一旦容器数量改变，还需要修改代码，即增加新的URL） 架构图 代码建立连接部分 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@ServerEndpoint(value = &quot;/ws/{role}/{token}&quot;, configurator = EndpointConf.class)@Component@Slf4jpublic class WsController { private static final String PARAM_TOKEN = &quot;token&quot;; private static final String PARAM_ROLE = &quot;role&quot;; private static final Set&lt;String&gt; ROLE_SET = new HashSet&lt;&gt;( Arrays.asList(AccountType.DRIVER.name().toLowerCase(), AccountType.PASSENGER.name().toLowerCase()) ); @Autowired private WsService wsService; @OnOpen public void onOpen(@PathParam(PARAM_ROLE) String role, @PathParam(PARAM_TOKEN) String token, Session session) throws IOException { if (!ROLE_SET.contains(role)) { // 登陆类型不正确 log.warn(&quot;token:{} login role error, role:{}&quot;, token, role); wsService.sendMessage(session, wsService.authFailMsg()); session.close(); return; } int userId = wsService.getUserIdByToken(role, token); if (userId == -1) { // 根据token找不到userId log.warn(&quot;token:{} login error, you are offline&quot;, token); wsService.sessionMap.remove(token); wsService.sendMessage(session, wsService.authFailMsg()); session.close(); return; } log.info(&quot;【{}】, token : {} open websocket connect&quot;, wsService.showInfoAboutToken(token), token); // 删除此token已有session Session oldSession = wsService.sessionMap.get(token); if (oldSession != null) { wsService.sessionMap.remove(token); wsService.sendMessage(oldSession, wsService.duplicateLoginMsg()); oldSession.close(); } wsService.sessionMap.put(token, session); } @OnClose public void onClose(@PathParam(PARAM_ROLE) String role, @PathParam(PARAM_TOKEN) String token, Session session) { log.info(&quot;close connection. 【{}】, token: {}&quot;, wsService.showInfoAboutToken(token), token); wsService.sessionMap.remove(token); wsService.sendMessage(session, wsService.authFailMsg()); } @OnError public void onError(@PathParam(PARAM_ROLE) String role, @PathParam(PARAM_TOKEN) String token, Session session, Throwable error) { log.error(&quot;【{}】, token : {}, sessionId: {}, websocket error: {}&quot;, wsService.showInfoAboutToken(token), token, session.getId(), error); } @OnMessage public void onMessage(@PathParam(PARAM_ROLE) String role, @PathParam(PARAM_TOKEN) String token, String message, Session session) throws IOException { log.info(&quot;receive from 【{}】, token : {}, message: {}&quot;,wsService.showInfoAboutToken(token), token, message); if (!ROLE_SET.contains(role)) { // 登陆类型不正确 wsService.sendMessage(session, wsService.authFailMsg()); session.close(); } //司机心跳缓存 if(role.equals(AccountType.DRIVER.name().toLowerCase())){ wsService.updateHeartBeat(token); } wsService.actionHandle(session, message); }} 接收各个模块发送WS的MQ消息 123456789101112131415161718192021222324252627282930@Slf4jpublic class WsMqMsgListener implements MessageListener { @Autowired private WsService wsService; @Override public Action consume(Message message, ConsumeContext context) { log.info(&quot;receive tag:{}, body:{}&quot;, message.getTag(), new String(message.getBody())); try { //消息体执行内容 String bodyStr = new String(message.getBody()); if (StringUtils.isEmpty(bodyStr)) return Action.CommitMessage; JSONObject body = JSONObject.parseObject(bodyStr); log.info(&quot;got a websocket mq msg&quot;); WebSocketMqMsg.Body wsMqBody = JSON.toJavaObject(body, WebSocketMqMsg.Body.class); wsService.sendMessage(wsMqBody); return Action.CommitMessage; } catch (Exception e) { e.printStackTrace(); log.error(&quot;消费MQ消息失败，原因是：{}&quot;, e.getMessage()); //消费失败 return Action.ReconsumeLater; } }} 收到各个模块的MQ消息后，提取出发送对象、发送内容，然后进行发送。如果没有找到对应客户端的连接，那么将抛弃掉该WS消息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public Map&lt;String, Session&gt; sessionMap = new ConcurrentHashMap&lt;&gt;();public void sendMessage(WebSocketMqMsg.Body message) { if (message.getIds().size() &gt; 0) { for (Integer id : message.getIds()) { cachedThreadPool.execute(() -&gt; { int maxIdx = message.getRole().equals(AccountType.PASSENGER.name()) ? 2 : 1; for (int i = 1; i &lt;= maxIdx; i++) { String key = String.format(Constants.CACHE_USER_TOKEN_LOGIN_PREFIX, message.getRole(), LoginType.valueOf((short) i), id); log.info(&quot;key is {}&quot;, key); String token = cacheService.getVal(key); log.info(&quot;token is {}&quot;, token == null ? &quot;null&quot; : token); boolean sendOfflineMsg = false; if (!StringUtils.isEmpty(token)) { Session session = sessionMap.get(token); log.info(&quot;session is {}&quot;, session == null ? &quot;null&quot; : &quot;not null&quot;); if (session == null || !sendMessage(session, message.getMsg().toString())) { sendOfflineMsg = true; } } else { sendOfflineMsg = true; } log.info(&quot;ws msg: role -&gt; 【{}】, id -&gt; 【{}】, terminal -&gt; 【{}】, status -&gt; 【{}】&quot;, message.getRole(), id, i == 1 ? LoginType.APP.name() : LoginType.WECHAT_APPLET.name(), sendOfflineMsg ? &quot;offline&quot; : &quot;online&quot;); } }); } }}public boolean sendMessage(Session session, String message) { session.getBasicRemote().sendPong(); if (!session.isOpen()) { return false; } try { session.getBasicRemote().sendText(message); } catch (IOException e) { log.error(&quot;send message to {} error {}&quot;, session.getId(), e); return false; } return true;} 后记按照上述架构完成的多实例WS服务部署，可以解决前面提到的两个问题。MQ作为一个中间这的角色，发挥出了它的作用。","link":"/2019/08/20/f51277d4e8ec.html"},{"title":"Windows连接L2TP&#x2F;IPSec的VPN","text":"Windows系统默认不支持连接在防火墙NAT后的L2TP/IPSec协议VPN，但是可以通过修改注册表解决。 修改方法如下： 定位注册表 ：HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\PolicyAgent 新建DWORD (32位)值，名称：AssumeUDPEncapsulationContextOnSendRule 值填 2 重启系统 In order to disable IPSec on Windows 7/Vista Click Start, then in search box type: run ENTER In the Run dialog type: regedit ENTER In Registry Editor: Locate and then click the following registry subkey: HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\Rasman\\Parameters On the Edit menu, click New&gt;DWORD As the name of the new key enter: ProhibitIpSec Double click the key to edit the value. In the Value data field, enter: 1 Quit Registry Editor, and then restart the computer. 当VPN启动后，还需要修改两项与路由相关的配置","link":"/2023/06/12/9a01df16fccc.html"},{"title":"Windows常见问题解决办法汇总","text":"在windows任务栏上显示秒https://www.ithome.com/html/win10/288555.htm用管理员模身份运CMD/POWERSHELL，使用下面命令，在注册表中，添加相应键值。 1Reg add HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced /v ShowSecondsInSystemClock /t REG_DWORD /d 1 然后重启explorer.exe进程即可。若要改回默认设置，直接删除ShowSecondsInSystemClock，重启explorer.exe进程即可。 Win/Unix系双系统时间同步问题原因：Windows将硬件时间当做CST时间，直接拿来在系统中显示；关机时直接存入硬件中。Unix系系统将硬件时间作为UTC时间，拿过来后，会转成成CST时间，即显示UTC + 8；关机时，会将系统显示的时间换算成UTC，即UTC - 8，存入硬件中。 黑苹果在开机时，如果联网了，会进行时间同步。所以会导致在黑苹果中时间显示正常，关机时存入了当前时间-8，再打开windows时，windows读取到-8后的时间，直接显示，形成一种windows总是慢8个小时的现象。 寻思着，为什么windows下面联网时不能自动同步时间呢？ 解决办法（两种选一即可）： 让windows认为硬件时间为UTC，拿到转换成CST。 用管理员模身份运CMD/POWERSHELL，使用下面命令，在注册表中，添加相应键值。 1Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 让Unix系系统把硬件时间看做CST，直接拿来用。关机时直接存入硬件中。解决办法要根据因系统不同而有所不同。以黑苹果为例(未尝试)： 1234# 貌似已经404了sudo sh -c &quot;$(curl -kfsSL https://raw.githubusercontent.com/hieplpvip/LocalTime-Toggle/master/fix_time_osx.sh)&quot;# 脚本还有，但是没有尝试过，可以做个参考sudo sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/xiaoMGithub/LocalTime-Toggle/master/fix_time_osx.sh)&quot; 大致的内容如下，貌似改的东西有点多啊，还是改windows算了。 12345678910111213141516171819202122232425262728293031323334353637#!/bin/sh#Script auto fix time on hackintosh#OSX: 10.6 and aboveDAEMON_PATH=/Library/LaunchDaemons/BIN_PATH=/usr/local/bin/TMP_PATH=/tmp/TIME_FIX_FILE=localtime-toggleTIME_DAEMON_FILE=org.osx86.localtime-toggle.plistecho &quot;Downloading required file&quot;sudo curl -o $TMP_PATH$TIME_FIX_FILE &quot;https://raw.githubusercontent.com/xiaoMGithub/LocalTime-Toggle/master/sbin/localtime-toggle&quot;sudo curl -o $TMP_PATH$TIME_DAEMON_FILE &quot;https://raw.githubusercontent.com/xiaoMGithub/LocalTime-Toggle/master/Library/LaunchDaemons/org.osx86.localtime-toggle.plist&quot;if [ ! -d &quot;$BIN_PATH&quot; ] ; then mkdir &quot;$BIN_PATH&quot; ;fiecho &quot;Copy file to destination place...&quot;sudo cp -R $TMP_PATH$TIME_FIX_FILE $BIN_PATHsudo cp -R $TMP_PATH$TIME_DAEMON_FILE $DAEMON_PATHsudo rm $TMP_PATH$TIME_FIX_FILEsudo rm $TMP_PATH$TIME_DAEMON_FILEecho &quot;Chmod localtime-toggle...&quot;sudo chmod +x $BIN_PATH$TIME_FIX_FILEsudo chown root $DAEMON_PATH$TIME_DAEMON_FILEsudo chmod 644 $DAEMON_PATH$TIME_DAEMON_FILEecho &quot;Load Localtime-toggle...&quot;if sudo launchctl list | grep --quiet localtime-toggle; then echo &quot;Stopping existing localtime-toggle daemon.&quot; sudo launchctl unload $DAEMON_PATH$TIME_DAEMON_FILEfisudo launchctl load -w $DAEMON_PATH$TIME_DAEMON_FILEecho &quot;Done!&quot;","link":"/2020/03/26/63fbfb6edb21.html"},{"title":"Windows初始化时安装应用的脚本","text":"挂载磁盘到wsl 1wsl --mount \\\\.\\PHYSICALDRIVE0 --partition 1 初始化安装软件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@echo off@REM 安装chocoSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))@REM 命令行终端choco install -y mobaxtermchoco install -y microsoft-windows-terminal@REM 浏览器choco install -y firefoxchoco install -y googlechrome@REM 工具choco install -y filezillachoco install -y foxitreaderchoco install -y sumatrapdf.installchoco install -y wiresharkchoco install -y everythingchoco install -y postmanchoco install -y googleearthprochoco install -y sourcetreechoco install -y telegram.installchoco install -y drawiochoco install -y picgochoco install -y potplayer@REM 系统工具choco install -y rufuschoco install -y etcherchoco install -y 7zip.installchoco install -y cpu-z.installchoco install -y gpu-zchoco install -y clash-for-windows@REM 办公choco install -y tencentqqchoco install -y tencentmeetingchoco install -y zoomchoco install -y wechatchoco install -y dingtalk@REM 虚拟机choco install -y multipasschoco install -y vmwareworkstationchoco install -y virtualbox@REM 游戏choco install -y steam-clientchoco install -y epicgameslauncher@REM 编程IDEchoco install -y codeblockschoco install -y androidstudiochoco install -y jetbrainstoolboxchoco install -y vscode.installchoco install -y notepadplusplus.installchoco install -y sublimetext3choco install -y mysql.workbenchchoco install -y ultraedit@REM 安卓choco install -y apktoolchoco install -y adb@REM 编程语言choco install -y python3choco install -y jdk8choco install -y jdk11choco install -y golangchoco install -y rustchoco install -y nodejs.installchoco install -y yarnchoco install -y makechoco install -y cmake.install@REM 命令行小工具choco install -y sqlitechoco install -y git.installchoco install -y wgetchoco install -y curlchoco install -y jqchoco install -y hugo@REM Kubernetes相关choco install -y kubernetes-clichoco install -y kubernetes-helmchoco install -y kustomizechoco install -y cue-clichoco install -y minikubechoco install -y kindchoco install -y docker-clichoco install -y docker-desktopchoco install -y lenschoco install -y k9schoco install -y k0schoco install -y k0sctlchoco install -y rancher-desktopchoco install -y rancher-clichoco install -y rkechoco install -y k3supchoco install -y k3dchoco install -y istioctlchoco install -y loki-logclichoco install -y fluxchoco install -y argocd-clichoco install -y podman-desktop@REM LaTexchoco install -y miktex.installchoco install -y texstudio","link":"/2023/06/12/29f9e7aa4913.html"},{"title":"2024年CKS考试准备","text":"Start : 2024.1.15 DDL1：2024.2.3 15:00 (Rescheduled) DDL2：2024.2.8 20:00 (Failed) DDL3: 2024.2.23 23:30 (Success) 学习环境搭建Install Calico CNI 12345678910111213141516171819# Other prerequisites# swap,br_netfilter....# Configure containerd$ containerd config default | sed 's|SystemdCgroup = false|SystemdCgroup = true|g' | sudo tee /etc/containerd/config.toml &gt; /dev/null$ sudo systemctl restart containerd &amp;&amp; systemctl status containerd# Hosts$ echo &quot;127.0.0.1 kube.multipass.local&quot; | sudo tee -a /etc/hosts &gt; /dev/null# Initialize Kubernetes cluster$ kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint kube.multipass.local# untaint master node$ kubectl get node --no-headers | grep control-plane | awk '{cmd=&quot;kubectl taint node &quot;$1&quot; node-role.kubernetes.io/control-plane-&quot;;system(cmd)}'# Install Calico CNI which supports Network Policy$ kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml$ curl https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml | sed 's|192.168|10.244|g' | kubectl apply -f - There may be lots of impediments to setting up this kubernetes cluster successfully due to network conditions or some misconfigurations, but those above can be solved step by step. Finally, node(s) is(are) ready as follows: 123$ kubectl get nodeNAME STATUS ROLES AGE VERSIONkube-master Ready control-plane 21m v1.28.3 做题工具alias123alias k=kubectl # will already be pre-configuredexport do=&quot;--dry-run=client -o yaml&quot; # k create deploy nginx --image=nginx $doexport now=&quot;--force --grace-period 0&quot; # k delete pod x $now vim123set tabstop=2set expandtabset shiftwidth=2 jsonpath https://kubernetes.io/docs/reference/kubectl/jsonpath/ Function Description Example Result text the plain text kind is {.kind} kind is List @ the current object {@} the same as input . or [] child operator {.kind}, {['kind']} or {['name\\.type']} List .. recursive descent {..name} 127.0.0.1 127.0.0.2 myself e2e * wildcard. Get all objects {.items[*].metadata.name} [127.0.0.1 127.0.0.2] [start:end:step] subscript operator {.users[0].name} myself [,] union operator {.items[*]['metadata.name', 'status.capacity']} 127.0.0.1 127.0.0.2 map[cpu:4] map[cpu:8] ?() filter {.users[?(@.name==&quot;e2e&quot;)].user.password} secret range, end iterate list {range .items[*]}[{.metadata.name}, {.status.capacity}] {end} [127.0.0.1, map[cpu:4]] [127.0.0.2, map[cpu:8]] '' quote interpreted string {range .items[*]}{.metadata.name}{'\\t'}{end} 127.0.0.1 127.0.0.2 \\ escape termination character {.items[0].metadata.labels.kubernetes\\.io/hostname} 127.0.0.1 Examples using kubectl and JSONPath expressions: 1234567kubectl get pods -o jsonkubectl get pods -o=jsonpath='{@}'kubectl get pods -o=jsonpath='{.items[0]}'kubectl get pods -o=jsonpath='{.items[0].metadata.name}'kubectl get pods -o=jsonpath=&quot;{.items[*]['metadata.name', 'status.capacity']}&quot;kubectl get pods -o=jsonpath='{range .items[*]}{.metadata.name}{&quot;\\t&quot;}{.status.startTime}{&quot;\\n&quot;}{end}'kubectl get pods -o=jsonpath='{.items[0].metadata.labels.kubernetes\\.io/hostname}' yqexamples 1234567891011# Read a valueyq '.a.b[0].c' file.yaml# Pipe from STDINyq '.a.b[0].c' &lt; file.yaml# Update a yaml file, in placeyq -i '.a.b[0].c = &quot;cool&quot;' file.yaml# Find and update an item in an arrayyq '(.[] | select(.name == &quot;foo&quot;) | .address) = &quot;12 cat st&quot;' jq tr truncate crictl cut awk常规使用 组装命令并执行 1kubectl get svc | awk '{cmd=&quot;kubectl get svc &quot;$1&quot; -oyaml&quot;;system(cmd)}' sed sha512sum podman(to build image) 日志查看 https://kubernetes.io/docs/concepts/cluster-administration/logging/#system-component-logs 对 kubelet 组件：journalctl -xefu kubelet 对以容器形式启动的 kubernetes 组件：在/var/log/pods下（当把kube-apiserver的yaml弄坏起不来之后，应该可以在这个目录下查看启动失败的原因） group缩写问题group为空时表示core group，此时的 gv 缩写只有 v，即 12345678910111213141516171819$ kubectl api-resources --api-group=''NAME SHORTNAMES APIVERSION NAMESPACED KINDbindings v1 true Bindingcomponentstatuses cs v1 false ComponentStatusconfigmaps cm v1 true ConfigMapendpoints ep v1 true Endpointsevents ev v1 true Eventlimitranges limits v1 true LimitRangenamespaces ns v1 false Namespacenodes no v1 false Nodepersistentvolumeclaims pvc v1 true PersistentVolumeClaimpersistentvolumes pv v1 false PersistentVolumepods po v1 true Podpodtemplates v1 true PodTemplatereplicationcontrollers rc v1 true ReplicationControllerresourcequotas quota v1 true ResourceQuotasecrets v1 true Secretserviceaccounts sa v1 true ServiceAccountservices svc v1 true Service 常见的控制器资源基本属于apps group 123456NAME SHORTNAMES APIVERSION NAMESPACED KINDcontrollerrevisions apps/v1 true ControllerRevisiondaemonsets ds apps/v1 true DaemonSetdeployments deploy apps/v1 true Deploymentreplicasets rs apps/v1 true ReplicaSetstatefulsets sts apps/v1 true StatefulSet 常见的几种需要填充group的地方 rbac role.rules.apiGroups 只需要填写group audit policy rules.resources.group 只需要填写group 做题方法论客观局限 网络卡顿，导致做题时及其不流畅； 题量大，总共有16道题，需要在120分钟内完成，完成一道题的平局时间应该120/16=7分钟； 主观局限 对安全相关的操作不熟练； 无做题策略，选择按顺序，从头做到尾； 开始做题前，未对该题进行自我评估，不确定能否短时间内搞定，做了一半，发现搞不定，非常浪费时间； 改进措施 改用香港/澳门移动网络漫游来做题（如果这次还是考不过，有网络卡顿的原因，下次得肉身跑到香港去了23333）； 及格分数需要67，粗略估计取得证书，需要做完67/(100/16)=11道题，可以允许5道题不做，但每题的平均用时为10分钟多一点。 做题步骤 花1分钟浏览全题，理解题意，并评估是否有把握能完成； 没把握的用flag标记，跳过，下一题； 优先去做的题目类型 audit policy apparmor pod security standard runtime class image policy webhook trivy &amp; kube-bench rbac &amp; opa secret security context 主题RBAC Reference: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ 创建sa、role、rolebinding 123kubectl create sa shs-sakubectl create role shs-role --resource=pods,secrets --verb=*kubectl create rolebinding shs-rolebinding --role=shs-role --serviceaccount=default:shs-sa 使用该ServiceAccount 1kubectl patch -p '{&quot;spec&quot;:{&quot;template&quot;:{&quot;spec&quot;:{&quot;serviceAccountName&quot;:&quot;shs-saax&quot;,&quot;serviceAccount&quot;:&quot;shs-saax&quot;}}}}' deployment shs-dep Tips: 如果sa异常（如：不存在），则deployment的pod不会建出来，因为rs控制器已经检测到了异常，所以未建pod。 deploy.spec.template.spec.serviceAccount 与 deploy.spec.template.spec.serviceAccountName 都需要修改。 NetworkPolicyPod Isolation Egress, outbound connection from pod, non-isolated by default. If NetworkPolicy selects this pod and was Egress type, then only out connections mentioned in it allowed. If lots of NetworkPolicy select the same pod, then all connections mentoined in those list are allowed. Additive. Ingress, inbound connection to pod, non-isolated by default. Effects are as the same as Egress. Only connections mentioned by NetworkPolicy can connect to this Pod successfully.Examples 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: test-network-policy namespace: defaultspec: # Indicates which pods this NetworkPolicy will apply to, selecting by pod's label # podSelector: {} indicates this NetworkPolicy apply to all pods in default ns. podSelector: matchLabels: role: db policyTypes: - Ingress - Egress # Defines which pod can connect to this pod. ingress: # both `from` and `port` rules are satitisfied, then allowed - from: # 1. IP CIDR, connections from pod whose IP in this CIDR are allowd to connect - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 # 2. Namespace, connection from pod whose namespace has following labels are allowed to connect - namespaceSelector: matchLabels: project: myproject # 3. Pod, connections from pod which has following labels are allowed to connect - podSelector: matchLabels: role: frontend # Based on `from`, if the target port of those connection was 6379 and protocl was TCP, allowed. ports: - protocol: TCP port: 6379 # Defines which pod can be connected by this pod # both `to` and `port` rules are satitisfied, then allowed egress: - to: # 1. Connections from this pod can connect to this CIDR - ipBlock: cidr: 10.0.0.0/24 # Based on `to`, if the target port and protocol of this connection was 5978 and TCP, allowed. ports: - protocol: TCP port: 5978 parameters of to and from was the same, as follows(irrelevant informations are omitted): 123456$ kubectl explain networkpolicy.spec.ingress from &lt;[]NetworkPolicyPeer&gt; ports &lt;[]NetworkPolicyPort&gt;$ kubectl explain networkpolicy.spec.egress to &lt;[]NetworkPolicyPeer&gt; ports &lt;[]NetworkPolicyPort&gt; details of NetworkPolicyPeer are as follows: 1234$ kubectl explain networkpolicy.spec.egress.to ipBlock &lt;IPBlock&gt; namespaceSelector &lt;LabelSelector&gt; podSelector &lt;LabelSelector&gt; As for details of IPBlock and LabelSelector, just kubectl explain before coding yamls. Tips NetworkPolicy was namespaced, and only works in the namespace to which it belongs. NetworkPolicy can define only allowed rules. NetworkPolicy selects pod by labels only. Default network policyDeny all in &amp; out bound traffics for a pod 123456789apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-deny-allspec: podSelector: {} policyTypes: - Ingress - Egress The OPA(Open Policy Agent) Gatekeeper Ref: https://kubernetes.io/blog/2019/08/06/opa-gatekeeper-policy-and-governance-for-kubernetes gatekeeper admission controller 拦截所有资源的创建、更新、删除请求，并针对相关资源，做所配置的校验。 定义校验模板12345678910111213141516171819202122232425262728293031apiVersion: templates.gatekeeper.sh/v1beta1kind: ConstraintTemplatemetadata: name: k8srequiredlabelsspec: crd: spec: names: kind: K8sRequiredLabels listKind: K8sRequiredLabelsList plural: k8srequiredlabels singular: k8srequiredlabels validation: # Schema for the `parameters` field openAPIV3Schema: properties: labels: type: array items: string targets: - target: admission.k8s.gatekeeper.sh rego: | package k8srequiredlabels deny[{&quot;msg&quot;: msg, &quot;details&quot;: {&quot;missing_labels&quot;: missing}}] { provided := {label | input.review.object.metadata.labels[label]} required := {label | label := input.parameters.labels[_]} missing := required - provided count(missing) &gt; 0 msg := sprintf(&quot;you must provide labels: %v&quot;, [missing]) } 创建具体约束每个命名空间都需要一个标签hr 1234567891011apiVersion: constraints.gatekeeper.sh/v1beta1kind: K8sRequiredLabelsmetadata: name: ns-must-have-hrspec: match: kinds: - apiGroups: [&quot;&quot;] kinds: [&quot;Namespace&quot;] parameters: labels: [&quot;hr&quot;] 审计Gatekeeper stores audit results as violations listed in the status field of the relevant Constraint. 123456789101112131415161718192021222324252627282930apiVersion: constraints.gatekeeper.sh/v1beta1kind: K8sRequiredLabelsmetadata: name: ns-must-have-hrspec: match: kinds: - apiGroups: [&quot;&quot;] kinds: [&quot;Namespace&quot;] parameters: labels: [&quot;hr&quot;]status: #... violations: - enforcementAction: deny kind: Namespace message: 'you must provide labels: {&quot;hr&quot;}' name: default - enforcementAction: deny kind: Namespace message: 'you must provide labels: {&quot;hr&quot;}' name: gatekeeper-system - enforcementAction: deny kind: Namespace message: 'you must provide labels: {&quot;hr&quot;}' name: kube-public - enforcementAction: deny kind: Namespace message: 'you must provide labels: {&quot;hr&quot;}' name: kube-system Apparmor https://kubernetes.io/docs/tutorials/security/apparmor/ Confine programs or containers to limited set of resources, such as Linux capabilities, network access, file permissions, etc. Works in 2 Modes enforcing, blocks access complain, only reports invalid access Prerequisites works on kubernetes v1.4 + AppArmor kernel moduls enabled Container Runtime supports AppArmor Profile is loaded by kernel UsageAdd annotations to pod which needed to be secured with key, name of container in Pod should be referred in key: 12container.apparmor.security.beta.kubernetes.io/&lt;container_name&gt;: &lt;profile_ref&gt;container.apparmor.security.beta.kubernetes.io/&lt;container_name&gt;: &lt;profile_ref&gt; The profile_ref can be one of: runtime/default to apply the runtime’s default profile localhost/&lt;profile_name&gt; to apply the profile loaded on the host with the name &lt;profile_name&gt; unconfined to indicate that no profiles will be loaded Works View Pod Events kubectl exec &lt;pod_name&gt; -- cat /proc/1/attr/current Helpful commands Show AppArmor Status 1$ apparmor_status Load Profile to kernel 12345678910111213$ apparmor_parser /etc/apparmor.d/nginx_apparmor$ sudo apparmor_parser -q &lt;&lt;EOF#include &lt;tunables/global&gt;profile k8s-apparmor-example-deny-write flags=(attach_disconnected) { #include &lt;abstractions/base&gt; file, # Deny all file writes. deny /** w,}EOF Audit Policy Reference: https://kubernetes.io/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy Getting Started Stage RequestReceived - Before handled by handler chain ResponseStarted - After response header sent, but before response body sent ResponseComplete - After response body sent Panic - After panic occurred. Audit Level None - don’t log events that match this rule Metadata - log request metadata only(user, timestamp,resource,vert) but not request or response body. Request - log event metadata plus request body RequestResponse - log event metadata plus request, response bodies. Example1234567891011apiVersion: audit.k8s.io/v1kind: PolicyomitStages:- ResponseStarted- ResponseComplete- Panicrules:- level: Metadata resources: - group: &quot;&quot; resources: [&quot;pods&quot;] Configure it to kube-apiserver, see audit log. TipsIf the Policy doesn’t work as expected, check kube-apiserver logs as below, make sure the Policy was loaded successfully. Since it seems to load a default AuditPolicy when failled to load the AuditPolicy passed in parameters of kube-apiserver. Logs are as below: 1W0122 16:00:29.139016 1 reader.go:81] Audit policy contains errors, falling back to lenient decoding: strict decoding error: unknown field &quot;rules[0].resources[0].resource&quot; Pod Security Standard Reference https://kubernetes.io/docs/concepts/security/pod-security-standards https://kubernetes.io/docs/concepts/security/pod-security-admission PoliciesThe Pod Security Standards define three different policies to broadly cover the security spectrum. These policies are cumulative and range from highly-permissive to highly-restrictive. This guide outlines the requirements of each policy. 3种策略，每种策略只是定义了检查、校验哪些字段、即校验范围。此3种策略，从上至下，校验范围依次增大。具体校验内容，可参考文档。 Profile Description Privileged Unrestricted policy, providing the widest possible level of permissions. This policy allows for known privilege escalations. Baseline Minimally restrictive policy which prevents known privilege escalations. Allows the default (minimally specified) Pod configuration. Restricted Heavily restricted policy, following current Pod hardening best practices. Levels有3种针对不符合上述3种Policy的处理方式，即强制要求（否则拒绝创建）、记录到审计日志中、用户可见警告。 Mode Description enforce Policy violations will cause the pod to be rejected. audit Policy violations will trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed. warn Policy violations will trigger a user-facing warning, but are otherwise allowed. Usage在命名空间上打标签 123456789101112# The per-mode level label indicates which policy level to apply for the mode.## MODE must be one of `enforce`, `audit`, or `warn`.# LEVEL must be one of `privileged`, `baseline`, or `restricted`.pod-security.kubernetes.io/&lt;MODE&gt;: &lt;LEVEL&gt;# Optional: per-mode version label that can be used to pin the policy to the# version that shipped with a given Kubernetes minor version (for example v1.29).## MODE must be one of `enforce`, `audit`, or `warn`.# VERSION must be a valid Kubernetes minor version, or `latest`.pod-security.kubernetes.io/&lt;MODE&gt;-version: &lt;VERSION&gt; SecurityContext Reference: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ 总共有两个安全配置的地方，位置分别为 pod.spec.securityContext 属于 PodSecurityContext 这个结构体，表示pod中所有的容器都使用这个配置； pod.spec[&quot;initContainers&quot;,&quot;containers&quot;].securityContext 属于 SecurityContext 这个结构体，只限于当前容器使用此配置，且优先级高于上面的配置。 上述两种不同位置的安全配置中，有的字段是重复的，SecurityContext 的优先级更高。两者之间值的差异（都存在的字段已加粗）： PodSecurityContext SecurityContext fsGroup allowPrivilegeEscalation fsGroupChangePolicy capabilities runAsGroup privileged runAsNonRoot procMount runAsUser readOnlyRootFilesystem seLinuxOptions runAsGroup seccompProfile runAsNonRoot supplementalGroups runAsUser sysctls seLinuxOptions windowsOptions seccompProfile windowsOptions 来源：https://www.mrdadong.com/archives/cks-securitycontext 按照如下要求修改 sec-ns 命名空间里的 Deployment secdep 一、用 ID 为 30000 的用户启动容器（设置用户 ID 为: 30000 runAsUser） 二、不允许进程获得超出其父进程的特权（禁止 allowPrivilegeEscalation） 三、以只读方式加载容器的根文件系统（对根文件的只读权限readOnlyRootFilesystem） 注意点： readOnlyRootFilesystem 和 allowPrivilegeEscalation 只存在于SecurityContext中，因此需要为各个容器都配置上，需注意容器数量，避免漏配； runAsUser 存在于PodSecurityContext 和SecurityContext中，可只配 PodSecurityContext RuntimeClass Reference: https://kubernetes.io/docs/concepts/containers/runtime-class/ Create RuntimeClass Specify created RuntimeClass in pod.spec.runtimeClassName Secret Reference: https://kubernetes.io/docs/concepts/configuration/secret Secret Type Mount to a pod 练手速【来源】 在 namespace istio-system 中获取名为 db1-test 的现有 secret 的内容。将 username 字段存储在名为 /cks/sec/user.txt 的文件中，并将 password 字段存储在名为 /cks/sec/pass.txt 的文件中。 注意：你必须创建以上两个文件，他们还不存在。 注意：不要在以下步骤中使用/修改先前创建的文件，如果需要，可以创建新的临时文件。 在istio-system namespace 中创建一个名为 db2-test 的新 secret，内容如下： username : production-instance password : KvLftKgs4aVH 最后，创建一个新的 Pod，它可以通过卷访问 secret db2-test Pod 名称 secret-pod Namespace istio-system 容器名 dev-container 镜像 nginx 卷名 secret-volume 挂载路径 /etc/secret ServiceAccount Reference: https://kubernetes.io/docs/concepts/security/service-accounts/ Prevent kubernetes from injecting credentials for a pod 12$ kubectl explain sa.automountServiceAccountToken$ kubectl explain pod.spec.automountServiceAccountToken Set one of fields above to false to prevent auto injection for a pod. Restrict access to SecretsSet annotation kubernetes.io/enforce-mountable-secrets to true for a ServiceAccount, then only secrets in the field of sa.secrets of this ServiceAccount was allowed to use in a pod, such as a secret volume, envFrom, imagePullSecrets. How to use ServiceAccount to connect to apiserver? reference 123curl --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt --header &quot;Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&quot; -X GET https://kubernetes.default.svc/api/v1/namespaces/default/secrets# orcurl -k -XGET --header &quot;Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&quot; https://kubernetes.default.svc/api/v1/namespaces/default/secrets 整个kubeAPIServer提供了三类API Resource接口： core group：主要在 /api/v1 下； named groups：其 path 为 /apis/$GROUP/$VERSION； 系统状态的一些 API：如/metrics 、/version 等； 而API的URL大致以 /apis/{group}/{version}/namespaces/{namespace}/{resources}/{name} 组成，结构如下图所示： Tips: 在apiserver的URL中，资源需要用复数形式，如： 12curl -k -H &quot;Authorization: Bearer $(cat /run/secrets/kubernetes.io/serviceaccount/token)&quot; \\https://kubernetes.default.svc/api/v1/namespaces/default/pods/shs-dep-b56c568d6-n8h6d etcdHow to use etcdctl to get raw data from etcd? 1234ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt \\--cert=/etc/kubernetes/pki/etcd/peer.crt \\--key=/etc/kubernetes/pki/etcd/peer.key \\get /registry/secrets/default -w=json | jq . Upgrade kubernetes versionFollow these steps: for master k drain controller-plane apt-mark unhold kubeadm apt-mark hold kubelet kubectl apt update &amp;&amp; apt upgrade -y kubeadm upgrade plan kubeadm upgrade apply v1.2x.x kubeadm upgrade plan(for check purpose) apt-mark hold kubeadm apt-mark unhold kubelet kubectl apt install kubectl=1.2x.x kubelet=1.2x.x apt-mark hold kubelet kubectl systemctl restart kubelet systemctl status kubelet k uncordon controller-plane for node k drain node apt update apt-mark unhold kubeadm apt-mark hold kubectl kubelet apt install kubeadm=1.2x.x kubeadm upgrade plan kubeadm upgrade node apt-mark hold kubeadm apt-mark unhold kubectl kubelet apt install kubectl=1.2x.x kubelet=1.2x.x systemctl restart kubelet systemctl status kubelet k uncordon kubelet check upgrade result k get node ImagePolicyWebhook https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook 安全工具使用kube-benchA tool to detect potential security issues and give the specific means to solve the issue. Reference: Running Method https://github.com/aquasecurity/kube-bench 123# Simple way in a kubernetes cluster created by kubeadm$ kubectl apply \\ -f https://raw.githubusercontent.com/aquasecurity/kube-bench/main/job.yaml ContentsConsists of the following topics: master etcd controlplane node policies Each topic starts with a list of items which was checked with checked status, then a list of remediations to FAIL or WARN items given. You can fix those issues under the given instructions. At last, check summary of this topic. Here is a output example for topic master 123456789101112131415[WARN] 1.1.9 Ensure that the Container Network Interface file permissions are set to 600 or more restrictive (Manual)[WARN] 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root (Manual)== Remediations master ==1.1.9 Run the below command (based on the file location on your system) on the control plane node.For example, chmod 600 &lt;path/to/cni/files&gt;1.1.10 Run the below command (based on the file location on your system) on the control plane node.For example,chown root:root &lt;path/to/cni/files&gt;== Summary master ==38 checks PASS9 checks FAIL13 checks WARN0 checks INFO Full contexts can be touch by this link trivy Reference: https://github.com/aquasecurity/trivy Scan a docker image 1trivy image --severity LOW,MEDIUM ghcr.io/feiyudev/shs:latest 扫描某命名空间下所有pod所使用的镜像包含 HIGH, CRITICAL 类型漏洞，并删除该pod 1k get pod -A -ojsonpath=&quot;{range .items[*]}{.spec['initContainers','containers'][*].image} {.metadata.name} {'#'} {end}&quot; | sed 's|#|\\n|g' | sed 's|^ ||g' | sed 's| $||g' | awk '{cmd=&quot;echo &quot;$2&quot;; trivy -q image &quot;$1&quot; --severity HIGH,CRITICAL | grep Total&quot;;system(cmd)}' 该命令的注意点： jsonpath range awk system(cmd) sed replace sysdig Reference: https://github.com/draios/sysdig Video Usage Installation(Based on Ubuntu 22.04) Download deb from sysdig-release sudo dpkg -i sysdig-0.34.1-x86_64.deb sudo apt -f install Output format12%evt.num %evt.outputtime %evt.cpu %proc.name (%thread.tid) %evt.dir %evt.type %evt.info173884 15:06:10.075401786 7 sudo (1453517.1453517) &gt; read fd=9(&lt;f&gt;/dev/ptmx) size=65536 Notes: evt.dir aka event direction, &lt; represents out, &gt; represents in. evt.type aka event type, perceiving it as a name of system call. Chiselspredefined function sets based on sysdig events, to implements complex situation. Locates in /usr/share/sysdig/chisels on Linux machine. What are those chisels? To see chisels. 123sysdig -cl# orsysdig --list-chisels To use a chisel 123456789101112131415161718# See HTTP logsysdig -c httplog2024-01-25 23:06:16.423272777 &lt; method=GET url=:8080/health response_code=200 latency=0ms size=2B2024-01-25 23:06:16.423299653 &gt; method=GET url=:8080/health response_code=200 latency=0ms size=2B# See CPU usage rankingsysdig -c topprocs_cpuCPU% Process PID--------------------------------------------------------------------------------8.01% kube-apiserver 391243.00% kubelet 250073.00% etcd 16132.00% sysdig 1024892.00% kube-controller 389572.00% calico-node 47051.00% containerd 8741.00% vmtoolsd 7901.00% kube-scheduler 390170.00% svlogd 2505 Advanced usage about a chisel 12345678910111213141516171819202122232425262728293031323334$ sysdig -i spy_fileCategory: I/O-------------spy_file Echo any read/write made by any process to all files. Optionall y, you can provide the name of one file to only intercept reads /writes to that file.This chisel intercepts all reads and writes to all files. Instead of all files, you can limit interception to one file.Args:[string] read_or_write - Specify 'R' to capture only read event s; 'W' to capture only write events; 'RW' to capture read and w rite events. By default both read and write events are captured .[string] spy_on_file_name - The name of the file which the chis el should spy on for all read and write activity.$ sysdig -c spy_file &quot;RW /root/spy_file_test.txt&quot;23:53:25.592303985 date(112109) W 32B /root/spy_file_test.txtThu Jan 25 11:53:25 PM HKT 202423:53:43.333152845 cat(112206) R 32B /root/spy_file_test.txtThu Jan 25 11:53:25 PM HKT 202423:53:43.333166670 cat(112206) R 0B /root/spy_file_test.txt NULL23:53:51.856062624 date(112270) W 32B /root/spy_file_test.txtThu Jan 25 11:53:51 PM HKT 202423:53:56.965894638 cat(112307) R 64B /root/spy_file_test.txtThu Jan 25 11:53:25 PM HKT 2024Thu Jan 25 11:53:51 PM HKT 202423:53:56.965902094 cat(112307) R 0B /root/spy_file_test.txt NULL Usage Save events to a file 1sysdig -w test.scap Read events from a file while analyzing (by chisels) 1sysdig -r test.scap -c httptop Specify the format to be used when printing the events-p , –print= Specify the format to be used when printing the events. With -pc or -pcontainer will use a container-friendly format. With -pk or -pkubernetes will use a kubernetes-friendly format. With -pm or -pmesos will use a mesos-friendly format. See the examples section below for more info. 1sysdig -r test.scap -c httptop -pc Specify the number of events Sysdig should capture by passing it the -n flag. Once Sysdig captures the specified number of events, it’ll automatically exit: 1sysdig -n 5000 -w test.scap Use the -C flag to configure Sysdig so that it breaks the capture into smaller files of a specified size.The following example continuously saves events to files &lt; 10MB: 1sysdig -C 10 -w test.scap Specify the maximum number of files Sysdig should keep with the -W flag. For example, you can combine the -C and -W flags like so: 1sysdig -C 10 -W 4 -w test.scap You can analyze the processes running in the WordPress container with: 1sysdig -pc -c topprocs_cpu container.name=wordpress-sysdig_wordpress_1 -M Stop collecting after reached. Help关于filter可用的字段，可以通过sysdig -l来查看所有支持的字段。例如查看容器相关的过滤字段，有： 12345678910111213141516171819202122232425ubuntu@primary:~$ sysdig -l | grep &quot;^container.&quot;container.id The truncated container ID (first 12 characters), e.g. 3ad7b26ded6d is extracted from thecontainer.full_id The full container ID, e.g.container.name The container name. In instances of userspace container engine lookup delays, this fieldcontainer.image The container image name (e.g. falcosecurity/falco:latest for docker). In instances ofcontainer.image.id The container image id (e.g. 6f7e2741b66b). In instances of userspace container enginecontainer.type The container type, e.g. docker, cri-o, containerd etc.container.privileged 'true' for containers running as privileged, 'false' otherwise. In instances of userspacecontainer.mounts A space-separated list of mount information. Each item in the list has the formatcontainer.mount (ARG_REQUIRED) Information about a single mount, specified by number (e.g.container.mount.source (ARG_REQUIRED) The mount source, specified by number (e.g. container.mount.source[0]) orcontainer.mount.dest (ARG_REQUIRED) The mount destination, specified by number (e.g. container.mount.dest[0])container.mount.mode (ARG_REQUIRED) The mount mode, specified by number (e.g. container.mount.mode[0]) orcontainer.mount.rdwr (ARG_REQUIRED) The mount rdwr value, specified by number (e.g. container.mount.rdwr[0])container.mount.propagation (ARG_REQUIRED) The mount propagation value, specified by number (e.g.container.image.repository The container image repository (e.g. falcosecurity/falco). In instances of userspacecontainer.image.tag The container image tag (e.g. stable, latest). In instances of userspace container enginecontainer.image.digest The container image registry digest (e.g.container.healthcheck The container's health check. Will be the null value (&quot;N/A&quot;) if no healthcheckcontainer.liveness_probe The container's liveness probe. Will be the null value (&quot;N/A&quot;) if no liveness probecontainer.readiness_probe The container's readiness probe. Will be the null value (&quot;N/A&quot;) if no readiness probecontainer.start_ts Container start as epoch timestamp in nanoseconds based on proc.pidns_init_start_ts andcontainer.duration Number of nanoseconds since container.start_ts.container.ip The container's / pod's primary ip address as retrieved from the container engine. Onlycontainer.cni.json The container's / pod's CNI result field from the respective pod status info. It contains 可以看出，container.id只能取前12个字符，另外也可以用容器id的全名，即container.full_id。另外k8s可支持的字段有： 1234567891011ubuntu@primary:~$ sysdig -l | grep &quot;^k8s.&quot;k8s.ns.name The Kubernetes namespace name. This field is extracted from the container runtime socketk8s.pod.name The Kubernetes pod name. This field is extracted from the container runtime socketk8s.pod.id [LEGACY] The Kubernetes pod UID, e.g. 3e41dc6b-08a8-44db-bc2a-3724b18ab19a. This legacyk8s.pod.uid The Kubernetes pod UID, e.g. 3e41dc6b-08a8-44db-bc2a-3724b18ab19a. Note that the pod UIDk8s.pod.sandbox_id The truncated Kubernetes pod sandbox ID (first 12 characters), e.g 63060edc2d3a. Thek8s.pod.full_sandbox_id The full Kubernetes pod / sandbox ID, e.gk8s.pod.label (ARG_REQUIRED) The Kubernetes pod label. The label can be accessed either with thek8s.pod.labels The Kubernetes pod comma-separated key/value labels. E.g. 'foo1:bar1,foo2:bar2'. Thisk8s.pod.ip The Kubernetes pod ip, same as container.ip field as each container in a pod shares thek8s.pod.cni.json The Kubernetes pod CNI result field from the respective pod status info, same as Traps 此处有坑 使用container.id过滤时，注意id的长度需要为12，不然数据出不来。通过crictl ps看到的container id是13位的，使用sysdig时，需要注意长度。 12345678910111213141516ubuntu@primary:~$ crictl ps | grep -v ^C | awk '{print $1,$2,$6,$7}'0fd88042f1ddf 848c5b919e8d3 Running calico-apiserverad81cac0dbf9e 848c5b919e8d3 Running calico-apiserverf6d6b81c75f69 4e87edec0297d Running calico-kube-controllers87c4fbddeb123 d36ef67f7b24c Running csi-node-driver-registrar46095b3ea4bf6 91c1c91da7602 Running calico-csi51e65353815dc cbb01a7bd410d Running coredns7fc6f4ad4aafa cbb01a7bd410d Running corednsde42d610f5530 1843802b91be8 Running calico-node21ae9adf53e47 b33768e0da1f8 Running calico-typhaa2f7701ceae6c 7bc79e0d3be4f Running tigera-operatord91edc95d2edf 9344fce2372f8 Running kube-proxy5f7d85179ade0 6fc5e6b7218c7 Running kube-schedulerd40dd28cc171c 138fb5a3a2e34 Running kube-controller-managerc71d33c5aea6e 8a9000f98a528 Running kube-apiserver0cdeff9542f15 a0eed15eed449 Running etcd falco Reference: https://falco.org/docs strace监控进程的系统调用和信号量，基础的使用方式 监听某个已存在的进程 strace -p &lt;pid&gt; 直接启动一个二进制 strace &lt;binary-name&gt; 对输出结果进行过滤 strace -e trace=file 考试说明书 Handbook of CKS exam Requirments of your computer, microphone, camera, speaker, etc. Don’t use headphone, earbuds. [PSI Bridge FAQ] System Requirements System Requirements to take the exam Browser recommand Google Chrome Exam Details Online tests, 15-20 performance-based tasks, 2 hours to complete the tasks. Don’t cheat, audio,camera,screen capture of the test will be reviewed.","link":"/2024/01/30/64634917304d.html"},{"title":"crossGFW玩具档案","text":"这是一个玩具脚本，能在windows和linux上面跑。当时有一个网站提供免费的ss账号，但是账号、密码会定时变更，所以写了这个脚本来爬取免费vpn账号，然后配置好参数，最后双击启动shadowsocks。好傻吊的玩具，被我校招时一直写简历上面，哈哈。放在 repo 里面，感觉不值得，以文章的形式留个纪念吧！ 项目树状结构图： 12345678910111213.├── Shadowsocks.exe├── crossGFW.jar├── gui-config.json├── src│ ├── GetData2Json.java│ ├── Main.java│ ├── Server.java│ └── StartProxy.java├── sss.bat└── statistics-config.json1 directory, 9 files 入口入口很简单，双击 sss.bat 脚本，代理就自己挂上了。但是貌似在jar包里面也启动了ss代理，搞不懂啊。 123java -jar crossGFW.jartype gui-config.jsonpause 抓取免费账号现在的疑问为什么当时不用Python写，非得用Java。 此处的入口是一个Main方法，它主要抓取免费账号、填充vpn配置和启动ss。 123456789/** * Created by fcy on 2017/3/6. */public class Main { public static void main(String[] args) { GetData2Json.getJson(); StartProxy.start(); }} 抓取免费账号与填充配置主要逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151import java.io.BufferedReader;import java.io.FileWriter;import java.io.IOException;import java.io.InputStreamReader;import java.net.URL;import java.net.URLConnection;import java.util.ArrayList;import java.util.List;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * Created by fcy on 2017/3/6. */public class GetData2Json { private static List&lt;String&gt; urlList ; private static List&lt;Server&gt; serverList = new ArrayList&lt;Server&gt;(); static{ urlList = new ArrayList&lt;String&gt;(); urlList.add(&quot;http://www.ishadowsocks.net&quot;); urlList.add(&quot;https://freessr.xyz&quot;); } public static String getHTML(String url){ StringBuffer sb = new StringBuffer(); BufferedReader br; String line = null; try{ URL url1 = new URL(url); URLConnection conn = url1.openConnection(); conn.setRequestProperty(&quot;accept&quot;, &quot;*/*&quot;); conn.setRequestProperty(&quot;connection&quot;, &quot;Keep-Alive&quot;); conn.setRequestProperty(&quot;user-agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot;); conn.connect(); br = new BufferedReader(new InputStreamReader(conn.getInputStream())); while ((line = br.readLine()) != null) { sb.append(line); sb.append(&quot;\\n&quot;); } }catch (Exception e){ e.printStackTrace(); }finally { return sb.toString(); } } private static void initData(){ String re = &quot; &lt;h4&gt;[ABC]服务器地址:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot; &lt;h4&gt;端口:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot;&lt;h4&gt;[ABC]密码:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot; &lt;h4&gt;加密方式:([^&lt;]*)&lt;/h4&gt;\\n&quot;; String HTML; HTML = getHTML(urlList.get(0)); Pattern p = Pattern.compile(re); Matcher m = p.matcher(HTML); while(m.find()){ serverList.add(new Server(m.group(1),m.group(2),m.group(3),m.group(4))); } re = &quot;\\\\s*&lt;h4&gt;[A-Z]*服务器地址:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot;\\\\s*&lt;h4&gt;端口:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot;\\\\s*&lt;h4&gt;密码:([^&lt;]*)&lt;/h4&gt;\\n&quot; + &quot;\\\\s*&lt;h4&gt;加密方式:([^&lt;]*)&lt;/h4&gt;&quot;; HTML = getHTML(urlList.get(1)); Pattern p2 = Pattern.compile(re); Matcher m2 = p2.matcher(HTML); while(m2.find()){ serverList.add(new Server(m2.group(1),m2.group(2),m2.group(3),m2.group(4))); } } public static void getJson() { String os = System.getProperty(&quot;os.name&quot;).toLowerCase(); initData(); StringBuffer sb = new StringBuffer(); for (int i = 0;i&lt;serverList.size();i++){ sb.append(serverList.get(i)); if(i&lt;serverList.size()-1){ sb.append(&quot;,\\n&quot;); }else{ sb.append(&quot;\\n&quot;); } } if(os.contains(&quot;windows&quot;)){ StringBuffer sb1 = new StringBuffer(); sb1.append(&quot;{\\n&quot; + &quot;\\&quot;configs\\&quot; : [\\n&quot;); sb1.append(sb.toString()); sb1.append(&quot;],\\n&quot; + &quot; \\&quot;strategy\\&quot;: null,\\n&quot; + &quot; \\&quot;index\\&quot;: 0,\\n&quot; + &quot; \\&quot;global\\&quot;: true,\\n&quot; + &quot; \\&quot;enabled\\&quot;: true,\\n&quot; + &quot; \\&quot;shareOverLan\\&quot;: false,\\n&quot; + &quot; \\&quot;isDefault\\&quot;: false,\\n&quot; + &quot; \\&quot;localPort\\&quot;: 1080,\\n&quot; + &quot; \\&quot;pacUrl\\&quot;: null,\\n&quot; + &quot; \\&quot;useOnlinePac\\&quot;: false,\\n&quot; + &quot; \\&quot;availabilityStatistics\\&quot;: false,\\n&quot; + &quot; \\&quot;autoCheckUpdate\\&quot;: true,\\n&quot; + &quot; \\&quot;isVerboseLogging\\&quot;: false,\\n&quot; + &quot; \\&quot;logViewer\\&quot;: {\\n&quot; + &quot; \\&quot;fontName\\&quot;: \\&quot;Consolas\\&quot;,\\n&quot; + &quot; \\&quot;fontSize\\&quot;: 8.0,\\n&quot; + &quot; \\&quot;bgColor\\&quot;: \\&quot;black\\&quot;,\\n&quot; + &quot; \\&quot;textColor\\&quot;: \\&quot;white\\&quot;,\\n&quot; + &quot; \\&quot;topMost\\&quot;: false,\\n&quot; + &quot; \\&quot;wrapText\\&quot;: false,\\n&quot; + &quot; \\&quot;toolbarShown\\&quot;: false,\\n&quot; + &quot; \\&quot;width\\&quot;: 600,\\n&quot; + &quot; \\&quot;height\\&quot;: 400,\\n&quot; + &quot; \\&quot;top\\&quot;: 328,\\n&quot; + &quot; \\&quot;left\\&quot;: 766,\\n&quot; + &quot; \\&quot;maximized\\&quot;: true\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;proxy\\&quot;: {\\n&quot; + &quot; \\&quot;useProxy\\&quot;: false,\\n&quot; + &quot; \\&quot;proxyType\\&quot;: 0,\\n&quot; + &quot; \\&quot;proxyServer\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;proxyPort\\&quot;: 0,\\n&quot; + &quot; \\&quot;proxyTimeout\\&quot;: 3\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;hotkey\\&quot;: {\\n&quot; + &quot; \\&quot;SwitchSystemProxy\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;ChangeToPac\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;ChangeToGlobal\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;SwitchAllowLan\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;ShowLogs\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;ServerMoveUp\\&quot;: \\&quot;\\&quot;,\\n&quot; + &quot; \\&quot;ServerMoveDown\\&quot;: \\&quot;\\&quot;\\n&quot; + &quot; }\\n&quot; + &quot;}&quot;); try { FileWriter fw = new FileWriter(&quot;gui-config.json&quot;); fw.write(sb1.toString()); fw.close(); } catch (IOException e) { e.printStackTrace(); } }else if(os.contains(&quot;linux&quot;)){ try { FileWriter fw = new FileWriter(&quot;.config.json&quot;); fw.write(serverList.get(4).toString()); fw.close(); } catch (IOException e) { e.printStackTrace(); } }else{ System.out.println(&quot;there is no solution yet!&quot;); } }} 没搞明白当时的想法，我为啥还定义了一个 Server POJO类，代码里面并没见到调用呀。 1234567891011121314151617181920212223242526272829303132/** * Created by fcy on 2017/3/6. */public class Server { String server,server_port,password,method,remarks,auth,timeout; String local_port; @Override public String toString() { return &quot;{&quot; + &quot;\\&quot;server\\&quot;: \\&quot;&quot; + server + &quot;\\&quot;,\\n&quot; + &quot;\\&quot;server_port\\&quot;: &quot; + server_port + &quot;,\\n&quot; + &quot;\\&quot;password\\&quot;: \\&quot;&quot; + password + &quot;\\&quot;,\\n&quot; + &quot;\\&quot;method\\&quot;: \\&quot;&quot; + method + &quot;\\&quot;,\\n&quot; + &quot;\\&quot;remarks\\&quot;: \\&quot;&quot; + remarks + &quot;\\&quot;,\\n&quot; + &quot;\\&quot;auth\\&quot;: &quot; + auth + &quot;,\\n&quot; + &quot;\\&quot;timeout\\&quot;: &quot; + timeout + &quot;,\\n&quot; + &quot;\\&quot;local_port\\&quot;: &quot;+local_port+&quot;\\n&quot;+ '}'; } public Server(String server, String server_port, String password, String method) { this.server = server; this.server_port = server_port; this.password = password; this.method = method; this.remarks = &quot;&quot;; this.auth = &quot;false&quot;; this.timeout = &quot;10&quot;; this.local_port = &quot;5555&quot;; }} 启动ss最魔幻的事情还是发生了，与sss.bat里面的代码貌似有点冲突。 123456789101112131415161718192021222324252627282930313233343536373839import java.io.IOException;/** * Created by fcy on 2017/3/6. */public class StartProxy { public static void winStart(){ Runtime rt = Runtime.getRuntime(); Process p = null; try { p = rt.exec(&quot;cmd&quot;); p = rt.exec(&quot;shadowsocks.exe&quot;); } catch (IOException e) { e.printStackTrace(); } System.out.println(p.toString()); } public static void linuxStart(){ Runtime rt = Runtime.getRuntime(); Process p = null; try { p=rt.exec(&quot;(nohup sslocal -c .config.json &gt; .iss.log &amp;)&quot;); } catch (IOException e) { e.printStackTrace(); } System.out.println(p.toString()); } public static void start(){ String os = System.getProperty(&quot;os.name&quot;).toLowerCase(); if(os.contains(&quot;windows&quot;)){ winStart(); }else if(os.contains(&quot;linux&quot;)){ linuxStart(); }else{ System.out.println(&quot;there is no solution yet!&quot;); } }} 也许是后面加的Java代码，但是 who cares，反正它也没有什么实际价值与维护的意义，当做纪念吧~","link":"/2017/03/06/4a853792aafb.html"},{"title":"curl设置header和表单数据","text":"老是分不清楚header和表单时的写法，每次都去翻别人的博客 从浏览器中获取某个请求的curl版本下面是几种上述方法拷贝出来的curl命令参数，特意列出来，供参考一下。 设置header与表单GET请求 12345678910curl 'http://xxxxxxxxx/vehicles?page=1&amp;size=20&amp;number=8' \\-H 'Accept-Encoding: gzip, deflate' \\-H 'Accept-Language: zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5' \\-H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36' \\-H 'Accept: application/json, text/plain, */*' \\-H 'Referer: http://xxxxxxxxx/' \\-H 'userId: 454' \\-H 'Connection: keep-alive' \\-H 'token: af0d8773933eaeffc81d97924bd2a8fc' \\--compressed POST请求，发送body信息--data-binary DATA HTTP POST binary data (H) 12345678910111213curl 'http://xxxxxxxxx/nemt/nemt/order/cancel' -H 'Origin: http://xxxxxxxxx' -H 'Accept-Encoding: gzip, deflate' -H 'Accept-Language: zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36' -H 'Content-Type: application/json' -H 'Accept: application/json, text/plain, */*' -H 'Referer: http://xxxxxxxxx/' -H 'userId: 454' -H 'Connection: keep-alive' -H 'token: af0d8773933eaeffc81d97924bd2a8fc' --data-binary '{&quot;id&quot;:&quot;10076&quot;,&quot;reasonId&quot;:0}' --compressed POST请求，发送表单--data DATA HTTP POST data (H) 12# 此例来自：http://www.ruanyifeng.com/blog/2011/09/curl.htmlcurl -X POST --data &quot;data=xxx&quot; example.com/form.cgi 文件上传123456# 此例来自项目中某安卓端代码do_upload(){ curl -X POST -F &quot;file=@$1&quot; $2}# 此例来自：http://www.ruanyifeng.com/blog/2011/09/curl.htmlcurl --form upload=@localfilename --form press=OK [URL] OK，清理书签完毕！","link":"/2019/03/22/2a22ce9bac07.html"},{"title":"gRPC go 入门示例","text":"准备 操作环境：macOS Big Sur 安装 protobuf1brew install protobuf 安装 protoc-gen-go*12go get google.golang.org/protobuf/cmd/protoc-gen-gogo get google.golang.org/grpc/cmd/protoc-gen-go-grpc 编写 proto123456789101112131415161718192021222324syntax = &quot;proto3&quot;;option go_package = &quot;github.com/feivxs/helloworld&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;// The greeting service definition.service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) {}}// The request message containing the user's name.message HelloRequest { string name = 1;}// The response message containing the greetingsmessage HelloReply { string message = 1;} 生成 client &amp; server 端接口1234protoc \\--go_out=. --go_opt=paths=source_relative\\ --go-grpc_out=. --go-grpc_opt=paths=source_relative\\ helloworld/helloworld.proto 当上述命令成功执行后，会生成两个文件，分别为： 12345$ tree helloworld helloworld├── helloworld.proto├── helloworld.pb.go (generated)└── helloworld_grpc.pb.go (generated) 其中所生成的两个文件的作用分别为： helloworld.pb.go生成 proto buffer 相关代码，包括请求、响应类型，以及发布、序列化等。 helloworld_grpc.pb.go 一个给 client 调用的接口类型（定义在 proto 中的方法） 一个给 server 端实现的接口类型（定义在 proto 中的方法） 编写 server 端实现接口代码12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;context&quot; &quot;log&quot; &quot;net&quot; pb &quot;github.com/feivxs/helloworld/helloworld&quot; &quot;google.golang.org/grpc&quot;)const ( port = &quot;:50051&quot;)// server is used to implement helloworld.GreeterServer.type server struct { pb.UnimplementedGreeterServer}// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) { log.Printf(&quot;Received: %v&quot;, in.GetName()) return &amp;pb.HelloReply{Message: &quot;Hello &quot; + in.GetName()}, nil}func main() { lis, err := net.Listen(&quot;tcp&quot;, port) if err != nil { log.Fatalf(&quot;failed to listen: %v&quot;, err) } s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server{}) if err := s.Serve(lis); err != nil { log.Fatalf(&quot;failed to serve: %v&quot;, err) }} 编写 client 端调用接口代码12345678910111213141516171819202122232425262728293031323334353637383940package mainimport ( &quot;context&quot; &quot;log&quot; &quot;os&quot; &quot;time&quot; pb &quot;github.com/feivxs/helloworld/helloworld&quot; &quot;google.golang.org/grpc&quot;)const ( address = &quot;localhost:50051&quot; defaultName = &quot;world&quot;)func main() { // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(&quot;did not connect: %v&quot;, err) } defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 { name = os.Args[1] } ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, &amp;pb.HelloRequest{Name: name}) if err != nil { log.Fatalf(&quot;could not greet: %v&quot;, err) } log.Printf(&quot;Greeting: %s&quot;, r.GetMessage())} Reference https://grpc.io/docs/languages/go/basics https://grpc.io/docs/languages/go/quickstart","link":"/2021/06/16/3154846ec83e.html"},{"title":"git中的回车换行符CRLF与LF","text":"设置core.autocrlf假如你正在Windows上写程序，又或者你正在和其他人合作，他们在Windows上编程，而你却在其他系统上，在这些情况下，你可能会遇到行尾结束符问题。这是因为Windows使用回车和换行两个字符来结束一行，而Mac和Linux只使用换行一个字符。虽然这是小问题，但它会极大地扰乱跨平台协作。 trueGit可以在你提交时自动地把行结束符CRLF转换成LF，而在签出代码时把LF转换成CRLF。用core.autocrlf来打开此项功能，如果是在Windows系统上，把它设置成true，这样当签出代码时，LF会被转换成CRLF：$ git config --global core.autocrlf true inputLinux或Mac系统使用LF作为行结束符，因此你不想 Git 在签出文件时进行自动的转换；当一个以CRLF为行结束符的文件不小心被引入时你肯定想进行修正，把core.autocrlf设置成input来告诉 Git 在提交时把CRLF转换成LF，签出时不转换：$ git config --global core.autocrlf input这样会在Windows系统上的签出文件中保留CRLF，会在Mac和Linux系统上，包括仓库中保留LF。 false如果你是Windows程序员，且正在开发仅运行在Windows上的项目，可以设置false取消此功能，把回车符记录在库中：$ git config --global core.autocrlf false 来源《git pro》","link":"/2019/01/28/85000bfee769.html"},{"title":"git使用笔记","text":"记录自己在使用git中所用到的命令，算是半个笔记吧~ git merge &amp; git rebase参考 git初次运行时的配置三个地方 系统级别，/etc/gitconfig, 修改此选项时需要加上 --system选项 当前用户级别，~/.gitconfig, 修改此选项时需要加上--global选项 当前仓库级别，.git/config。低级别覆盖高级别的配置信息。 配置信息 用户名 git config --global user.name &quot;John Doe&quot; 用户邮箱 git config --global user.email johndoe@example.com 编辑器 git config --global core.editor vim 查看信息 查看所有配置信息 git config --list 查看某项配置信息 git config user.name 忽略文件.gitignore文件忽略不想进行版本控制的文件。参考https://github.com/github/gitignore 命令的详情git add三个作用： 添加追踪 添加到暂存区 标记冲突文件状态为已解决 git status -s如果嫌弃不带-s的命令输出的信息太繁杂，那么可以使用这个。新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。出现在右边的 M 表示该文件被修改了但是还没放入暂存区，出现在靠左边的 M 表示该文件被修改了并放入了暂存区。 查看修改git diff 查看尚未暂存的文件更新了哪些部分git diff --staged 查看已暂存的将要添加到下次提交里的内容 提交更新git commit -m 添加一段信息，作为提交说明-a 跳过暂存区，直接将已追踪的文件暂存起来并提交–amend 此次提交的结果替代上次提交的结果 删除文件git rm 从已跟踪文件清单中移除（确切地说，是从暂存区域移除），并连带从工作目录中删除指定的文件-f 删除之前修改过并且已经放到暂存区域的文件–cached 把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中 移动文件（或重命名）git mv等价于 123mv git rmgit add 查看提交git log -p 显示每次提交的差异-p -2 显示最近两次的差异–stat 每次提交的简略的统计信息–graph 显示 ASCII 图形表示的分支合并历史。–pretty使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和format（后跟指定格式）。 移除暂存文件git reset HEAD &lt;file&gt;... 将文件从暂存区移除 撤销文件的修改内容git checkout -- &lt;file&gt;... 将此文件做的文件全部撤销 使用总结git基本命令 git init 在执行命令的目录下创建git仓库 git add * 添加所有的文件到缓存区 git commit * -m 提交所有追踪的文件到git仓库 git pull origin master 从远程仓库拉代码到本地git仓库 git push origin master 将自己的代码推送到远程git仓库 创建新的分支 git branch 显示所有的分支 git branch -a 显示所有的分支包括远程的分支 git checkout -b branch_name 创建branch_name分支并切换到该分支上 git checkout branch_name 切换到branch_name分支上 关于.gitignore文件 这个文件顾名思义是起到忽略作用的，在git仓库中使用此文件，将不需要添加进git仓库的文件排除在外。可是在使用的时候，会遇到向其中添加了文件名，却不起作用的情况。很奇怪，参考网上的说法，当已经添加该文件进入git仓库后，再在.gitignore中除去该文件，就会遇到这种情况，我就是属于这种情况，这时需要将其从仓库中删除，然后再执行git add时就会忽略掉该文件..gitignore只对未追踪的文件有过滤效果。可参考如下代码 123git rm -r --cached .git add .git commit -m &quot;comment&quot; 关于本地分支与远程分支的链接关系当从远程仓库上面拉下代码之后，其中有若干分支，如若想在本地建立一个分支，并使之与远程分支中的某个分支对应，那么该如何操作呢？ git checkout --track origin/branch_name local_branch_name 这个命令会自动创建local_branch_name，如果它已经存在了，那么将执行失败~ 查看、删除远程仓库分支/Tag 试了试将所有的feature分支都推送到远程仓库，后来发现那个分支基本上没啥用，在将feature分支merge到dev分支上后，feature分支就一直处于当初的那个状态，当dev一直向前走的时候，你再次回到该feature分支，相当于回到了dev分支之前的某个节点，因此我认为将其推送到远程仓库是没有多大的意义的，所以动起了删掉所有本地和远程仓库中已merge的feature分支。 首先是查看远程仓库里面所含有的feature分支： 123456789asahi@asahis-MBP  ~/AndroidStudioProjects/NHKNews   master  git branch -a dev feature-remote* master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/feature-main-page remotes/origin/feature-remote remotes/origin/master 当使用git branch -d feature-main-page之后，得到的结果如上，可是我只是删除了本地的分支，远程的分支依然还在，该如何删除这个远程仓库里面的分支呢？有git命令为git push origin --delete origin/feature-main-page，可是出现错误，不能删除，因此试了另外一个命令git push origin :feature-main-page，成功删除。然后对于feature-remote分支，直接使用前条命令，可将本地与远程仓库里面的分支一起删除. 再次使用git remote show origin，查询得到的结果如下： 123456789101112* remote origin Fetch URL: git@github.com:xuchuanjun/NHKNews.git Push URL: git@github.com:xuchuanjun/NHKNews.git HEAD branch: master Remote branches: dev tracked master tracked Local branch configured for 'git pull': master merges with remote master Local refs configured for 'git push': dev pushes to dev (up to date) master pushes to master (up to date) 总结：超强的总结","link":"/2017/09/25/7170b57313bb.html"},{"title":"Google Pixel 7a玩机攻略","text":"获取root权限解锁bootloader 12adb reboot bootloaderfastboot flashing unlock 刷带magisk的init_boot.img 要解锁 ADB 锁屏，可以使用命令 adb shell input keyevent 26，这将模拟设备上的电源键按下，从而解锁屏幕。 Referenceshttps://sspai.com/post/76276 https://developers.google.com/android/images","link":"/2024/02/21/84ee50d29e8e.html"},{"title":"jQuery的基础使用方法","text":"jQuery 语法jQuery 语法是通过选取 HTML 元素，并对选取的元素执行某些操作。 基础语法： $(selector).action()美元符号定义 jQuery选择符（selector）”查询”和”查找” HTML 元素jQuery 的 action() 执行对元素的操作 实例:$(this).hide() - 隐藏当前元素$(&quot;p&quot;).hide() - 隐藏所有&lt;p&gt; 元素$(&quot;p.test&quot;).hide() - 隐藏所有 class=&quot;test&quot; 的 &lt;p&gt; 元素$(&quot;#test&quot;).hide() - 隐藏所有 id=&quot;test&quot; 的元素 文档就绪事件jQuery中： 123$(document).ready(function(){ // 执行代码}); 或者 123$(function(){ // 执行代码}); JavaScript中： 123window.onload = function () { // 执行代码} jQuery 入口函数与 JavaScript 入口函数的区别： jQuery 的入口函数是在 html 所有标签(DOM)都加载之后，就会去执行。JavaScript 的 window.onload 事件是等到所有内容，包括外部图片之类的文件加载完后，才会执行。 也就是说，可以这样理解，如果一个图片需要下载很久，那么window.onload事件需要等到图片加载完成了之后才会执行。 jQuery 选择器在Chrome的Web开发者工具的console中，是可以使用jQuery选择器的，可以完成一些比较骚气的操作。记得以前《英雄联盟》出了一个活动，说是点击一个页面中的某个东西100次，然后就可以领一个皮肤。在这里，打开console，写个定时执行的函数，在函数中通过jQuery选择器选中所需要点击的控件，然后进行点击，一下子就点好了，贼舒服！ 基于id$(&quot;p&quot;)：选取在页面中选取所有 &lt;p&gt;元素$(&quot;#test&quot;) ：选取id为test的元素$(&quot;.test&quot;)：选取所有class为test的元素$(&quot;p.intro&quot;)：选取 class 为 intro 的 &lt;p&gt; 元素$(&quot;p#intro&quot;)：选取 id 为 intro 的 &lt;p&gt; 元素$(&quot;[href]&quot;)：选取带有 href 属性的元素$(&quot;a[target='_blank']&quot;)：选取所有 target 属性值等于 “_blank” 的&lt;a&gt;元素，同理还有不等于$(&quot;:button&quot;)：选取所有 type=”button” 的 &lt;input&gt; 元素 和 &lt;button&gt; 元素$(&quot;div p.intro&quot;)：选取所有的div元素中，class为intro的&lt;p&gt;元素，同理可换成#$(&quot;div , p&quot;)：选取所有的div和p元素$(&quot;div &gt; p&quot;)：选取所有的父集是div的p元素$(&quot;div + p&quot;)：选取所有的跟在div后面的p元素 还可参考css选择器中更多的用法：http://www.runoob.com/cssref/css-selectors.html jQuery 事件常见 DOM 事件： 1234567891011121314151617181920212223242526272829303132333435363738394041// click()点击事件$(&quot;p&quot;).click(function(){ $(this).hide();});// dblclick()双击元素$(&quot;p&quot;).dblclick(function(){ $(this).hide();});// 鼠标指针穿过元素$(&quot;#p1&quot;).mouseenter(function(){ alert('您的鼠标移到了 id=&quot;p1&quot; 的元素上!');});// 当鼠标指针离开元素$(&quot;#p1&quot;).mouseleave(function(){ alert(&quot;再见，您的鼠标离开了该段落。&quot;);});// 当鼠标指针移动到元素上方，并按下鼠标按键时$(&quot;#p1&quot;).mousedown(function(){ alert(&quot;鼠标在该段落上按下！&quot;);});// 当在元素上松开鼠标按钮时$(&quot;#p1&quot;).mouseup(function(){ alert(&quot;鼠标在段落上松开。&quot;);});// 当鼠标移动到元素上时，会触发指定的第一个函数(mouseenter);当鼠标移出这个元素时，会触发指定的第二个函数(mouseleave)$$((&quot;&quot;#p1#p &quot;).hover( function(){ alert(&quot;你进入了 p1!&quot;); }, function(){ alert(&quot;拜拜! 现在你离开了 p1!&quot;); });// 当元素获得焦点时，发生 focus 事件。当通过鼠标点击选中元素或通过 tab 键定位到元素时，该元素就会获得焦点。$(&quot;input&quot;).focus(function(){ $(this).css(&quot;background-color&quot;,&quot;#cccccc&quot;);});// 当元素失去焦点时，发生 blur 事件。blur() 方法触发 blur 事件，或规定当发生 blur 事件时运行的函数$(&quot;input&quot;).blur(function(){ $(this).css(&quot;background-color&quot;,&quot;#ffffff&quot;);}); jQuery 效果显示与隐藏1234567891011$(&quot;#hide&quot;).click(function(){ $(&quot;p&quot;).hide();}); $(&quot;#show&quot;).click(function(){ $(&quot;p&quot;).show();});$(&quot;button&quot;).click(function(){ $(&quot;p&quot;).hide(1000);}); 语法: 12$(selector).hide(speed,callback);$(selector).show(speed,callback); 可选的 speed 参数规定隐藏/显示的速度，可以取以下值：”slow”、”fast” 或毫秒。可选的 callback 参数是隐藏或显示完成后所执行的函数名称。 jQuery toggle()通过 jQuery，您可以使用 toggle() 方法来切换 hide() 和 show() 方法。显示被隐藏的元素，并隐藏已显示的元素。 123$(&quot;button&quot;).click(function(){ $(&quot;p&quot;).toggle();}); $(selector).toggle(speed,callback);可选的 speed 参数规定隐藏/显示的速度，可以取以下值：”slow”、”fast” 或毫秒。可选的 callback 参数是隐藏或显示完成后所执行的函数名称。 淡入淡出语法： 1234$(selector).fadeIn(speed,callback);// 用于淡入已隐藏的元素。$(selector).fadeOut(speed,callback);// 用于淡出可见元素。$(selector).fadeToggle(speed,callback);// 在 fadeIn() 与 fadeOut() 方法之间进行切换。$(selector).fadeTo(speed,opacity,callback);// 渐变为给定的不透明度（值介于 0 与 1 之间）。 示例： 1234567891011121314151617181920212223$(&quot;button&quot;).click(function(){ $(&quot;#div1&quot;).fadeIn(); $(&quot;#div2&quot;).fadeIn(&quot;slow&quot;); $(&quot;#div3&quot;).fadeIn(3000);});$(&quot;button&quot;).click(function(){ $(&quot;#div1&quot;).fadeOut(); $(&quot;#div2&quot;).fadeOut(&quot;slow&quot;); $(&quot;#div3&quot;).fadeOut(3000);});$(&quot;button&quot;).click(function(){ $(&quot;#div1&quot;).fadeToggle(); $(&quot;#div2&quot;).fadeToggle(&quot;slow&quot;); $(&quot;#div3&quot;).fadeToggle(3000);});$(&quot;button&quot;).click(function(){ $(&quot;#div1&quot;).fadeTo(&quot;slow&quot;,0.15); $(&quot;#div2&quot;).fadeTo(&quot;slow&quot;,0.4); $(&quot;#div3&quot;).fadeTo(&quot;slow&quot;,0.7);}); 滑动语法： 123$(selector).slideDown(speed,callback);$(selector).slideUp(speed,callback);$(selector).slideToggle(speed,callback);","link":"/2018/08/30/4fa5f2b89d02.html"},{"title":"docker命令记录","text":"安装及配置docker(基于Ubuntu)1234567891011121314151617181920212223242526272829sasurai@ubuntu:~$ sudo apt install docker.iosasurai@ubuntu:~$ docker versionClient: Version: 19.03.2 API version: 1.40 Go version: go1.12.9 Git commit: 6a30dfca03 Built: Mon Sep 16 03:56:22 2019 OS/Arch: linux/amd64 Experimental: falseServer: Engine: Version: 19.03.2 API version: 1.40 (minimum version 1.12) Go version: go1.12.9 Git commit: 6a30dfca03 Built: Wed Sep 11 22:45:55 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.10-0ubuntu1 GitCommit: runc: Version: spec: 1.0.1-dev GitCommit: docker-init: Version: 0.18.0 GitCommit: 设置为阿里云的镜像加速器1sudo vim /etc/docker/daemon.json 内容如下： 123{ &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;]} 重启docker： 12sudo systemctl daemon-reloadsudo systemctl restart docker 免sudo使用docker命令Linux 中将用户添加到指定组的指令 将一个已有用户 testuser 增加到一个已有用户组 root 中，使此用户组成为该用户的附加用户组，可以使用带 -a 参数的 usermod 指令。-a 代表 append， 也就是将用户添加到新用户组中而不必离开原有的其他用户组。不过需要与 -G 选项配合使用：usermod -a -G root testuser如果要同时将 testuser 的主要用户组改为 root，则直接使用 -g 选项：usermod -g root testuser如果要将testuser用户从root组中删除，则gpasswd -d testuser root 12# 将当前用户加入docker组sudo gpasswd -a $USER docker 注销该用户后，重新登录该用户 网上还有一种修改如下： 123456# 新增docker组（如果不存在docker组）sudo groupadd docker# docker组中加入当前用户sudo usermod -aG docker $USER# 重启docker服务sudo systemctl restart docker 也有稍微带了一点说明的如下： Docker守候进程绑定的是一个unix socket，而不是TCP端口。这个套接字默认的属主是root，其他是用户可以使用sudo命令来访问这个套接字文件。因为这个原因，docker服务进程都是以root帐号的身份运行的。当docker进程启动的时候，会设置该套接字可以被docker这个分组的用户读写。 但是少了一个验证的环节，/var/run/docker.sock的具体权限如下： 123456# socket文件权限sasurai@ubuntu:~$ ll /var/run/docker.socksrw-rw---- 1 root docker 0 Nov 18 01:05 /var/run/docker.sock=# docker命令权限sasurai@ubuntu:~$ ll `which docker`-rwxr-xr-x 1 root root 89057216 Sep 11 15:45 /usr/bin/docker* 从以上权限可看出： 对/var/run/docker.sock，其他用户无读写权限，只有docker组用户和root用户可以读写。而对docker命令来说，任何用户都可以运改命令，但是并不一定都能通过该命令操作/var/run/docker.sock。 拉取MySQL镜像可用的标签如下： 8.0.18, 8.0, 8, latest 5.7.28, 5.7, 5 5.6.46, 5.6 这里选择5.7版本的MySQL数据库：docker pull mysql:5.7 将MySQL跑起来最简单的方式： 12345docker run \\ # Run a command in a new container--name mysql-master \\ # Assign a name to the container-e MYSQL_ROOT_PASSWORD=mysql-master \\ # Set environment variables-p 3306:3306 \\ # Publish a container's port(s) to the hostmysql:5.7 # 镜像名称:版本号 环境变量 MYSQL_ROOT_PASSWORD ：强制要求的，会在容器创建时将root用户密码设置成改变量的值。没有启动会报错，如下所示： 123456sasurai@ubuntu:~$ docker run --name mysql-master2 -p 3307:3307 mysql:5.72019-11-19 06:16:27+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 5.7.28-1debian9 started.2019-11-19 06:16:27+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'2019-11-19 06:16:27+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 5.7.28-1debian9 started.2019-11-19 06:16:27+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD MYSQL_DATABASE：可选项。会在容器创建的时候创建改数据库。如果有指定用户名和密码，会将该用户设置成改数据库的超级用户。 MYSQL_USER, MYSQL_PASSWORD：可选项。容器创建时创建该用户。 挂载自定义配置文件123docker run --name some-mysql \\-v /my/custom:/etc/mysql/conf.d \\ # Bind mount a volume-e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 疑问docker run与docker container run之间是什么关系？ CLI restructured Docker has grown many features over the past couple years and the Docker CLI now has a lot of commands (40 at the time of writing). Some, like build or run are used a lot, some are more obscure, like pause or history. The many top-level commands clutters help pages and makes tab-completion harder. In Docker 1.13, we regrouped every command to sit under the logical object it’s interacting with. For example list and startof containers are now subcommands of docker container and history is a subcommand of docker image. docker container list docker container start docker image history These changes let us clean up the Docker CLI syntax, improve help text and make Docker simpler to use. The old command syntax is still supported, but we encourage everybody to adopt the new syntax. from : https://www.docker.com/blog/whats-new-in-docker-1-13/ 简而言之，两者等效，但是后者是命令重构之后的写法，更推荐后面的写法。同时，还有很多其他类似的命令如：docker start与docker container start，也是同样的道理。但是感觉前面的命令不用敲container，用起来还是蛮香的。","link":"/2019/11/20/17bd70c92e4d.html"},{"title":"libstreaming局域网构建Android相机实时流媒体流程分析","text":"这是一个涉及东西比较多的第三方库，里面的一些代码细节有点让人云里雾里。如果真的是这样，那说明了解的东西还太少，真正的去了解这些详细的东西，起码得知道相应的概念，如RTSP、RTP、H264、H264打包。我觉得首要的事是将大体的逻辑打通，然后再慢慢深入代码的细节，了解相关的技术与知识。奈何，这部分在我遇到的项目DEMO并不是很重要，所以花的时间并不多，基本上解决了这里面出现的问题后，就不再关注一些细节，但是回过头来看，我觉得这部分的内容还是比较值得学习的。 原项目地址：github.com/fyhertz/libstreaming 了解清楚大致的流程后，可以选择相应的模块，继续深入了解。 粗略流程图中的流程并没有包括一些其他的细枝末节，还有一些其他的如：如何获取一些所需参数、如何构建RTSP服务器等都不在此流程图中。因为一些显示效果的调整，只需要明白这样的一个流程就可以做出修改。因此此篇文章也是围绕此流程图来展开对大致流程的分析。 从何处开始了解这个库之前，我先接触的是使用这个库实现了利用Android相机的实时数据作为一个直播源的应用：Endoscope。 剖开这个应用的一些表面操作，背后其实就是libstreaming这个库的一个使用。而这个库的调用，出现的地方大概是只有一处，就是通过SeesionBuilder构造除了一个Session。后来看了libstreaming库的readme，发现也是同样的一段代码。但是仔细去看这个代码的话，前面都是一些设置参数的操作，后面的build()也是将这个前面的参数，塞到一个Session中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public Session build() { Session session; session = new Session(); session.setOrigin(mOrigin); session.setDestination(mDestination); session.setTimeToLive(mTimeToLive); session.setCallback(mCallback); switch (mAudioEncoder) { case AUDIO_AAC: AACStream stream = new AACStream(); session.addAudioTrack(stream); if (mContext!=null) stream.setPreferences(PreferenceManager.getDefaultSharedPreferences(mContext)); break; case AUDIO_AMRNB: session.addAudioTrack(new AMRNBStream()); break; } switch (mVideoEncoder) { case VIDEO_H263: session.addVideoTrack(new H263Stream(mCamera)); break; case VIDEO_H264: H264Stream stream = new H264Stream(mCamera); if (mContext!=null) stream.setPreferences(PreferenceManager.getDefaultSharedPreferences(mContext)); session.addVideoTrack(stream); break; } if (session.getVideoTrack()!=null) { VideoStream video = session.getVideoTrack(); video.setFlashState(mFlash); video.setVideoQuality(mVideoQuality); video.setSurfaceView(mSurfaceView); video.setPreviewOrientation(mOrientation); video.setDestinationPorts(5006); } if (session.getAudioTrack()!=null) { AudioStream audio = session.getAudioTrack(); audio.setAudioQuality(mAudioQuality); audio.setDestinationPorts(5004); } return session;} 仔细看，在前面选的编码器是H264，这里也看见了一个H264Stream。这个类与其他相关类的简单继承关系如下： 我们可以看到，在其之前有两个抽象类，已实现一些基本的共同的操作。在创建H264Stream的过程中，其构造函数中代码如下： 1234567891011121314151617181920212223public H264Stream(int cameraId) { super(cameraId); mMimeType = &quot;video/avc&quot;; // 指定Camera中原始数据的类型 mCameraImageFormat = ImageFormat.NV21; // 指定编码类型 mVideoEncoder = MediaRecorder.VideoEncoder.H264; // 创建H264的打包器，使用RTP协议 mPacketizer = new H264Packetizer(); ((H264Packetizer)mPacketizer).setListener(new H264Packetizer.OnFrameListener() { @Override public void onFrame() { if (Build.VERSION.SDK_INT &gt;= 23) { if (System.currentTimeMillis()-timestamp&gt;=1000) { timestamp=System.currentTimeMillis(); Bundle params = new Bundle(); params.putInt(MediaCodec.PARAMETER_KEY_REQUEST_SYNC_FRAME, 1); mMediaCodec.setParameters(params); } } } });} 其中，有一个打包的类，与它相关的类的简单继承关系图如下： 相应的，这就是将H264的NALU数据，使用RTP协议进行封包，然后将其发送出去。这个类对应的角色，就是前面流程图中右侧的部分，即不断地取数据，然后打包发送。打开其中的类，我们粗略地过一下代码： 它继承了Runnable，其中的run()方法中有一个死循环： 其中的send()方法，内容比较多，可以看到其调用取数据的方法： 这个 is 就是从哪里来的？它有一个设置方法，而且确实存在着设置is代码，所以我们先记着有这么一个输入流，等待后续的代码来说明。 至此，我们的初始化算是完成了。但是我们对于最前面的流程图，还有左边一部分是不清楚的。 所以，想想这个库的效果：当进入预览摄像头的界面时，开始是没有预览的，需要等到有对此播放流的请求后，才会开始预览（发送数据）。 因此，实现这样的操作的地方在哪里？这便是我们接下来需要思考的问题。 看使用libstreaming的应用Endoscope源代码里面，构建完Session后，还进行了RtspServer的初始化，即： 123456// StartStreamPresenter # startRtspServer()private void startRtspServer() { rtspServer = new RtspServer(); rtspServer.addCallbackListener(this); rtspServer.start();} 所以，我们应该再去看看这个RtspServer长啥样。 1public class RtspServer extends Service 继承自Service，然后再初始化完成后，还调用了start()方法，这个方法中，初始化了一个RequestListener。 12345678910111213// RtspServer.javapublic void start() { if (!mEnabled || mRestart) stop(); if (mEnabled &amp;&amp; mListenerThread == null) { try { // 这个将用来监听socket请求 mListenerThread = new RequestListener(); } catch (Exception e) { mListenerThread = null; } } mRestart = false;} 这个RequestListener是一个内部类，继承自Thread。并且在构造函数中初始化了一个ServerSocket后，开启自己的线程，跑自己run()里面的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738class RequestListener extends Thread implements Runnable { private final ServerSocket mServer; public RequestListener() throws IOException { try { // 创建服务端socket mServer = new ServerSocket(mPort); // 开启自身线程 start(); } catch (BindException e) { Log.e(TAG,&quot;Port already in use !&quot;); postError(e, ERROR_BIND_FAILED); throw e; } } public void run() { Log.i(TAG,&quot;RTSP server listening on port &quot;+mServer.getLocalPort()); while (!Thread.interrupted()) { try { // 阻塞线程，监听socket，并将socket传给WorkThread new WorkerThread(mServer.accept()).start(); } catch (SocketException e) { break; } catch (IOException e) { Log.e(TAG,e.getMessage()); continue; } } Log.i(TAG,&quot;RTSP server stopped !&quot;); } public void kill() { try { mServer.close(); } catch (IOException e) {} try { this.join(); } catch (InterruptedException ignore) {} }} 那么这个WorkThread将进行什么样的操作呢？同样它也是一个内部类，继承自Thread。对于这个内部类，我们要想理清楚整体的逻辑，就必须先舍弃掉一些细节，不然就会卡在此处。 这个内部类所在的类，即RtspServer，顾名思义就是一个RTSP服务器，这个类前的注释中也有说明，说这是RTSP协议子集的一个实现（RFC 2326），所以我们可以将那些不能理解的都归于RTSP协议的实现。继续看逻辑： 那么拿着从socket那里获取到的输入与输出是要干什么呢？当然是进行通信。接着看其中的主要run()中的逻辑。 因此，主要的逻辑现在已经到达了对消息的处理中，即processRequest()中。 这个方法，挑重点看，我们可以看到其中对Session.syncConfigure()与Session.syncStart()方法的调用。再看Session中的这个方法。我们不难发现，前者调用涉及到Stream.configure()，后者调用涉及到Stream.start()。 因此，我们应该直接看H264相关的这两个方法。于是，又回到了之前的地方——H264Stream.java。 经过这两个方法的对比，发现后者会调用前者。所以，我们直接看后者的逻辑即可。 这里关于 mConfig 的获取方式，如果配置信息以及存在了，就不会去通过一定的方式去获取，如果不存在，就需要进行额外的步骤。代码就不贴了，有点长。 在这里曾经遇到过一个bug，在这个第三方库上面的issue里面也有讨论，是The decoder did not decode anything.。原因是while中所给的时间太小，在规定的时间内得不到相应的帧数。 所以把时间稍微改大一些，就能够获取到足够的帧数，就不会报错，正常运行。 但是性能堪忧！ 这两个方法都调用了父类的相应的方法，其中实现如下： 这个encodeWithMediaCodec()的实现在VideoStream.java中，如下：这其中，使用的是方法encodeWithMediaCodecMethod1()。 123456789101112/** * Video encoding is done by a MediaCodec. */protected void encodeWithMediaCodec() throws RuntimeException, IOException { if (mMode == MODE_MEDIACODEC_API_2) { // Uses the method MediaCodec.createInputSurface to feed the encoder encodeWithMediaCodecMethod2(); } else { // Uses dequeueInputBuffer to feed the encoder encodeWithMediaCodecMethod1(); }} 接下来的方法中，干货满满，基本上可以覆盖最前面流程图左边的全部内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * Video encoding is done by a MediaCodec. */@SuppressLint(&quot;NewApi&quot;)protected void encodeWithMediaCodecMethod1() throws RuntimeException, IOException { // Updates the parameters of the camera if needed createCamera();// 设置相机参数并开启相机 updateCamera();// 更新参数 // Estimates the frame rate of the camera measureFramerate(); // Starts the preview if needed if (!mPreviewStarted) { try { mCamera.startPreview(); mPreviewStarted = true; } catch (RuntimeException e) { destroyCamera(); throw e; } } EncoderDebugger debugger = EncoderDebugger.debug(mSettings, mQuality.resX, mQuality.resY); // 将NV21(yuv420sp)转换成yuv420p(H264编码要求此颜色格式) final NV21Convertor convertor = debugger.getNV21Convertor(); // H264编码器 mMediaCodec = MediaCodec.createByCodecName(debugger.getEncoderName()); MediaFormat mediaFormat; if (EncoderDebugger.ROTATE) { mediaFormat = MediaFormat.createVideoFormat(&quot;video/avc&quot;, mQuality.resY, mQuality.resX); } else { mediaFormat = MediaFormat.createVideoFormat(&quot;video/avc&quot;, mQuality.resX, mQuality.resY); } mediaFormat.setInteger(MediaFormat.KEY_BIT_RATE, mQuality.bitrate); mediaFormat.setInteger(MediaFormat.KEY_FRAME_RATE, mQuality.framerate); mediaFormat.setInteger(MediaFormat.KEY_COLOR_FORMAT,debugger.getEncoderColorFormat()); mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 1); mMediaCodec.configure(mediaFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE); mMediaCodec.start(); // Camera每一帧的回调 Camera.PreviewCallback callback = new Camera.PreviewCallback() { long now = System.nanoTime()/1000, oldnow = now, i=0; ByteBuffer[] inputBuffers = mMediaCodec.getInputBuffers(); @Override public void onPreviewFrame(final byte[] data, final Camera camera) { // 做一些处理 oldnow = now; now = System.nanoTime() / 1000; if (i++ &gt; 3) { i = 0; } try { int bufferIndex = mMediaCodec.dequeueInputBuffer(500000); if (bufferIndex &gt;= 0) { inputBuffers[bufferIndex].clear(); if (data == null) Log.e(TAG, &quot;Symptom of the \\&quot;Callback buffer was to small\\&quot; problem...&quot;); else { Camera.CameraInfo camInfo = new Camera.CameraInfo(); Camera.getCameraInfo(mCameraId, camInfo); Camera.Size previewSize = camera.getParameters().getPreviewSize(); int cameraRotationOffset = camInfo.orientation, mHeight = previewSize.height, mWidth = previewSize.width; Log.e(&quot;DEBUG&quot;, &quot;orientation = &quot; + cameraRotationOffset + &quot;, width = &quot; + previewSize.width + &quot;, height = &quot; + previewSize.height); // Cancel mirror effect for blink camera. byte tempData; for (int i = 0; i &lt; mHeight * 3 / 2; i++) { for (int j = 0; j &lt; mWidth / 2; j++) { tempData = data[i * mWidth + j]; data[i * mWidth + j] = data[(i + 1) * mWidth - 1 - j]; data[(i + 1) * mWidth - 1 - j] = tempData; } } // TODO: 2018/6/4 modify pic's attributes // mirror Util.yuvRotate(data, 1, previewSize.width, previewSize.height, 90); convertor.convert(data, inputBuffers[bufferIndex]); } // 塞进一个地方，让它去编码 mMediaCodec.queueInputBuffer(bufferIndex, 0, inputBuffers[bufferIndex].position(), now, 0); } else { Log.e(TAG, &quot;No buffer available ! &quot;); } } finally { mCamera.addCallbackBuffer(data); } } }; for (int i=0;i&lt;10;i++) mCamera.addCallbackBuffer(new byte[convertor.getBufferSize()]); mCamera.setPreviewCallbackWithBuffer(callback); // The packetizer encapsulates the bit stream in an RTP stream and send it over the network // 这里便回答了上面的一个问题，就是关于打包类的is来源问题 // 这里使用其中自己写的类进行了相应的封装，本质上还是MediaCodec的 mPacketizer.setInputStream(new MediaCodecInputStream(mMediaCodec)); // 开启打包线程 mPacketizer.start(); mStreaming = true;} 至此，粗略地分析大致结束。 但是如果仔细看一下源代码的话，你可能会对这个Session产生一些疑问。如果真的有，可以仔细去看一下源代码。我的疑问已经通过看一些详细的代码解决。 我的问题是：在RtspServer中，每有一个socket传过来，都会创建了一个Session，这个session与我们之前创建的那个session有什么区别呢？ 实现的地方是在对请求的处理函数中，有几个操作会去给session重新赋值，那么来处当然应该也是之前创建的吧。 粗浅分析，欢迎批评指正！","link":"/2018/06/16/98abde6e451b.html"},{"title":"leetcode回溯法题目解法若干","text":"N皇后问题 N-Queens N-Queens II 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import java.util.ArrayList;import java.util.List;/* * @lc app=leetcode id=51 lang=java * * [51] N-Queens */public class Solution { List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); private static int total = 0; public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) { total = n; int[][] board = new int[n][n]; backtrack(board, 1); return result; } private void backtrack(int[][] board, int idx) { if (idx &gt; total) { // ok result.add(transform(board)); return; } for (int i = 0; i &lt; total; i ++) { if (isOk(board, idx - 1, i)) { // board[idx - 1][i] = 1; backtrack(board, idx + 1); board[idx - 1][i] = 0; } } } private boolean isOk(int[][] board, int xx, int yy) { for (int i = 0; i &lt; total; i++) { if (board[xx][i] == 1) { return false; } if (board[i][yy] == 1) { return false; } } int x = xx, y = yy; while (x &lt; total &amp;&amp; y &gt;= 0) if (board[x ++][y --] == 1) return false; x = xx; y = yy; while (x &lt; total &amp;&amp; y &lt; total) if (board[x ++][y ++] == 1) return false; x = xx; y = yy; while (x &gt;= 0 &amp;&amp; y &gt;= 0) if (board[x --][y --] == 1) return false; x = xx; y = yy; while (x &gt;=0 &amp;&amp; y &lt; total) if (board[x --][y ++] == 1) return false;// System.out.println(&quot;OK&quot;); return true; } private List&lt;String&gt; transform(int[][] board) { List&lt;String&gt; oneAnswer = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; board.length; i ++) { StringBuilder sb = new StringBuilder(); for (int j = 0; j &lt; board[i].length; j ++) { sb.append(board[i][j] == 0 ? '.' : 'Q'); } oneAnswer.add(sb.toString()); }// showAnswer(oneAnswer); return oneAnswer; } private void showAnswer(List&lt;String&gt; answer) { System.out.println(); for (String line : answer) { System.out.println(line); } } public static void main(String[] args) { List&lt;List&lt;String&gt;&gt; result = new Solution().solveNQueens(4); System.out.println(result.size()); }} Letter Combinations of a Phone NumberGiven a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent. A mapping of digit to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters. 1234567891011121314151617181920212223242526272829303132333435363738import java.util.ArrayList;import java.util.List;/* * @lc app=leetcode id=17 lang=java * * [17] Letter Combinations of a Phone Number */class Solution { private int[][] maps = { {}, {}, {'a', 'b', 'c'}, {'d', 'e', 'f'}, {'g', 'h', 'i'}, {'j', 'k', 'l'}, {'m', 'n', 'o'}, {'p', 'q', 'r', 's'}, {'t', 'u', 'v'}, {'w', 'x', 'y', 'z'} }; List&lt;String&gt; result = new ArrayList&lt;&gt;(); public List&lt;String&gt; letterCombinations(String digits) { backtrack(digits, &quot;&quot;, 0); return result; } private void backtrack(String digits, String sb, int idx) { if (idx &gt;= digits.length()) { if (sb.length() &gt; 0) result.add(sb.toString()); return; } int mapsIdx = digits.charAt(idx) - '0'; for (int i = 0; i &lt; maps[mapsIdx].length; i ++) { backtrack(digits, sb + (char) maps[mapsIdx][i], idx + 1); } }} Generate ParenthesesGiven n pairs of parentheses, write a function to generate all combinations of well-formed parentheses. For example, given n = 3, a solution set is: 1234567[ &quot;((()))&quot;, &quot;(()())&quot;, &quot;(())()&quot;, &quot;()(())&quot;, &quot;()()()&quot;] 123456789101112131415161718192021222324252627class Solution { List&lt;String&gt; sets = new ArrayList&lt;&gt;(); // 22 public List&lt;String&gt; generateParenthesis(int n) { produce(2 * n, 0, n, n, &quot;&quot;); return sets; } private void produce(int blank, int sum, int lcnt, int rcnt, String seq) { if (sum &lt; 0) return; if (blank == 0) { sets.add(seq); return; } if (lcnt &gt; 0) { produce(blank - 1, sum + 1, lcnt - 1, rcnt, seq + &quot;(&quot;); } if (rcnt &gt; 0) { produce(blank - 1, sum - 1, lcnt, rcnt - 1, seq + &quot;)&quot;); } }} Sudoku SolverWrite a program to solve a Sudoku puzzle by filling the empty cells. A sudoku solution must satisfy all of the following rules: Each of the digits 1-9 must occur exactly once in each row. Each of the digits 1-9 must occur exactly once in each column. Each of the the digits 1-9 must occur exactly once in each of the 9 3x3 sub-boxes of the grid. Empty cells are indicated by the character ‘.’. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/* * @lc app=leetcode id=37 lang=java * * [37] Sudoku Solver */public class Solution { private static class Point { public int x, y; public Point(int x, int y) { this.x = x; this.y = y; } @Override public String toString() { return &quot;&lt;&quot; + x + &quot;, &quot; + y + &quot;&gt;&quot;; } } static char[][] data = { {'5', '3', '.', '.', '7', '.', '.', '.', '.'}, {'6', '.', '.', '1', '9', '5', '.', '.', '.'}, {'.', '9', '8', '.', '.', '.', '.', '6', '.'}, {'8', '.', '.', '.', '6', '.', '.', '.', '3'}, {'4', '.', '.', '8', '.', '3', '.', '.', '1'}, {'7', '.', '.', '.', '2', '.', '.', '.', '6'}, {'.', '6', '.', '.', '.', '.', '2', '8', '.'}, {'.', '.', '.', '4', '1', '9', '.', '.', '5'}, {'.', '.', '.', '.', '8', '.', '.', '7', '9'} }; public static void main(String[] args) { new Solution().solveSudoku(data); printBoard(data, &quot;最终结果&quot;); } private static void printBoard(char[][] data, String msg) { System.out.println(&quot;\\n&quot; + msg + &quot;:&quot;); for (int i = 0; i &lt; data.length; i ++) { for (int j = 0; j &lt; data[i].length; j++) { System.out.print(data[i][j] + &quot; &quot;); } System.out.println(); } System.out.println(); } boolean over = false; public void solveSudoku(char[][] board) { backtrack(board, nextPoint(board, new Point(0, 0))); } private void backtrack(char[][] board, Point focus) { if (over || isOver(board)) { over = true; return; } if (focus == null) { over = true; return; } for (int val = 1; val &lt;= 9 &amp;&amp; !over; val++) { board[focus.x][focus.y] = (char) ('0' + val); if (isValid(board, focus, (char) ('0' + val))) { backtrack(board, nextPoint(board, focus)); } } if (!over) board[focus.x][focus.y] = '.'; } private boolean isValid(char[][] board, Point p, char val) { // 横向 for (int i = 0; i &lt;= 8; i++) { if (i != p.y &amp;&amp; board[p.x][i] == val) return false; } // 纵向 for (int i = 0; i &lt;= 8; i++) { if (i != p.x &amp;&amp; board[i][p.y] == val) return false; } // 方形 for (int i = (p.x / 3 * 3); i &lt;= (p.x / 3 * 3) + 2; i++) { for (int j = (p.y / 3 * 3); j &lt;= (p.y / 3 * 3) + 2; j++) { if (i != p.x &amp;&amp; j != p.y &amp;&amp; board[i][j] == val) return false; } }// printBoard(board, &quot;位置&quot; + p + &quot;, 对值&lt;&quot; + (char)val + &quot;&gt;合适&quot;); return true; } private boolean isOver(char[][] board) { for (int i = 0; i &lt; board.length; i++) { for (int j = 0; j &lt; board[i].length; j++) { if (board[i][j] == '.') return false; } } return true; } private Point nextPoint(char[][] board, Point p) { Point returnPoint = null; int x = p.x, y = p.y; while (x &lt;= 8 &amp;&amp; returnPoint == null) { for (int i = y; i &lt;= 8; i++) { if (board[x][i] == '.') { returnPoint = new Point(x, i); break; } } y = 0; x ++; }// System.out.println(p + &quot; -&gt; &quot; + returnPoint); return returnPoint; }} Combination Sum 相关问题：Combination Sum II 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import java.util.ArrayList;import java.util.List;/* * @lc app=leetcode id=39 lang=java * * [39] Combination Sum */class Solution { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); private int maxInt = 0; public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) { sort(candidates); maxInt = candidates[candidates.length - 1] + 1; backtrack(candidates, target, new ArrayList&lt;&gt;()); return result; } private void sort(int[] arr) { for (int i = 0; i &lt; arr.length; i ++) { for (int j = i; j &lt; arr.length; j ++) { if (arr[i] &gt; arr[j]) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; } } } } private void backtrack(int[] candidates, int target, List&lt;Integer&gt; answer) { if (target == 0) { // find the answer// showArray(answer); if (!isDuplicated(result, answer, candidates)) result.add(new ArrayList&lt;&gt;(answer)); else {// System.out.println(&quot;Duplicated&quot;); } } else if (target &lt; 0) { return; } for (int i = 0; i &lt; candidates.length; i++) { answer.add(candidates[i]); backtrack(candidates, target - candidates[i] , answer); answer.remove(answer.size() - 1); } } private void showArray(List&lt;Integer&gt; arr) { System.out.print(&quot;[&quot;); for (int i = 0; i &lt; arr.size(); i ++) { System.out.print(String.valueOf(arr.get(i)) + (i == arr.size() - 1 ? &quot;]&quot; : &quot;, &quot;)); } System.out.println(); } private boolean isDuplicated(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; oneAnswer, int[] candidates) { for (List&lt;Integer&gt; r : result) { if (r.size() == oneAnswer.size()) { int[] sr = new int[maxInt]; int[] si = new int[maxInt]; for (int i = 0; i &lt; r.size(); i ++) {// System.out.println(r.get(i) + &quot; + 1&quot;); sr[r.get(i)] ++;// System.out.println(oneAnswer.get(i) + &quot; + 1&quot;); si[oneAnswer.get(i)] ++; } boolean isDuplicatedWithThisResult = true; for (int i = 0; i &lt; candidates.length; i ++) { // System.out.println(candidates[i] + &quot;,&quot; + sr[candidates[i]] + &quot;,&quot; + si[candidates[i]]); if (sr[candidates[i]] != si[candidates[i]]) { isDuplicatedWithThisResult = false; continue; } } if (isDuplicatedWithThisResult) return true; } } return false; } public static void main(String[] args) { int [] arr = {8,7,4,3}; new Solution().combinationSum(arr, 11); }} Permutations 相关问题：Permutations II 1234567891011121314151617181920212223242526class Solution { List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); private boolean[] USAGE; public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) { USAGE = new boolean[nums.length]; List&lt;Integer&gt; answer = new ArrayList(); backtrack(nums, 0, answer); return result; } private void backtrack(int[] nums, int idx, List&lt;Integer&gt; answer) { if (idx &gt;= nums.length) { result.add(new ArrayList(answer)); return; } for (int i = 0; i &lt; nums.length; i ++) { if (!USAGE[i]) { answer.add(nums[i]);USAGE[i] = true; backtrack(nums, idx + 1, answer); answer.remove(answer.size() - 1);USAGE[i] = false; } } }} Permutation Sequence 1234567891011121314151617181920212223242526272829303132333435class Solution { private boolean[] usage; private String result; private int targetIdx, currentIdx; private boolean over = false; public String getPermutation(int n, int k) { targetIdx = k; usage = new boolean[n + 1]; StringBuilder sb = new StringBuilder(); backtrack(n, 1, sb); return result; } private void backtrack(int n, int idx, StringBuilder sb) { if (over) return; if (idx &gt; n) { currentIdx ++; if (currentIdx == targetIdx) { result = sb.toString(); over = true; } return ; } for (int i = 1; i &lt;= n; i ++) { if (over) break; if (!usage[i]) { sb.append(i);usage[i] = true; backtrack(n, idx + 1, sb); sb.deleteCharAt(sb.length() - 1);usage[i] = false; } } }} Combinations 1234567891011121314151617181920212223242526class Solution { private List&lt;List&lt;Integer&gt;&gt; result = new ArrayList(); private boolean[] USAGE; private int depth; public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) { depth = k; USAGE = new boolean[n + 1]; backtrack(1, n, 1, new ArrayList&lt;&gt;()); return result; } private void backtrack(int startIdx, int n, int idx, List&lt;Integer&gt; answer) { if (idx &gt; depth) { result.add(new ArrayList(answer)); return; } for (int i = startIdx; i &lt;= n; i ++) { if (!USAGE[i]) { answer.add(i);USAGE[i] = true; backtrack(i + 1, n, idx + 1, answer); answer.remove(answer.size() - 1);USAGE[i] = false; } } }}","link":"/2019/10/22/884217edc248.html"},{"title":"docker客户端连接超时的解决办法","text":"Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)的解决办法链接：https://stackoverflow.com/a/48776535/8437428链接：https://github.com/docker/for-win/issues/611#issuecomment-315036774","link":"/2019/01/01/16af75f77c75.html"},{"title":"linux中bash配置文件的读取执行顺序","text":"全文摘自man bash中对执行流程的注释，并在其中加入自己的理解 登录shell与交互shell A login shell is one whose first character of argument zero is a -, or one started with the –login option.通俗点说就是：是不是用来登录用的。 An interactive shell is one started without non-option arguments (unless -s is specified) and without the -c option whose standard input and error are both connected to terminals (as determined by isatty(3)), or one started with the -i option. PS1 is set and $- includes i if bash is interactive, allowing a shell script or a startup file to test this state.通俗点说就是：是不是用来交互的，即是不是你给个输入，它给个输出 读取配置流程黑窗口登录或图形界面登录When bash is invoked as an interactive login shell, or as a non-interactive shell with the –login option, it first reads and executes commands from the file /etc/profile, if that file exists. After reading that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile, in that order, and reads and executes commands from the first one that exists and is readable. The --noprofile option may be used when the shell is started to inhibit this behavior. 用户登出When an interactive login shell exits, or a non-interactive login shell executes the exit builtin command, bash reads and executes commands from the file ~/.bash_logout, if it exists. 登录后开启一个terminalWhen an interactive shell that is not a login shell is started, bash reads and executes commands from /etc/bash.bashrc and ~/.bashrc, if these files exist. This may be inhibited by using the --norcoption. The --rcfile file option will force bash to read and execute commands from file instead of /etc/bash.bashrc and ~/.bashrc. 关于zsh感觉与bash类似 来源暂时找不到linux下的截图了，可喜的是他们内容一样。","link":"/2019/01/28/815988e48afb.html"},{"title":"hackintosh如何解决app store无法登录的问题","text":"现象打开 App Store 之后，输入账号&amp;密码之后，登录框就消失了，且软件中并没有显示登录信息，多次尝试后，仍然如此。 原因en0 网卡不存在。 可以通过 ifconfig en0查看网络适配器是否存在。 解决办法 移除 NetworkInterfaces.plist 1$ sudo rm -rf /Library/Preferences/SystemConfiguration/NetworkInterfaces.plist* 删除所有的网络设备 打开 系统偏好设置 - 网络，移除左侧所有的网络设备，左侧清空后，点击右下角的应用 重启 重新添加网络设备 检查网络状态 123456789$ ifconfig en0 en0: flags=8863&lt;UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST&gt; mtu 1500 options=46b&lt;RXCSUM,TXCSUM,VLAN_HWTAGGING,TSO4,TSO6,CHANNEL_IO&gt; ether 00:e2:4c:68:33:20 inet6 fe80::ce1:3fd8:3799:2a45%en0 prefixlen 64 secured scopeid 0x4 inet 192.168.105.106 netmask 0xffffff00 broadcast 192.168.105.255 nd6 options=201&lt;PERFORMNUD,DAD&gt; media: autoselect (1000baseT &lt;full-duplex&gt;) status: active 再次尝试在 App Store 中进行登录","link":"/2023/01/07/563e92e56be2.html"},{"title":"macOS如何sudo免输入密码","text":"每次使用 sudo 时都要输入密码，太过繁琐。想能像在 Linux 中一样，配置下 /etc/sudoers 文件就能免输入密码，可以一劳永逸。 操作 先给/etc/sudoers文件加修改权限 sudo chmod u+w /etc/sudoers 修改配置 sudo vim /etc/sudoers中的 %admin 行，如下： 1234567# root and users in group wheel can run anything on any machine as any userroot ALL = (ALL) ALL%admin ALL = (ALL) NOPASSWD:ALL## Read drop-in files from /private/etc/sudoers.d## (the '#' here does not indicate a comment)#includedir /private/etc/sudoers.d 修改完成后，将文件的权限恢复回去 sudo chmod u-w /etc/sudoers 至此，就可以愉快的输入 sudo 了。 插曲 macOS管理员用户无法使用sudo命令该如何解决？ 一开始 %admin 那行的配置写错了，导致当前管理员用户不能使用 sudo 了！当时想了几种解决方法： ❌ 新建管理员用户，以新用户登陆进去尝试修正/etc/sudoers文件。 后面发现管理员用户也属于 admin 组，所以现在只有 root 用户能修改此文件。 ❌ 使用 su 切换到 root 用户。 由于之前没有设置过 root 密码，所以不知道 root 密码，切换不了 root 用户。 ❌ 进入某个能挂载 APFS 文件系统的外挂系统中，挂载整个 macOS 的系统磁盘，然后修改 /etc/sudoers 文件。但是没想到有手头设备能做到。 进 Mac 的 Recovery，然后直接改 /etc/sudoers 文件。 果然修改这种本来不让修改的文件，确实可能会遇到预期之外的问题，挺有意思的。","link":"/2023/01/07/3523eb04dfcb.html"},{"title":"macOS操作记录","text":"去掉开机提示：电脑关机是因为发生了问题 控制台 -&gt; 诊断报告 -&gt; Sleep Wake Failure日志 -&gt; 删除 除此之外也可以用清理工具，清理下系统和用户日志也可恢复正常。 查看 SSD 的写入量具体是否为disk0可在关于本机–&gt;系统报告中查看 12brew install smartmontoolssmartctl -a disk0 homebrew安装时网络受限最近github上的仓库拉不下来，在mac上面安装homebrew时，也无法将安装所需的仓库拉下来。困扰了很久，找到了两种解决办法。 让git走代理12git config --global http.proxy socks5://127.0.0.1:1086git config --global https.proxy socks5://127.0.0.1:1086 拉取https的仓库url时，速度提升并不明显，可能时代理慢了，然后就没尝试让git协议的也走代理了。 修改安装脚本homebrew的安装命令官方给出的是：/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;，其实就是从github上面下载一个脚本，然后用ruby去执行它。所以将该ruby脚本下载下来，然后再将其中的仓库名称修改成国内的镜像仓库，可明显提高速度。 这里下载下来的脚本改名为了brew_install。 修改brew_install中BREW_REPO配置项为：BREW_REPO = &quot;https://mirrors.ustc.edu.cn/brew.git&quot;.freeze，保存，直接用ruby运行：/usr/bin/ruby brew_install。 后面的安装过程中，home-core和home-cask的仓库又变成了从github上面拉，可能是brew_install里面还有配置没改到，但是没找到该配置，并且找到了另外一种方法：直接将home-core的仓库拉下来，放到相应的位置，home-cask亦是如此即可。 12git clone git://mirrors.ustc.edu.cn/homebrew-core.git/ /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core --depth=1git clone git://mirrors.ustc.edu.cn/homebrew-cask.git/ /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask --depth=1 至此基本完工。 升级系统版本后xcrun报错从10.13升级到10.14后，git用不了了，提示的错误信息详细如下。 123xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun 感觉应该是xcode出问题了，可以考虑把xcode全部删除了，再重新装一个xcode应该可以。不过感觉重装一下CommandLineTools也行，只是不知道该如何操作。从网上摘抄过来的教程如下： open a dialog for installation of the command line developer tools.尝试安装Command Line Tools。xcode-select --install 如果上述不能生效，考虑先将Command Line Tools删除，删除的目录为：rm -rf /Library/Developer/CommandLineTools 尝试时，第一项方法即完成了错误的修改。 主机开机状态电源灯闪烁重新睡眠一次，然后正常开机能解决。 http://machbbs.com/chiphell/44345 删除Microsoft Edge浏览器123456rm -rf /Applications/Microsoft\\ Edge.apprm -rf ~/Library/Application\\ Support/Microsoft\\ Edgerm -rf ~/Library/Caches/Microsoft\\ Edgerm -rf ~/Library/Saved\\ Application\\ State/com.microsoft.edgemac.savedStaterm -rf ~/Library/WebKit/com.microsoft.edgemacrm -rf ~/Library/Preferences/com.microsoft.edgemac.plist 查看/修改 hostname123scutil --get/set HostNamescutil --get/set ComputerNamescutil --get/set LocalHostName Office设置默认语言为中文123defaults write com.microsoft.Word AppleLanguages '(&quot;zh-cn&quot;)'defaults write com.microsoft.Excel AppleLanguages '(&quot;zh-cn&quot;)'defaults write com.microsoft.Powerpoint AppleLanguages '(&quot;zh-cn&quot;)' 修改launchpad显示行列数1234➜ ~ defaults write com.apple.dock springboard-columns -int 10 // 列数➜ ~ defaults write com.apple.dock springboard-rows -int 7 // 行数➜ ~ defaults write com.apple.dock ResetLaunchPad -bool TRUE➜ ~ killall Dock 修改之后的启动台如下，感觉强迫症又好了一点： Hackintosh安装记录 破解CodeRunner 打开安装包之后如下： 当在CodeRunner中输入生成器生成的license时，老是提示Invalid License。这时候网上一般会有一个附加的程序，如下所示： 这个程序主要是修改了hosts文件，让CodeRunner无法访问他的服务器，从而达到阻止校验的目的，让CodeRunner以为处于离线状态，猜测：此时如果有license，则它以为是正常的license，校验通过。 这个程序运行后，修改hosts（目录：/private/etc/hosts）的内容如下： 其实我对这些程序并不是很放心，毕竟授予给它的运行权限有点高，如果同样你对此程序并不放心，可以直接修改hosts文件如上即可。（未尝试，仅猜测） 附带一些生成的license： 12345AEAAA-AFHOO-4F7KD-TXBPQAEAAA-AGPM4-B7DUD-HAPYQAEAAA-AG7YC-CZLYG-AQWKQAEAAA-ADXG3-2EW6B-W6RFQAEAAA-ACHQF-SUGSE-BMVBQ","link":"/2021/04/05/c94cae87f054.html"},{"title":"nginx实现Tomcat的负载均衡集群","text":"在Linux中安装时需要自行下载源代码、安装依赖，然后编译、安装。在macOS中，有一个简便的方式，那就是使用homebrew。在Linux中安装以及配置nginx的连接为：https://blog.csdn.net/asahinokawa/article/details/82288567。虽然用了很长一段时间，但基本上是使用`brew install xxxx`此类命令上，对其他的用法不是很了解。借着安装nginx的机会，熟悉一下其他的一些有用的用法。 熟悉homebrew安装方式，可参考官网教程说明：https://brew.sh/。 基本用法：按照惯例，应该使用brew help或man brew去了解一下基本的用法。使用brew help就已经足够了，其结果也是相当地易懂、易操作，如下： 123456789101112131415161718192021222324➜ ~ brew helpExample usage: brew search [TEXT|/REGEX/] # 搜索软件，实用 brew info [FORMULA...] # 查询软件相关信息，非常有用 brew install FORMULA... # 这个不解释 brew update # 更新软件列表 brew upgrade [FORMULA...] # 更新xx软件 brew uninstall FORMULA... # 卸载xx软件 brew list [FORMULA...] # 列出通过brew安装的软件Troubleshooting: brew config brew doctor brew install --verbose --debug FORMULAContributing: brew create [URL [--no-fetch]] brew edit [FORMULA...]Further help: brew commands brew help [COMMAND] man brew https://docs.brew.sh 但是我记得之前使用过一个叫做brew cask install xxxx的方式来安装某些程序，这一次特地去找了一找关于它的用法。 123456789101112131415161718192021222324➜ ~ brew cask helpHomebrew Cask provides a friendly CLI workflow for the administrationof macOS applications distributed as binaries.Commands: audit verifies installability of Casks cat dump raw source of the given Cask to the standard output create creates the given Cask and opens it in an editor doctor checks for configuration issues edit edits the given Cask fetch downloads remote application files to local cache home opens the homepage of the given Cask info displays information about the given Cask install installs the given Cask list with no args, lists installed Casks; given installed Casks, lists staged files outdated list the outdated installed Casks reinstall reinstalls the given Cask style checks Cask style using RuboCop uninstall uninstalls the given Cask upgrade upgrades all outdated casks zap zaps all files associated with the given CaskSee also &quot;man brew-cask&quot; 这个cask可以用来装一些atom、Google Chrome之类的图形化应用。记得之前安装的是一个Android开发工具之一的ADB以及一个视频播放器iina，用list查看如下： 12➜ ~ brew cask listandroid-platform-tools iina 安装nginx12345678910111213141516171819202122232425262728293031323334353637383940414243# 更新软件列表➜ ~ brew updateAlready up-to-date.# 搜索nginx相关的软件➜ ~ brew search nginx==&gt; Formulaenginx ✔# 查看nginx相关的信息➜ ~ brew info nginxnginx: stable 1.15.3 (bottled), HEADHTTP(S) server and reverse proxy, and IMAP/POP3 proxy serverhttps://nginx.org//usr/local/Cellar/nginx/1.15.3 (23 files, 1.4MB) * Poured from bottle on 2018-09-12 at 15:32:54From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/nginx.rb==&gt; Dependencies # 依赖相关，安装时会自动安装上Required: openssl ✘, pcre ✘Optional: passenger ✘==&gt; Options--with-passenger Compile with support for Phusion Passenger module--HEAD Install HEAD version==&gt; CaveatsDocroot is: /usr/local/var/www # 文档位置# 这里解释了为什么会监听8080端口的原因，这样就可以不用sudo也能启动nginx# 这里可以注意一下nginx.conf的位置The default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so thatnginx can run without sudo.# 启动时会加载这个目录下的配置文件，在上面的配置文件中有相应的配置nginx will load all files in /usr/local/etc/nginx/servers/.To have launchd start nginx now and restart at login: brew services start nginx #启动nginx的方式之一Or, if you do not want/need a background service you can just run: nginx #启动nginx的方式之二，感觉我一般会倾向于用这个，毕竟mac不会一直用来当服务器。==&gt; Analyticsinstall: 35395 (30d), 114392 (90d), 354080 (365d)install_on_request: 32185 (30d), 99518 (90d), 300056 (365d)build_error: 103 (30d)➜ ~ brew install nginx # 这里已经安装过了，输出请忽略Warning: nginx 1.15.3 is already installed and up-to-dateTo reinstall 1.15.3, run `brew reinstall nginx` 运行直接输入nginx，便运行成功。修改配置文档后，需要使用nginx -s reload进行重新加载；需要停止时，则使用nginx -s stop即可。 配置Tomcat的负载均衡集群123456789101112131415161718192021upstream tomcatclustertest.com{ // 这是一个在本机运行的tomcat服务器 server 127.0.0.1:8088 weight=1;// weight表示按权重分配请求 // 这是一个在虚拟机中运行的tomcat服务器 server 192.168.31.104:8080 weight=2;}server { listen 8080;// 监听8080端口的请求 server_name localhost; // 服务器名字为localhost access_log /usr/local/etc/nginx/logs/access.log combined; // 日志输出文件 index index.html index.htm index.jsp index.php; #error_page 404 /404.html; if ( $query_string ~* &quot;.*[\\;'\\&lt;\\&gt;].*&quot; ) { return 404; } location / { // 将请求分配给tomcatclustertest.com这个集群，即上面的upstream中的两个tomcat组成的服务器集群 proxy_pass http://tomcatclustertest.com; proxy_redirect default; }} nginx负载均衡的策略 轮询（默认）优点：实现简单缺点：不考虑每台服务器的处理能力配置示例如下： 12345upstream www.xxx.com { # 需要负载的server列表 server www.xxx.com:8080; server www.xxx.com:9080;} 权重，使用的较多的策略优点：考虑了每台服务器处理能力的不同，哪台机器性能高就给哪台机器的权重高一些配置示例如下： 12345upstream www.xxx.com { # 需要负载的server列表，weight表示权重，weight默认为1，如果多个配置权重的节点，比较相对值 server www.xxx.com:8080 weight=15; server www.xxx.com:9080 weight=10;} ip hash优点：能实现同一个用户始终访问同一个服务器缺点：根据 ip hash 不一定平均配置示例如下： 123456upstream www.xxx.com { ip_hash; # 需要负载的server列表 server www.xxx.com:8080; server www.xxx.com:9080;} url hash （第三方插件）优点：能实现同一个服务访问同一个服务器，也就是根据url进行负载缺点：和ip hash一样，根据 url hash 分配请求不一定平均，请求频繁的url会请求到同一台服务器上配置示例如下（需要事先安装插件） 123456upstream www.xxx.com { # 需要负载的server列表 server www.xxx.com:8080; server www.xxx.com:9080; hash $request_uri;} fair （第三方插件）特点：按后端服务器的响应时间来分配请求，响应时间短的优先分配配置示例如下（需要事先安装插件） 123456upstream www.xxx.com { # 需要负载的server列表 server www.xxx.com:8080; server www.xxx.com:9080; fair;} 一些负载均衡参数简介： 12345678upstream www.xxx.com { ip_hash; # 需要负载的server列表 server www.xxx.com:8080 down; # down表示当前的server暂时不参与负载 server www.xxx.com:9080 weight=2; # weight默认值为1，weight的值越大，负载的权重就越大 server www.xxx.com:7080 backup; # 其他所有的非backup机器，在down掉或者很忙的时候，才请求backup机器，也就是一个备用机器 server www.xxx.com:6080;} 参考：https://www.cnblogs.com/meng1314-shuai/p/8335140.htmlhttps://blog.csdn.net/wang379275614/article/details/47778201http://blog.51cto.com/zero01/2112989","link":"/2018/09/13/fe78553d633b.html"},{"title":"linux中的pushd、popd与dirs","text":"最近在项目中，看到一些模块的启动脚本中，有一些 pushd、popd等操作。之前并没有接触过这类命令，但是目测它是与目录相关的，因为都是操作完了目录之后，才能运行启动命令。 dirs展示目录栈。 什么是目录栈？ 使用cd命令进入一个目录后，该目录会存放进以个栈中，当前目录永远位于栈顶。dirs 可以用来查看栈中的目录信息。如： 注意：最左边表示栈顶，最右边表示栈底。 一些具体操作： 123456-c：删除目录栈中的所有记录-l：以完整格式显示-p：一个目录一行的方式显示-v：每行一个目录来显示目录栈的内容，每个目录前加上的编号+N：显示从左到右的第n个目录，数字从0开始-N：显示从右到左的第n个日录，数字从0开始 有了目录栈，自然会有与栈相关的操作，如入栈与出栈，即可通俗理解成pushd、popd。 pushd主要功能就是修改栈顶目录，即切换目录。主要有如下3种体现： 将目录入栈，即加入到栈顶。 将栈中某个目录切换栈顶。 不带参数，与cd -同语义： 带目录，与cd some_dir同语义： 带+/-n，切换栈中某个具体位置的目录到栈顶： pushd +N: 将栈内元素循环左移，直到将（从右边数）第N个元素移动到栈顶，由0开始计。 pushd -N: 将栈内元素循环左移，直到将（从左边数）第N个元素移动到栈顶，由0开始计。 注：图中~/Movies的标号应该为3，特此更正。 popd主要功能是将目录出栈。包括栈顶（修改当前目录为上次目录，即单向的cd -）、及其他位置目录（可能不修改栈顶目录）。 不带任何参数：栈顶元素出栈。 popd +N：删除栈中（从右边数）第N个元素，由0开始计。 popd -N：删除栈中（从左边数）第N个元素，由0开始计。 小结可以理解为cd -的加强版本，实际作用可能并不是特别大。","link":"/2020/05/19/df65a64c0546.html"},{"title":"nginx的安装与配置、使用","text":"安装依赖库1sudo yum -y install gcc pcre zlib zlib-devel openssl openssl-devel 下载&amp;安装下载页面：http://nginx.org/en/download.html此处的下载版本为：http://nginx.org/download/nginx-1.10.3.tar.gz 12345678910# 下载并解压wget http://nginx.org/download/nginx-1.10.3.tar.gztar -xzvf nginx-1.10.3.tar.gz -C ~/devtools/# 进入解压目录cd devtools/nginx-1.10.3/# 编译./configuremake# 安装，因为默认是安装到/usr/local/目录下，需要提升权限sudo make install 可通过whreeis来查看： 12[asahi@localhost nginx-1.10.3]$ whereis nginxnginx: /usr/local/nginx 进入到/usr/local/nginx目录下，然后启动nginx， 1sudo /usr/local/nginx/sbin/nginx 访问得到的页面如下：（如果成功运行后，不能访问，考虑修改防火墙相关设置） 端口转发配置比如说，我想让虚拟机里面占用8080端口的Tomcat的域名编程www.ddgg.com。 首先，我需要在访问这个网址的设备上，将192.168.1.5 www.ddgg.com加入到 hosts 文件中。它的意思就是，如果要访问www.ddgg.com，那么将这个请求发送给 192.168.1.5 这个ip，它知道怎么处理。 注意，这是在宿主机中，非虚拟机中的host！ 虚拟机CentOS的80端口将拿到这个请求时。nginx可以做到监听80端口，如果这个请求的服务器为www.ddgg.com，就将请求转发到8080端口，这样就会交给Tomcat来处理，便完成了一种虚拟域名的功能。 首先，在nginx的主目录下，创建一个vhost文件夹，里面放一些端口转发的配置。结构如下： 12[asahi@localhost nginx]$ ls vhostwww.ddgg.com.conf www.ddgg.com.conf 这个配置文件的内容如下： 123456789101112131415server { listen 80; # 监听80端口 autoindex on; server_name www.ddgg.com; # 如果请求的服务器是www.ddgg.com access_log /usr/local/nginx/logs/access.log combined; # log配置 index index.html index.htm index.jsp index.php; #error_page 404 /404.html; if ( $query_string ~* &quot;.*[\\;'\\&lt;\\&gt;].*&quot; ) { return 404; } location / { proxy_pass http://127.0.0.1:8080; # 就转向本机的8080端口 add_header Access-Control-Allow-Origin *; }} 最后，要将上述配置文件加入到nginx的 conf/ningx.conf 配置文件中，需要在其中加上下面的语句： 端口转发结果 映射到本地文件夹在vhost文件夹下，新建一个 image.ddgg.com.conf，内容如下： 123456789101112131415server { listen 80; autoindex on; server_name image.ddgg.com; access_log /usr/local/nginx/logs/access.log combined; index index.html index.htm index.jsp index.php; #error_page 404 /404.html; if ( $query_string ~* &quot;.*[\\;'\\&lt;\\&gt;].*&quot; ) { return 404; } location / { root /home/ftpfile/; # 此处指向本地文件夹/home/ftpfile/ add_header Access-Control-Allow-Origin *; }} 映射结果","link":"/2018/09/02/8cf4bb422c50.html"},{"title":"nc的简易使用","text":"端口扫描nc -zvn 192.168.126.135 22 z 参数告诉netcat使用0 IO,连接成功后立即关闭连接， 不进行数据交换. v 参数指详细输出. n 参数告诉netcat 不要使用DNS反向查询IP地址的域名. 聊天室 服务器角色：nc -l 1081 客户端角色：nc 192.168.126.135 1081 不管你在机器B上键入什么都会出现在机器A上。 文件传输服务器向客户端传文件 服务器角色：nc -l 1081 &lt; test.txt 客户端角色：nc -n 192.168.126.135 1081 &gt; test.txt 客户端向服务器传文件 服务器角色：nc -l 1081 &gt; test.txt 客户端角色：nc -n 192.168.126.135 1081 &lt; .bashrc 目录传输服务器发送目录 服务器角色：tar -cvf - cpp | nc -l 1081 客户端角色：nc -n 192.168.126.135 1081 | tar -xvf - 服务器接收目录 服务器角色：nc -l 1081 | tar -xvf - 客户端角色：tar -cvf - test_dir | nc -n 192.168.126.135 1081 以上的列举是比较常用的。但是存在一个问题是传输速度可能不快。","link":"/2019/05/21/ba2abc0731b7.html"},{"title":"tcpdump cheat sheet","text":"Packet Capturing Options Switch Syntax Description -i any tcpdump -i any Capture from all interfaces -i eth0 tcpdump -ieth0 Capture from specific interface ( Ex Eth0) -c tcpdump -i eth0 -c 10 Capture first 10 packetsand exit -D tcpdump -D Show available interfaces -A tcpdump -i eth0 -A Print in ASCII -w tcpdump -i eth0 -w tcpdump.txt To save capture to a file -r tcpdump -r tcpdump.txt Read and analyze savedcapture file -n tcpdump -n -I eth0 Do not resolve host names -nn tcpdump -n -i eth0 Stop Domain name translationand lookups (Host names or port names ) tcp tcpdump -i eth0 -c 10 -w tcpdump.pcap tcp Capture TCP packets only port tcpdump -i eth0 port 80 Capture traffic from a defined port only host tcpdump host 192.168.1.100 Capture packets from specific host net tcpdump net 10.1.1.0/16 Capture files from network subnet src tcpdump src 10.1.1.100 Capture from a specific source address dst tcpdump dst 10.1.1.100 Capture from a specific destination address service tcpdump http Filter traffic based on a port number for aservice port tcpdump port 80 Filter traffic based on a service port range tcpdump portrange 21-125 Filter based on port range -S tcpdump -S http Display entire packet ipv6 tcpdunp -IPV6 Show only IPV6 packets -d tcpdump -d tcpdump.pcap display human readable form in standardoutput -F tcpdump -F tcpdump.pcap Use the given file as input for filter -I tcpdump -I eth0 set interface as monitor mode -L tcpdump -L Display data link types for the interface -N tcpdump -N tcpdump.pcap not printing domian names -K tcpdump -K tcpdump.pcap Do not verify checksum -p tcpdump -p -i eth0 Not capturing in promiscuous mode Logical Operators Operator Syntax Example Description AND and, &amp;&amp; tcpdump -n src 192.168.1.1 and dst port 21 Combine filtering options OR or, || tcpdump dst 10.1.1.1 &amp;&amp; !icmp Either of the condition can match EXCEPT not, ! tcpdump dst 10.1.1.1 and not icmp Negation of the condition LESS &lt; tcpdump &lt;32 Shows packets size less than 32 GREATER &gt; tcpdump &gt;=32 Shows packets size greater than 32 Installation Commands Linux Distro Command CENT OS and REDHAT $ sudo yum install tcpdump Fedora $ dnf install tcpdump Ubuntu, Debian and Linux Mint $ apt-get install tcpdump Display / Output Options Switch Description -q Quite and less verbose modedisplay less details -t Do not print time stamp details in dump -v Little verbose output -vv More verbose output -vvv Most verbose output -x Print data and headers in HEX format -xx Print datawith link headers in HEX format -X Print output in HEX and ASCII format excluding link headers -XX Print output in HEX and ASCII format including link headers -e Print Link (Ethernet) headers -S Print sequence numbers in exact format ProtocolsEther, fddi, icmp ,ip, ip6 , ppp, radio, rarp, slip, tcp , udp, wlan Common Commands with Protocols for Filtering Captures Options Description src/ dsthost (host name or IP) Filter by source or destination IP address or host ether src/ dst host (ethernet host name or IP) Ethernet host filtering by source or destination src/ dstnet(subnet mask in CIDR) Filter by subnet tcp/udp src/dst port ( port number) Filter TCP or UDP packets by source or destination port tcp/udp src/dst port range ( port number range) Filter TCP or UDP packets by source or destination port range ether/ip broadcast Filter for Ethernet or IP broadcasts ether/ip multicast Filter for Ethernet or IP multicasts","link":"/2023/01/06/3b88cfb96204.html"},{"title":"try、catch、finally与return的执行顺序问题","text":"finally一定会执行 return以最后一次为准 return后的finally是否修改了数据，得看具体类型 try{} catch(){}finally{} return按照正常的顺序执行：有错会执行catch，finally都会执行，最后执行return。 1234567891011121314private static int returnInFinally_00(){ int a ; try { System.out.println(&quot;try...&quot;); a = 3 / 0; } catch (Exception e){ System.out.println(&quot;catch...&quot;); } finally { System.out.println(&quot;finally...&quot;); a = 2; } return 100;}// 100 try{ return; }catch(){} finally{} returntry中已经return，所以不再执行finally后面的return。 123456789101112131415private static int returnInFinally_01(){ int a ; try{ System.out.println(&quot;try...&quot;); a = 3 / 1; return a; } catch (Exception e){ System.out.println(&quot;catch...&quot;); } finally { System.out.println(&quot;finally...&quot;); a = 2; } return 100;}// 3 try{ } catch(){return;} finally{} return与上述情况类似 123456789101112131415private static int returnInFinally_02(){ int a = 0; try{ System.out.println(&quot;try...&quot;); a = 3 / 0; } catch (Exception e){ System.out.println(&quot;catch...&quot;); return a; } finally { System.out.println(&quot;finally...&quot;); a = 2; } return a;}// 0 try{ return; }catch(){} finally{return;}程序执行try块中return之前（包括return语句中的表达式运算）代码；再执行finally块，因为finally块中有return所以提前退出（这提前退出的意思是指：后面的代码都不会再执行了，所以就退出）。 12345678910111213141516private static int returnInFinally_03(){ int a ; try{ System.out.println(&quot;try...&quot;); a = 3 / 1; return a; } catch (Exception e){ System.out.println(&quot;catch...&quot;); } finally { System.out.println(&quot;finally...&quot;); a = 2; return a; } //return 100; 不可能执行此代码，编译器直接报错}// 2 try{} catch(){return;}finally{return;}与上述类似 123456789101112131415private static int returnInFinally_04(){ int a = 0; try{ System.out.println(&quot;try...&quot;); a = 3 / 0; } catch (Exception e){ System.out.println(&quot;catch...&quot;); return a ++; } finally { System.out.println(&quot;finally...&quot;); a ++; return a; }}// 2 try{ return;}catch(){return;} finally{return;}同上述类似 12345678910111213141516private static int returnInFinally_05(){ int a = 1; try{ System.out.println(&quot;try...&quot;); a = 3 / 0; return a; } catch (Exception e){ System.out.println(&quot;catch...&quot;); return a ++; } finally { System.out.println(&quot;finally...&quot;); a ++; return a; }}// 3 return后在finally中修改值是否会影响结果？问题回到传值还是传引用上啦，这里有疑问就再回去看看传值与传引用吧 123456789101112131415161718192021222324252627282930313233343536// 一个普通测试类private static class TestObject{ private int x; public int getX() { return x; } public void setX(int x) { this.x = x; } // 覆盖toString @Override public String toString() { return &quot;x = &quot; + x; }}private static TestObject returnInFinally_06(){ TestObject to = new TestObject(); try{ System.out.println(&quot;try...&quot;); to.setX(1);// 设为1 return to; } catch (Exception e){ System.out.println(&quot;catch...&quot;); to.setX(2);// 设为2 return to; } finally { System.out.println(&quot;finally...&quot;); to.setX(3);// 最终设为3 }}// try...// finally...// x = 3","link":"/2018/07/06/313d1f4f0aba.html"},{"title":"linux中free命令背后的故事","text":"available当应用程序需要内存时，如果没有足够的 free 内存可以用，内核就会从 buffer 和 cache 中回收内存来满足应用程序的请求。所以从应用程序的角度来说，available = free + buffer + cache。请注意，这只是一个很理想的计算方式，实际中的数据往往有较大的误差。 used= total - free - buffers - cache （来自man free）。 free是真正尚未被使用的物理内存数量。 buff/cache中的内容来自对磁盘内容的缓存。","link":"/2019/02/20/a27177743283.html"},{"title":"windows激活服务器搭建及激活流程","text":"1234slmgr /upkslmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GXslmgr /skms kms.loli.beerslmgr /ato 搭建流程下载压缩包 wget https://github.com/Wind4/vlmcsd/releases/download/svn1112/binaries.tar.gz 解压 tar -xzvf binaries.tar.gz 进入解压得到的目录，如下： 12345678910111213141516171819202122232425262728293031323334➜ binaries tree -L 2.|-- Android| |-- arm| |-- intel| `-- mips|-- DragonFly| `-- intel|-- FreeBSD| `-- intel|-- Hurd| `-- intel|-- Linux| |-- arm| |-- intel| |-- mips| |-- ppc| |-- s390| `-- sparc|-- MacOSX| |-- intel| `-- ppc|-- Minix| `-- intel|-- NetBSD| `-- intel|-- OpenBSD| `-- intel|-- Solaris| `-- intel|-- Windows| `-- intel`-- iOS `-- arm 根据系统类型，选择相应系统，然后选择进入相应CPU架构的目录，这里是进入Linux/Intel目录。 查看系统类型：uname，如下： 12➜ binaries unameLinux 查看CPU相关参数：cat /proc/cpuinfo，如下： 123456789101112131415161718192021222324252627➜ binaries cat /proc/cpuinfoprocessor : 0vendor_id : GenuineIntelcpu family : 6model : 63model name : Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHzstepping : 2microcode : 0x3dcpu MHz : 2399.964cache size : 30720 KBphysical id : 0siblings : 1core id : 0cpu cores : 1apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault invpcid_single pti fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveoptbugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tfbogomips : 4800.06clflush size : 64cache_alignment : 64address sizes : 46 bits physical, 48 bits virtualpower management: 进入static目录，如下： 12345678910➜ static ls -ltotal 852-rwxr-xr-x 1 ubuntu ubuntu 97115 Oct 20 2018 vlmcs-x64-musl-static-rwxr-xr-x 1 ubuntu ubuntu 94488 Oct 20 2018 vlmcs-x86-musl-static-rwxr-xr-x 1 ubuntu ubuntu 93051 Oct 20 2018 vlmcsd-x64-musl-static-rwxr-xr-x 1 ubuntu ubuntu 92344 Oct 20 2018 vlmcsd-x86-musl-static-rwxr-xr-x 1 ubuntu ubuntu 92760 Oct 20 2018 vlmcsd-x86-musl-static-threads-rwxr-xr-x 1 ubuntu ubuntu 130363 Oct 20 2018 vlmcsdmulti-x64-musl-static-rwxr-xr-x 1 ubuntu ubuntu 129912 Oct 20 2018 vlmcsdmulti-x86-musl-static-rwxr-xr-x 1 ubuntu ubuntu 129912 Oct 20 2018 vlmcsdmulti-x86-musl-static-threads 没有运行权限的加个运行权限：sudo chmod +x vlmcsd-x64-musl-static 运行服务：nohup ./vlmcs-x64-musl-static 激活流程打开cmd/powershell（管理员）直接输入下列命令： 1234567891011121314151617# 卸载产品密钥slmgr /upk # 配置系统序列号slmgr /ipk W269N-WFGWX-YVC9B-4J6C9-T83GX #不同系统版本这里的激活码不一样# 配置KMS服务器地址slmgr /skms 13.231.43.2xx# 激活系统slmgr /ato# 查看系统激活到期时间slmgr /xpr#查看授权详细信息slmgr /dlv 关于slmgr命令的详细参数说明，可在cmd/powershell中输入slmgr后直接点击回车，就会出现详细说明 不同版本系统的激活码一览表 Windows 10 操作系统版本 KMS客户端设置密钥 Windows 10 专业版 W269N-WFGWX-YVC9B-4J6C9-T83GX Windows 10 专业N版 MH37W-N47XK-V7XM9-C7227-GCQG9 Windows 10 企业版 NPPR9-FWDCX-D2C8J-H872K-2YT43 Windows 10 企业N版 DPH2V-TTNVB-4X9Q3-TJR4H-KHJW4 Windows 10 教育（家庭）版 NW6C2-QMPVW-D7KKK-3GKT6-VCFB2 Windows 10 教育（家庭）N版 2WH4N-8QGBV-H22JP-CT43Q-MDWWJ Windows 10 企业版2015 LTSB WNMTR-4C88C-JK8YV-HQ7T2-76DF9 Windows 10 企业版 2015 LTSB N 2F77B-TNFGY-69QQF-B8YKP-D69TJ Windows 10 企业版 2016 LTSB DCPHK-NFMTC-H88MJ-PFHPY-QJ4BJ Windows 10 企业版 2016 LTSB N QFFDN-GRT3P-VKWWX-X7T3R-8B639 完结 撒花！","link":"/2019/08/01/a4d33ee26064.html"},{"title":"【leetcode】21. Merge Two Sorted Lists","text":"Merge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists.Example:Input: 1-&gt;2-&gt;4, 1-&gt;3-&gt;4Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 题目属于简单类型，但是好久没写这种题了，再加上C语言也很久没写过了，费了很久。。。思路很简单，先以一个为基准，然后再将另外一个逐个插入其中（然而开始的时候并不是这么想的，用的某种骚操作，结果发现写着写着搞不定了，这种写代码的方式果然不行呀）。感觉还可以有提高的地方，比如用个二分什么的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * Definition for singly-linked list. * struct ListNode { * int val; * struct ListNode *next; * }; */#define FINISHED -1#define UNFINISHED -2#define SKIP 0void showList(struct ListNode* l) { printf(&quot;[&quot;); while (l != NULL) { printf(&quot;%d&quot;, l-&gt;val); if (l-&gt;next != NULL) { printf(&quot;,&quot;); } l = l-&gt;next; } printf(&quot;]\\n&quot;);}int insertNode(struct ListNode* l, struct ListNode* node) { struct ListNode* tmp; struct ListNode* pre = NULL; struct ListNode* tp = l; int handled = 0; // printf(&quot;Before insert: &quot;);showList(l); while (tp != NULL) { // printf(&quot;tp-&gt;val = %d, node-&gt;val = %d\\n&quot;, tp-&gt;val, node-&gt;val); if (node-&gt;val &lt;= tp-&gt;val) { if (tp == l) { int ti = l-&gt;val; l-&gt;val = node-&gt;val; node-&gt;val = ti; tmp = l-&gt;next; l-&gt;next = node; node-&gt;next = tmp; } else { pre-&gt;next = node; node = node-&gt;next; pre-&gt;next-&gt;next = tp; } handled = 1; break; } pre = tp; tp = tp-&gt;next; } if (!handled) { pre-&gt;next = node; return FINISHED; } // printf(&quot;After insert: &quot;);showList(l); return UNFINISHED;}struct ListNode* mergeTwoLists(struct ListNode* l1, struct ListNode* l2){ struct ListNode* root = NULL; if (l1 == NULL || l2 == NULL) { if (root == NULL) root = (l1 == NULL ? l2 : l1); return root; } if (root == NULL) { root = l1; } l1 = l2; int finished = UNFINISHED; while (l1 != NULL) { struct ListNode* next = l1-&gt;next; int res = insertNode(root, l1); switch(res){ case FINISHED: return root; case UNFINISHED: case SKIP: l1 = next; break; } // printf(&quot;Wait to insert: &quot;);showList(l1); } return root;}","link":"/2019/06/10/6528e594295b.html"},{"title":"《图解设计模式》之简易UML类图","text":"每一种设计模式都可以用UML类图来表示，能看懂UML类图，就能够对该设计模式有宏观上的认知和理解。 单个类里面的简单格式 以长方形表示类，长方形内部被分成3个区域，分别表示类名、属性名、方法名。 格式 含义 斜体 抽象类、抽象方法 下划线 静态方法、静态字段 方法和字段前面的符号，+表示public， -表示private， #表示protected，~表示同一个包下可访问。 接口用&lt;&lt;interface&gt;&gt;表示。 类之间的关系 继承父类（extends） 实线三角，箭头从子类指向父类。泛化(generalization)：表示is-a的关系，是对象之间耦合度最大的一种关系，子类继承父类的所有细节。直接使用语言中的继承表达。 实现接口（implements） 虚线三角，箭头从实现类指向接口。实现（Realization）:在类图中就是接口和实现的关系。 聚合 空心菱形，能分离而独立存在，空心菱形部指向整体。聚合(Aggregation) : 表示has-a的关系，是一种不稳定的包含关系。较强于一般关联,有整体与局部的关系,并且没有了整体,局部也可单独存在。如公司和员工的关系，公司包含员工，但如果公司倒闭，员工依然可以换公司。 组合 实心菱形，精密关联不可分，实心的菱形从局部指向整体。组合(Composition) : 表示contains-a的关系，是一种强烈的包含关系。组合类负责被组合类的生命周期。是一种更强的聚合关系。部分不能脱离整体存在。如公司和部门的关系，没有了公司，部门也不能存在了；调查问卷中问题和选项的关系；订单和订单选项的关系。 关联 实线箭头，箭头从使用类指向被关联的类。可以是单向和双向。关联(Association) : 对象之间一种引用关系，比如客户类与订单类之间的关系。这种关系通常使用类的属性表达。关联又分为一般关联、聚合关联与组合关联。后两种在后面分析。 依赖 虚线箭头，箭头从使用类指向被依赖的类。依赖(Dependency)：对象之间最弱的一种关联方式，是临时性的关联。代码中一般指由局部变量、函数参数、返回值建立的对于其他对象的调用关系。一个类调用被依赖类中的某些方法而得以完成这个类的一些职责。 聚合和组合的区别这两个比较难理解，重点说一下。聚合和组合的区别在于：聚合关系是“has-a”关系，组合关系是“contains-a”关系；聚合关系表示整体与部分的关系比较弱，而组合比较强；聚合关系中代表部分事物的对象与代表聚合事物的对象的生存期无关，一旦删除了聚合对象不一定就删除了代表部分事物的对象。组合中一旦删除了组合对象，同时也就删除了代表部分事物的对象。 时序图黑色实线箭头表示方法调用；虚线箭头表示方法调用返回。 实例：用长方形表示，里面的内容为实例名:类名，其中实例名可省略。 生命线：每个实例往下沿伸的虚线。 时序图的阅读书序是沿着生命线从上至下阅读。 参考： 《图解设计模式》 UML类图与类的关系详解","link":"/2019/12/24/a5645407e2ce.html"},{"title":"nginx中的root与alias的差别","text":"格式nginx指定文件路径有两种方式root和alias，指令的使用方法和作用域：[root]语法：root path默认值：root html配置段：http、server、location、if[alias]语法：alias path配置段：location root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上。root的处理结果是：root路径 ＋ location路径alias的处理结果是：使用alias路径替换location路径alias是一个目录别名的定义，root则是最上层目录的定义。还有一个重要的区别是alias后面必须要用“/”结束，否则会找不到文件的，而root则可有可无。 例： 12345678910# 如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/t/a.html的文件。location ^~ /t/ { root /www/root/html/;}# 如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/new_t/a.html的文件。# 注意这里是new_t，因为alias会把location后面配置的路径丢弃掉，把当前匹配到的目录指向到指定的目录。location ^~ /t/ { alias /www/root/html/new_t/;} 注意 使用alias时，目录名后面一定要加”/“。 alias在使用正则匹配时，必须捕捉要匹配的内容并在指定的内容处使用。 alias只能位于location块中。（root可以不放在location中） 搬运工：文章为: nginx.cn原创，转载请注明本文地址: http://www.nginx.cn/4658.html","link":"/2019/02/20/5ca02b540a6b.html"},{"title":"【工具使用】Linux实用命令之文件搜索","text":"在工作中，经常遇到只知道一些模糊、大致的名字的一些类名或字段，从已知的一个目录下去搜索。然而有些命令实在是太好用了，好用到赞不绝口，也有一些命令，老是忘记。。。 find最常用的场景是在framework目录下，有一些类，只知道类名，但是不知道它的具体的路径，总不可能去一个一个搜吧，还有一个可行的是去百度，但是这也不是很适合，因为还有更快的。 这个命令的功能实在是太强大了，所以按需而罗列吧。 按文件名查找find dirname -name &quot;filename&quot;find dirname -name &quot;*filename*&quot; （使用正则表达式）find dirname -iname &quot;filename&quot; （忽略大小写）find dirname -name &quot;filename 2&gt; /dev/null&quot; （忽略错误信息） grep这个也是一个强大的命令，配合正则表达式也是一个逆天的存在，但是一般情况下会我用到它的场景也就是两种： 查找某个目录下所有的某列包含某字符串的文件grep -Rn &quot;PatternSequence&quot; . (找到并显示行号，不要太好用！) 查找某文本中所有的含有某字符串的列这个不解释","link":"/2018/01/31/1ca864566e27.html"},{"title":"【转载-摘要】彻底搞懂 Git-Rebase","text":"原文链接：http://jartto.wang/2018/12/11/git-rebase/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io rebase的主要功能就是改变commit历史，在这篇文章中，场景一是改变未push的commit历史，场景二是在合并分支时，改变当前分支的历史，从而达到简化commit历史的目的，让历史一目了然。对强迫症患者来说简直就是福音。 Rebase 场景一：如何合并多次提交纪录？1.我们来合并最近的 4 次提交纪录，执行：git rebase -i HEAD~42.这时候，会自动进入 vi 编辑模式： 123456789101112131415161718192021s cacc52da add: qrcodes f072ef48 update: indexeddb hacks 4e84901a feat: add indexedDB floders 8f33126c feat: add test2.js# Rebase 5f2452b2..8f33126c onto 5f2452b2 (4 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like &quot;squash&quot;, but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.# 有几个命令需要注意一下： 1234567p, pick = use commitr, reword = use commit, but edit the commit messagee, edit = use commit, but stop for amendings, squash = use commit, but meld into previous commitf, fixup = like “squash”, but discard this commit’s log messagex, exec = run command (the rest of the line) using shelld, drop = remove commit 按照如上命令来修改你的提交纪录： 1234s cacc52da add: qrcodes f072ef48 update: indexeddb hacks 4e84901a feat: add indexedDB floderp 8f33126c feat: add test2.js 3.如果保存的时候，你碰到了这个错误：error: cannot 'squash' without a previous commit注意不要合并先前提交的东西，也就是已经提交远程分支的纪录。 4.如果你异常退出了 vi 窗口，不要紧张： git rebase --edit-todo这时候会一直处在这个编辑的模式里，我们可以回去继续编辑，修改完保存一下： git rebase --continue5.查看结果 git log三次提交合并成了一次，减少了无用的提交信息。 Rebase 场景二：分支合并1.我们先从 master 分支切出一个 dev 分支，进行开发： git:(master) git checkout -b feature12.这时候，你的同事完成了一次 hotfix，并合并入了 master 分支，此时 master 已经领先于你的 feature1 分支了：3.恰巧，我们想要同步 master 分支的改动，首先想到了 merge，执行： git:(feature1) git merge master图中绿色的点就是我们合并之后的结果，执行： git:(feature1) git log就会在记录里发现一些 merge 的信息，但是我们觉得这样污染了 commit 记录，想要保持一份干净的 commit，怎么办呢？这时候，git rebase 就派上用场了。 4.让我们来试试 git rebase ，先回退到同事 hotfix 后合并 master 的步骤：5.使用 rebase 后来看看结果： git:(feature1) git rebase master这里补充一点：rebase 做了什么操作呢？ 首先，git 会把 feature1 分支里面的每个 commit 取消掉；其次，把上面的操作临时保存成 patch 文件，存在 .git/rebase 目录下；然后，把 feature1 分支更新到最新的 master 分支；最后，把上面保存的 patch 文件应用到 feature1 分支上；从 commit 记录我们可以看出来，feature1 分支是基于 hotfix 合并后的 master ，自然而然的成为了最领先的分支，而且没有 merge 的 commit 记录，是不是感觉很舒服了。 6.在 rebase 的过程中，也许会出现冲突 conflict。在这种情况，git 会停止 rebase 并会让你去解决冲突。在解决完冲突后，用 git add 命令去更新这些内容。 注意，你无需执行 git-commit，只要执行 continue git rebase --continue这样 git 会继续应用余下的 patch 补丁文件。 7.在任何时候，我们都可以用 –abort 参数来终止 rebase 的行动，并且分支会回到 rebase 开始前的状态。 git rebase —abort 不足只要你的分支上需要 rebase 的所有 commits 历史还没有被 push 过，就可以安全地使用 git-rebase来操作。 因为push到远程仓库后，你再次提交时，git对比会发现两个仓库的历史不一致。","link":"/2019/03/20/67f245149110.html"},{"title":"一种 shell 脚本很酷的写法——多行字符串变量","text":"在看 Kubernetes 的文档时，看到一种定义多行字符串作为变量的写法，感觉挺有意思，如下： 123456789101112131415161718192021222324kubectl apply -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]EOF# Create a secret with several keys from stdincat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: password: $(echo -n &quot;s33msi4&quot; | base64 -w0) username: $(echo -n &quot;jane&quot; | base64 -w0)EOF 看起来很是牛逼的感觉，实际上也避免了一些不必要的文件创建、可以让命令更加地精简。 Here documentWikipedia 定义 In computing, a here document (here-document, here-text, heredoc, hereis, here-string or here-script) is a file literal or input stream literal: it is a section of a source code file that is treated as if it were a separate file. The term is also used for a form of multiline string literals that use similar syntax, preserving line breaks and other whitespace (including indentation) in the text. 简单理解 它是一种特殊的表达方式，它本质上是源代码的一部分，但是表现出来像是真的从独立文件里面获取到的一样。 格式： 123[n]&lt;&lt;word here-documentdelimiter n 为文件描述符，省略是默认为0，即标准输入； word 被引号括住，不解析变量、数据计算等； &lt;&lt; 不省略 ；&lt;&lt;- 会忽略 。 word 与 delimiter 被称为 here tag，它们之间的文字叫做 here doc。 使用场景示例 下面几种是 here doc 的常见使用模板 多行输出12345678cat &lt;&lt; EOFheredoc&gt; biubiubiuheredoc&gt; balaheredoc&gt; EOF# 输出biubiubiubala 定义多行变量1234567891011sql=$(cat &lt;&lt;EOFSELECT foo, bar FROM dbWHERE foo='baz'EOF)echo $sql# 输出SELECT foo, bar FROM dbWHERE foo='baz' 将多行数据重定向到文件123456789101112cat &lt;&lt;EOF &gt; print.sh#!/bin/bashecho \\$PWDecho $PWDEOFcat print.sh# 输出#!/bin/bashecho $PWDecho /Users/feiv 将多行数据通过管道传递给后续命令123456789cat &lt;&lt;EOF | grep 'b' | tee b.txtfoobarbazEOF# 输出barbaz 思考与尝试here tag 即常用的 EOF 是只要求前后匹配即可，不一定非得要 EOF，如下： 12345678cat &lt;&lt; BALABALAbiubiubiubalaBALABALA# 输出biubiubiubala 关于引号把 word 括起来的效果，可以参考如下示例： 123456789101112131415161718192021222324252627a=0cat &lt;&lt;EOF$aEOF# 输出0#################a=0cat &lt;&lt;'EOF'$aEOF# 输出$a#################a=0cat &lt;&lt;&quot;EOF&quot;$aEOF# 输出$a cat 后面其实可以接多个 &lt;&lt; word，但目前还未发现其用途，如下： 12345cat &lt;&lt;eof1; cat &lt;&lt;eof2Hi,eof1Helene.eof2 Reference What is Cat EOF in Bash Script How does “cat &lt;&lt; EOF” work in bash? 2.7.4 Here-Document","link":"/2021/08/22/fc99d804f91c.html"},{"title":"一种基于redis的分布式锁的实现（当前项目中在使用）","text":"主要思想是利用redis执行命令时的单线程特性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147/** * 分布式锁 */@Componentpublic class DistributedLock { public static final Logger logger = LoggerFactory.getLogger(DistributedLock.class); /** * 加锁默认超时时间 */ private static final long DEFAULT_TIMEOUT_SECOND = 5; /** * 获取所等待的时间 */ private static final long DEFAULT_WAITE_TIMEOUT_SECOND = 5; /** * 加锁循环等待时间 */ private static final long LOOP_WAIT_TIME_MILLISECOND = 30; @Autowired @Qualifier(&quot;redisCacheService&quot;) private BaseCacheService cacheService; /** * 有超时等待的加锁 * * @param timeoutSecond 如果为null,使用默认超时时间 * @param waiteTimeoutSecond 若果为null,使用默认超时时间 * @return 加锁的值（超时时间：-1表示获取失败，超时） */ public long lock(String key, Long timeoutSecond, Long waiteTimeoutSecond) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; start lock&quot;); long beganTime = System.currentTimeMillis() / 1000; //如果参数错误 if (timeoutSecond != null &amp;&amp; timeoutSecond &lt;= 0) { timeoutSecond = DEFAULT_TIMEOUT_SECOND; } timeoutSecond = timeoutSecond == null ? DEFAULT_TIMEOUT_SECOND : timeoutSecond; if (waiteTimeoutSecond != null &amp;&amp; waiteTimeoutSecond &lt;= 0) { waiteTimeoutSecond = DEFAULT_WAITE_TIMEOUT_SECOND; } waiteTimeoutSecond = waiteTimeoutSecond == null ? DEFAULT_WAITE_TIMEOUT_SECOND : waiteTimeoutSecond; while (true) { //等待超时判断 long endTime = System.currentTimeMillis() / 1000; if ((endTime - beganTime) &gt;= waiteTimeoutSecond) { return -1l; } //超时时间点 long timeoutTimeMilli = cacheService.getCurrentTimeMilliForCache() + timeoutSecond * 1000; //如果设置成功 if (cacheService.setIfAbsent(key, timeoutTimeMilli)) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; lock success&quot;); return timeoutTimeMilli; } //如果已经超时 Long value = cacheService.getVal(key, Long.class); if (value != null &amp;&amp; value.longValue() &lt; cacheService.getCurrentTimeMilliForCache()) { //设置新的超时时间 Long oldValue = cacheService.getAndSet(key, timeoutTimeMilli); //多个线程同时getset，只有第一个才可以获取到锁 if (value.equals(oldValue)) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; lock success&quot;); return timeoutTimeMilli; } } //延迟一定毫秒，防止请求太频繁 try { Thread.sleep(LOOP_WAIT_TIME_MILLISECOND); } catch (InterruptedException e) { logger.error(&quot;DistributedLock lock sleep error&quot;, e); } } } /** * 无超时等待的加锁 * * @param timeoutSecond 如果为null,使用默认超时时间 * @return 加锁的值（超时时间） */ public long lock(String key, Long timeoutSecond) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; start lock&quot;); //如果参数错误 if (timeoutSecond != null &amp;&amp; timeoutSecond &lt;= 0) { timeoutSecond = DEFAULT_TIMEOUT_SECOND; } timeoutSecond = timeoutSecond == null ? DEFAULT_TIMEOUT_SECOND : timeoutSecond; while (true) { //超时时间点 long timeoutTimeMilli = cacheService.getCurrentTimeMilliForCache() + timeoutSecond * 1000; //如果设置成功 // 若在redis中、没有相应的key值，那么可以认为，当前线程即或得该锁。 if (cacheService.setIfAbsent(key, timeoutTimeMilli)) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; lock success&quot;); return timeoutTimeMilli; } //如果已经超时 // 此时该key在redis已存在，获取该key的值 Long value = cacheService.getVal(key, Long.class); if (value != null &amp;&amp; value.longValue() &lt; cacheService.getCurrentTimeMilliForCache()) { //设置新的超时时间 // 如果此时获取到的oldValue，与前面获取的value相同，则说明该线程可以获得锁 // 获得锁后，set进新值。 Long oldValue = cacheService.getAndSet(key, timeoutTimeMilli); //多个线程同时getset，只有第一个才可以获取到锁 if (value.equals(oldValue)) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; lock success&quot;); return timeoutTimeMilli; } } //延迟一定毫秒，防止请求太频繁 try { Thread.sleep(LOOP_WAIT_TIME_MILLISECOND); } catch (InterruptedException e) { logger.error(&quot;DistributedLock lock sleep error&quot;, e); } } } /** * 释放锁 */ public void unLock(String key, long lockValue) { logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; start unlock&quot;); Long value = cacheService.getVal(key, Long.class); if (value != null &amp;&amp; value.equals(lockValue)) {//如果是本线程加锁 cacheService.deleteVal(key); logger.info(&quot;Thread：&quot; + Thread.currentThread().getName() + &quot; unlock success&quot;); } }}","link":"/2019/02/27/63bdd864316e.html"},{"title":"两个Netty入门用法Demo","text":"大概一年多前，用过Netty做局域网内自动组网，但是当时的主要代码不是我写的，并且时间过了很久，忘得差不多了，然而发现Netty确实是一个很有意思的框架，值得去深入研究、学习。本文的例子，之前也看过、写过，在各种介绍Netty的书籍中都有看到，并且Netty的官方文档也有这样的例子。 EchoServerNetty官方Echo例子，其实在源码中也有该例子。 EchoServer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;public class EchoServer { private int port; public EchoServer(int port) { this.port = port; } public void run() { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new EchoServerHandler()); } }) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); try { ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } } public static void main(String[] args) { new EchoServer(8888).run(); System.out.println(&quot;运行完毕&quot;); }} EchoServerHandler 12345678910111213141516171819202122232425262728293031import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;import io.netty.util.ReferenceCountUtil;import java.util.Arrays;import java.util.List;public class EchoServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ByteBuf in = ((ByteBuf) msg); System.out.println(&quot;Server received : &quot; + in.toString(CharsetUtil.UTF_8)); ctx.writeAndFlush(msg); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {// ctx.writeAndFlush(Unpooled.EMPTY_BUFFER).addListener(ChannelFutureListener.CLOSE); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} EchoClient 12345678910111213141516171819202122232425public class EchoClient { private static int port = 8888; public static void main(String[] args) throws InterruptedException { EventLoopGroup workGroup = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(workGroup) .channel(NioSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new EchoClientHandler()); } }); ChannelFuture f = b.connect(&quot;localhost&quot;, port).sync(); f.channel().closeFuture().sync(); } finally { workGroup.shutdownGracefully(); } }} EchoClientHandler 123456789101112131415161718192021222324252627282930313233343536import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.util.CharsetUtil;public class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { super.channelActive(ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;Hello world&quot;, CharsetUtil.UTF_8)); System.out.println(&quot;通道已打开&quot;); }// @Override// public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {// ByteBuf m = (ByteBuf) msg; // (1)// try {// System.out.println(&quot;Client received : &quot; + ((ByteBuf) msg).toString(CharsetUtil.UTF_8));// } finally {// m.release();// }// } @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception { System.out.println(&quot;Client received: &quot; + msg.toString(CharsetUtil.UTF_8)); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} TimeServer这个例子主要来自《Netty权威指南》，包括后面的粘包和拆包的例子都是基于此demo。 TimeServer 1234567891011121314151617181920212223242526272829303132333435363738394041public class TimeServer { public void bind(int port) { EventLoopGroup bossGroup = new NioEventLoopGroup(); NioEventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new TimeServerHandler()); } }); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } catch (InterruptedException var9) { var9.printStackTrace(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException var3) { System.out.println(&quot;输入参数有误&quot;); } } new TimeServer().bind(port); }} 123456789101112131415161718192021222324252627import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import java.util.Date;public class TimeServerHandler extends ChannelInboundHandlerAdapter { private int counter; public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;The time server receive order : &quot; + body + &quot;; the counter is : &quot; + ++counter); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? (new Date()).toString() : &quot;BAD ORDER&quot;; currentTime = currentTime + System.getProperty(&quot;line.separator&quot;); ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.writeAndFlush(resp); } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close(); }} TimeClient 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.LineBasedFrameDecoder;import io.netty.handler.codec.string.StringDecoder;public class TimeClient { public void connect(String host, int port) throws Exception { NioEventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new ChannelHandler[]{new TimeClientHandler()}); } }); ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); } finally { group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException var3) { System.out.println(&quot;输入参数有误&quot;); } } new TimeClient().connect(&quot;localhost&quot;, port); }} TimeClientHandler 1234567891011121314151617181920212223242526272829303132333435363738import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import lombok.extern.slf4j.Slf4j;import java.nio.charset.StandardCharsets;@Slf4jpublic class TimeClientHandler extends ChannelInboundHandlerAdapter { private int counter; private byte[] req; public TimeClientHandler() { req = (&quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;)).getBytes(); } public void channelActive(ChannelHandlerContext ctx) throws Exception { ByteBuf msg; for (int i = 0; i &lt; 100; i++) { msg = Unpooled.buffer(req.length); msg.writeBytes(req); ctx.writeAndFlush(msg); } } public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;Now is : &quot; + body + &quot;; the counter is : &quot; + ++ counter); } public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { log.info(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); }} 这里的代码是已经处理好了粘包/拆包问题，如果要看粘包/拆包的现象，只需要将LineBasedFrameDecoder和StringDecoder不加入到pipeline中即可。 参考：https://netty.io/wiki/index.htmlhttps://netty.io/wiki/user-guide-for-4.x.html","link":"/2019/08/27/7d5387d5bed2.html"},{"title":"了解Gradle之groovy概览","text":"def的用途用def定义的变量时无类型的变量，这里所说的无类型的变量，并不表示该变量就不属于某一个类型了，def修饰变量正是Groovy为动态语言的标记，大概def修饰变量就相当于Java中Object来修饰变量吧。如果通过使用def关键字使用可选类型，那么整数的类型将是可变的：它取决于这个类型实际包含的值。 12345assert a instanceof Integer//assert a instanceof Long//错误 def b = 2147483648assert b instanceof Long 关于函数的定义如果所定义的函数没有参数，那么必须在调用的时候加上括号。 要有返回值的类型声明，如def、void、String等。 可以使用return返回值，若不写，则默认返回最后一行的值，没有则为null。 闭包是什么?A closure in Groovy is an open, anonymous, block of code that can take arguments, return a value and be assigned to a variable. A closure may reference variables declared in its surrounding scope. In opposition to the formal definition of a closure, Closure in the Groovy language can also contain free variables which are defined outside of its surrounding scope.Apache Groovy Doc 语法与用法1234567891011121314151617181920212223242526{ println 'hi' }{ name -&gt; println name }{ String x, int y -&gt; println &quot;hey ${x} the value is ${y}&quot;}{ reader -&gt; def line = reader.readLine() line.trim()}// as an objectdef listener = { e -&gt; println &quot;Clicked on $e.source&quot; } assert listener instanceof ClosureClosure callback = { println 'Done!' } Closure&lt;Boolean&gt; isTextFile = { File it -&gt; it.name.endsWith('.txt') }//闭包是有返回值的，默认最后一行语句就是该闭包的返回值，如果最后一行语句没有不输入任何类型，闭包将返回null。// 调用闭包def code = { 123 }assert code() == 123assert code.call() == 123 访问外部变量12345def str='hello world'def closure={ println str}closure() 语法糖 .闭包可作为一个参数传给另一个闭包，也可在闭包中返回一个闭包。 123456789101112131415def timesThree = { num -&gt; num * 3}def runTwice = { num, func -&gt; func(func(num))}println runTwice(10,timesThree)def times = { x -&gt; { y -&gt; x * y }}println times(3)(4) 闭包的一些快捷写法. 当闭包作为闭包或方法的最后一个参数，可以将闭包从参数圆括号中提取出来接在最后。 如果闭包中不包含闭包，则闭包或方法参数所在的圆括号也可以省略。 对于有多个闭包参数的，只要是在参数声明最后的，均可以按上述方式省略。 闭包的Delegation代理 this 指闭包所在的最近的类 .class owner 指定义闭包的宿主，不仅仅是类，还可能是一个闭包 delegate 代理，默认使用的是owner delegate strategy 代理的代理策略 123456789101112131415161718def p = new Person(name:'Jessica', age:42)def t = new Thing(name:'Printer')def cl = p.fetchAgecl.delegate = p //设置代理assert cl() == 42cl.delegate = tassert cl() == 42 //owner优先，fetchAge是一个闭包，它的owner是Personcl.resolveStrategy = Closure.DELEGATE_ONLY //修改策略cl.delegate = passert cl() == 42cl.delegate = ttry { cl() assert false //呵呵，delegate上面没有该属性，报错} catch (MissingPropertyException ex) { // &quot;age&quot; is not defined on the delegate //没有定义} 至此基本的东西差不多解决了。","link":"/2017/12/26/66d93e75bf19.html"},{"title":"为什么SSH执行命令不会退出","text":"通过 ssh 在主机上面执行命令时，遇到 ssh 连接不会自动断开，在程序结束时才断开的情况。如何才能让 ssh 执行完命令后自动退出？以及这种问题该如何分析？背后的原理又是什么？ 现象一般情况下，执行简单的命令，会在命令执行完成后，立刻返回；若执行的程序堵塞，ssh 会一直不返回，直到堵塞的程序自己结束，才会断开 ssh 连接。 123ssh devcloud pwdssh devcloud sleep 3sssh devcloud java -jar balabala.jar 效果如下： 同时还可以发现平时常用的 nohup + &amp; 没有作用： 12ssh devcloud &quot;nohup sleep 3s &amp;&quot;ssh devcloud &quot;nohup java -jar balabala.jar &amp;&quot; 正确的姿势应该是 12ssh devcloud &quot;sleep 3s &gt;/dev/null &amp;&quot;ssh devcloud &quot;java -jar balabala.jar &gt;/dev/null 2&gt;&amp;1 &amp;&quot; 且调换 &gt;/dev/null 与 2&gt;&amp;1 的顺序，会导致 ssh 命令不会退出。 12ssh devcloud &quot;sleep 3s 2&gt;&amp;1 &gt;/dev/null &amp;&quot;ssh devcloud &quot;java -jar balabala.jar 2&gt;&amp;1 &gt;/dev/null &amp;&quot; ssh 执行远程命令的过程一般通过 ssh 远程执行某个命令时，会在远程机器上先建立一个 sshd 的子进程（父进程是 sshd daemon），然后由这个 sshd 进程启动一个 bash 进程（取决于该用户所设置的默认 shell）来执行传递过来的命令。 12345678910$ ssh devcloud &quot;ps -ef | grep -v grep | grep sshd&quot;root 9425 1 0 2020 ? 00:00:07 /usr/sbin/sshd -Droot 10130 9425 0 13:49 ? 00:00:00 sshd: root@nottyroot 10633 9425 0 13:51 ? 00:00:00 sshd: root@notty$ ssh devcloud &quot;ps -ef | grep -v grep | grep sleep&quot;root 10132 10130 0 13:49 ? 00:00:00 sleep 1000sroot 10559 8630 0 13:51 ? 00:00:00 sleep 60$ ssh devcloud &quot;pstree -p 9425&quot;sshd(9425)-+-sshd(10130)---sleep(10132) `-sshd(10642)---pstree(10645) 针对这次任务建立的 sshd 进程和 bash 进程在文件描述符方面有一定关系：bash 进程的 0、1、2 三个文件描述符通过管道与 sshd 的相应文件描述符联系起来。可以通过如下的脚本来查看上述对应关系： 1234567891011121314151617181920212223242526272829$ ssh devcloud &quot;TMPSPID=\\$(ps -ef | grep -v grep | grep -e 'sshd.*notty' | awk '{print \\$2}');echo SSHD子进程:\\$TMPSPID;ps -ef | grep -v grep | grep sshd;echo ;ls -l /proc/\\$TMPSPID/fd;echo ;echo SHELL 进程:\\$\\$;ps -ef | grep \\$\\$;echo ;ls -l /proc/\\$\\$/fd&quot;SSHD子进程:688root 688 9425 0 15:49 ? 00:00:00 sshd: root@nottyroot 9425 1 0 2020 ? 00:00:07 /usr/sbin/sshd -D总用量 0lrwx------ 1 root root 64 4月 29 15:49 0 -&gt; /dev/nulllrwx------ 1 root root 64 4月 29 15:49 1 -&gt; /dev/nulll-wx------ 1 root root 64 4月 29 15:49 11 -&gt; pipe:[2517193862]lr-x------ 1 root root 64 4月 29 15:49 12 -&gt; pipe:[2517193863]lr-x------ 1 root root 64 4月 29 15:49 14 -&gt; pipe:[2517193864]lrwx------ 1 root root 64 4月 29 15:49 2 -&gt; /dev/nulllrwx------ 1 root root 64 4月 29 15:49 3 -&gt; socket:[2517182996]lrwx------ 1 root root 64 4月 29 15:49 4 -&gt; socket:[2517189863]lr-x------ 1 root root 64 4月 29 15:49 5 -&gt; pipe:[2517189866]l-wx------ 1 root root 64 4月 29 15:49 6 -&gt; /run/systemd/sessions/360922.refl-wx------ 1 root root 64 4月 29 15:49 7 -&gt; pipe:[2517189866]SHELL进程:690root 690 688 0 15:49 ? 00:00:00 zsh -c TMPSPID=$(ps -ef | grep -v grep | grep -e 'sshd.*notty' | awk '{print $2}');echo SSHD子?程:$TMPSPID;ps -ef | grep -v grep | grep sshd;echo ;ls -l /proc/$TMPSPID/fd;echo ;echo SHELL?程:$$;ps -ef | grep $$;echo ;ls -l /proc/$$/fdroot 699 690 0 15:49 ? 00:00:00 ps -efroot 700 690 0 15:49 ? 00:00:00 grep 690root 26903 1 0 2020 ? 01:18:33 /usr/local/sa/agent/plugins/sap1015总用量 0lr-x------ 1 root root 64 4月 29 15:49 0 -&gt; pipe:[2517193862]l-wx------ 1 root root 64 4月 29 15:49 1 -&gt; pipe:[2517193863]l-wx------ 1 root root 64 4月 29 15:49 2 -&gt; pipe:[2517193864]lr-x------ 1 root root 64 4月 29 15:49 3 -&gt; /proc/690/fd 可以看出 shell 进程的 0、1、2 文件描述符均来自 sshd 进程的管道。 如果远程执行的命令是后台执行，那么新启动的命令的父进程成了 1，而输入即描述符 0 重定向到了 /dev/null。 nohup 的误解可以从 man nohup 中看到这个命令说明。其中它的作用是将命令运行成不受 SIGHUP 信号的模式；它主要做的事为如下 3 点： 若标准输入是终端，将它重定向到一个不可达的文件(/dev/null) 若标准输出是终端，将它重定向到 nohup.out 文件。若当前目录的 nohup.out 不可用，则使用 ${HOME}/nohup.out 文件。 若标准错误是终端，将它重定向到标准输出。 也就是说，如果标准输入不是终端的话，那么 nohup 将不会发挥出作用。因此，在上述上下文里面，nohup 是可以不要的。 SIGHUP 信号是当终端关闭时，发送给该终端所控制的进程。当进程收到这个信号后，默认操作为终止进程；但是也可以对此信号做捕捉，比如 wget 能捕获SIGHUP 信号，并忽略它，这样就算退出了 Linux 登录，wget 也 能继续下载。 那 ssh 执行命令，能获取到终端吗？ 先来一个简单的表述： TTY。TeleTypeWriter，通过 console 登录。 pts。pseudo terminal slave，通过 ssh 登录。 notty。通过 SFTP 或其他不需要终端的方式登录。 通过 ssh 执行命令获取到的是 notty。 终端和我们想象中的终端可能有一些差别，内容也非常长，可以参考下面的文章进行详细的了解： The TTY demystified Linux TTY/PTS概述 参考： https://blog.csdn.net/oneinmore/article/details/50073443","link":"/2021/04/22/689e71ecdbb3.html"},{"title":"二叉树的(迭代式)遍历","text":"终于到写这篇的时候了。这是一篇对于邓俊辉的《数据结构(C++语言版)(第3版)》中二叉树遍历部分的读书笔记，图片来自DSACPP。感觉这本书很用心。当初要买这本书的原因也就是看到了他对迭代式遍历二叉树的这些内容，很赞。 先序遍历图05-32.先序遍历过程：先沿左侧通路自顶而下访问沿途节点，再自底而上依次遍历这些节点的右子树 123456789101112131415161718192021222324252627282930313233343536373839/****************************************************************************************** * Data Structures in C++ * ISBN: 7-302-33064-6 &amp; 7-302-33065-3 &amp; 7-302-29652-2 &amp; 7-302-26883-3 * Junhui DENG, deng@tsinghua.edu.cn * Computer Science &amp; Technology, Tsinghua University * Copyright (c) 2006-2013. All rights reserved. ******************************************************************************************/#pragma once//从当前节点出发，沿左分支不断深入，直至没有左分支的节点；沿途节点遇到后立即访问template &lt;typename T, typename VST&gt; //元素类型、操作器static void visitAlongLeftBranch ( BinNodePosi(T) x, VST&amp; visit, Stack&lt;BinNodePosi(T)&gt;&amp; S ) { while ( x ) { visit ( x-&gt;data ); //访问当前节点 S.push ( x-&gt;rc ); //右孩子入栈暂存（可优化：通过判断，避免空的右孩子入栈） x = x-&gt;lc; //沿左分支深入一层 }}template &lt;typename T, typename VST&gt; //元素类型、操作器void travPre_I2 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树先序遍历算法（迭代版#2） Stack&lt;BinNodePosi(T)&gt; S; //辅助栈 while ( true ) { visitAlongLeftBranch ( x, visit, S ); //从当前节点出发，逐批访问 if ( S.empty() ) break; //直到栈空 x = S.pop(); //弹出下一批的起点 }}//***************************************************************template &lt;typename T, typename VST&gt; //元素类型、操作器void travPre_I1 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树先序遍历算法（迭代版#1） Stack&lt;BinNodePosi(T)&gt; S; //辅助栈 if ( x ) S.push ( x ); //根节点入栈 while ( !S.empty() ) { //在栈变空之前反复循环 x = S.pop(); visit ( x-&gt;data ); //弹出并访问当前节点，其非空孩子的入栈次序为先右后左 if ( HasRChild ( *x ) ) S.push ( x-&gt;rc ); if ( HasLChild ( *x ) ) S.push ( x-&gt;lc ); }} 图05-31.迭代式先序遍历实例（出栈节点以深色示意） 中序遍历图05-33.中序遍历过程：顺着左侧通路，自底而上依次访问沿途各节点及其右子树 12345678910111213141516171819202122232425262728293031323334353637383940/****************************************************************************************** * Data Structures in C++ * ISBN: 7-302-33064-6 &amp; 7-302-33065-3 &amp; 7-302-29652-2 &amp; 7-302-26883-3 * Junhui DENG, deng@tsinghua.edu.cn * Computer Science &amp; Technology, Tsinghua University * Copyright (c) 2006-2013. All rights reserved. ******************************************************************************************/#pragma oncetemplate &lt;typename T&gt; //从当前节点出发，沿左分支不断深入，直至没有左分支的节点static void goAlongLeftBranch ( BinNodePosi(T) x, Stack&lt;BinNodePosi(T)&gt;&amp; S ) { while ( x ) { S.push ( x ); x = x-&gt;lc; } //当前节点入栈后随即向左侧分支深入，迭代直到无左孩子}template &lt;typename T, typename VST&gt; //元素类型、操作器void travIn_I1 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树中序遍历算法（迭代版#1） Stack&lt;BinNodePosi(T)&gt; S; //辅助栈 while ( true ) { goAlongLeftBranch ( x, S ); //从当前节点出发，逐批入栈 if ( S.empty() ) break; //直至所有节点处理完毕 x = S.pop(); visit ( x-&gt;data ); //弹出栈顶节点并访问之 x = x-&gt;rc; //转向右子树 }}// 等价于上面的方法travIn_I1()，只是换了种表达方式template &lt;typename T, typename VST&gt; //元素类型、操作器void travIn_I2 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树中序遍历算法（迭代版#2） Stack&lt;BinNodePosi(T)&gt; S; //辅助栈 while ( true ) if ( x ) { S.push ( x ); //根节点进栈 x = x-&gt;lc; //深入遍历左子树 } else if ( !S.empty() ) { x = S.pop(); //尚未访问的最低祖先节点退栈 visit ( x-&gt;data ); //访问该祖先节点 x = x-&gt;rc; //遍历祖先的右子树 } else break; //遍历完成} 图05-34.迭代式中序遍历实例（出栈节点以深色示意） 图05-35.中序遍历过程中，在无右孩子的节点处需做回溯 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/****************************************************************************************** * Data Structures in C++ * ISBN: 7-302-33064-6 &amp; 7-302-33065-3 &amp; 7-302-29652-2 &amp; 7-302-26883-3 * Junhui DENG, deng@tsinghua.edu.cn * Computer Science &amp; Technology, Tsinghua University * Copyright (c) 2006-2013. All rights reserved. ******************************************************************************************/ // 寻找此节点中序遍历的后继template &lt;typename T&gt; BinNodePosi(T) BinNode&lt;T&gt;::succ() { //定位节点v的直接后继 BinNodePosi(T) s = this; //记录后继的临时变量 if ( rc ) { //若有右孩子，则直接后继必在右子树中，具体地就是 s = rc; //右子树中 while ( HasLChild ( *s ) ) s = s-&gt;lc; //最靠左（最小）的节点 } else { //否则，直接后继应是“将当前节点包含于其左子树中的最低祖先”，具体地就是 while ( IsRChild ( *s ) ) s = s-&gt;parent; //逆向地沿右向分支，不断朝左上方移动 s = s-&gt;parent; //最后再朝右上方移动一步，即抵达直接后继（如果存在） } return s;}template &lt;typename T, typename VST&gt; //元素类型、操作器void travIn_I3 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树中序遍历算法（迭代版#3，无需辅助栈） bool backtrack = false; //前一步是否刚从右子树回溯——省去栈，仅O(1)辅助空间 while ( true ) if ( !backtrack &amp;&amp; HasLChild ( *x ) ) //若有左子树且不是刚刚回溯，则 x = x-&gt;lc; //深入遍历左子树 else { //否则——无左子树或刚刚回溯（相当于无左子树） visit ( x-&gt;data ); //访问该节点 if ( HasRChild ( *x ) ) { //若其右子树非空，则 x = x-&gt;rc; //深入右子树继续遍历 backtrack = false; //并关闭回溯标志 } else { //若右子树空，则 if ( ! ( x = x-&gt;succ() ) ) break; //回溯（含抵达末节点时的退出返回） backtrack = true; //并设置回溯标志 } }}template &lt;typename T, typename VST&gt; //元素类型、操作器void travIn_I4 ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树中序遍历（迭代版#4，无需栈或标志位） while ( true ) if ( HasLChild ( *x ) ) //若有左子树，则 x = x-&gt;lc; //深入遍历左子树 else { //否则 visit ( x-&gt;data ); //访问当前节点，并 while ( !HasRChild ( *x ) ) //不断地在无右分支处 if ( ! ( x = x-&gt;succ() ) ) return; //回溯至直接后继（在没有后继的末节点处，直接退出） else visit ( x-&gt;data ); //访问新的当前节点 x = x-&gt;rc; //（直至有右分支处）转向非空的右子树 }} 后序遍历图05-36.后序遍历过程也可划分为模式雷同的若干段 12345678910111213141516171819202122232425262728293031/****************************************************************************************** * Data Structures in C++ * ISBN: 7-302-33064-6 &amp; 7-302-33065-3 &amp; 7-302-29652-2 &amp; 7-302-26883-3 * Junhui DENG, deng@tsinghua.edu.cn * Computer Science &amp; Technology, Tsinghua University * Copyright (c) 2006-2013. All rights reserved. ******************************************************************************************/#pragma oncetemplate &lt;typename T&gt; //在以S栈顶节点为根的子树中，找到最高左侧可见叶节点static void gotoHLVFL ( Stack&lt;BinNodePosi(T)&gt;&amp; S ) { //沿途所遇节点依次入栈 while ( BinNodePosi(T) x = S.top() ) //自顶而下，反复检查当前节点（即栈顶） if ( HasLChild ( *x ) ) { //尽可能向左 if ( HasRChild ( *x ) ) S.push ( x-&gt;rc ); //若有右孩子，优先入栈 S.push ( x-&gt;lc ); //然后才转至左孩子 } else //实不得已 S.push ( x-&gt;rc ); //才向右 S.pop(); //返回之前，弹出栈顶的空节点}template &lt;typename T, typename VST&gt;void travPost_I ( BinNodePosi(T) x, VST&amp; visit ) { //二叉树的后序遍历（迭代版） Stack&lt;BinNodePosi(T)&gt; S; //辅助栈 if ( x ) S.push ( x ); //根节点入栈 while ( !S.empty() ) { if ( S.top() != x-&gt;parent ) //若栈顶非当前节点之父（则必为其右兄），此时需 gotoHLVFL ( S ); //在以其右兄为根之子树中，找到HLVFL（相当于递归深入其中） x = S.pop(); visit ( x-&gt;data ); //弹出栈顶（即前一节点之后继），并访问之 }} 图05-37.迭代式后序遍历实例（出栈节点以深色示意，发生gotoHLVFL()调用的节点以大写字母示意）","link":"/2018/06/26/1a171790ce7d.html"},{"title":"云主机如何应对大批量的漏洞测试请求","text":"云主机上面跑的WordPress实例被别人用各种漏洞测试工具在做测试，通过日志发现，其搜寻的漏洞内容包括：SQL注入、XSS等。由于其请求的频率过高，以致于nginx做转发出现502错误，造成了宕机的假象。 正对这种情况，想到了以下两种处理方式。 wordpress拒绝请求由于WordPress是PHP写的，在根目录下面有一个wordpress/.htaccess的文件可以将要限制的IP地址写进去，如下： 1234567891011121314# BEGIN WordPress# 在`BEGIN WordPress`与`END WordPress`之间的指令（行）是# 动态生成的，只应被WordPress过滤器修改。# 任何对标记之间的指令的修改都会被覆盖。&lt;IfModule mod_rewrite.c&gt;RewriteEngine OnRewriteBase /RewriteRule ^index\\.php$ - [L]RewriteCond %{REQUEST_FILENAME} !-fRewriteCond %{REQUEST_FILENAME} !-dRewriteRule . /index.php [L]&lt;/IfModule&gt;deny from 106.12.223.189# END WordPress 这样只要是这个IP的请求，那么将都被统一返回一个HTTP状态码403，也就是服务器没有对请求作出处理就返回了，但请求还是到达了应用层。 通过iptables限制IP请求在到达应用层之前就被过滤掉了，也就是说请求到不了应用层，在一定程度上减轻了服务器处理请求的压力。 一些关于iptables的博客文档： https://lesca.me/archives/iptables-tutorial-structures-configuratios-examples.html https://www.zsythink.net/archives/1199 http://shanks.leanote.com/post/iptables%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97","link":"/2020/02/01/ccf7f43b1e3f.html"},{"title":"从Android源代码来看WiFi直连","text":"什么是WiFi直连通俗点说，它可以不通过网络，也不通过蓝牙，只要两台设备都支持WiFi直连，打开WiFi，不用连接任何WiFi，就可以进行信息的传输（请忽略下面两张图中的WiFi连接标志，因为其与WiFi的连接与否无关，打开就可以）。 在Android的设置-&gt;网络与互联网-&gt;WLAN-&gt;WLAN偏好设置-&gt;高级-&gt;WLAN直连中可以找到关于Wi-Fi直连的设置，如下： 在参考其它博客时，写出来的代码并不能搜索到Wi-Fi中的其他设备，但是在这设置里面却可以。因此，找来其Android8.0的源代码作为参考，并成功解决问题。 源代码位置： /packages/apps/Settings/src/com/android/settings/wifi/p2p/WifiP2pSettings.java 在线Android8.0 WiFi直连相关源代码 我们可以通过系统的源代码来了解其相应的API的使用。下面是对应的系统源代码的分析： 注册权限12345&lt;uses-permission android:name=&quot;android.permission.ACCESS_WIFI_STATE&quot;/&gt;&lt;uses-permission android:name=&quot;android.permission.CHANGE_WIFI_STATE&quot;/&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_NETWORK_STATE&quot;/&gt;&lt;uses-permission android:name=&quot;android.permission.CHANGE_NETWORK_STATE&quot;/&gt;&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot;/&gt; 广播的接收与处理在onResume()中注册广播接收，在onPause()中取消广播接收。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*** Broadcast intent action to indicate whether Wi-Fi p2p is enabled or disabled. An* extra {@link #EXTRA_WIFI_STATE} provides the state information as int.** @see #EXTRA_WIFI_STATE*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_STATE_CHANGED_ACTION);/*** Broadcast intent action indicating that the available peer list has changed. This* can be sent as a result of peers being found, lost or updated.** &lt;p&gt; An extra {@link #EXTRA_P2P_DEVICE_LIST} provides the full list of* current peers. The full list of peers can also be obtained any time with* {@link #requestPeers}.** @see #EXTRA_P2P_DEVICE_LIST*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_PEERS_CHANGED_ACTION);/*** Broadcast intent action indicating that the state of Wi-Fi p2p connectivity* has changed. One extra {@link #EXTRA_WIFI_P2P_INFO} provides the p2p connection info in* the form of a {@link WifiP2pInfo} object. Another extra {@link #EXTRA_NETWORK_INFO} provides* the network info in the form of a {@link android.net.NetworkInfo}. A third extra provides* the details of the group.** @see #EXTRA_WIFI_P2P_INFO* @see #EXTRA_NETWORK_INFO* @see #EXTRA_WIFI_P2P_GROUP*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_CONNECTION_CHANGED_ACTION);/*** Broadcast intent action indicating that this device details have changed.*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_THIS_DEVICE_CHANGED_ACTION);/*** Broadcast intent action indicating that peer discovery has either started or stopped.* One extra {@link #EXTRA_DISCOVERY_STATE} indicates whether discovery has started* or stopped.** &lt;p&gt;Note that discovery will be stopped during a connection setup. If the application tries* to re-initiate discovery during this time, it can fail.*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_DISCOVERY_CHANGED_ACTION);/*** Broadcast intent action indicating that remembered persistent groups have changed.* @hide*/mIntentFilter.addAction(WifiP2pManager.WIFI_P2P_PERSISTENT_GROUPS_CHANGED_ACTION); 对上面广播的处理（需要留意的是，这些数据都是从Intent中取出来的）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private final BroadcastReceiver mReceiver = new BroadcastReceiver() { @Override public void onReceive(Context context, Intent intent) { String action = intent.getAction(); if (WifiP2pManager.WIFI_P2P_STATE_CHANGED_ACTION.equals(action)) { mWifiP2pEnabled = intent.getIntExtra(WifiP2pManager.EXTRA_WIFI_STATE, WifiP2pManager.WIFI_P2P_STATE_DISABLED) == WifiP2pManager.WIFI_P2P_STATE_ENABLED; handleP2pStateChanged(); } else if (WifiP2pManager.WIFI_P2P_PEERS_CHANGED_ACTION.equals(action)) { // 这里是直接从Intent中取出了列表数据 mPeers = (WifiP2pDeviceList) intent.getParcelableExtra( WifiP2pManager.EXTRA_P2P_DEVICE_LIST); handlePeersChanged(); } else if (WifiP2pManager.WIFI_P2P_CONNECTION_CHANGED_ACTION.equals(action)) { if (mWifiP2pManager == null) return; NetworkInfo networkInfo = (NetworkInfo) intent.getParcelableExtra( WifiP2pManager.EXTRA_NETWORK_INFO); // 此处的WifiP2pInfo可以让我们获取到GO(Group Owner)的IP // 这是最神奇的地方，没有网络的连接，却得到了IP // 然后我们可以通过这个IP，与GO进行socket通信 WifiP2pInfo wifip2pinfo = (WifiP2pInfo) intent.getParcelableExtra( WifiP2pManager.EXTRA_WIFI_P2P_INFO); if (networkInfo.isConnected()) { if (DBG) Log.d(TAG, &quot;Connected&quot;); } else if (mLastGroupFormed != true) { //start a search when we are disconnected //but not on group removed broadcast event startSearch(); } mLastGroupFormed = wifip2pinfo.groupFormed; } else if (WifiP2pManager.WIFI_P2P_THIS_DEVICE_CHANGED_ACTION.equals(action)) { mThisDevice = (WifiP2pDevice) intent.getParcelableExtra( WifiP2pManager.EXTRA_WIFI_P2P_DEVICE); if (DBG) Log.d(TAG, &quot;Update device info: &quot; + mThisDevice); updateDevicePref(); } else if (WifiP2pManager.WIFI_P2P_DISCOVERY_CHANGED_ACTION.equals(action)) { int discoveryState = intent.getIntExtra(WifiP2pManager.EXTRA_DISCOVERY_STATE, WifiP2pManager.WIFI_P2P_DISCOVERY_STOPPED); if (DBG) Log.d(TAG, &quot;Discovery state changed: &quot; + discoveryState); if (discoveryState == WifiP2pManager.WIFI_P2P_DISCOVERY_STARTED) { updateSearchMenu(true); } else { updateSearchMenu(false); } } else if (WifiP2pManager.WIFI_P2P_PERSISTENT_GROUPS_CHANGED_ACTION.equals(action)) { if (mWifiP2pManager != null) { mWifiP2pManager.requestPersistentGroupInfo(mChannel, WifiP2pSettings.this); } } }}; 点击搜索点击菜单栏上的搜索后，会进行如下操作。然后会接收到相应的广播，刷新是在对相应广播的处理中进行的。 1234567891011private void startSearch() { if (mWifiP2pManager != null &amp;&amp; !mWifiP2pSearching) { mWifiP2pManager.discoverPeers(mChannel, new WifiP2pManager.ActionListener() { public void onSuccess() { } public void onFailure(int reason) { if (DBG) Log.d(TAG, &quot; discover fail &quot; + reason); } }); }} 在对广播的处理中，设备变化的处理主要是靠handlePeersChanged()： 123456789101112private void handlePeersChanged() { mPeersGroup.removeAll(); mConnectedDevices = 0; if (DBG) Log.d(TAG, &quot;List of available peers&quot;); for (WifiP2pDevice peer: mPeers.getDeviceList()) { if (DBG) Log.d(TAG, &quot;-&gt; &quot; + peer); mPeersGroup.addPreference(new WifiP2pPeer(getActivity(), peer)); if (peer.status == WifiP2pDevice.CONNECTED) mConnectedDevices++; } if (DBG) Log.d(TAG, &quot; mConnectedDevices &quot; + mConnectedDevices);} 连接设备或断开连接 连接设备1234567891011121314151617181920212223242526272829WifiP2pConfig config = new WifiP2pConfig();config.deviceAddress = mSelectedWifiPeer.device.deviceAddress;int forceWps = SystemProperties.getInt(&quot;wifidirect.wps&quot;, -1);if (forceWps != -1) { config.wps.setup = forceWps;} else { if (mSelectedWifiPeer.device.wpsPbcSupported()) { config.wps.setup = WpsInfo.PBC; } else if (mSelectedWifiPeer.device.wpsKeypadSupported()) { config.wps.setup = WpsInfo.KEYPAD; } else { config.wps.setup = WpsInfo.DISPLAY; }}mWifiP2pManager.connect(mChannel, config, new WifiP2pManager.ActionListener() { public void onSuccess() { if (DBG) Log.d(TAG, &quot; connect success&quot;); } public void onFailure(int reason) { Log.e(TAG, &quot; connect fail &quot; + reason); Toast.makeText(getActivity(), R.string.wifi_p2p_failed_connect_message, Toast.LENGTH_SHORT).show(); } }); 对这段代码中，有一个使用了android.os.SystemProperties这个{@hide}修饰的类。我们可以考虑通过反射的方式来近行调用，如下： 1234567891011private int getSystemProp(){ try { Class&lt;?&gt; cls = Class.forName(&quot;android.os.SystemProperties&quot;); Method m = cls.getDeclaredMethod(&quot;get&quot;, String.class, String.class); return Integer.parseInt((String)m.invoke(null,&quot;wifidirect.wps&quot;,&quot;-1&quot;)); } catch (Exception e) { Log.i(TAG, &quot;E = &quot; + e.getMessage()); e.printStackTrace(); } return -1;} 断开连接 123456789101112131415161718//disconnect dialog listenermDisconnectListener = new OnClickListener() { @Override public void onClick(DialogInterface dialog, int which) { if (which == DialogInterface.BUTTON_POSITIVE) { if (mWifiP2pManager != null) { mWifiP2pManager.removeGroup(mChannel, new WifiP2pManager.ActionListener() { public void onSuccess() { if (DBG) Log.d(TAG, &quot; remove group success&quot;); } public void onFailure(int reason) { if (DBG) Log.d(TAG, &quot; remove group fail &quot; + reason); } }); } } }}; 取消已发送的邀请 12345678910111213141516171819//cancel connect dialog listenermCancelConnectListener = new OnClickListener() { @Override public void onClick(DialogInterface dialog, int which) { if (which == DialogInterface.BUTTON_POSITIVE) { if (mWifiP2pManager != null) { mWifiP2pManager.cancelConnect(mChannel, new WifiP2pManager.ActionListener() { public void onSuccess() { if (DBG) Log.d(TAG, &quot; cancel connect success&quot;); } public void onFailure(int reason) { if (DBG) Log.d(TAG, &quot; cancel connect fail &quot; + reason); } }); } } }}; 重命名设备名称12345678910111213141516171819202122232425262728293031323334mRenameListener = new OnClickListener() { @Override public void onClick(DialogInterface dialog, int which) { if (which == DialogInterface.BUTTON_POSITIVE) { if (mWifiP2pManager != null) { String name = mDeviceNameText.getText().toString(); if (name != null) { for (int i = 0; i &lt; name.length(); i++) { char cur = name.charAt(i); if(!Character.isDigit(cur) &amp;&amp; !Character.isLetter(cur) &amp;&amp; cur != '-' &amp;&amp; cur != '_' &amp;&amp; cur != ' ') { Toast.makeText(getActivity(), R.string.wifi_p2p_failed_rename_message, Toast.LENGTH_LONG).show(); return; } } } mWifiP2pManager.setDeviceName(mChannel, mDeviceNameText.getText().toString(), new WifiP2pManager.ActionListener() { public void onSuccess() { if (DBG) Log.d(TAG, &quot; device rename success&quot;); } public void onFailure(int reason) { Toast.makeText(getActivity(), R.string.wifi_p2p_failed_rename_message, Toast.LENGTH_LONG).show(); } }); } } }}; 如何进行信息的传输？对于GO来说，当与GC(Group Client)连接完成后，也就是接收到WifiP2pManager.WIFI_P2P_CONNECTION_CHANGED_ACTION广播后，需要充当的角色是服务器，所以可以利用Java中socket通信中的SocketServer来阻塞当前的线程(子)，监听所受到的socket。如下： 123456789101112131415161718192021222324252627282930if (wifip2pinfoG.isGroupOwner) { // 充当服务器 new Thread(new Runnable() {// 不能阻塞主线程 @Override // 同时也不允许在主线程中进行网络通信 public void run() { // 所以开启子线程 try { ServerSocket server = new ServerSocket(6666, 100, wifip2pinfoG.groupOwnerAddress); Socket socket; while((socket = server.accept()) != null){ InputStream bis = socket.getInputStream(); BufferedReader br = new BufferedReader(new InputStreamReader(bis)); String info = br.readLine(); final String log = info; // 显示出所接收的信息 Log.e(&quot;TAG&quot;, log); MainActivity.this.runOnUiThread(new Runnable() { @Override public void run() { Toast.makeText(context, log, Toast.LENGTH_SHORT).show(); } }); } } catch (IOException e) { e.printStackTrace(); } } }).start(); Toast.makeText(context, &quot;服务器已启动&quot;, Toast.LENGTH_SHORT).show();} else { // 充当客户端 Toast.makeText(context, &quot;可发送消息&quot;, Toast.LENGTH_SHORT).show();} 对GC来说，当与GO连接好了之后，即可发送给GO发送消息。如下： 1234567891011121314151617new Thread(new Runnable() {// 不能在主线程中进行网络通信，需要子线程 @Override public void run() { try { sendSocket = new Socket(wifip2pinfoG.groupOwnerAddress, 6666); OutputStreamWriter osw = new OutputStreamWriter(sendSocket.getOutputStream()); // getInfo()是一个输入框，没有输入时默认返回hello osw.write(getInfo()); osw.flush(); Log.e(&quot;TAG&quot;, &quot;info sended&quot;); // 注意这里，需要及时关闭socket sendSocket.close(); } catch (IOException e) { e.printStackTrace(); } }}).start();","link":"/2018/06/28/f5d38d5963f5.html"},{"title":"从动图来理解 Raft 协议关键概念","text":"节点状态 Follower Candidate Leader Learner 领导选举(Leader Selection)节点的初始状态为 Follower。 选举超时(Election Timeout)当处于 Follower 状态的节点没有收到 Leader 节点的心跳时，会开启计时，经过 Election Timeout 后，他们会变成 Candidate 状态。 当节点变成 Candidate 状态后，会开始为自己拉票做 Leader。当多数人投票给当前节点时，当前节点当选 Leader。 心跳超时(Heartbeat Timeout)节点当选 Leader 之后，会周期性地向 Follower 发送心跳包；当 Follower 收到心跳后，会重置自己的 Election Timeout 计时，并向 Leader 发送响应。 当 Leader 处于不可用的状态时，率先结束 Election Timeout 的 Follower 节点，会发起选举投票。 得到大多数投票后，当选下个 Term 的 Leader。 同时存在两个 Follower 在拉票，且双方都不能得到大多数投票时，此次选举作废，并开启下一轮投票。具体情景说明如下： A、B 节点几乎同时发起投票，并且各自为各自投一张票 此时，D 未收到投票请求，发起了自己的投票，并为自己投了一票。 B 为 C 投了一票，此时的得票为 A(1)，C(2)，D(1)，无论谁都不能获取到大多数的投票，因此此次投票作废，等待下次某个幸运的节点发起选举投票。 日志复制(Log Replication) 假设客户端是将修改的请求发送给 Leader，则修改的流程如下： 写入 Leader 的 log 中； 等待下次 HeartBeat，将修改信息同步给 Follower； Follower 给 Leader 发出确认响应； 当 Leader 收到大多数 Follower 确认的信息后，将修改确认； 在下次 HeartBeat 时，将修改确认的信息同步给所有 Follower。 节点出现网络隔离假设出现网络隔离后，出现两个独立的网络，此时： 少数派：只读，修改不能确认，因为得不到大多数 Follower 节点的确认。 多数派：能正常读写。 假设两个网络对同一个 key 做了操作，当网络隔离取消后，会以多数派的数据为准。 Reference thesecretlivesofdata raft.github.io","link":"/2022/03/23/2721dc98c09e.html"},{"title":"位图法","text":"定义位图法即 bitmap，就是用一个 bit 位来标记某个元素对应的 Value，而 Key 即是该元素。由于采用了 Bit 为单位来存储数据，因此在内存占用方面，可以大大节省。适用于大规模数据，但数据状态不是很多的情况。通常是用来判断某个数据存不存在。 实现应用求集合的所有子集集合有 n 个元素，它的子集的个数就是对这 n 个元素做组合，一共有n个位置可以组合，每个位置上该元素可以出现也可以不出现，所以最后总的个数为2的n次方。 这种状态只有两个，一共有 n 个位置的情况，完全适合适用位图。 因此只需要从 0 遍历到 2^n，即可将所有的子集遍历出来。然后再针对每一个值，去出相应位上的 bit 值，0 不出现在子集中，1 出现在子集中。 100亿整型数据去重整型数据为 32 位最多有 2^32 (42亿多），所以 100 亿整型数据一定有重复的，2^32 个整形用位表示，需要 (2^32)bit == 512MB，需要 512MB 内存表示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt; #define MAX (0xffffffff)/* 根据num将对应的MAP的bit位置1 */void setBuf(char *buf, unsigned int num){ *(buf+(num&gt;&gt;0x3)) |= (0x1&lt;&lt;(num&amp;0x7)); return;}/* 获取num对应的MAP的bit位值 */unsigned int getBuf(char *buf, int num){ unsigned int flag = 0; flag = ((*(buf+(num&gt;&gt;0x3)) &amp; (0x1&lt;&lt;(num&amp;0x7))) != 0)? 1:0; return flag;} int main(int argc,char **argv){ if(argc &lt; 2) { printf(&quot;usage:./a {0-9}*\\n&quot;); return 0; } unsigned int index = 1; unsigned int num; unsigned int max = 0; char* buf = (char*)calloc((MAX&gt;&gt;0x3)+1,sizeof(char)); while(index &lt; argc) { num = atoi(argv[index]); max = max&gt;num? max:num; setBuf(buf,num); ++index; } for(index = 0; index &lt;= max; index++) { if(getBuf(buf,index) == 1) { printf(&quot;id:%-10u flag:0x%-16x value:%-10u state:%-2d\\n&quot;, index&gt;&gt;0x3, (unsigned int)buf[index&gt;&gt;0x3], index, getBuf(buf,index)); } printf(&quot;process[%u]:%.2f%%\\r&quot;,index,(float)(index)/max*100); } printf(&quot;\\n&quot;); return 0;} 参考 https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg https://blog.csdn.net/wypblog/article/details/8237956","link":"/2021/05/17/d143446dd809.html"},{"title":"你所理解的 protected 关键字大概率❌","text":"权限控制表 修饰词 本类 同一个包的类 继承类 其他类 private √ × × × 无（默认） √ √ × × protected √ √ √ × public √ √ √ √ 关于protected最近在看Effective Java时，遇到了一个关于protected修饰符的问题。这个问题中，对于它的认识与我之前对它的认识有一些出入。所以在这里记录一下。 很多介绍Java语言的书籍(包括《Java编程思想》)都对protected介绍的比较的简单，基本都是一句话，就是:被protected修饰的成员对于本包和其子类可见。这种说法有点太过含糊，常常会对大家造成误解。实际上，protected的可见性在于两点： 父类的protected成员是包内可见的，并且对子类可见； 若子类与父类不在同一包中，那么在子类中，子类实例可以访问其从父类继承而来的protected方法，而不能访问父类实例的protected方法。 在碰到涉及protected成员的调用时，首先要确定出该protected成员来自何方，其可见性范围是什么，然后就可以判断出当前用法是否可行。 这里有一个疑问就是上述结论的第二点。咋一看是比较绕口的，甚至有点矛盾，但是在看了下面的几个例子之后，理解就会更加深一点。 示例一p1/Father1.java 12345package basic.testprotected.p1;public class Father1 { protected void f() {} // 父类Father1中的protected方法} p1/Son1.java 123package basic.testprotected.p1;public class Son1 extends Father1{} p11/Son11.java 12345package basic.testprotected.p11;import basic.testprotected.p1.Father1;public class Son11 extends Father1{} p1/Test1.java 首先，看(1)(3)，其中的f()方法从类Father1继承而来，其可见性是包p1及其子类Son1和Son11，而由于调用f()方法的类Test1所在的包也是p1，因此（1）(3)处编译通过。 也就是说，如果我们换一个包，比如Test11.java在p11下，那么将都不可访问。如下： 其次，看(2)(4)，其中的clone()方法的可见性是java.lang包及其所有子类，对于语句son1.clone();和son11.clone();，二者的clone()在类Son1、Son11中是可见的，但对Test1是不可见的，因此（1）(3)处编译不通过。 也就是说，如果在Son1或Son11这两个类中调用clone()方法，则是可以编译通过的。 其实到此，我所遇到的问题已基本解决。因为我遇到的情况和这里的示例代码是一模一样的。 示例二p2/MyObject2.java 1234567package basic.testprotected.p2;public class MyObject2 { protected Object clone() throws CloneNotSupportedException{ return super.clone(); }} p22/Test2.java 对于(1)而言，clone()方法来自于类MyObject2本身，因此其可见性为包p2及MyObject2的子类，虽然Test2是MyObject2的子类，**但在Test2中不能访问父类MyObject2的protected方法clone()**，因此编译不通过; 对于(2)而言，由于在Test2中访问的是其本身实例的从父类MyObject2继承来的的clone()，因此编译通过。 所以在这里，就很好地阐述了上面所给的第二条结论： 若子类与父类不在同一包中，那么在子类中，子类实例可以访问其从父类继承而来的protected方法，而不能访问父类实例的protected方法。 为什么要这样以及这样要如何解释呢？我想这可能需要思考一下 对子类可见 的定义。先加一个构造函数，在这个构造函数里面，可以访问clone方法，这个方法来自MyObject2。 所以，再写一个类Test22继承自MyObject2，然后重新写个方法testSuperClone()，如下： 感觉这两个之间还是存在一些差距。所以，我的不太恰当理解为：对子类的实例可见，即可以在子类中，通过子类的实例去访问相应的protected方法。 示例三p3/MyObject3.java 12345package basic.testprotected.p3;import basic.testprotected.p33.Test3;public class MyObject3 extends Test3 {} p33/Test3.java 对于(1)而言，clone()方法来自于类Test3，因此其可见性为包p33及其子类MyObject3，而（1）正是在p33的类Test3中调用，属于同一包，编译通过。 示例四p4/MyObject4.java 123456789package basic.testprotected.p4;import basic.testprotected.p44.Test4;public class MyObject4 extends Test4 { protected Object clone() throws CloneNotSupportedException { return super.clone(); }} p44/Test4.java 对于(1)而言，clone()方法来自于类MyObject4，因此其可见性为包p4及其子类(此处没有子类)，而类Test4却在包p44中，因此不满足可见性，编译不通过。 示例五p5/MyObject5.java 1234567package basic.testprotected.p5;public class MyObject5 { protected Object clone() throws CloneNotSupportedException{ return super.clone(); }} p5/Test5.java 对于(1)而言，clone()方法来自于类MyObject5，因此其可见性为包p5及其子类(此处没有子类)，而类Test5也在包p5中，因此满足可见性，编译通过。 示例六12345678910package p6;class MyObject6 extends Test6{}public class Test6 { public static void main(String[] args) { MyObject6 obj = new MyObject6(); obj.clone(); // Compile OK -------（1） }} 对于(1)而言，clone()方法来自于类Test6，因此其可见性为包p6及其子类MyObject6，而类Test6也在包p6中，因此满足可见性，编译通过。 示例七1234567891011package p7;class MyObject7 extends Test7 { public static void main(String[] args) { Test7 test = new Test7(); test.clone(); // Compile Error ----- (1) }}public class Test7 {} 对于(1)而言，clone()方法来自于类Object，因此该clone()方法可见性为包java.lang及其子类Test7，由于类MyObject7不在此范围内，因此不满足可见性，编译不通过。 参考： https://blog.csdn.net/justloveyou_/article/details/61672133","link":"/2018/06/24/9945a378968f.html"},{"title":"使用SSH连接不能通过公网访问的机器","text":"众所周知，如果给定一个公网IP，我们只需要接入互联网即可访问；那么如果我想访问不处于公网、且不在同一局域网下的机器，可以做到吗？可能直觉告诉我们，不行。但是这里想说的是，可以，且只需要一条ssh命令即可。 场景通俗点描述为：A不能访问B，但是A能连接到外网，并且B也能访问外网，即A、B可以同时连接上公网主机。 认识ssh的端口转发对于这个命令，我们用的最多的可能就是用它来连服务器，然后看服务器的log。对于此文章相关的主题，我相信，知道ssh可以实现的并不多。在这里分享这部分内容的同时，也将自己的理解记录下来。 远程端口转发既然A能连通公网主机，那么A肯定能与公网主机建立ssh连接。所以我们可以先在B上运行下面的命令，命令的意思为，在ec2-ip.ap-northeast-1.compute.amazonaws.com上以ubuntu身份登录，然后将2222端口的数据，转发到B，然后B再将数据转发到localhost:22。其中这个localhost:22的意思为是，localhost的22端口，当然这个localhost可以为127.0.0.1，也可以为任何B可以访问到的ip，至于这个22端口，可以更具需要，改变成相应的端口也是没问题的。 1ssh -R 2222:localhost:22 ubuntu@ec2-ip.ap-northeast-1.compute.amazonaws.com -Nf 然后我们在A上，连接上公网主机，如下：然后再执行： 1ssh -p 2222 feiyu@localhost 这句命令是在公网主机上执行的，所以localhost也就是公网主机本身，而2222端口，就是上一条命令中的2222端口，因为公网主机的2222端口，会把数据都转发到B的22端口上去。而这个feiyu就是B机器上的某个用户。 整个流程即如上所示。 本地端口转发如果A想访问C，但是不能访问，此时B可以访问C并且A能访问B，即条件如下：A-&gt;BB-&gt;C此时A应当也能连通到C。好像传递性啊。然后这条命令就是ssh -L。详细如下： 1ssh -L 2121:C:21 B 就是A指定SSH绑定本地端口2121，然后指定B将所有的数据，转发到目标主机C的21端口。 隧道的维持SSH 连接是会超时关闭的，如果连接关闭，隧道无法维持。这里推荐一个小工具，叫做autossh，官网的链接为：http://www.harding.motd.ca/autossh/。其编译比较简单，跟着逛网的教程做即可，过程如下：至于使用，参考 1234# 其中 -M 参数指定的端口用来监听隧道的状态，与端口转发无关。autossh -p 22 -M 6777 -NR 6766:127.0.0.1:22 usera@a.site# 之后你可以在A上通过6766 端口访问B 了：ssh -p 6766 userb@127.0.0.1 参考资料：http://www.ruanyifeng.com/blog/2011/12/ssh_port_forwarding.htmlhttps://blog.csdn.net/lidongshengajz/article/details/73482908https://www.cnblogs.com/keerya/p/7612715.html","link":"/2019/01/01/22f3c2a20487.html"},{"title":"使用阿里云的RocketMQ中遇到的若干问题","text":"Python的TCP订阅模式官方文档上面RocketMQ的Python版本只支持HTTP的GroupID，链接为：https://github.com/aliyunmq/mq-http-python-sdk。 HTTP版本的SDK看起来是以轮询的形式来获取数据的，并且在控制台上也看不到使用HTTP版本SDK的连接状态。 还有社区版本的SDK。是用Python调用C++的SDK，其实也就是TCP版的C++ SDK。 无奈当时官网上并没有放出社区版本的Python SDK，现在已经有了，可以直接在官方文档上看到。如下： 订阅一致来源：https://help.aliyun.com/document_detail/43523.html 订阅关系一致指的是同一个消费者 Group ID 下所有 Consumer 实例的处理逻辑必须完全一致。一旦订阅关系不一致，消息消费的逻辑就会混乱，甚至导致消息丢失（关于消息丢失，在项目中确实遇到了，绞尽脑汁也没找出原因是什么，后面看到这个概念才恍然大悟）。消息队列 RocketMQ 里的一个消费者 Group ID 代表一个 Consumer 实例群组。对于大多数分布式应用来说，一个消费者 Group ID 下通常会挂载多个 Consumer 实例。 由于消息队列 RocketMQ 的订阅关系主要由 Topic + Tag 共同组成，因此，保持订阅关系一致意味着同一个消费者 Group ID 下所有的实例需在以下两方面均保持一致： 订阅的 Topic 必须一致 订阅的 Topic 中的 Tag 必须一致 正确订阅关系图片示例在下图中，多个 Group ID 订阅了多个 Topic，并且每个 Group ID 里的多个消费者实例的订阅关系保持了一致。 错误订阅关系图片示例在下图中，单个 Group ID 订阅了多个 Topic，但是该 Group ID 里的多个消费者实例的订阅关系并没有保持一致。 RocketMQ的三种发送模式来源：https://help.aliyun.com/document_detail/43163.html 消息队列 RocketMQ 是基于发布/订阅模型的消息系统。消息的订阅方订阅关注的 Topic，以获取并消费消息。由于订阅方应用一般是分布式系统，以集群方式部署有多台机器。因此消息队列 RocketMQ 约定以下概念。 集群：使用相同 Group ID 的订阅者属于同一个集群。同一个集群下的订阅者消费逻辑必须完全一致（包括 Tag 的使用），这些订阅者在逻辑上可以认为是一个消费节点。 集群消费：当使用集群消费模式时，消息队列 RocketMQ 认为任意一条消息只需要被集群内的任意一个消费者处理即可。 广播消费：当使用广播消费模式时，消息队列 RocketMQ 会将每条消息推送给集群内所有注册过的客户端，保证消息至少被每台机器消费一次。 集群消费模式： 适用场景&amp;注意事项 消费端集群化部署，每条消息只需要被处理一次。 由于消费进度在服务端维护，可靠性更高。 集群消费模式下，每一条消息都只会被分发到一台机器上处理。如果需要被- 集群下的每一台机器都处理，请使用广播模式。 集群消费模式下，不保证每一次失败重投的消息路由到同一台机器上，因此处理消息时不应该做任何确定性假设。 广播消费模式： 适用场景&amp;注意事项 广播消费模式下不支持顺序消息。 广播消费模式下不支持重置消费位点。 每条消息都需要被相同逻辑的多台机器处理。 消费进度在客户端维护，出现重复的概率稍大于集群模式。 广播模式下，消息队列 RocketMQ 保证每条消息至少被每台客户端消费一次，但是并不会对消费失败的消息进行失败重投，因此业务方需要关注消费失败的情况。 广播模式下，客户端每一次重启都会从最新消息消费。客户端在被停止期间发送至服务端的消息将会被自动跳过，请谨慎选择。 广播模式下，每条消息都会被大量的客户端重复处理，因此推荐尽可能使用集群模式。 目前仅 Java 客户端支持广播模式。 广播模式下服务端不维护消费进度，所以消息队列 RocketMQ 控制台不支持消息堆积查询、消息堆积报警和订阅关系查询功能。 使用集群模式模拟广播：如果业务需要使用广播模式，也可以创建多个 Group ID，用于订阅同一个 Topic。 适用场景&amp;注意事项 每条消息都需要被多台机器处理，每台机器的逻辑可以相同也可以不一样。 消费进度在服务端维护，可靠性高于广播模式。 对于一个 Group ID 来说，可以部署一个消费端实例，也可以部署多个消费端实例。 当部署多个消费端实例时，实例之间又组成了集群模式（共同分担消费消息）。 假设 Group ID 1 部署了三个消费者实例 C1、C2、C3，那么这三个实例将共同分担服务器发送给 Group ID 1 的消息。 同时，实例之间订阅关系必须保持一致。","link":"/2019/08/20/c1520c333a2d.html"},{"title":"修改framework后如何编译、生效！生效！","text":"被framework生效问题困了一天， 一定要记下来。试了网上各种答案，得到的结果都没生效。最终还是从同事那里得到的一份答案，还是同事靠谱啊。 一、framework编译方法一般修改framework层的内容分为两种，一种是res，一种是源代码。前者只需要在其目录下，通过mm的方式即可将framework-res.apk编译出来，并且通过将其push到手机/system/framework/目录下，可即时生效。后者则有一箩筐要说。 遇到了修改res下的内容，生成framework-res.apk后推到手机里面后，出现无法开机、资源无法找到的问题。困惑了很久，后来慢慢意识到可能是当前手机的系统版本的原因。手机当前的系统为客户分支系统，而当前的framework-res.apk编译自master分支，客户分支当然有很多master分支没有的东西，所以推送到客户分支所编译出来的系统之后，出现了资源无法找到等奇怪的错误。正确的姿势是将当前的手机系统，刷成master分支所编译出来的系统，然后再进行操作。这个坑靠着自己的直（xia）觉（meng）怕了出来。 1.使用m命令编译framework只有在系统初次编译后第一次使用有效，之后编译会失败，需使用make命令。 2.编译命令及解释 编译指令 解释 m 在源码树的根目录执行编译 mm 编译当前路径下所有模块，但不包含依赖 mmm [module_path] 编译指定路径下所有模块，但不包含依赖 mma 编译当前路径下所有模块，且包含依赖 mmma [module_path] 编译指定路径下所有模块，且包含依赖 make [module_name] 无参数，则表示编译整个Android代码 下面列举部分模块的编译指令： 模块 make命令 mmm命令 init make init mmm system/core/init zygote make app_process mmm frameworks/base/cmds/app_process system_server make services mmm frameworks/base/services java framework make framework mmm frameworks/base framework资源 make framework-res mmm frameworks/base/core/res jni framework make libandroid_runtime mmm frameworks/base/core/jni binder make libbinder mmm frameworks/native/libs/binder ·对于make命令，模块名称未确定时，到相应目录下Android.mk文件中查找 LOCAL_PACKAGE_NAME 值。 通过上面的方法，可以编译成功得到framework.jar文件，但是将其push到/system/framework/后，则不一定会生效。 二、如何让它生效？一般网上看到的做法是这样： 方法一：将编译所生成的framework.jar推送到手机相应的位置，重启，看是否生效。如果没有生效，则继续删除/system/framework/arm目录和/system/framework/arm64目录中的boot.art和boot.oat删除掉，之后重启机器。 如果这样操作后还是不生效该怎么办？ 方法二：在源代码的根目录，初始化好环境之后，在源代码的根目录下使用make snod，重新打包生成system.img，然后通过fastboot flash system %src_dir%\\system.img，将新生成的system.img刷入手机，然后重启。 很遗憾，我还是没有生效。我把上面两者结合起来还是没有生效。。 方法三：较为花式，请慎重服用。但这种近乎重新刷机的做法，感觉一定会生效。 修改好了framework里面的东西之后，全局编译一次，然后将编译得到的结果刷入手机。 注意事项： 如果在修改framework之前就已经进行过全局编译操作，那么在修改后，再进行全局编译，速度则非常快。 如果在修改之后，还进行了git pull操作拉取了其他人对代码的修改，那么此次全局编译的速度就未知，不过基本上很慢。","link":"/2018/03/14/53dea99bd910.html"},{"title":"关于 kubectl apply 的流程分析","text":"本文主要介绍与 kubectl apply 相关的几个概念、相关操作的主要逻辑，主要包括 Server Side Apply、Client Side Apply。 环境搭建 这里其实可以直接用 kubernetes 仓库，但它里面的内容太多，如果只用 kubectl 仓库 看起来会更简洁、纯粹。 Kubernetes 集群 克隆 kubectl 的源代码到本地用 GoLand 打开 git clone https://github.com/kubernetes/kubectl.git 将程序入口拷贝进 kubectl 中。 cd kubectl wget https://github.com/kubernetes/kubernetes/blob/master/cmd/kubectl/kubectl.go 修改 doc.go 中包名为 main 直接跑 kubectl.go 中的 main 方法来从源码编译、启动 kubectl 命令。 添加如下命令参数：apply -f testdata/apply/cm.yaml --field-manager=some-controller Client Side Apply入口在 pkg/cmd/apply/apply.go 中的 cmdutil.CheckErr(o.Run())。 ① 资源读取1infos, err := o.GetObjects() 这个方法会将 kubectl apply 命令将要操作的对象（通常是本地的文件、文件夹等）加载到到内存中，保存在 info.Object 中，并返回 infos 列表。当把所有需要 apply 的对象读出来后，会通过 for 循环去依次做 apply 操作。 12345for _, info := range infos { if err := o.applyOneObject(info); err != nil { errs = append(errs, err) }} 所以，对每个资源的 apply 操作是分隔开来的，同时，处理的逻辑也进入到 o.applyOneObject(info) 中。 ② 处理第一次 apply 操作 📢注意：此处的 info.Object 是刚从 kubectl client 端加载进来的内容。 在从 k8s 集群中进行一次查询前，会先计算出一个 modified，它表示此次 apply 结束后，在目标集群中该资源的终态。 1modified, err := util.GetModifiedConfiguration(info.Object, true, unstructured.UnstructuredJSONScheme) modified 的计算逻辑是先从 info.Object 中删除 kubectl.kubernetes.io/last-applied-configuration，然后将 info.Object 本身作为 kubectl.kubernetes.io/last-applied-configuration 的值塞进去。 12345678910111213141516171819202122232425262728293031323334func GetModifiedConfiguration(obj runtime.Object, annotate bool, codec runtime.Encoder) ([]byte, error) { var modified []byte annots, err := metadataAccessor.Annotations(obj) original := annots[v1.LastAppliedConfigAnnotation] delete(annots, v1.LastAppliedConfigAnnotation) if err := metadataAccessor.SetAnnotations(obj, annots); err != nil { return nil, err } // 此时 modified 等于 info.Object 的 Annotation 减去 kubectl.kubernetes.io/last-applied-configuration modified, err = runtime.Encode(codec, obj) if annotate { // 将此时的 modified 作为 kubectl.kubernetes.io/last-applied-configuration 塞进 Annotation 中 annots[v1.LastAppliedConfigAnnotation] = string(modified) if err := metadataAccessor.SetAnnotations(obj, annots); err != nil { return nil, err } // 重新生成 modified modified, err = runtime.Encode(codec, obj) if err != nil { return nil, err } } annots[v1.LastAppliedConfigAnnotation] = original if err := metadataAccessor.SetAnnotations(obj, annots); err != nil { return nil, err } return modified, nil} 当第一次 apply 某个资源到 k8s 集群中时，会显式地执行创建逻辑。对于是否执行创建逻辑，则通过一次对该资源的查询操作来确定。 12345678910111213if err := info.Get(); err != nil { if !errors.IsNotFound(err) { return ... } if o.DryRunStrategy != cmdutil.DryRunClient { // Then create the resource and skip the three-way merge obj, err := helper.Create(info.Namespace, true, info.Object) // ... info.Refresh(obj, true) } // ... return nil} 如果资源存在，则不会进入该 if 语句，且能够获取到集群中该资源的定义，并覆盖 info.Object 字段。 📢注意：此时的 info.Object 就变成了资源在 k8s 集群中的定义。 ③ 客户端重试机制当 apply 的资源在 k8s 集群中已存在时，会先创建 Patcher，然后调用 patcher.Patch() 方法来完成 patch 操作。其中该函数的入参注释如下： current runtime.Object: 当前集群中该资源的定义。 modified []byte: 参照第②步中的解释 12345678910111213// 初始化入参helper := resource.NewHelper(info.Client, info.Mapping). DryRun(o.DryRunStrategy == cmdutil.DryRunServer). WithFieldManager(o.FieldManager). WithFieldValidation(o.ValidationDirective)// 创建 patcherpatcher, err := newPatcher(o, info, helper)// 执行 Patch 操作patchBytes, patchedObject, err := patcher.Patch(info.Object, modified, info.Source, info.Namespace, info.Name, o.ErrOut) 进入 patcher.Patch() 之后，是一个特别熟悉的 for 循环。目的是当遇到冲突时，（默认5次）进行 maxPatchRetry 重试。执行的主体函数是 p.patchSimple()。 123456patchBytes, patchObject, err := p.patchSimple(current, modified, source, namespace, name, errOut)for i := 1; i &lt;= p.Retries &amp;&amp; errors.IsConflict(err); i++ { // ... current, getErr = p.Helper.Get(namespace, name) patchBytes, patchObject, err = p.patchSimple(current, modified, source, namespace, name, errOut)} 分析下 p.patchSimple() 的入参： current -&gt; obj : 当前集群中该资源的定义。 modified: 参照第②步中的解释。 ④ 计算 Patch进入 patchSimple() 后，主要做的操作就是先计算 patch 的内容，这个内容是指客户端通过计算，得出来发生变更的字段。而计算的方式是 ThreeWayMerge。该函数的定义如下： 1234func CreateThreeWayMergePatch(original, modified, current []byte, schema LookupPatchMeta, overwrite bool, fns ...mergepatch.PreconditionFunc) ([]byte, error) {} 前3个入参对应的含义如下（因为后面 patch 的计算，需要用到此3个入参，搞清楚他们的含义特别重要）： original: 当前集群中该资源的定义中 Annotations 中 kubectl.kubernetes.io/last-applied-configuration 对应的内容。 1original, err := util.GetOriginalConfiguration(obj) modified: 参照第②步中的解释。 current: 当前集群中该资源的定义。 1current, err := runtime.Encode(unstructured.UnstructuredJSONScheme, obj) 基于对上面 3 个入参的认知，开始进入 patch 计算的过程，其中的 ThreeWay 应该就是指通过上面的 3 个入参。 先将 original,modified,current 三个变量转成 map[string]interface{}类型为 originalMap、modifiedMap 、currentMap，以便于后面计算： 1234567originalMap := map[string]interface{}{}if len(original) &gt; 0 { if err := json.Unmarshal(original, &amp;originalMap); err != nil { return nil, mergepatch.ErrBadJSONDoc }}// ... 接下来会计算 3 组数据，分别为 deltaMap: current 与 modified 之间的差异（除去 deletion 操作） 12345deltaMapDiffOptions := DiffOptions{ IgnoreDeletions: true, SetElementOrder: true,}deltaMap, err := diffMaps(currentMap, modifiedMap, schema, deltaMapDiffOptions) deletionsMap: originalMap 与 modifiedMap 之间的 deletions 操作 12345deletionsMapDiffOptions := DiffOptions{ SetElementOrder: true, IgnoreChangesAndAdditions: true,}deletionsMap, err := diffMaps(originalMap, modifiedMap, schema, deletionsMapDiffOptions) patchMap: deltaMap 和 deletionsMap 执行 merge 操作后得到 patchMap 12mergeOptions := MergeOptions{}patchMap, err := mergeMap(deletionsMap, deltaMap, schema, mergeOptions) 最终返回 json.Marshal(patchMap)。至此计算 patch 结束。 ❓为什么 patch 的计算方法是这样的呢？ ⑤ 发送 PATCH 请求给 api-server在 strategicpatch.CreateThreeWayMergePatch() 函数执行完后，得到 patch 的结果，然后调用 client 发送 PATCH 请求给到 api-server，如下： 123456789// 此种情形得到的 apply 结果是 unchanged。if string(patch) == &quot;{}&quot; { return patch, obj, nil}// 调用 client 发送 PATCH 请求patchedObj, err := p.Helper.Patch(namespace, name, patchType, patch, nil)return patch, patchedObj, err Server Side Apply官网文档说明见链接。 启用 Server Side Apply 需要添加 --server-side 参数、以及通过 --field-manager=some-controller 来指定 manager（可选）。如下： 1kubectl apply --server-side --field-manager=some-controller -f testdata/apply/cm.yaml 运行完成后，可以在获取该 ConfigMap 时，添加 --show-managed-fields 参数以展示 managedFields 字段。如下： 1kubectl get cm test1 -o json --show-managed-fields 冲突当本次 apply 操作中想要修改的值，已经被其它 manager 管理后，出现的一种状态。主要是为了避免字段被别的用户修改。","link":"/2022/06/09/d092d4969a94.html"},{"title":"关于Bitmap相关的一些总结","text":"如何从当前View获取到Bitmap123v.setDrawingCacheEnabled(true);v.buildDrawingCache();Bitmap bitmap = v.getDrawingCache(); 如何从TextureView中获取Bitmap1mTextureView.getBitmap(); 如何压缩Bitmap压缩成适配目标宽、高的Bitmap 12345678910111213141516171819202122232425262728/** * get a scaled bitmap from a file located in path, adjust to destWidth and destHeight * @param path the bitmap's file location * @param destWidth destination width * @param destHeight destination height * @return a scaled bitmap */public static Bitmap getScaledBitmap(String path, int destWidth, int destHeight){ BitmapFactory.Options options = new BitmapFactory.Options(); options.inJustDecodeBounds = true; BitmapFactory.decodeFile(path, options); float srcWidth = options.outWidth; float srcHeight = options.outHeight; int inSampleSize = 1; if (srcHeight &gt; destHeight || srcWidth &gt; destWidth){ float heightScale = srcHeight / destHeight; float widthScale = srcWidth / destWidth; inSampleSize = Math.round(heightScale &gt; widthScale ? heightScale : widthScale); } options = new BitmapFactory.Options(); options.inSampleSize = inSampleSize; return BitmapFactory.decodeFile(path, options);} 如何将Bitmap与byte[]相互转换从Bitmap到byte[] 1234int bytes = bmp.getByteCount();ByteBuffer buf = ByteBuffer.allocate(bytes);bmp.copyPixelsToBuffer(buf);byte[] byteArray = buf.array(); 从byte[]到Bitmap 123Bitmap stitchBmp = Bitmap.createBitmap(width, height, type);stitchBmp.copyPixelsFromBuffer(ByteBuffer.wrap(byteArray));imageView.setImageBitmap(stitchBmp); 缩略图相关理解ThumbnaiUtils","link":"/2018/04/29/1aa78a1af661.html"},{"title":"关于String与常量池的问题","text":"面试必问题吧，但是好像还有一个比较容易漏的地方。 总体的流程，搞清楚执行此代码后，他们的结果是什么，以及为什么就差不多算理解了。 12345678910111213141516171819202122String a1 = new String(&quot;ab&quot;);System.out.println(a1 == a1.intern());//falseString a2 = &quot;ab&quot;;System.out.println(a2 == a2.intern());// trueSystem.out.println(a2 == a1); // falseSystem.out.println(a2 == a1.intern()); // trueString a3 = &quot;cd&quot;;System.out.println(a3 == a3.intern());// trueString a4 = new StringBuilder().append(&quot;ef&quot;).append(&quot;gh&quot;).toString();String a5 = a4.intern();System.out.println(a4 == a5); // trueString a6 = new String(&quot;ij&quot;) + new String(&quot;k&quot;);String a7 = a6.intern();System.out.println(a6 == a7); // trueString a8 = &quot;l&quot; + &quot;mn&quot;;String a9 = a8.intern();System.out.println(a9 == a8); // true 关于intern()方法： Returns a canonical representation for the string object.A pool of strings, initially empty, is maintained privately by the class String.When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned.It follows that for any two strings s and t, s.intern() == t.intern() is true if and only if s.equals(t) is true.All literal strings and string-valued constant expressions are interned. String literals are defined in section 3.10.5 of the The Java™ Language Specification.","link":"/2019/03/30/f7ca5bf2a4a7.html"},{"title":"关于final修饰符的一点思考","text":"背景在看HashMap的源代码的时候，发现其中的每个键值对的类型为一个Node&lt;K, V&gt;，其中包含了一个成员变量hash，被final修饰符修饰，但是并没有被初始化。这就有点奇怪了。 为什么可以在声明时不直接赋值？是因为不是所有的被final修饰的值都要在声明时马上赋值吗？之前看到的关于final修饰变量时基本上时这么说的呀。写了一个测试类，如下 123456class Demo1{ final int hi; public Demo1(int hi){ this.hi = hi; }} 当注释掉构造器中的赋值语句之后，编译器报错。这或许是可以被理解的。当构造器执行完了之后，一个对象才会被创建完成，其中的成员变量才有可能被访问到，所以它在被访问到之前，还是完成了初始化，得到了值。 那它还是final变量吗？当然是的。在this.hi = hi;后面，再添加一条语句如下， 1234567class Demo1{ final int hi; public Demo1(int hi){ this.hi = hi; this.hi = 666; }} 此时编译器是报错的，因为final变量的值不能被改变。 那对于对象呢？测试的结果与基本数据类型相同。 1234567891011class Demo1{ final int hi; final Demo2 demo2; public Demo1(int hi){ this.hi = hi; //this.hi = 666; this.demo2 = new Demo2(); }}class Demo2{} 依旧无编译错误。","link":"/2017/12/20/62df0eb93752.html"},{"title":"关于org.springframework.web.bind.annotation.RequestMapping","text":"仔细查看maven构建的输入日志后，发现是因为在这个org.springframework.web.bind.annotation包没有导入成功。要怎么才能导入这个包？后面再Stack Overflow上找到一个回答，成功地解决了问题。回答如下： I had the same problem. After spending hours, I came across the solution that I already added dependency for “spring-webmvc” but missed for “spring-web”. So just add the below dependency to resolve this issue. If you already have, just update both to the latest version. It will work for sure. 检查是否漏掉了这个依赖，漏掉了的话先加上，然后再试试看。 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;","link":"/2018/08/03/fe10bf43c7bc.html"},{"title":"分清堆和栈","text":"其实关于堆栈的问题在脑海中盘旋了挺久的了。从C语言开始，到数据结构，再到现在的Java，它一直在！现在就让我们从头开始吧。 明确概念首先应该明确堆和栈是不同的东西，其次数据结构中的堆和栈与编程语言中的堆和栈不是同一个概念。 从数据结构说起栈：即Stack，是一个LIFO队列。对它的操作有pop()，push()，peek()等。 堆：即Heap，是一棵完全二叉树（heap的某一种），它的特点是父节点的值大于（小于）两个子节点的值（分别称为大顶堆和小顶堆）。 具体内容可以参考后续关于数据结构的系列博客。 再到C语言123456789101112int a = 0; //全局初始化区 char *p1; //全局未初始化区 main() { int b; //栈 char s[] = &quot;abc&quot;; //栈 char *p2; //栈 char *p3 = &quot;123456&quot;; //123456\\0在常量区，p3在栈上。 static int c =0； //全局（静态）初始化区 p1 = (char *)malloc(10); //堆 p2 = (char *)malloc(20); //堆 } 一个比较直观的感受就是使用malloc（）函数分配出来的空间在堆上，其它经过系统初始化的在栈上。堆上的不能自己回收，栈上的会随着函数结束后自动回收。 Java中的堆和栈堆区：存放所有new出来的对象本身 栈区：存放基本类型的变量数据和对象的引用 静态域：存放静态成员（由static定义） 常量池：存放字符串常量和基本类型常量（public static final）","link":"/2017/12/18/ec026ab3dd70.html"},{"title":"初始化Linux系统","text":"multipass 安装虚拟机命令 123multipass launch --mem=2G --disk=20G --cpus=2 --name=master jammymultipass launch --mem=2G --disk=20G --cpus=2 --name=work-1 jammymultipass launch --mem=2G --disk=20G --cpus=2 --name=work-2 jammy 初始化虚拟机中的Linux系统 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364cat &lt;&lt; EOF | sudo tee /etc/apt/sources.list &gt;/dev/null &amp;&amp; sudo apt update &amp;&amp; sudo apt -y upgrade deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverseEOF############# network #############sudo apt install -y \\net-tools bridge-utils iputils-ping iproute2 \\netcat telnet traceroute############# zsh #############sudo apt install -y zshsh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestionssed -i '2s/# //g' ~/.zshrcsed -i 's/ZSH_THEME=.*/ZSH_THEME=ys/g' ~/.zshrcsed -i 's/plugins=(git)/plugins=(git zsh-syntax-highlighting zsh-autosuggestions)/' ~/.zshrc############# docker #############echo &quot;See https://docs.docker.com/engine/install/ubuntu if any problem&quot;#curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo tee /etc/apt/trusted.gpg.d/kubernetes-aliyun.gpg &gt;/dev/nullsudo apt-get install -y ca-certificates curl gnupg lsb-releasesudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\$(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.iocontainerd config default | sudo tee /etc/containerd/config.toml &gt; /dev/nullsudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.tomlsudo systemctl restart containerdsudo usermod -aG docker $USERcat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json &gt;/dev/null{ &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot;, &quot;https://reg-mirror.qiniu.com&quot; ]}EOFsudo systemctl restart docker# Docker 开启 TCP 访问sudo sed -i '/^ExecStart=/s#$# -H tcp://0.0.0.0:2375#' /lib/systemd/system/docker.servicesudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker############# kube #############curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo tee /etc/apt/trusted.gpg.d/kubernetes-aliyun.gpg &gt;/dev/nullcat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list &gt;/dev/nulldeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial mainEOFsudo apt updatesudo apt install -y kubelet kubeadm kubectl kubernetes-cni############# kube join #############sudo kubeadm join 192.168.64.3:6443 --token y3oi0w.cykyv4tdfusizfmw --discovery-token-ca-cert-hash sha256:7d8e37e91f682d6474ae10e889d1aefac908d1d5ad24775f28b4b653381c965e","link":"/2023/06/12/d41521e88108.html"},{"title":"利用OpenWrt为虚拟机做流量代理","text":"安装Openwrt虚拟机下载镜像：Index of /releases/22.03.5/targets/x86/64/ (openwrt.org) 转换镜像： 1qemu-img convert -f raw -O vdi openwrt-22.03.5-x86-64-generic-ext4-combined-efi.img openwrt-22.03.5-x86-64-generic-ext4-combined-efi.img.vdi 配置虚拟机网卡： 在VirtualBox中新建HostNetwork（Host-Only网络），网段为192.168.56.0/24 在openwrt虚拟机的网络选项中设置： 1）启用网卡1，连接方式选仅主机网络，名称选上步创建的HostNetwork 2）启用网卡2，连接方式选桥接网卡，名称选本机上能访问外网的网卡 进入openwrt虚拟机，为lan口设置静态IP地址为HostNetwork中的一个IP，这里用 192.168.56.2 123456789101112131415161718192021222324252627282930root@OpenWrt:~# cat /etc/config/networkconfig interface 'loopback' option device 'lo' option proto 'static' option ipaddr '127.0.0.1' option netmask '255.0.0.0'config globals 'globals' option ula_prefix 'fdd4:bccc:9ebb::/48'config device option name 'br-lan' option type 'bridge' list ports 'eth0'config interface 'lan' option device 'br-lan' option proto 'static' option ipaddr '192.168.56.2' option netmask '255.255.255.0' option ip6assign '60'config interface 'wan' option device 'eth1' option proto 'dhcp'config interface 'wan6' option device 'eth1' option proto 'dhcpv6' OPENWRT开启SFTP，实现文件下载上传同时也能使用scp命令进行拷贝 1234opkg updateopkg install vsftpd openssh-sftp-server/etc/init.d/vsftpd enable/etc/init.d/vsftpd start OpenClash安装与配置123#iptablesopkg updateopkg install coreutils-nohup bash iptables dnsmasq-full curl ca-certificates ipset ip-full iptables-mod-tproxy iptables-mod-extra libcap libcap-bin ruby ruby-yaml kmod-tun kmod-inet-diag unzip luci-compat luci luci-base 如果需要强制安装，可以先opkg remove，再opkg install。 在Releases · vernesong/OpenClash (github.com)页面，将openclash安装包下载到openwrt虚拟机中，通过 opkg install 安装。 配置手册：Home · vernesong/OpenClash Wiki (github.com) 其他虚拟机的旁路由配置此处用的是ubuntu server，可以在安装界面时设置，也可以等安装完成后，手动修改配置。手动修改的配置如下： 123456789101112131415$ cat /etc/netplan/00-installer-config.yaml# This is the network config written by 'subiquity'network: ethernets: enp0s3: addresses: - 192.168.56.3/24 nameservers: addresses: - 114.114.114.114 search: [] routes: - to: default via: 192.168.56.2 version: 2 配置修改后，可以看到默认路由已变成 192.168.56.2： 1234$ ip routedefault via 192.168.56.2 dev enp0s3 proto static172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown192.168.56.0/24 dev enp0s3 proto kernel scope link src 192.168.56.3 Reference OpenWrt/利用虚拟机安装X86之OpenWrt.md at master · peiyake/OpenWrt · GitHub VMware Workstation安装软路由OpenWrt_林鸿风采的技术博客_51CTO博客 VirtualBox虚拟机安装openwrt供本机使用 - 知乎 (zhihu.com) VMware安装OpenWrt让宿主机上网&amp;旁路由（两种方案）_vmware openwrt旁路由_aglo的博客-CSDN博客 如何在vmware虚拟机中安装OpenWrt系统？ - 知乎 (zhihu.com) 软路由OpenWrt X86软路由安装 (toutiao.com)","link":"/2023/06/26/dee71ca0ecee.html"},{"title":"利用自定义线程池解决OOM问题","text":"从Camera获取到了byte[]类型的图像数据之后，需要送到so库中，让so库进行相应的处理，并对其处理的结果进行相应的反馈；1s大概有30帧的数据，但是除去一些装载数据的事件，时间就变大了，实际可拿到的帧率就变小了；在此每秒取5帧，每张图片大致1~3M。这大致就是解决这个问题的背景框架。 起因处理图片时，耗时较长，放在主线程中，会造成卡顿，严重的时候会造成ANR。但是算法库处理时，会依赖于上一帧的数据，所以还是要按照顺序，一帧一帧来处理。从Camera取数据后，立即开启线程处理的代码如下： 12345678910111213141516171819//取数据mCamera.addCallbackBuffer(new byte[size.width * size.height * ImageFormat.getBitsPerPixel(ImageFormat.NV21) / 8]);mCamera.setPreviewCallbackWithBuffer(new Camera.PreviewCallback() { @Override public void onPreviewFrame(byte[] data, Camera camera) { if (mCallback != null &amp;&amp; mCamera != null){ // 处理数据回调 mCallback.onImageAvaliable(data, size.width, size.height); mCamera.addCallbackBuffer(new byte[size.width * size.height * ImageFormat.getBitsPerPixel(ImageFormat.NV21) / 8]); } }});// 开启线程处理部分ExecutorService pool = Executors.newSingleThreadExecutor();...if (isSwitchOn(R.id.fall_detect)) { pool.execute(new CheckFallAndMoveThread(buf, width, height));} 这样的话，只允许一个线程执行，多来了的，就排队等待处理，这样便实现了一帧一帧处理，并且还不会阻塞主线程。但是很可惜，这样会造成OOM。 原因so库处理的时间达到了2s左右（处理的图片没有经过resize），有点长。这样的话，每个需要处理的Runnable都需要一定的空间去存储这个图片，并且此种Executor是Runnable是无限长的，长度会自动变化，空间很快就会用完，也是合情合理。 解决办法看了一下，默认提供的几种线程池，并不能达到自己的需求，只能自己重新设置一下其中的参数，然后利用这些参数，设置成自己想要的那种模式，即队列长度有限，按顺序执行，然后宁愿少处理几帧，也要避免OOM。 123456789101112131415161718192021public class CalTaskThreadExecutor { private static final ExecutorService instance = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2), new ThreadFactory() { private final AtomicInteger mCount = new AtomicInteger(1); public Thread newThread(Runnable r) { return new Thread(r, &quot;SingleTaskPoolThread #&quot; + mCount.getAndIncrement()); } }, new RejectedExecutionHandler() { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { Log.e(&quot;TAG&quot;, &quot;超了&quot;); executor.remove(r); } }); public static ExecutorService getInstance(){ return instance; }} 十分感谢这篇博客，让我大致明白了其中参数所代表的意义，并按照自己的需求整个相应线程池出来。线程池，这一篇或许就够了。","link":"/2018/05/20/4ab25bec96b9.html"},{"title":"单例模式","text":"有很多关于单例模式的博客，书上也有些介绍，了解它也算挺久了。但是部觉得少了点什么，怕自己记了，也怕自己后面找起来麻烦，所以还是写一篇博客来记录一下吧。 单例模式的概念我的认识是这样，可能不是非常标准，一点自己的想法，不想copy而已： 只有一个实例 构造方法为private， 无法被直接实例化；类中持有一个本类的静态私有对象，并提供静态方法给外界提供访问。 实现方式不同的方式有不同应用场景，可以按需要选择。其实我还是有个小小的疑问，就是关于饿汉式，instance实例化的时机是当前类被引用的时候，可以认为是在调用getInstance()的时候 ，此时类中的变量按照相应的初始化顺序，依次初始化。这样的话，就和懒汉式的效果是一样的了=.=可能是我的想法不太对吧 饿汉式即初始化类的时候就创建好实例，不用担心多线程的环境下出现问题，但是有可能浪费资源。 1234567public class SingletonHangry { private static SingletonHangry instance; private SingletonHangry(){} public static SingletonHangry getInstance(){ return instance; }} 懒汉式即在被需要时才创建实例，这在并发的环境下会出现一些问题。 不加任何措施脑洞一下，都知道这个不一定是只有一个实例。123456789class SingletonLazy { private SingletonLazy(){} private static SingletonLazy instance; public static SingletonLazy getInstance(){ if (instance == null) instance = new SingletonLazy(); return instance; }} 加上同步锁虽然这样就保证了只有一个实例，但是这个同步锁在每次调用getInstance()时都会工作，而显然这些同步工作中非常大的一部分是不需要的。所以在性能上必定会有所损失。123456789class SingletonLazy { private SingletonLazy(){} private static SingletonLazy instance; public synchronized static SingletonLazy getInstance(){ if (instance == null) instance = new SingletonLazy(); return instance; }} Double Check Lock（DCL）说起这个，我刚开始的时候只了解到这有两个if。后来才知道这就是大名鼎鼎的DCL，失敬失敬！12345678910111213141516class SingletonLazy { private SingletonLazy(){} private static volatile SingletonLazy instance; public static SingletonLazy getInstance(){ if (instance == null) { // 使用这个if是为了在instance已被初始化之后，避免同步 synchronized (SingletonLazy.class) { if (instance == null) { // 这个if是为了因为，如果同时有两个进程A,B执行了getInstance()，它们是都会有机会通过第1个if， // 也就是说会依次执行同步锁里面的内容。因此没有这个if也是有可能不能保证单例的。 instance = new SingletonLazy(); } } } return instance; }} 至于那个关键字volatile，与Java中的内存模型有关，加上了这个才能保证单例。它大致做的事情是这样的：instance = new SingletonLazy()并非是原子操作，事实上在JVM中这句话做了三件事： 1.给instance分配内存2.调用SingletonLazy()的构造函数来初始化成员变量3.将instance对象指向分配的空间（执行完这一步instance就不为null） 但是在JVM的即时编译器中存在指令重排序的优化，也就是说上面的第二步和第三步是不能保证顺序的，最终执行的顺序可能是1-2-3或者是1-3-2。如果是后者，则在3执行完毕，2执行之前，被线程2抢占了，这时instance已经是非null了（但却没有初始化），所以线程2会直接返回instance，然后使用，然后会报错。使用了volatile就保证了：取操作必须在执行完1-2-3之后或者1-3-2之后，不存在执行到1-3然后取到值的情况。 静态内部类因为类的初始化是虚拟机保证只加载一次，因此是线程安全的。 123456789class SingletonStaticInnerClass { static class SingletonHolder { private final static SingletonStaticInnerClass instance = new SingletonStaticInnerClass(); } private SingletonStaticInnerClass(){} private static SingletonStaticInnerClass getInstance(){ return SingletonHolder.instance; }} 枚举枚举的相信息：http://blog.csdn.net/u013256816/article/details/50562905 123456789101112131415161718enum SingletonEnum { INSTANCE1, INSTANCE2; class Singleton { private Singleton(){} } private Singleton instance; private SingletonEnum(){ instance = new Singleton(); } public Singleton getInstance() { return instance; }}public static void main(String[] args) { SingletonEnum.INSTANCE1.getInstance(); SingletonEnum.INSTANCE2.getInstance();} 容器这个有点迷","link":"/2018/01/22/d5c578fe1096.html"},{"title":"反向代理为什么叫反向代理","text":"Nginx可以实现端口转发，这又叫反向代理。那么什么叫反向代理呢？一开始特别不理解，然后去找一些答案时，发现一个特别形象和容易懂的回答。来自知乎中对此问题的一个回答：https://www.zhihu.com/question/24723688 正向代理隐藏真实客户端，反向代理隐藏真实服务端 自己的理解：正向代理就是我们平常使用的那种代理软件的效果，我们将自己的请求发给代理服务器，然后再由代理服务器发送给目标服务器；反向代理，顾名思义，方向相反，当代理服务器收到请求后，依照某种规则，转发给不同的服务器。因此，结合上面两幅生动形象、网友所给的图，可以非常容易理解为什么叫反向代理。","link":"/2018/09/13/75d68d2a6874.html"},{"title":"压箱底的 macOS 环境搭建、常用软件分享","text":"Git打开 Terminal 输入 git，回车，然后安装开发工具，等待安装完毕。 Surge12curl -LO https://dl.nssurge.com/mac/v4/Surge-latest.zipunzip Surge-latest.zip Homebrew使用官方提供的安装命令，默认会访问 GitHub 仓库， 1/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; 如果有网络问题，可以使用清华大学的镜像仓库，已经有现成的脚本 12345678910111213export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git&quot;export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git&quot;export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles&quot;# 从本镜像下载安装脚本并安装 Homebrew / Linuxbrewgit clone --depth=1 https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/install.git brew-install/bin/bash brew-install/install.shrm -rf brew-install##### 或者# 也可从 GitHub 获取官方安装脚本安装 Homebrew / Linuxbrew/bin/bash -c &quot;$(curl -fsSL https://github.com/Homebrew/install/raw/master/install.sh)&quot; iTerm21brew install --cask iterm2 安装 Fira Code 字体作为 iTerm2 的显示字体。可参考：GitHub 或 Gitee 镜像 为了使用后续的 oh my zsh 主题，这里直接安装 powerline fonts： 123git clone git@github.com:powerline/fonts.gitcd fonts./install.sh 然后在 iTerm2 中打开设置，做如下设置： Profiles - Colors - Color Presets: Tango Dark Profiles - Text - Font: monofur for powerline, Regular, 20 Profiles - Window - Settings for New Window: Columns 105, Rows 25 login shell使用 zsh 并安装 oh-my-zsh 主题 1sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 可以考虑使用此主题：https://github.com/romkatv/powerlevel10k oh my zsh 插件 1234# zsh-syntax-highlighting 命令是否正确git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting# zsh-autosuggestions 根据命令历史推荐git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 然后打开 ~/.zshrc 将 plugins 行修改为：plugins=(git zsh-syntax-highlighting zsh-autosuggestions) vim1sh &lt;(curl https://j.mp/spf13-vim3 -L) 或者参考：spf13-vim 浏览器1brew install --cask google-chrome firefox 编程语言123brew install node go python@3.9brew install maven gradlebrew install --cask mactex IDE12brew install --cask jetbrains-toolbox \\visual-studio-code 通过 jetbrains-toolbox 安装 JetBrains 全家桶吧！ InteliJ IDEA Ultimate GoLand CLion PyCharm Professional Hackintosh1234brew install --cask opencore-configurator \\hackintool \\kext-utility \\balenaetcher 容器相关123brew install --cask docker lensbrew install helmbrew install grafana 安装 Docker Desktop 版的 k8s 集群，可参考阿里云的官方步骤 12curl -fsSL -O https://raw.githubusercontent.com/AliyunContainerService/k8s-for-docker-desktop/v1.22.4/images.propertiesbash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/AliyunContainerService/k8s-for-docker-desktop/v1.22.4/load_images.sh)&quot; 编辑配置文件 1234&quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot;, &quot;https://mirror.baidubce.com&quot;], 命令行小工具12345brew install wget tig jq neofetch tldr tree dos2unixbrew install asciinemabrew install smartmontools# 图片压缩brew install jpegoptim optipng 腾讯系软件1brew install --cask qq wechat wechatwork qqmusic tencent-meeting 其他软件12brew install --cask neteasemusic yinxiangbiji sogouinput futubull thunder utoolsbrew install --cask postman sourcetree iina paper telegram-desktop Typora收费版 1brew install --cask typora 破解版本 uPic开源版本只更新到 19 年 1brew install --cask upic 收费版本 iStat Menus1brew install --cask istat-menus 激活码 982092332@qq.com GAWAE-FCWQ3-P8NYB-C7GF7-NEDRT-Q5DTB-MFZG6-6NEQC-CRMUD-8MZ2K-66SRB-SU8EW-EDLZ9-TGH3S-8SGA Alfred免费版 1brew install --cask alfred 破解版本 JDK这里选用Azul Zulu Builds of OpenJDK，默认用 JDK 1.8，如有其他版本 JDK 需要，可在 IDE 里面进行配置。 12345678910111213141516171819# 进入临时目录cd /tmpcurl -LO https://cdn.azul.com/zulu/bin/zulu8.60.0.21-ca-jdk8.0.322-macosx_x64.dmgopen .# 点击安装 JDK pkg。# 查看已安装 JDK 的路径/usr/libexec/java_home# JDK 11curl -LO https://cdn.azul.com/zulu/bin/zulu11.54.25-ca-jdk11.0.14.1-macosx_x64.zipunzip zulu11.54.25-ca-jdk11.0.14.1-macosx_x64.zipsudo mv zulu11.54.25-ca-jdk11.0.14.1-macosx_x64/zulu-11.jdk /Library/Java/JavaVirtualMachines# JDK 17curl -LO https://cdn.azul.com/zulu/bin/zulu17.32.13-ca-jdk17.0.2-macosx_x64.zipunzip zulu17.32.13-ca-jdk17.0.2-macosx_x64.zipmv zulu17.32.13-ca-jdk17.0.2-macosx_x64/zulu-17.jdk /Library/Java/JavaVirtualMachines PDF Expert破解版本 Navicat Premium破解版本 Microsoft Office破解版本 Final Cut Pro破解版本 Vmware Fusion破解版本 OmniGraffle破解版本 Charles破解版本 Xmind破解版本 Redis Desktop Manager破解版本","link":"/2021/07/28/3183ef1107ec.html"},{"title":"听说过 OCI Runtime 不止 runc 还有 kata","text":"OS：Ubuntu 22.04 安装与配置通过 snap 安装 kata-containers，目前【2022-08-25】snap 中最新版本是 2.4.2 2022-06-08，但是官网的 release 已经发布到了 2.5.0。 1sudo snap install kata-containers --stable --classic 设置默认的配置文件 /etc/kata-containers/configuration.toml 12345sudo mkdir -p /etc/kata-containerssudo cp /snap/kata-containers/current/usr/share/defaults/kata-containers/configuration.toml /etc/kata-containers/# 将 sandbox_cgroup_only 设置为 truesudo sed -i 's/sandbox_cgroup_only=.*$/sandbox_cgroup_only=true/' /etc/kata-containers/configuration.toml 将 kata 的二进制链接到 PATH 涵盖的目录中，以便 containerd 能直接访问该二进制 1234sudo ln -sf /snap/kata-containers/current/usr/bin/containerd-shim-kata-v2 \\ /usr/local/bin/containerd-shim-kata-v2sudo ln -sf /snap/kata-containers/current/usr/bin/kata-runtime \\ /usr/local/bin/kata-runtime 修改 containerd 的配置文件 /etc/containerd/config.toml 12345678910[plugins] [plugins.&quot;io.containerd.grpc.v1.cri&quot;] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd] #default_runtime_name = &quot;kata&quot; [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes] [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.kata] runtime_type = &quot;io.containerd.kata.v2&quot; privileged_without_host_devices = true pod_annotations = [&quot;io.katacontainers.*&quot;] container_annotations = [&quot;io.katacontainers.*&quot;] 检验安装是否正确测试 kata-containers 配置是否正常，两次 ctr run 输出的结果应该会一样 123456sudo ctr image pull docker.io/library/busybox:latest# 将使用 kata runtimesudo ctr run --rm -t --runtime &quot;io.containerd.kata.v2&quot; \\ docker.io/library/busybox:latest test-kata-containers uname -r# 将使用 runc runtimesudo ctr run --rm -t docker.io/library/busybox:latest test-kata-containers uname -r 在 K8s 中使用 Kata 运行时，需要先创建 RuntimeClass 对象到 K8s 集群中，如下： 1234567cat &lt;&lt;EOF | kubectl apply -f -apiVersion: node.k8s.io/v1kind: RuntimeClassmetadata: name: katahandler: kataEOF 然后在 yaml 中手动指定 pod.spec.runtimeClass 字段为：名称是 kata 的 RuntimeClass 对象，然后 containerd 才会使用 kata 作为运行时。 1234567891011121314151617181920212223242526272829303132cat &lt;&lt;EOF | kubectl apply -f -apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-dep labels: app: nginxspec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: runtimeClassName: kata containers: - name: nginx image: ghcr.io/joengjyu/nginx:latest ports: - containerPort: 80 imagePullPolicy: IfNotPresent resources: requests: cpu: 500m memory: 512Mi limits: cpu: 500m memory: 512MiEOF 成功运行后，结果如下： 12345$ uname -r5.15.0-46-generic$ kubectl exec nginx-dep-f6bbd75cf-7c9sq -- uname -r5.15.26.container 遇到的问题在配置完 containerd 和 kata 后，检测是否能正常运行时，遇到了如下报错 123$ sudo ctr run --cni --runtime io.containerd.run.kata.v2 -t --rm docker.io/library/busybox:latest hello shctr: failed to create shim task: Could not create the sandbox resource controller cgroups: cgroup mountpoint does not exist: not found 在 kata-container 的 ISSUE #1927 中，找到一个与此问题类似的讨论，主要是将 kata 配置文件中的 sandbox_cgroup_only 字段设置成 true。 但是修改后，错误依然存在。 索性找到了此报错信息在 kata-containers 中源码的位置，打了相关日志，重新创建 kata 相关的链接后 123sudo ln -sf ~/kata-containers/src/runtime/kata-runtime /usr/local/bin/kata-runtimesudo ln -sf ~/kata-containers/src/runtime/containerd-shim-kata-v2 /usr/local/bin/containerd-shim-kata-v2sudo ln -sf ~/kata-containers/src/runtime/kata-monitor /usr/local/bin/kata-monitor 再次运行后，发现问题消失了。可能是 kata 版本的问题，通过 snap 安装的 kata 版本是 2.4.2 ，发布于 2022 年 6 月，最新稳定版本是 2.5.0，发布于 2022 年 8 月。其间只是隔了一两个版本。 Reference Kata Containers snap package Install Kata Containers with containerd 成为 Kata Containers 开发者 Day 1 - 人间指南","link":"/2022/08/29/abbcdaf10c8c.html"},{"title":"在 Golang 中开启 cgo 时遇到的问题与思考","text":"对纯 Go 代码，可以在 go build 时添加 GOOS 和 GOARCH 变量来指定二进制的目标系统与架构，实现交叉编译；但对开启了 CGO 的代码，如何做到交叉编译呢？ 错误的示范总共在项目中遇到了两类错误。 环境搭建在宿主机上使用 multipass 开启 3 个不同版本的 Ubuntu 系统，如下： 12345678910multipass launch --name=a release:18.04multipass launch --name=b release:20.04multipass launch --name=c release:22.04# 虚拟机列表$ multipass listName State IPv4 Imagea Running 172.16.73.16 Ubuntu 18.04 LTSb Running 172.16.73.17 Ubuntu 20.04 LTSc Running 172.16.73.18 Ubuntu 22.04 LTS 依赖安装 123sudo apt updatesudo apt upgradesudo apt install -y make golang-go 查看当前系统 GLIBC 版本 getconf GNU_LIBC_VERSION 1glibc 2.35 ldd --version 12345ldd (Ubuntu GLIBC 2.35-0ubuntu3) 2.35Copyright (C) 2022 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.Written by Roland McGrath and Ulrich Drepper. 查看各系统的 glibc 版本 123multipass exec a getconf GNU_LIBC_VERSIONmultipass exec b getconf GNU_LIBC_VERSIONmultipass exec c getconf GNU_LIBC_VERSION 详细如下： 系统版本 glibc 版本 a 18.04 glibc 2.27 b 20.04 glibc 2.31 c 22.04 glibc 2.35 二进制编译时依赖的库的版本与实际运行时系统中存在的库之间的差异 在 Ubuntu 22.04 LTS 中编译的二进制，无法在 Ubuntu 18.04.6 LTS 运行（架构：amd64）。 按步骤来操作，此问题必现 在 c 机器上构建 linux amd64 架构的二进制 demo，并将 demo 分发到 a, b 两台机器上。 分别在 a, b 两台机器上执行二进制 demo。 对 demo 文件的分析 在 macOS 12 中开启 CGO 编译的二进制，无法在 macOS 11 中运行（架构：amd64）。 后续未复现 二进制编译时用的系统与运行时的系统不同GLIBC版本不兼容问题构建 linux 的二进制文件时，做静态打包，将 glibc 的依赖一起打包进二进制文件中。 1GOOS=linux GOARCH=amd64 CGO_ENABLED=1 go build -ldflags &quot;-extldflags '-static'&quot; -o $(NAME) 但是遇到以下的 Warning，大致意思是虽然用了静态编译，但是还是会动态链接到进行 linker 操作时的 glibc 版本上。如果放任这个错误不管，可能会出现一些莫名其妙的问题。 1234/usr/bin/ld: /tmp/go-link-922118976/000010.o: in function `unixDlOpen':/home/ubuntu/go/pkg/mod/github.com/mattn/go-sqlite3@v1.14.0/sqlite3-binding.c:39881: warning: Using 'dlopen' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking/usr/bin/ld: /tmp/go-link-922118976/000016.o: in function `_cgo_6cc2654a8ed3_C2func_getaddrinfo':/tmp/go-build/cgo-gcc-prolog:58: warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking 这里一种可行的方式是不使用 glibc 这种 libc，换成 musl，在 Ubuntu 上面安装： 1sudo apt install -y musl musl-dev musl-tools 编译时只需要在 go build 时添加 CC=/usr/bin/musl-gcc 变量。 1CC=/usr/bin/musl-gcc GOOS=linux GOARCH=amd64 CGO_ENABLED=1 go build -ldflags &quot;-extldflags '-static'&quot; -o $(NAME)-musl 在 c 机器上面构建完成后，分发到 a、b 机器上面，都可以正常运行，结果如下： 12345678910111213ubuntu@b:~$ ./demo-musl upINFO[2022-07-20 21:54:09.228] done init dbINFO[2022-07-20 21:54:09.228] scheduler started...INFO[2022-07-20 21:54:09.229] Connecting to wss://xxx/ncd/ws/connectionINFO[2022-07-20 21:54:09.362] Response: &amp;{Status:101 Switching Protocols StatusCode:101 Proto:HTTP/1.1 ProtoMajor:1 ProtoMinor:1 Header:map[Connection:[upgrade] Date:[Wed, 20 Jul 2022 13:54:05 GMT] Sec-Websocket-Accept:[7PJbg/gEi9umEJ4bnOaWAciTq0k=] Server:[Nginx] Upgrade:[websocket]] Body:{Reader:0xc00042f9e0} ContentLength:0 TransferEncoding:[] Close:false Uncompressed:false Trailer:map[] Request:0xc0000ad000 TLS:&lt;nil&gt;}INFO[2022-07-20 21:54:09.363] send message: [RequestId: 015e63a3-7bad-4cba-a3d6-c515e61f6e42, Command: GET_AGENT_UPDATE_INFO, Code: 0, Message: , MaxFramePayload: 0, TimeoutSeconds: 30]ubuntu@a:~$ ./demo-musl upINFO[2022-07-20 21:57:37.345] done init dbINFO[2022-07-20 21:57:37.345] scheduler started...INFO[2022-07-20 21:57:37.347] Connecting to wss://xxx/ncd/ws/connectionINFO[2022-07-20 21:57:37.560] Response: &amp;{Status:101 Switching Protocols StatusCode:101 Proto:HTTP/1.1 ProtoMajor:1 ProtoMinor:1 Header:map[Connection:[upgrade] Date:[Wed, 20 Jul 2022 13:57:34 GMT] Sec-Websocket-Accept:[NgGXU/yXwW9Hk6ecEhVICTjmKiI=] Server:[Nginx] Upgrade:[websocket]] Body:{Reader:0xc00061b1d0} ContentLength:0 TransferEncoding:[] Close:false Uncompressed:false Trailer:map[] Request:0xc0000a5100 TLS:&lt;nil&gt;}INFO[2022-07-20 21:57:37.561] send message: [RequestId: eb05129e-3722-4ecd-88f5-23cb2e734df3, Command: GET_AGENT_UPDATE_INFO, Code: 0, Message: , MaxFramePayload: 0, TimeoutSeconds: 30] 如何交叉编译在 macOS (x86) 上搭建编译 linux amd64 和 arm64 平台的环境 安装 musl-cross 1brew install FiloSottile/musl-cross/musl-cross --with-aarch64 安装完成后，可以看到对应架构的编译器 编译 123BUILD_FLAGS=&quot;-X $(PKG)/version.Commit=$(COMMIT)\\ -X '$(PKG)/version.BuildTime=$(BUILD_TIME)'\\ -X '$(PKG)/version.Version=$(VERSION)' -extldflags '-static'&quot; amd64 架构 1GOOS=linux GOARCH=amd64 CGO_ENABLED=1 CC=&quot;/usr/local/bin/x86_64-linux-musl-gcc&quot; go build -ldflags $(BUILD_FLAGS) -o $(NAME)-amd64 arm64 架构 1GOOS=linux GOARCH=arm64 CGO_ENABLED=1 CC=&quot;/usr/local/bin/aarch64-linux-musl-gcc&quot; go build -ldflags $(BUILD_FLAGS) -o $(NAME)-arm64 在 macOS (x86) 上搭建编译 windows amd64 架构的环境1brew install mingw-w64 amd64 架构 1GOOS=windows GOARCH=amd64 CGO_ENABLED=1 CC=&quot;/usr/local/bin/x86_64-w64-mingw32-gcc&quot; go build -ldflags $(BUILD_FLAGS) -o $(NAME).exe Reference Go语言涉及CGO的交叉编译(跨平台编译)解决办法 - 知乎 (zhihu.com) 含有CGO代码的项目如何实现跨平台编译 - SegmentFault 思否 Statically compiled Go programs, always, even with cgo, using musl (honnef.co) go - 使用 cgo、LuaJIT 和 musl 构建静态二进制文件 - IT工具网 (coder.work) mattn/go-sqlite3: sqlite3 driver for go using database/sql (github.com) 《程序员的自我修养——链接、装载与库》","link":"/2022/07/20/adb9a934b8da.html"},{"title":"基于Netty实现局域网内自动组网","text":"这种功能的实现首先考虑到的是广/多播，然后通过所受到的广播，获取到发送某种广播的ip地址，即实现“发现设备”功能。得到IP，即完成组网功能。 多播与广播 在这里选择的是多播。 选项 单播 多播（组播） 广播 描述 主机之间一对一的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。 主机之间一对一组的通讯模式，也就是加入了同一个组的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。 主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要） 优点 1）服务器及时响应客户机的请求2）服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。 1）需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。2）由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。 3）此协议和单播协议一样允许在Internet宽带网上传输。 1）网络设备简单，维护简单，布网成本低廉2）由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低 缺点 1）服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。2）现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞。而将主干扩展20倍几乎是不可能。 1）与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。2）现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。 1）无法针对每个客户的要求和时间及时提供个性化服务。2）网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。3）广播禁止允许在Internet宽带网上传输。 组网流程服务端与客户端同时加入一个多播，然后客户端不断发送寻找主机的报文，知道得到服务端的响应。获取到服务端的响应后，即可得到主机的IP，从而停止发送寻找主机的报文，并开始着手进行连接主机，即完成自动组网。 实践代码客户端：不断地向目标组内发送UDP报文，直到得到主机的回应或被关闭。 12345678910111213141516171819202122232425262728293031323334353637EventLoopGroup group = new OioEventLoopGroup();try { Bootstrap b = new Bootstrap(); b.group(group) .channelFactory(new ChannelFactory&lt;Channel&gt;() { public Channel newChannel() { return new OioDatagramChannel(); } }) .option(ChannelOption.SO_REUSEADDR, true) .handler(new ChannelInitializer&lt;DatagramChannel&gt;() { @Override public void initChannel(DatagramChannel ch) throws Exception { // 将byte解码成所需数据 ch.pipeline().addLast(new UdpPacketDecoder()); // 将所需数据整成byte流 ch.pipeline().addLast(new UdpPacketEncoder()); // 对所接收到的报文进行处理 ch.pipeline().addLast(new ClientMulticastHandler()); } }); ch = (DatagramChannel) b.bind(port).sync().channel(); // 此地址为一个多播地址，此处为239.255.27.1 ch.joinGroup(groupAddress); // 开始通过发送UDP报文寻找主机 startSearch(); ch.closeFuture().sync(); Log.d(&quot;MulticastClient&quot;,&quot;MulticastClient.run stop&quot;);} catch (InterruptedException e) { e.printStackTrace();} catch (Exception e) { e.printStackTrace();} finally { group.shutdownGracefully();}setCallback(null); 发送UDP报文 1234567891011public void startSearch() { if (search != null) { search.cancel(true); } // 每隔1s发送一次多播报文 search = ch.eventLoop().scheduleAtFixedRate(new Runnable() { public void run() { ch.writeAndFlush(UdpPacket.newSearchRequest(serverAddress)); } }, 0, 1, TimeUnit.SECONDS);} 此处再贴上客户端收到服务端的回应之后的处理逻辑，也就是ClientMulticastHandler： 123456789101112131415161718public class ClientMulticastHandler extends SimpleChannelInboundHandler&lt;UdpPacket&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, UdpPacket msg) throws Exception { if (msg.isSearchResponse()) {// 是服务端的响应 MulticastClient.Callback callBack = MulticastClientCallback.INSTANCE.getCallback(); if (callBack != null) { // 交给回调函数处理或直接在此处理 callBack.onSearch(msg.getDstAddress().getHostString(), msg.getPort()); } } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); }} 服务端：监听 1234567891011121314151617181920212223242526272829303132333435EventLoopGroup group = new OioEventLoopGroup();try { Bootstrap b = new Bootstrap(); b.group(group) .channelFactory(new io.netty.channel.ChannelFactory&lt;Channel&gt;() { public Channel newChannel() { return new OioDatagramChannel(); } }) .option(ChannelOption.SO_REUSEADDR, true) .handler(new ChannelInitializer&lt;DatagramChannel&gt;() { @Override public void initChannel(DatagramChannel ch) throws Exception { // 翻译成所需信息 ch.pipeline().addLast(new UdpPacketDecoder()); // 翻译成byte ch.pipeline().addLast(new UdpPacketEncoder()); // 处理客户端发送过来的寻找主机请求 ch.pipeline().addLast(new ServerMulticastHandler()); } }); ch = (DatagramChannel)b.bind(port).sync().channel(); ch.joinGroup(groupAddress).sync(); ch.closeFuture().sync(); System.out.println(&quot;MulticastServer stop&quot;);} catch (InterruptedException e) { e.printStackTrace();} catch (Exception e) { e.printStackTrace();} finally { group.shutdownGracefully();} 对“寻找主机请求”的处理： 1234567891011121314151617public class ServerMulticastHandler extends SimpleChannelInboundHandler&lt;UdpPacket&gt; { @Override protected void channelRead0(ChannelHandlerContext ctx, UdpPacket msg) throws Exception { if (msg.isSearchRequset()) { ctx.channel().writeAndFlush( // 给客户端一个回复 UdpPacket.newSearchResponse(Ip.getLocalIp(ctx.channel()), Ip.SERVER_TCP_PORT, msg.getDstAddress())); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); }} 至此，通过多播组网的这一部分基本完成。 参考： http://www.cnblogs.com/wolfocme110/p/5504054.html","link":"/2018/06/27/8670d179c372.html"},{"title":"基于containerd CRI如何查看容器的文件内容？","text":"CRI：containerd 安装 crictl：https://github.com/kubernetes-sigs/cri-tools/releases exec进入容器中查看使用 crictl crictl exec -it &lt;container-id&gt; &lt;shell-in-container&gt; 需要在 Pod 所在的 Node 上执行。 12345678ubuntu@work-1:~$ sudo crictl psCONTAINER IMAGE CREATED STATE NAME ATTEMPT POD ID POD64aad8b603123 985a52bfdfe21 13 minutes ago Running simple-http-server 0 0c2daa092abd3 shs-5698fcd598-dpxlgubuntu@work-1:~$ sudo crictl exec -it 64aad8b603123 bashbash-5.1# ls -ltotal 6352-rwxr-xr-x 1 root root 6503679 Oct 28 05:48 simple-http-server 使用 kubectl kubectl exec -it &lt;pod-name&gt; -- bash 12345# ubuntu @ master in ~ [23:16:17]$ kubectl exec -it shs-5698fcd598-dpxlg -- bashbash-5.1# ls -ltotal 6352-rwxr-xr-x 1 root root 6503679 Oct 28 05:48 simple-http-server 前提 容器中需要存在 shell 或 ls 等命令； 如果在容器中想做一些操作，它还需要存在你想使用的命令。 使用 nsenter 需要在 Pod 所在 Node 上执行 查找目标 Pod 进程 id。有两种方式 直接 ps -ef ，然后用 grep 去过滤出来 Pod 的启动命令。 123ubuntu@work-1:~$ ps -ef | grep simple-http-server | grep -v greproot 7630 7510 0 23:00 ? 00:00:00 /app/simple-http-serverroot 8158 8103 0 23:01 ? 00:00:00 /app/simple-http-server 如果分得清楚是哪个 Pod 的进程，直接那对应进程的 pid 即可；如果分不清，那继续看下一种方法。 先用 kubectl get pod &lt;target-pod&gt; -oyaml | grep containerID 找目标 Pod 中业务容器的 id，然后再用 crictl inspect &lt;container-id&gt; 获取到容器进程的pid 1234567$ kubectl get pod shs-5698fcd598-sjq5p -oyaml | grep containerID - containerID: containerd://602515a3a5fb6e36902844a0654d82841bb565d57df9d4b0e6ecf024947b0407$ sudo crictl inspect 602515a3a5fb6e36902844a0654d82841bb565d57df9d4b0e6ecf024947b0407 | grep pid &quot;pid&quot;: 7630, &quot;pid&quot;: 1 &quot;type&quot;: &quot;pid&quot; 使用 nsenter 进入容器进程的各个 namespace 中 1234ubuntu@work-1:~$ sudo nsenter -t 7630 -a bashbash-5.1# ls -lh /apptotal 6M-rwxr-xr-x 1 root root 6.2M Oct 28 05:48 simple-http-server 此种方法仍然需要在容器中有 shell 程序或者相应命令。但也可以单独只指定某个 namespace。 例如，对 CoreDNS 抓包。CoreDNS 使用了 Google distroless/static 作为基础镜像的容器，需要对其进行网卡抓包，但容器中又没有 tcpdump 命令时，便可以只进入 net namespace，同时使用宿主机的 shell 和 tcpdump 程序，对其网卡进行抓包。 1234567891011121314151617181920$ kubectl -n kube-system get pod -owide | grep corednscoredns-84b58f6b4-qd4vp 1/1 Running 11 (57m ago) 30d 172.20.251.235 192.168.64.5$ kubectl -n kube-system exec -it coredns-84b58f6b4-qd4vp -- /bin/zsherror: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec &quot;...&quot;: OCI runtime exec failed: exec failed: unable to start container process: exec: &quot;/bin/zsh&quot;: stat /bin/zsh: no such file or directory: unknown$ ps -ef | grep -i coredns | grep -v greproot 1738 1618 0 22:45 ? 00:00:11 /coredns -conf /etc/coredns/Corefile$ sudo nsenter -t 1738 -n /bin/zshwork-2# ip address show dev eth03: eth0@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 66:b9:35:7b:77:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.20.251.235/32 brd 172.20.251.235 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::64b9:35ff:fe7b:7702/64 scope link valid_lft forever preferred_lft foreverwork-2# tcpdump -i eth0tcpdump: verbose output suppressed, use -v[v]... for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes 另外 nsenter 还可以单独进入其他的 namespace，分别如下： 1234567891011-a, --all enter all namespaces-m, --mount[=&lt;file&gt;] enter mount namespace-u, --uts[=&lt;file&gt;] enter UTS namespace (hostname etc)-i, --ipc[=&lt;file&gt;] enter System V IPC namespace-n, --net[=&lt;file&gt;] enter network namespace-p, --pid[=&lt;file&gt;] enter pid namespace-C, --cgroup[=&lt;file&gt;] enter cgroup namespace-U, --user[=&lt;file&gt;] enter user namespace-T, --time[=&lt;file&gt;] enter time namespace-S, --setuid &lt;uid&gt; set uid in entered namespace-G, --setgid &lt;gid&gt; set gid in entered namespace 单独进入某个 namespace 或多个 namespace 时，需要注意其他的 namespace 仍然是宿主机的默认 namespace，可能会产生一些有意思的现象，可能是个莫名奇妙的问题，需要适当拿捏这种情况。 在宿主机的文件系统中查找先找到运行中的容器 ID 123$ kubectl -n kube-system get pod coredns-84b58f6b4-qd4vp -oyaml | grep containerID - containerID: containerd://2bf4db84e5ec38f4cd2c7aebd144258bffd9e3883fcd8741d1bc535a7438cc7d containerID: containerd://833f8abbb616895dc8bd8fb15c2153adddd0dcbef8a51a540a53ed2f663ac3ee 这里有两个，其中下面那个是该 Pod 的上一个容器的 ID，处于异常状态，第一个才是处于 Running 状态的容器。 到该 Pod 所在的 Node 节点上，用 df -h | grep &lt;container-id&gt; 的方式，来获取挂载信息 12# df -h | grep 2bf4db84e5ec38f4cd2c7aebd144258bffd9e3883fcd8741d1bc535a7438cc7doverlay 20G 4.7G 15G 25% /run/containerd/io.containerd.runtime.v2.task/k8s.io/2bf4db84e5ec38f4cd2c7aebd144258bffd9e3883fcd8741d1bc535a7438cc7d/rootf 进入 /run/containerd/io.containerd.runtime.v2.task/k8s.io/&lt;container-id&gt; 目录，可以看到如下信息： 123456789101112# ls -ltotal 36-rw-r--r-- 1 root root 89 Jan 5 22:45 address-rw-r--r-- 1 root root 11554 Jan 5 22:45 config.json-rw-r--r-- 1 root root 4 Jan 5 22:45 init.pidprwx------ 1 root root 0 Jan 5 22:45 log-rw-r--r-- 1 root root 170 Jan 5 23:45 log.json-rw------- 1 root root 23 Jan 5 22:45 options.jsondrwxr-xr-x 1 root root 4096 Jan 5 22:45 rootfs-rw------- 1 root root 0 Jan 5 22:45 runtime-rw------- 1 root root 37 Jan 5 22:45 shim-binary-pathlrwxrwxrwx 1 root root 121 Jan 5 22:45 work -&gt; /var/lib/containerd/io.containerd.runtime.v2.task/k8s.io/2bf4db84e5ec38f4cd2c7aebd144258bffd9e3883fcd8741d1bc535a7438cc7d 在 rootfs 目录便是容器的目录，但是内容不是挂载完成之后的。 12345# ls rootfscoredns dev etc proc sys var# cat rootfs/etc/resolv.conf# 无输出 也可以用 /proc/&lt;pid&gt;/mounts 来查看 overlay 的挂载详情（即第一条根目录/的挂载信息） 1234567891011# cat /proc/1738/mountsoverlay / overlay ro,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/20/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/19/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/926/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/926/work 0 0.../dev/vda1 /etc/coredns ext4 ro,relatime,discard,errors=remount-ro 0 0/dev/vda1 /etc/hosts ext4 rw,relatime,discard,errors=remount-ro 0 0/dev/vda1 /dev/termination-log ext4 rw,relatime,discard,errors=remount-ro 0 0/dev/vda1 /etc/hostname ext4 ro,relatime,discard,errors=remount-ro 0 0/dev/vda1 /etc/resolv.conf ext4 ro,relatime,discard,errors=remount-ro 0 0shm /dev/shm tmpfs rw,nosuid,nodev,noexec,relatime,size=65536k,inode64 0 0tmpfs /var/run/secrets/kubernetes.io/serviceaccount tmpfs ro,relatime,size=307200k,inode64 0 0... 通过 /proc/&lt;pid&gt;/root 来查看先获取到目标 Pod 中容器的进程 pid，然后到 Pod 所在的 Node 上，直接 cd &amp; ls &amp; cat 即可。 123456789101112131415161718192021root@work-2:/home/ubuntu# cd /proc/1738/rootroot@work-2:/proc/1738/root# cat etc/coredns/Corefile.:53 { errors health { lameduck 5s } ready kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure fallthrough in-addr.arpa ip6.arpa ttl 30 } prometheus :9153 forward . /etc/resolv.conf { max_concurrent 1000 } cache 30 reload loadbalance} Reference Where are my container’s files? Inspecting container filesystems | Pixie Labs Blog (px.dev)","link":"/2023/01/06/f1a244286fc0.html"},{"title":"处理后端与Android之间WebSocket连接经常断开的情况","text":"nginx配置ws转发1234567891011121314location ~ /(mq|ws)/ { proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_read_timeout 600s; proxy_send_timeout 600s; proxy_pass http://mq-service;} 添加头部信息，这两个字段表示请求服务器升级协议为WebSocket： 12proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection $connection_upgrade; 默认情况下，连接将会在无数据传输60秒后关闭，proxy_read_timeout参数可以延长这个时间。源站通过定期发送ping帧以保持连接并确认连接是否还在使用。 proxy_read_timeout 该指令设置与代理服务器的读超时时间。它决定了nginx会等待多长时间来获得请求的响应。 这个时间不是获得整个response的时间，而是两次reading操作的时间。 proxy_send_timeout 这个指定设置了发送请求给upstream服务器的超时时间。超时设置不是为了整个发送期间，而是在两次write操作期间。 如果超时后，upstream没有收到新的数据，nginx会关闭连接 Android/微信小程序心跳机制 定时发送心跳包。如果发送失败，就进行重连。 一些关键的操作，可以在重连后，根据实际情况，立刻进行调用 参考：https://www.xncoding.com/2018/03/12/fullstack/nginx-websocket.html","link":"/2019/08/26/505be8700b2a.html"},{"title":"基础Shell脚本大法","text":"shell中的变量变量的设置规则 读取变量的时候，$PATH 与 ${PATH}是等同的 双引号内的特殊符号如$等，可以保持原有的特性。 单引号内的特殊符号则仅为一般字符(纯文本) `命令` 与 $(命令)是等同的 变量如何加1语法 1234((i=i+1));let i=i+1;x=$(( $x + 1 ))x=`expr $x + 1` 实例 123456789until example#bin/bashi=1s=0until [[ i -gt 30 ]];do ((s=s+i)); ((i=i+1));done 易混淆的变量与字符串 shell中的控制语句if语句格式： 1234567if [[ condition ]]; then #statementselif [[ condition ]]; then #statementselse #statementsfi if语句内判断参数 运算符 描述 –b 当file存在并且是块文件时返回真 -c 当file存在并且是字符文件时返回真 -d 当pathname存在并且是一个目录时返回真 -e 当pathname指定的文件或目录存在时返回真 -f 当file存在并且是正规文件时返回真 -g 当由pathname指定的文件或目录存在并且设置了SGID位时返回为真 -h 当file存在并且是符号链接文件时返回真，该选项在一些老系统上无效 -k 当由pathname指定的文件或目录存在并且设置了“粘滞”位时返回真 -p 当file存在并且是命令管道时返回为真 -r 当由pathname指定的文件或目录存在并且可读时返回为真 -s 当file存在文件大小大于0时返回真 -u 当由pathname指定的文件或目录存在并且设置了SUID位时返回真 -w 当由pathname指定的文件或目录存在并且可执行时返回真。一个目录为了它的内容被访问必然是可执行的。 -o 当由pathname指定的文件或目录存在并且被子当前进程的有效用户ID所指定的用户拥有时返回真。 文件比较运算符、字符串比较运算符、算术比较运算符* 运算符 描述 示例 -e file 如果 file存在，则为真 [ -e /var/log/syslog ] -d file 如果 file 为目录，则为真 [ -d /tmp/mydir ] -r file 如果 file可读，则为真 [ -r /var/log/syslog ] -w file 如果 file可写，则为真 [ -w /var/mytmp.txt ] -x file 如果 file可执行，则为真 [ -L /usr/bin/grep ] file1 -nt file2 如果 file1 比 file2 新，则为真 [ /tmp/install/etc/services -nt /etc/services ] file1 -ot file2 如果 file1 比 file2 旧，则为真 [ /boot/bzImage -ot arch/i386/boot/bzImage ] -z string 如果 string 长度为零，则为真 [ -z $myvar ] -n string 如果 string 长度非零，则为真 [ -n $myvar ] string1 = string2 如果 string1 与 string2 相同，则为真 [ $myvar = one two three ] string1 != string2 如果 string1 与 string2 不同，则为真 [ $myvar != one two three ] num1 -eq num2 等于 [ 3 -eq $mynum ] num1 -ne num2 不等于 [ 3 -ne $mynum ] num1 -lt num2 小于 [ 3 -lt $mynum ] num1 -le num2 小于或等于 [ 3 -le $mynum ] num1 -gt num2 大于 [ 3 -gt $mynum ] num1 -ge num2 大于或等于 [ 3 -ge $mynum ] switch语句格式： 1234case word in pattern ) ;;esac for语句 for循环的几种写法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/bin/bashfor((i=1;i&lt;=10;i++));do echo $(expr $i \\* 3 + 1);donefor i in $(seq 1 10)do echo $(expr $i \\* 3 + 1);donefor i in {1..10}do echo $(expr $i \\* 3 + 1);doneawk 'BEGIN{for(i=1; i&lt;=10; i++) print i}'for i in `ls`;do echo $i is file name\\! ;donefor i in $* ;do echo $i is input chart\\! ;donefor i in f1 f2 f3 ;do echo $i is appoint ;donelist=&quot;rootfs usr data data2&quot;for i in $list;do echo $i is appoint ;donefor file in /proc/*;do echo $file is file path \\! ;donefor file in $(ls *.sh)do echo $file is file path \\! ;done shell中的函数$1 是第一个参数。$2 是第二个参数。$n 是第n个参数。$@ 被扩展成$1 $2 $3等。$* 被扩展成$1c$2c$3c，其中c是IFS的第一个字符。$# 函数所接受的参数的个数 echo详解echo不换行刷新数据1234567#!/bin/bash while [ 1 ] do a=$(ifconfig eth0 | grep 'RX pac' | awk '{print $2}' | awk -F: '{print $NF}') echo -ne &quot;$a\\r&quot; #不换行刷新数据 done echo echo颜色输出格式: echo -e &quot;\\e[字背景颜色;字体颜色m字符串\\e[0m&quot; 0 重新设置属性到缺省设置1 设置粗体2 设置一半亮度(模拟彩色显示器的颜色)4 设置下划线(模拟彩色显示器的颜色)5 设置闪烁7 设置反向图象2J 清除屏幕0q 关闭所有的键盘指示灯1q 设置”滚动锁定”指示灯(Scroll Lock)2q 设置”数值锁定”指示灯(Num Lock)3q 设置”大写锁定”指示灯(Caps Lock)15:40H 把关闭移动到第15行，40列\\007 发蜂鸣生beep 字体颜色 背景颜色 黑 30 40 红 31 41 绿 32 42 黄 33 43 蓝 34 44 紫 35 45 深绿 36 46 白 37 47 123456789101112131415161718192021222324#!/bin/bash#定义颜色的变量RED_COLOR='\\E[1;31m' #红GREEN_COLOR='\\E[1;32m' #绿YELOW_COLOR='\\E[1;33m' #黄BLUE_COLOR='\\E[1;34m' #蓝PINK='\\E[1;35m' #粉红RES='\\E[0m'#需要使用echo -eecho -e &quot;${RED_COLOR}======red color======${RES}&quot;echo -e &quot;${YELOW_COLOR}======yelow color======${RES}&quot;echo -e &quot;${BLUE_COLOR}======green color======${RES}&quot;echo -e &quot;${GREEN_COLOR}======green color======${RES}&quot;echo -e &quot;${PINK}======pink color======${RES}&quot;echo &quot;#############################################################&quot;#直接把echo -e放到变量里面，使用的时候直接输出变量即可SETCOLOR_SUCCESS=&quot;echo -en \\\\033[1;32m&quot;SETCOLOR_FAILURE=&quot;echo -en \\\\033[1;31m&quot;SETCOLOR_WARNING=&quot;echo -en \\\\033[1;33m&quot;SETCOLOR_NORMAL=&quot;echo -en \\\\033[0;39m&quot;echo ----oldboy trainning----- &amp;&amp; $SETCOLOR_SUCCESSecho ----oldboy trainning----- &amp;&amp; $SETCOLOR_FAILUREecho ----oldboy trainning----- &amp;&amp; $SETCOLOR_WARNINGecho ----oldboy trainning----- &amp;&amp; $SETCOLOR_NORMAL","link":"/2018/01/22/17eb9048ffb4.html"},{"title":"如何下载并导入Android系统源代码到Android Studio","text":"下载源代码 对于下载源代码这种操作，官方给的说明确实也是很详细。但是奈何GFW。所以用国内的源跑得比什么都快。网上也有很多教程，但是这些感觉是copy——因为它们都比不上国内源的网站上给的操作说明。 国内有哪些Android的镜像源1. 中国科技大学2. 清华大学从上面的两个链接直接点进去便是帮助文档，跟着帮助文档一步一步走就OK了。但是我还是想偷一下懒。。。也许有一天我并不想点这两个链接，那就看下面吧。 下载步骤（同AOSP(Android) 镜像使用帮助)按照 Google 官方教程 https://source.android.com/source/downloading.html，将 https://android.googlesource.com/platform/manifest 替换为 git://mirrors.ustc.edu.cn/aosp/platform/manifest。 具体做法摘录如下（以防墙抽风）： 1. 首先下载 repo 工具。mkdir ~/binPATH=~/bin:$PATHcurl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repo 如果上述 URL 不可访问，可以用下面的：curl https://storage-googleapis.proxy.ustclug.org/git-repo-downloads/repo &gt; ~/bin/repochmod a+x ~/bin/repo 2. 然后建立一个工作目录（名字任意）mkdir WORKING_DIRECTORYcd WORKING_DIRECTORY 3. 初始化仓库：repo init -u git://mirrors.ustc.edu.cn/aosp/platform/manifest 如果提示无法连接到gerrit.googlesource.com，可以编辑 ~/bin/repo，把 REPO_URL 一行替换成下面的：REPO_URL = 'https://gerrit-googlesource.proxy.ustclug.org/git-repo'如果需要某个特定的 Android 版本（Android 版本列表）：repo init -u git://mirrors.ustc.edu.cn/aosp/platform/manifest -b android-4.0.1_r1 4. 同步源码树（以后只需执行这条命令来同步）：repo sync 5. 已有仓库如何改用科大源如果您已经从官方同步了 AOSP 仓库，现在希望使用科大的 AOSP 仓库，请修改.repo/manifests.git/config，将url = https://android.googlesource.com/platform/manifest修改成url = git://mirrors.ustc.edu.cn/aosp/platform/manifest即可。 导入到 Android Studio 之前弄过一次，过了这么久再弄时就已经忘记得差不多了，特地记下来。经过这样的配置之后，可以实现点击一些类时进行跳转。R文件还是没有搞定，其中的资源还是无法进行跳转，不过这样基本上已满足工作上的需求。 修改AS配置文件在AS的bin目录下，打开studio64.vmoptions文件，修改成如下数值： 12-Xms1024m-Xmx1024m 大一些应该也没关系。 生成AS项目配置文件1、首先全局编译一次。2、查看out/host/linux-x86/framework/idegen.jar是否存在；若已不存在，先执行下面命令以生成它： 123source build/envsetup.shlunch [选择刚全局编译时的参数]mmm development/tools/idegen/ 3、执行以下命令以生成所需配置文件。 1development/tools/idegen/idegen.sh 导入系统源代码至AS1、此时在根目录下，就已经生成了android.ipr、android.iml，可以将整个源代码导入AS。2、（可选）设置模块过滤有些不想导入AS的模块，可以通过在android.iml中加入excludeFolder，达到过滤效果。 123456789101112131415&lt;excludeFolder url=&quot;file://$MODULE_DIR$/.repo&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/abi&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/frameworks/base/docs&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/art&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/bionic&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/bootable&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/out&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/pdk&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/prebuilts&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/sdk&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/system&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/tools&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/trusty&quot;/&gt;&lt;excludeFolder url=&quot;file://$MODULE_DIR$/vendor&quot;/&gt;... 3、第一次导入时间有点长，耐心等待 配置AS的JDK、SDK下面的这些操作，是为了让在看代码的时候，能够自由、正确地显示、跳转到相应的地方。在上一步操作之后的等待期间刚好让我们来配置一下JDK和SDK。在AS中参照下图Project Structure设置，在SDKs设置中加入必须的JDK，SDK。创建一个新的JDK,可以取名为1.7(No Libraries)，然后删除classpath标签页下面的jar文件。 这样可以确保使用Android源码里的库文件。之后将1.7(No Libraries)作为Android SDK要使用的Java SDK。如下图之后在Project标签中的Project SDK中选择对应的Android API版本。 结果还没弄得太好，R文件还没导入，不过感觉这个不是很重要。 参考：http://blog.csdn.net/heqiangflytosky/article/details/62236001http://blog.csdn.net/aaa111/article/details/43227367http://blog.csdn.net/murphykwu/article/details/52117907https://www.cnblogs.com/qianxudetianxia/p/3721202.html导入Eclipse可以参考罗升阳的PPT简略文档：https://wenku.baidu.com/view/2d820c973b3567ec112d8a91.html","link":"/2018/01/21/6591aea996f1.html"},{"title":"在 Kubernetes 中遇见 NFS 存储","text":"当在 K8s 中使用到 NFS 类型的存储时，首先需要搭建一个 NFS 服务，另外注意一个挂载路径问题，就能愉快地玩耍它啦。 安装NFS服务1sudo apt install -y nfs-kernel-server rpcbind 创建目录 ~/nfs 作为共享目录，并在该目录下，新建一个文件 date &gt; time.txt。 配置NFS服务添加共享目录配置：/etc/exports 1234567891011# /etc/exports: the access control list for filesystems which may be exported# to NFS clients. See exports(5).## Example for NFSv2 and NFSv3:# /srv/homes hostname1(rw,sync,no_subtree_check) hostname2(ro,sync,no_subtree_check)## Example for NFSv4:# /srv/nfs4 gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check)# /srv/nfs4/homes gss/krb5i(rw,sync,no_subtree_check)#/home/ubuntu/nfs *(rw,sync,no_root_squash) 访问权限选项 rw 可读写 ro 只读 用户映射选项 all_squash 将远程访问的所有普通用户及所属组都映射为匿名用户或用户组（nfsnobody） no_all_squash：与all_squash取反（默认设置） root_squash：将root用户及所属组都映射为匿名用户或用户组（默认设置） no_root_squash：与rootsquash取反 anonuid=xxx：将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户（UID=xxx） anongid=xxx：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID=xxx） 其它选项 secure：限制客户端只能从小于1024的tcp/ip端口连接nfs服务器（默认设置） insecure：允许客户端从大于1024的tcp/ip端口连接服务器 sync：将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性 async：将数据先保存在内存缓冲区中，必要时才写入磁盘 wdelay：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置） no_wdelay：若有写操作则立即执行，应与sync配合使用 subtree：若输出目录是一个子目录，则nfs服务器将检查其父目录的权限(默认设置) no_subtree：即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率 其他操作启动/重启NFS服务：/etc/init.d/nfs-kernel-server 12sudo /etc/init.d/nfs-kernel-server startsudo /etc/init.d/nfs-kernel-server restart 刷新NFS配置：exportfs 12# 重新读取 /etc/exports 配置信息exportfs -r 查看共享的目录：showmount 123456# 本机共享目录showmount -e# 已连上的NFS服务的共享目录showmount -a# 查询指定服务器上共享的目录showmount -e &lt;nfs-ip&gt; 在别的机器上面进行 mount 操作 1sudo mount -t nfs &lt;nfs-server-ip&gt;:/home/ubuntu/nfs /data/backups -o nolock 进入该目录，可以看到之前的 time.txt文件，进行修改后，可在服务器所在机器上看到变更。 12345$ cd /data/backups$ lspvc-1e8ff556-d183-4471-92cd-3869ffbcb589 pvc-9f429e24-c6da-45c9-9860-f4e338f61068 time.txt$ cat time.txtMon Jul 11 01:19:44 AM UTC 2022 卸载目录 1sudo umount /data/backups 权限问题说明 客户端连接时候，对普通用户的检查 如果明确设定了普通用户被映射的身份，那么此时客户端用户的身份转换为指定用户； 如果NFS server上面有同名用户，那么此时客户端登录账户的身份转换为NFS server上面的同名用户； 如果没有明确指定，也没有同名用户，那么此时用户身份被映射成nfsnobody； 客户端连接的时候，对root的检查 如果设置no_root_squash，那么此时root用户的身份被映射为NFS server上面的root； 如果设置了all_squash、anonuid、anongid，此时root 身份被映射为指定用户； 如果没有明确指定，此时root用户被映射为nfsnobody； 如果同时指定no_root_squash与all_squash 用户将被映射为 nfsnobody，如果设置了anonuid、anongid将被映射到所指定的用户与组； Kubernetes中添加NFS支持 csi-driver-nfs/charts at master · kubernetes-csi/csi-driver-nfs (github.com) csi-driver-nfs/driver-parameters.md at master · kubernetes-csi/csi-driver-nfs (github.com) 添加 StorageClass 1234567891011121314apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: nfs-csiprovisioner: nfs.csi.k8s.ioparameters: server: &lt;server-ip&gt; share: / mountPermissions: &quot;0777&quot; # csi.storage.k8s.io/provisioner-secret is only needed for providing mountOptions in DeleteVolume # csi.storage.k8s.io/provisioner-secret-name: &quot;mount-options&quot; # csi.storage.k8s.io/provisioner-secret-namespace: &quot;default&quot;reclaimPolicy: DeletevolumeBindingMode: Immediate 遇到的坑如果 NFS 服务 /etc/exports 里设置的共享路径是 /home/ubuntu/nfs，在 StorageClass 中 share 字段如果填 / 的话，挂载时会报权限不足。 通过 csi-driver-nfs 的日志可以发现，在创建 PV 时，用的路径是 /pod-xxxxxx。 Pod 启动失败，报 0/1 nodes are available: 1 pod has unbound immediate PersistentVolumeClaims。 PVC 处于 Pending 状态，报 failed to provision volume with StorageClass &quot;nfs-csi&quot;: rpc error: code = Internal desc = failed to make subdirectory: mkdir /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2: read-only file system。 csi-nfs-controller 日志： 1234567891011I0720 09:53:52.378454 1 controllerserver.go:285] internally mounting 192.168.59.102:/ at /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2I0720 09:53:52.378935 1 controllerserver.go:300] internally unmounting /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2I0720 09:53:52.378942 1 nodeserver.go:163] NodeUnpublishVolume: unmounting volume 192.168.59.102##pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2# on /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2I0720 09:53:52.378955 1 mount_helper_common.go:99] &quot;/tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2&quot; is a mountpoint, unmountingI0720 09:53:52.378959 1 mount_linux.go:294] Unmounting /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2W0720 09:53:52.387057 1 mount_helper_common.go:133] Warning: &quot;/tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2&quot; is not a mountpoint, deletingI0720 09:53:52.387102 1 nodeserver.go:168] NodeUnpublishVolume: unmount volume 192.168.59.102##pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2# on /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2 successfullyE0720 09:53:52.387108 1 utils.go:93] GRPC error: rpc error: code = Internal desc = failed to make subdirectory: mkdir /tmp/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2/pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2: read-only file systemI0720 09:54:48.201408 1 utils.go:88] GRPC call: /csi.v1.Controller/CreateVolumeI0720 09:54:48.201568 1 utils.go:89] GRPC request: {&quot;capacity_range&quot;:{&quot;required_bytes&quot;:1000000000},&quot;name&quot;:&quot;pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2&quot;,&quot;parameters&quot;:{&quot;csi.storage.k8s.io/pv/name&quot;:&quot;pvc-ca0ab165-9aa5-42a4-ae15-f4fd036142d2&quot;,&quot;csi.storage.k8s.io/pvc/name&quot;:&quot;data-primary-mariadb-cluster-primary-0&quot;,&quot;csi.storage.k8s.io/pvc/namespace&quot;:&quot;default&quot;,&quot;mountPermissions&quot;:&quot;0777&quot;,&quot;server&quot;:&quot;192.168.59.102&quot;,&quot;share&quot;:&quot;/&quot;},&quot;volume_capabilities&quot;:[{&quot;AccessType&quot;:{&quot;Mount&quot;:{}},&quot;access_mode&quot;:{&quot;mode&quot;:7}}]} 在其他 Linux 机器上面，使用 mount 命令尝试挂载： 123456789$ sudo mount -t nfs 192.168.59.102:/ /tmp/nfs$ ls /tmp/nfs/home$ ls /tmp/nfs/homeubuntu$ ls /tmp/nfs/home/ubuntunfs$ ls /tmp/nfs/home/ubuntu/nfspvc-1e8ff556-d183-4471-92cd-3869ffbcb589 pvc-9f429e24-c6da-45c9-9860-f4e338f61068 time.txt 看到这里本能地想到了 StorageClass share 字段应当修改成 /home/ubuntu/nfs 如果填写 /，会将 NFS 服务上的 / 挂载在 K8s 所在机器的 /tmp/pvc-xxxx 下，当在 /tmp/pvc-xxx 目录中创建子目录时，即在 NFS 服务器上的 / 下创建目录，理所应当会失败。 Reference Linux mount命令详解：挂载Linux系统外的文件 (biancheng.net) NFS服务配置解析详解_weixin_33753845的博客-CSDN博客","link":"/2022/07/20/310a860b4b36.html"},{"title":"如何在容器中对镜像进行操作","text":"Docker VS Podman由于只需要对镜像进行 pull、tag、push 操作，因此不需要全套的 Docker 服务，这里选择了 Podman。Podman 有一个子命令就是 buildah，它主要负责镜像相关的操作，这样会更加精简。 问题描述在镜像中添加完 buildah 的依赖后，在容器中运行 buildah 时，报如下错误： 解决方案 此问题的其中一个解决方案为：在宿主机中，修改 /proc/sys/user/max_user_namespaces 文件里面的值。但若采取此种方案，会导致线上环境 K8S 所在的宿主机，可能也要修改，这样的操作是不太可行的。 同事的踩坑经验：可以在 k8s 的 yaml 配置中，为 pod 开启特权模式，这样可以避免使用 user namespace。在 pod 定义处，添加配置，修改如下： 12securityContext: privileged: true 修改后，buildah 在容器中不再报错。但对上面的修改，一方面持有安全疑虑，另一方面不太明白其中的原理。 为什么为什么在本地的 K8S 环境中 rosco 执行没有问题？ 为什么将 pod 设置成特权模式之后便能正常执行 buildah? 一篇比较具有参考价值的相关 issue。通过上述 issue 得知，即使使用 root 启动 buildah ，还是需要 user namespace 来获取相应的 capabilities。 privileged 参数应该是会添加所有的 capabilities 到容器中(参考，Docker文档)。 如何改进只给 buildah 所需的 Linux capabilities，初步验证在 testing 运行 ok。 12345securityContext: # privileged: true capabilities: add: - &quot;SYS_ADMIN&quot; 其中 CAP_SYS_ADMIN 的作用是：允许执行系统管理任务，如加载或卸载文件系统、设置磁盘配额等。","link":"/2021/05/17/5d7dfb8329d3.html"},{"title":"如何实现在公网对私有部署 k8s 集群的访问","text":"","link":"/2021/05/17/7ae19a660f12.html"},{"title":"如何快速确认链表上是否存在环","text":"这个问题遇到过很多次了，但是并不是说每次都很清楚。所以这次用golang的代码来实现一遍，加深理解与记忆。 如果一个链表上不存在环，那么一定能够遍历完链表中所有的Node节点；如果存在环，那么可以想象成存在一个圆形操场。在一个圆里面，如果有两个人，行走的速度不一样，那么一定会有相遇的那一刻。最佳的解法便是基于此想法，当然也有其他的解法，比如说将每个遍历的节点放进一个set里面，如果存在过，那么就存在环。 数据结构： 1234type Node struct { index int next *Node} 构建链表，随机选择是否生成环 12345678910111213141516171819202122232425262728293031323334func createNodeList() *Node{ rand.Seed(time.Now().Unix()) length := rand.Intn(100) + 1 head := new(Node) var tail *Node // 构建链表 for idx ,curNode := 1, head; idx &lt;= length; idx ++ { curNode.index = idx if idx != length { curNode.next = new(Node) curNode = curNode.next } else { tail = curNode } } buildRing := rand.Intn(2) if buildRing == 0 { // 构建环 enterRingIndex := rand.Intn(length) + 1 enterRingNode := head for idx:= 2; idx &lt;= enterRingIndex; idx ++{ enterRingNode = enterRingNode.next } tail.next = enterRingNode fmt.Println(&quot;length : &quot;, length, &quot;, enter ring index : &quot;, enterRingIndex, &quot;, Ring length : &quot;, length - enterRingIndex + 1) } else { fmt.Println(&quot;don't build ring&quot;) } return head} 输出链表，用于debug 123456func outputNodeList(head * Node) { for head != nil { fmt.Print(head.index, &quot; &quot;) head = head.next }} 使用两个下标，用于抽象表示圆形操场中的两个人，leader走前面，每次走两步，follower走后面，每次走一步，如果相遇，返回相遇时的Node节点。 1234567891011121314151617func nodeListExistRing(head * Node) *Node { leader, follower := head, head for leader != nil &amp;&amp; follower != nil { leader = leader.next if leader == nil { return nil } leader = leader.next follower = follower.next if (leader == follower) { return leader } } return nil} 如果链表中存在环，那么环的长度就等于：follower再走一圈时走过的步长。 123456789func calRingLength(meetNode * Node) int { curNode := meetNode curNode = curNode.next count := 1 for ; curNode != meetNode; count ++ { curNode = curNode.next; } return count} 如果链表存在环，那么入环点等于将leader指向head后，并以每次一步的速度往前，直到与follower再次相遇，此时的节点便是入环点。 如何证明上面的步骤是正确的？ 也就是说，入环时走过的路程，等于S2加上(S1+S2)的整数倍，如果leader步长变成1，并且从A点出发到达B点，那么走过的路程D，一定会等于S2+(n-1)(S1 + S2)，也就是说一定会在B点相遇。B点即入环点。 123456789func calEnterRingIndex(meetNode * Node, head * Node) int { var enterRingIndex = 0; for head != meetNode { head = head.next meetNode = meetNode.next enterRingIndex ++ } return enterRingIndex + 1} 启动类，将前面过程，按照想要的逻辑拼装在一起。 123456789func main() { head := createNodeList() meetNode := nodeListExistRing(head) if meetNode == nil { outputNodeList(head) } else { fmt.Println(&quot;RING EXIST!&quot;, &quot;, Ring length: &quot;, calRingLength(meetNode), &quot;, Enter Ring Index : &quot;, calEnterRingIndex(meetNode, head)) }} 附录： 文中公式、图及推算过程的latex源码: 1234567891011121314151617181920212223242526272829303132\\begin{tikzpicture} % \\draw[dashed, file=blue!20]{0, 0} circle(0.5cm); \\draw(0, 0) circle (1.5cm); \\coordinate[label = above:$O$] (O) at (0, 0); \\node at(0, 0)[circle,fill,inner sep=1pt]{}; \\coordinate[label = right:$C$] (C) at (-30:1.5); \\node at(C)[circle,fill,inner sep=1pt]{}; \\coordinate[label = below right:$S_1$] (S1) at (-60:1.5); \\coordinate[label = left:$S_2$] (S2) at (120:1.5); \\coordinate[label = below: $B$] (B) at (-90:1.5); \\node at(B)[circle,fill,inner sep=1pt]{}; \\coordinate[label = below: $A$] (A) at (-7, -1.5); \\node at(A)[circle,fill,inner sep=1pt]{}; \\draw (A) -- (B) node[above, midway] (line) {$D$};\\end{tikzpicture}设n为leader与follower在相遇前，比follower多走的圈数，那么便存在\\[ 2(D + S_1) = D + S_1 + n * (S_1 + S_2) \\]化简得：\\[ 2*D + 2*S_1 = D + S_1 + n * (S_1 + S_2) \\]\\[ D + S_1 = n * (S_1 + S_2) \\]\\[ D = n * (S_1 + S_2) - S_1 \\]\\[ D = (n - 1) * (S_1 + S_2) + S_1 + S_2 - S_1 \\]即：\\[ D = (n - 1) * (S_1 + S_2) + S_2 \\] 参考：https://zouyu4524.github.io/blog/tikz-plot/","link":"/2020/03/16/a3995576f721.html"},{"title":"如何用 random9 求 random10","text":"大意如果有一个 random9() 函数，可以产生 1-9 的 整数随机数，请利用 random9 实现 random10 函数，返回 1-10 的整数随机数 要点random9 只能随机产生 1-9 范围内的数，也就是 1-9 出现的概率是一样的；而如果要随机产生 1-10 范围的整数，就需要 1-10 出现的概率是一样的。 所以问题就变成了：如何通过等概率出现的 1-9 产生等概率的 1-10 ？ 解决 以一种马后炮的思想尝试解释一下，看能不能说服自己。 random9 显然产生不了 10，所以肯定需要用到加/乘法，那如何产生 10？ random9 + n如果只用加法，这样便可以随机产生[n+1, n+9]范围的整数，可以达到10，但是肯定不能产生[1, 10]范围内的数，所以这样不行。 random9 * n如果只用乘法，这样便可以随机产生[n, 2n, 3n, …, 9n]，这样产生的数显然也不可能做到随机产生[1, 10]，因为中间存在空位，并且无法保证是等概率的。 要想等概率产生[1, 10]范围的数，可以利用等概率产生[1, 20]范围的整数，然后%10 + 1。这里有个重点，怎么样才能等概率？ 既然 random9 加/乘一个固定的数，不能达到目的，那么如果加/乘一个不固定但是等概率出现的某一范围的数（也就是 random9）是否可行呢？ random9 + random9能出现的最大数：9 + 9 = 18；能出现的最小数：1 + 1 = 2先考虑能否等概率出现10，先看2-18是否为等概率出现的。出现2、18的概率都是1/81，但出现3的概率是2/81，即1+2和2+1，这个就不是等概率出现的了，所以不能做到随机产生。 random9 * random9最大数：81，最小数：1。是否连续？否。是否等概率？否。最大、小数的概率是1/81。但是9的概率是3/81。 random9 * n + random9random9 * n 可等概率产生 1n,2n,3n…9n，如果加上 random9，是否等概率取决于1n和2n之间的间距，如果刚好等于9，那么加上random9就有希望产生连续、并且等概率的整数，范围为：[10, 90]。 如何通过等随机产生的 [10, 90] 来随机产生 [1, 10]?将随机产生的 [10, 90] 限制为 [10, 89]，然后模10，便可以获得随机产生的[0, 9]，然后再加1，即可得到随机产生的[1, 10]。 总结为：先通过 random9 * 9 + random9 随机产生[10, 90]范围的整数，然后限制随机产生 [10, 89]，再模10，得到[0, 9]，再加1即可得到[1, 10]。 所以最终的代码： 12while ((result = 9 * random9() + random9()) &gt;= 90);return result % 10 + 1; 但是，我看到的答案是这样的，还不太明白这两者之间有什么差别。 1234567public int rand10() { int result; do { result = rand9()+(rand9()-1)*9; } while (result &gt; 80); return 1 + (result - 1) % 10;} 更加简单粗暴的方式但是这个问题是由 random7 求 random10，不过思想是相通的。 感觉这一种方式更加通俗易懂，获取一维数组是随机的，获取第二维数组也是随机，整个过程都是随机的。 123456789101112public static int random10() { int[][] seed = { { 1, 2, 3, 4, 5, 6, 7 }, { 8, 9, 10, 11, 12, 13, 14 }, { 15, 16, 17, 18, 19, 20, 11 }, { 22, 23, 24, 25, 26, 27, 28 }, { 29, 30, 31, 32, 33, 34, 35 }, { 36, 37, 38, 39, 40, 41, 42 }, { 43, 44, 45, 46, 47, 48, 49 } }; int result; do { result = seed[random7() - 1][random7() - 1]; } while (result &gt; 40); return result % 10 + 1;}","link":"/2020/06/20/4819a3af8e85.html"},{"title":"安卓系统应用调试脚本","text":"这是一个对之前写的脚本的记录档案，自己也看不太懂当时的写法了，羞愧。用一个 repo 放这些脚本代码感觉有些浪费，干脆整个文章记录曾经的那段历史吧！ 这代码的主要目的就是想少敲点命令，一步到位，做一个快男！ 说明 - AndroidROMToolsAndroid run script tools for debugging system apps or frameworks. This was used by myself when debugging system apps or frameworks. In this project, module names was not given to avoid the project name, but the main structure was reminded. 此脚本主要分成一个入口与两个模块，详细的树状图如下： 123456789101112131415.├── README.md├── btool├── modules│ ├── handleFramework.sh│ ├── handleXxxx.sh│ └── handleXxxxxx.sh└── utils ├── handleSpecificTask.sh ├── init.sh ├── printOperationTip.sh ├── tipWhenNotImplement.sh └── tipWhenParametersError.sh2 directories, 10 files 入口名字叫 btool，为啥起这个怪名字，我也不知道。 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bash# initialize variablesvar1=$1var2=$2var3=$3UTILS_DIR=~/.PersonalTools/utilsMODULES_DIR=~/.PersonalTools/modulescase $var1 in &quot;init&quot; ) ${UTILS_DIR}/init.sh ;; &quot;log&quot; ) adb logcat -b main \\*:E | grep &quot;TAG&quot; ;; &quot;wxxxx&quot; ) ${MODULES_DIR}/handleXXXX.sh $var2 $var3 ;; &quot;txxxx&quot; ) ${MODULES_DIR}/handlexxxxxx.sh $var2 $var3 #${UTILS_DIR}/tipWhenNotImplement.sh $var1 ;; &quot;txxxx&quot; ) ${UTILS_DIR}/tipWhenNotImplement.sh $var1 ;; &quot;mxxxx&quot; ) ${UTILS_DIR}/tipWhenNotImplement.sh $var1 ;; * ) #${UTILS_DIR}/tipWhenParametersError.sh init xxxxxx *xxxxxx* *xxxxxx* *xxxxxx* if [ &quot;${var1}&quot; == &quot;&quot; ]; then ${UTILS_DIR}/tipWhenParametersError.sh init xxxx *xxxx* *xxxxxx* *xxxxxx* elif [ -f ${MODULES_DIR}/$var1.sh ]; then #${UTILS_DIR}/tipWhenParametersError.sh init xxxxxx *xxxxxx* *xxxxxx* *xxxxxx* ${MODULES_DIR}/$var1.sh else ${UTILS_DIR}/tipWhenParametersError.sh init xxxxxx *txxxxxx* *txxxxxx* *mxxxxxx* ${UTILS_DIR}/tipWhenNotImplement.sh &quot;${var1}&quot; fi ;;esacexit Utils 初始化：init.sh 123#!/bin/bashadb rootadb wait-for-device remount 打印带颜色的字符：printOperationTip.sh 123456#!/bin/bash#echo -e &quot;\\e[31;43m-----------------------------------------------------------\\e[0m&quot;echo &quot;&quot;echo -e &quot;\\e[31;47m\\t&quot;$1&quot;\\t\\e[0m&quot;echo &quot;&quot;#echo -e &quot;\\e[31;43m-----------------------------------------------------------\\e[0m&quot; 模块未完成的告警提示：tipWhenNotImplement.sh 12#/bin/bashecho -e &quot;\\nModule &lt; \\e[41m$1\\e[0m \\e[31m&gt;NOT IMPELEMNT!\\e[0m\\n&quot; 参数错误提示：tipWhenParametersError.sh 123456789101112131415161718192021#/bin/bash#clearecho &quot;&quot;echo -e &quot;\\e[31;42mOops! Please give me the \\e[0m\\e[1;5;40;31mcorrect\\e[0m\\e[31;42m parameters!!!\\e[0m&quot;echo &quot;&quot;params=&quot;&quot;cnt=1;for i in $@;do if [ $cnt != 1 ]; then params=$params&quot;,\\e[1;5;31;40m &quot;$i&quot; \\e[0m&quot; else params=&quot;\\e[1;5;31;40m &quot;$i&quot; \\e[0m&quot; fi cnt=$(($cnt+1))doneif [ $cnt == 1 ]; then params=&quot;\\e[4;31mNONE\\e[0m&quot;fiecho -e &quot;\\e[33mavaliable parameters are :\\e[0m&quot; $params&quot;\\n&quot; 处理特定任务：handleSpecificTask.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#!/bin/bashUTILS_DIR=~/.PersonalTools/utilsOP_INDEX=$1PROJECT_SRC_DIR=$2APP_SRC_DIR=$3APP_OUT_DIR=$4APP_REMOTE_DIR=$5APP_PKG_NAME=$6PROJECT_LUNCH_IDX=$7#for i in $@; do #statements# echo $i#done# for compile SnapCamera APK in #if [ -f /tmp/btoollog ]; then #echo &quot;exist&quot;#else #echo &quot;/tmp/btoollog not exists&quot; #mkdir /tmp/btoollog#fifunction compileModifiedSourceCode(){ ${UTILS_DIR}/printOperationTip.sh &quot;&lt;Prepare to Compile&gt;&quot; cd ${PROJECT_SRC_DIR} pwd source build/envsetup.sh lunch ${PROJECT_LUNCH_IDX} cd ${APP_SRC_DIR} pwd mm}function makeSureCloseCompletelyAndReopen(){ ${UTILS_DIR}/printOperationTip.sh &quot;&lt;Prepare to force-stop APK&gt;&quot; echo -e &quot;\\n\\e[32m\\ttry to stop app\\e[0m&quot; adb shell am force-stop ${APP_PKG_NAME} echo -e &quot;&quot; echo -e &quot;\\n\\e[32m\\ttry to start app\\e[0m&quot; adb shell am start -n ${APP_PKG_NAME} echo -e &quot;&quot;}function pushCompiledAPK2Phone(){ ${UTILS_DIR}/printOperationTip.sh &quot;&lt;Prepare to Push APK&gt;&quot; cd ${APP_OUT_DIR} #pwd #echo &quot;${APP_OUT_DIR}&quot; adb push . ${APP_REMOTE_DIR} #adb push oat/arm64/$appname.odex /system/priv-app/$appname/oat/arm64/$appname.odex if [ $? -eq 0 ]; then echo -e &quot;\\n\\e[32m\\tpush app to phone successfully\\e[0m&quot; fi echo -e &quot;&quot;}function checkPushedFilesStatus(){ ${UTILS_DIR}/printOperationTip.sh &quot;&lt;Prepare to Check Push Result&gt;&quot; adb shell ls -l ${APP_REMOTE_DIR} ${APP_REMOTE_DIR}/oat/arm64/ if [ $? -eq 0 ]; then echo -e &quot;\\n\\e[32m\\tconnect to phone successfully\\e[0m&quot; fi echo -e &quot;&quot;}case $1 in&quot;0&quot; ) compileModifiedSourceCode pushCompiledAPK2Phone makeSureCloseCompletelyAndReopen checkPushedFilesStatus ;;&quot;1&quot; ) compileModifiedSourceCode ;;&quot;2&quot; ) pushCompiledAPK2Phone ;;&quot;3&quot; ) makeSureCloseCompletelyAndReopen ;;&quot;4&quot; ) checkPushedFilesStatus ;;&quot;subl&quot; ) subl ${APP_SRC_DIR} ;;&quot;src&quot; ) echo ${APP_SRC_DIR} ;;* ) ${UTILS_DIR}/tipWhenParametersError.sh 0 1 2 3 4 subl src echo -e &quot;\\t\\e[1;4;5;31;40m 0 \\e[0m\\t : \\e[33m1 -&gt; 2 -&gt; 3 -&gt; 4\\e[0m&quot; echo -e &quot;\\t\\e[1;4;5;31;40m 1 \\e[0m\\t : \\e[33mCompile Modified Source Code\\e[0m&quot; echo -e &quot;\\t\\e[1;4;5;31;40m 2 \\e[0m\\t : \\e[33mPush Compiled APK 2 Phone\\e[0m&quot; echo -e &quot;\\t\\e[1;4;5;31;40m 3 \\e[0m\\t : \\e[33mClose App\\e[0m&quot; echo -e &quot;\\t\\e[1;4;5;31;40m 4 \\e[0m\\t : \\e[33mShow App Info\\e[0m&quot; echo -e &quot;\\t\\e[1;4;5;31;40m subl \\e[0m\\t : \\e[33mOpen App Src With Sublime Text\\e[0m\\n&quot; echo -e &quot;\\t\\e[1;4;5;31;40m src \\e[0m\\t : \\e[33mPrint SRC path\\e[0m\\n&quot; ;;esac 模块 Android Framework 处理：handleFramework.sh 123456789101112131415161718#!/bin/bashSRC_HOME=/home/ckt/work/xxxxxx/msm8909_go/LINUX/android/frameworks/baseOUT_HOME=/home/ckt/work/xxxxxx/msm8909_go/LINUX/android/out/target/product/msm8909go/system/frameworkcd /home/ckt/work/xxxxxx/msm8909_go/LINUX/android/source build/envsetup.shlunch 29make frameworkmake snodadb push ${OUT_HOME}/arm/boot.oat /system/framework/arm/adb push ${OUT_HOME}/arm/boot.art /system/framework/arm/adb push ${OUT_HOME}/framework.jar /system/framework/adb push ${OUT_HOME}/framework-res.apk /system/framework/adb reboot bootloader 桌面时钟：handleXxxx.sh 1234567891011121314151617181920212223#/bin/bashUTILS_DIR=~/.PersonalTools/utilsPROJECT_DIR=&quot;/home/ckt/work/android8&quot;PROJECT_SRC_DIR=${PROJECT_DIR}PROJECT_OUT_DIR=${PROJECT_DIR}/out/target/product/msm8953_64PROJECT_LUNCH_IDX=39DESKCLOCK_SRC_DIR=${PROJECT_SRC_DIR}/packages/apps/DeskClock/DESKCLOCK_OUT_DIR=${PROJECT_OUT_DIR}/system/app/DeskClock/DESKCLOCK_PKG_NAME=com.android.deskclockDESKCLOCK_REMOTE_DIR=/system/app/DeskClockcase $1 in &quot;deskclock&quot; ) ${UTILS_DIR}/handleSpecificTask.sh $2 ${PROJECT_SRC_DIR} ${DESKCLOCK_SRC_DIR} ${DESKCLOCK_OUT_DIR} ${DESKCLOCK_REMOTE_DIR} ${DESKCLOCK_PKG_NAME} ${PROJECT_LUNCH_IDX} ;; * ) ${UTILS_DIR}/tipWhenParametersError.sh deskclock ;;esac 多媒体应用：handleXxxxxx.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bashUTILS_DIR=~/.PersonalTools/utilsPROJECT_DIR=&quot;/home/ckt/work/xxxxxxx/LINUX/android&quot;PROJECT_SRC_DIR=&quot;${PROJECT_DIR}&quot;PROJECT_OUT_DIR=&quot;${PROJECT_DIR}/out/target/product/msm8909go&quot;PROJECT_LUNCH_IDX=29SOUNDRECORDER_SRC_DIR=&quot;${PROJECT_SRC_DIR}/packages/apps/SoundRecorder/&quot;SOUNDRECORDER_OUT_DIR=&quot;${PROJECT_OUT_DIR}/system/priv-app/SoundRecorder/&quot;SOUNDRECORDER_PKG_NAME=com.android.soundrecorderSOUNDRECORDER_REMOTE_DIR=/system/priv-app/SoundRecorderGALLERY_SRC_DIR=&quot;${PROJECT_SRC_DIR}/packages/apps/Gallery2/&quot;GALLERY_OUT_DIR=&quot;${PROJECT_OUT_DIR}/system/app/Gallery2/&quot;GALLERY_PKG_NAME=com.android.gallery3dGALLERY_REMOTE_DIR=/system/app/Gallery2SNAPDRAGONMUSIC_SRC_DIR=&quot;${PROJECT_SRC_DIR}/packages/apps/Music/&quot;SNAPDRAGONMUSIC_OUT_DIR=&quot;${PROJECT_OUT_DIR}/system/app/Music/&quot;SNAPDRAGONMUSIC_PKG_NAME=com.android.musicSNAPDRAGONMUSIC_REMOTE_DIR=/system/app/MusicCLOCK_SRC_DIR=&quot;${PROJECT_SRC_DIR}/packages/apps/DeskClock&quot;CLOCK_OUT_DIR=&quot;${PROJECT_OUT_DIR}/system/app/DeskClock&quot;CLOCK_PKG_NAME=com.android.deskclockCLOCK_REMOTE_DIR=/system/app/DeskClockcase $1 in &quot;soundrecorder&quot; ) ${UTILS_DIR}/handleSpecificTask.sh $2 ${PROJECT_SRC_DIR} ${SOUNDRECORDER_SRC_DIR} ${SOUNDRECORDER_OUT_DIR} ${SOUNDRECORDER_REMOTE_DIR} ${SOUNDRECORDER_PKG_NAME} ${PROJECT_LUNCH_IDX} ;; &quot;gallery&quot; ) ${UTILS_DIR}/handleSpecificTask.sh $2 ${PROJECT_SRC_DIR} ${GALLERY_SRC_DIR} ${GALLERY_OUT_DIR} ${GALLERY_REMOTE_DIR} ${GALLERY_PKG_NAME} ${PROJECT_LUNCH_IDX} ;; &quot;music&quot; ) ${UTILS_DIR}/handleSpecificTask.sh $2 ${PROJECT_SRC_DIR} ${SNAPDRAGONMUSIC_SRC_DIR} ${SNAPDRAGONMUSIC_OUT_DIR} ${SNAPDRAGONMUSIC_REMOTE_DIR} ${SNAPDRAGONMUSIC_PKG_NAME} ${PROJECT_LUNCH_IDX} ;; &quot;clock&quot; ) ${UTILS_DIR}/handleSpecificTask.sh $2 ${PROJECT_SRC_DIR} ${CLOCK_SRC_DIR} ${CLOCK_OUT_DIR} ${CLOCK_REMOTE_DIR} ${CLOCK_PKG_NAME} ${PROJECT_LUNCH_IDX} ;; * ) ${UTILS_DIR}/tipWhenParametersError.sh soundrecorder gallery music clock ;;esac 目前这些脚本对我来说，已无实际用途，不能保证准确性，只是做一个纪念，纪念那段无知却在挣扎的时光。","link":"/2018/04/19/858b4c830e1e.html"},{"title":"如何在macOS中编译OpenJDK10源代码","text":"这段时间准备开始学习《深入理解Java虚拟机》，先搭个可以调试的环境出来。按照书中的配置，感觉有许多问题的，这篇文章就用来记录成功编译OpenJDK源代码的一些过程，以及其中的一些配置。 配置信息综述系统版本：macOS 10.14 BetaOpenJDK版本：jdk-10+46，TAG链接、zip包下载链接、unofficial-openjdk项目主页。 何处下载OpenJDK源代码地方有两个， 其一，是书中所说的通过Mercurial代码管理版本管理工具从Repository中直接获取源码(Repository为http://hg.openjdk.java.net)，这种方法不是特别爽，听说有速度问题； 其二，就是使用类似源码镜像的方式去下载。这里可以给出一个连接：https://github.com/unofficial-openjdk/openjdk。在这个网站上，可以直接从release中下载相应版本的源代码。 自动检测依赖进入解压后的文件夹，然后运行bash ./configure。这是一项检测所需要的依赖是否安装好了的脚本。只需要根据其提供的错误提示，将相应错误修改完成即可。 前后遇到的问题有： gcc版本问题。因为jdk8需要用到gcc，但是macOS中的gcc已经链接到clang上了。需要重新装gcc，并链接。但是可以选择编译jdk9或jdk10，听说这两个是可以用clang编译。jdk9没试，jdk10是的。下载了jdk10的源代码后，运行configure就没问题了。太震惊了，现在jdk都已经到12了。 【这步应该可忽略】提示xcodebuild相关的错误。可能还是与之前升级了系统有关。其详细的错误信息&amp;解决过程如下： 123456configure: error: No xcodebuild tool and no system framework headers found, use --with-sysroot or --with-sdk-name to provide a path to a valid SDK# 于是运行了一下`xcodebuild`，错误信息如下：xcode-select: error: tool 'xcodebuild' requires Xcode, but active developer directory '/Library/Developer/CommandLineTools' is a command line tools instance# 解决方案：sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer# Xcode若有后续版本，可能需要根据实际情况去做些修改。 没有freetype。提示使用brew安装：brew install freetype。但是安装后，并没有再次运行时，仍然出现相同的提示。找了挺多方法，包括看这些脚本是怎么写的，就是想知道是怎么找的，然后看它为什么会输出”Could not find freetype!…..”。不够收益不大，并没有找到解决办法。这时候看了看doc/building.html，内容如下： 123If a required library is not detected by configure, you need to provide the path to it. There are two forms of the configure arguments to point to an external library: --with-&lt;LIB&gt;=&lt;path&gt; or --with-&lt;LIB&gt;-include=&lt;path to include&gt; --with-&lt;LIB&gt;-lib=&lt;path to lib&gt;. configure的时候一定要带上–disable-warnings-as-errors这个参数，否则编译过程中的warning也会中断编译的进程，实际上这些warning并不影响编译后的目标JDK的运行 所以后面我运行的configure如下： Update : 2019/1/15 1bash configure --with-debug-level=slowdebug --enable-dtrace --with-jvm-variants=server --with-target-bits=64 --enable-ccache --with-num-cores=8 --with-memory-size=8000 --disable-warnings-as-errors 至此，自动检测的错误全部解决。 开始编译：使用make时，使用了images*,即make images。其后面可用的参数如下： Apart from the default target, here are some common make targets: hotspot - Build all of hotspot (but only hotspot)hotspot-&lt;variant&gt; - Build just the specified jvm variantimages or product-images - Build the JRE and JDK imagesdocs or docs-image - Build the documentation imagetest-image - Build the test imageall or all-images - Build all images (product, docs and test)bootcycle-images - Build images twice, second time with newly built JDK (good for testing)clean - Remove all files generated by make, but not those generated by configuredist-clean - Remove all files, including configuratio 验证编译完成后，验证编译结果如下： 参考：https://hunterzhao.io/post/2018/01/29/compile-openjdk10-source-code-on-mac/https://juejin.im/post/5a6d7d106fb9a01ca47abd8b","link":"/2018/08/31/cf43eff32829.html"},{"title":"完整了解tar的使用及其有意思的花活","text":"常用参数主要的操作模式（只能用一个） -c/--create 创建 tar 文件 --delete 从 tar 文件中删除某个文件 -r/--append 往 tar 文件尾部追加文件 -u/--update 更新 tar 文件中的文件 -t/--list 查看 tar 文件中的文件 -x/--extract/--get 从 tar 文件解压文件 解压缩选项 -z/--gzip/--gunzip/--ungzip 过滤gzip方式压缩的文件(.tar.gz/.tgz) -j/--bzip2 过滤bzip2方式压缩的文件(.tar.bz2) -J/--xz 过滤xz方式压缩的文件(.tar.xz/.txz) -Z/--compress/--uncompress 过滤compress方式压缩的文件 其他选项 -f/--file=ARCHIVE 操作的 tar 文件路径，此参数后必须跟文件路径名 -f - 操作对象在标准输入/输出 -C/--directory 操作目录/解压后文件放置的目录 -v：显示所有过程 -O：将文件解开后，将内容打印到标准输出 TLDR创建 tar 文件 1234567# 创建 tar 包tar cvf xx.tar /tmp/1.txt /tmp/2.txt# 创建使用 gzip/uncompress/bzip2/xz 压缩过 tar 包tar czvf xx.tar.gz /tmp/1.txt /tmp/2.txttar cZvf xx.tar.Z /tmp/1.txt /tmp/2.txttar cjvf xx.tar.bz2 /tmp/1.txt /tmp/2.txttar cJvf xx.tar.xz /tmp/1.txt /tmp/2.txt 粗略测试下压缩的效果和压缩的时间，tar.Z 的没创建成功，每种不同的压缩方式运行的时间也不尽相同 粗略结论：gzip/bz2 压缩是比较折中的选项，压缩后的大小还行，时间也能接受 12345678910111213141516171819# 压缩所用的时间排序 xz &gt; bz2 &gt; gz &gt; none$ time tar cf hi.tar file1 file2 dir1tar cf hi.tar file1 file2 dir1 0.01s user 0.25s system 95% cpu 0.277 total$ time tar czf hi.tar.gz file1 file2 dir1tar czf hi.tar.gz file1 file2 dir1 5.66s user 0.39s system 103% cpu 5.867 total$ time tar cJf hi.tar.xz file1 file2 dir1tar cJf hi.tar.xz file1 file2 dir1 62.73s user 1.15s system 100% cpu 1:03.42 total$ time tar cjf hi.tar.bz2 file1 file2 dir1tar cjf hi.tar.bz2 file1 file2 dir1 15.90s user 0.35s system 99% cpu 16.277 total# 压缩后的大小排序 none &gt; gz &gt; bz2 &gt; xz$ ls -lh hi.tar hi.tar.bz2 hi.tar.gz hi.tar.xz-rw-rw-r-- 1 ubuntu ubuntu 196M Jan 5 14:14 hi.tar-rw-rw-r-- 1 ubuntu ubuntu 105M Jan 5 14:13 hi.tar.bz2-rw-rw-r-- 1 ubuntu ubuntu 109M Jan 5 14:14 hi.tar.gz-rw-rw-r-- 1 ubuntu ubuntu 99M Jan 5 14:12 hi.tar.xz 解压 tar 文件 12345678# 一拳超人tar xvf xx.tar/xx.tar.gz/xx.tar.xz/xx.tar.bz2/xx.tar.Z# 或者画蛇添足tar xvf xx.tartar xzvf xx.tar.gztar xZvf xx.tar.Ztar xjvf xx.tar.bz2tar xJvf xx.tar.xz 解压 tar 文件中的某一个文件 1tar -xf archive.tar.xz file1 dir2 解压其他压缩文件 123456789101112# 解压 rar, 可能需要先安装 sudo apt install -y unrarunrar e file.rar# 解压 zipunzip file.zip# 解压 gzipgzip/gunzip -d file.gz# 解压 bzip2bzip2/bunzip2 -d file.bz2# 解压 Zuncompress -d file.Z# 解压 xzxz -d file.xz 查看 tar 包内容，加 v 可以看到权限、用户等详细信息。 1tar tvf source.tar 添加新文件（压缩后的不能追加） 1tar rvf target.tar appended-file.txt 整花活从 Pod 中拷贝数据时，可能会用到 kubectl cp，但是执行这个命令，在目标容器中必须存在 tar 命令，也就是它依赖于 tar 命令来实现拷贝功能。有几个比较有意思的命令： 本地 -&gt; Pod 1tar cf - /tmp/foo | kubectl exec -i -n &lt;some-namespace&gt; &lt;some-pod&gt; -- tar xf - -C /tmp/bar Pod -&gt; 本地 1kubectl exec -n &lt;some-namespace&gt; &lt;some-pod&gt; -- tar cf - /tmp/foo | tar xf - -C /tmp/bar 通过标准输入/输出来传递要拷贝的文件/目录，这花活整得挺秀。尝试着整了一些其他类似的花活： 123456789101112131415# 想直接输出到 terminal，失败了$ tar cjf - a.txt b.txttar: Refusing to write archive contents to terminal (missing -f option?)tar: Error is not recoverable: exiting now# 创建压缩的 tar 包tar cjf - a.txt b.txt &gt; hi.tar.bz2# 输出压缩后的 tar 包内容tar cjf - a.txt b.txt | cat# 创建后查看内容（太搞笑了）$ tar cjf - a.txt b.txt | tar tjvf --rw-rw-r-- ubuntu/ubuntu 1174 2022-12-13 14:09 a.txt-rwxrwxr-x ubuntu/ubuntu 2623 2022-12-22 09:46 b.txt 还找到一个下载 kernel 代码时的用法，优雅~ 1curl https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.1.3.tar.xz | tar xJf -","link":"/2023/01/05/1fb01c4e1eec.html"},{"title":"容器中的信号处理与tini的详细解读","text":"","link":"/2022/04/20/6edaa3c6dae6.html"},{"title":"对Ubuntu开（关）机启动慢的处理","text":"没有及时截图，只能来个恢复现场，所以主要是以解决的思路为主吧，其它的就当个参考，随便看看就好。 Ubuntu升级后开（关）机贼慢开（关）机的时候，老是卡在这个地方（其实是有光的），是升级16.04之后出现的。这种情况，我总是觉得有点不对，因为之前用过的Ubuntu都是启动飞快的。为什么？它为什么开机要这么久，它开机到底做了一些什么事？脑海中突然想到了，它有可能是在开机的时候，做了很多事或者一直在等待（卡住）某事。然后就想着去看它的开机log。 看log大法好网上说它的log文件位于/var/log/boot.log，cat一看，果然不失所望。一抹清绿中却含有淡淡的红。大致是与swap分区相关吧。网上有解决办法。原因是/etc/fstab里面记录的swap分区的UUID没有及时变更，所以找了很久没有找到，所以耗时~只要把其中的UUID修改成现在的UUID，问题就解决了。 后续处理log文件显示，除了上一个之外，后面还出现了一个其它耗时操作，搞清楚它所出现的原因后，果断修复，然后重启，开关机就像水一样润滑。 祝你好运！","link":"/2018/02/07/d007a708ea48.html"},{"title":"如何避免 MacBook Pro 玩游戏时卡顿的问题","text":"经过如下设置后，我的 MBP 就不卡了： 鼠标的刷新率 游戏界面质量最低 win+R输入msconfig 然后选择引导中的 高级选项把核心数量设置成4或者6，多试几次。 其它原因 1、笔记本电脑玩英雄联盟，大多是因为过热降频导致的，说白了就是因为笔记本散热不行，解决方法：加风扇，或者取消笔记本CPU过热保护功能 2、使用电源平衡模式，不要随随便便设置显卡，默认就是最好的 3、关掉wegame、卸载所有杀毒软件、驱动大师等垃圾软件 4、不要随便下载小电影，可能是中毒了 Mac到底能不能玩英雄联盟 可以！甚至MacBook Air都可以流畅玩，一点问题没有，不懂的不要瞎bb，没亲自试过就自己说：MacBook 不能玩游戏！之类的言论都是信口开河的傻子们说的 作者：村雨Mura https://www.bilibili.com/read/cv7185704 出处：bilibili 咳咳，终于解决macbook玩lol卡顿了，直接进入正文：降低鼠标刷新率（回报率）！降低鼠标刷新率（回报率）！降低鼠标刷新率（回报率）！重要的事情说三遍。本机配置：Macbook pro 15寸（2019款）i7 + 16G + 256G +AMD（4g） 双系统装了window10 专业版（想着偶尔玩个游戏，不然出门带两部电脑也挺麻烦，抱着不服输的心开始了联（zuo）盟（si）之旅！ 还是熟悉的操作还是熟悉的味道安装tgp→安装lol→登陆游戏虽然已经有了心理准备，Macbook玩LOL会爆炸但是当进入游戏的时候还是很激动人心的（会不会我的就没事？） 结果！！！FPS开始坐过山车一会160一会30，电脑还对对我的手持续输出 首先，在想是不是因为cpu过热自动降频？网上各位大神也是这样说的，所以先调节电源设置右键电脑右下角的小电池?点击电源选项然后点击更改计划设置更改高级电源设置如下设置（吐槽贴吧上传图片真的麻烦，为什么不能拖拽上传呢？？？） 设置完成后基本上不会发热了可是…..fps还是起伏不定！！尤其移动鼠标就会更卡！emmmm 百度了一下发现鼠标有一个设置叫：鼠标刷新率，好像也叫鼠标轮询率，大概意思就是设备向电脑回报的频率，越高越实时吧。贴一个我的鼠标设置： 调低这个设置即可，好像这个设置比较高的时候占用cpu比较多，但是打开了任务管理器实际上cpu占用很低 可能是玄学吧~调低至500的时候 FPS基本上稳定在100左右，CPU温度也是稳定在70度左右但是。。。不知道是不是因为调低这个的原因，感觉调低了之后，走A好像不流畅了，影响我拿五杀（手动滑稽） 你是装了双系统吗?如果是的话这个答案可以供你参考。(虚拟机我就不知道咋处理了)你是否使用了有线鼠标，如果是的话建议使用无线鼠标或者购买带电源的thunderbolt3拓展坞。原因可能是电脑需要给有线鼠标供电，这会影响CPU供电从而导致掉帧。或者换一个96W的电源适配器不知道会不会好一点。 还记得，那些年，为了装x、为了乔帮主、为了漂亮的设计，买了苹果电脑。习惯了Mac os后，用起来也确实好用，就是一到打游戏的时候，不是卡到想拍桌、就是热到能煎蛋。 但是Mac买都已经买了，游戏呢也是不能不打的，后悔无用、抱怨无用，下面是我亲测的用4G内存的Mac air，打LOL、新倩女幽魂等等游戏流畅不卡顿的干货解决方法。 因为LOL国服/新倩女幽魂没有Mac版，我是安装虚拟机后，用win系统版本的游戏软件来打的。进行如下一系列优化后，Mac air，4G内存，跑LOL的fps值是60左右，基本是流畅不卡顿的。 解决方案： 1.游戏内视频效果、画质设置调低 游戏内按ESC键，点击视频选项，就会出现下图所示的选项。然后主要修改以下三个地方： ①首先将分辨率改成最大，一般都是1920*1080，之后勾选“隐藏地图细节特效”的选项，是否色盲模式则要看个人的喜好。如果你的电脑配置真的非常烂，那么可以把游戏的分辨率调低一些。 ②在图形选项，建议将人物细节品质、环境品质和特效品质都改成低，阴影关闭。(不要改成最低，因为FPS几乎是一样的)，特效品质改成低或非常低，这个选项的非常低是有效的。人物描边从勾选改成不勾选状态。 ③最后一步设置，帧率封顶设置改成不封顶，抗锯齿和等待垂直同步全都不勾选。 2.系统及控制面板设置 ①首先点左下角开始，打开控制面板，硬件和声音，找到电源选项，然后选择“高性能”。 ②第二步，回到桌面，右击我的电脑（根据win版本的不同，或从文件进去，“这台电脑”或“计算机”右键），选择属性选项打开，点左侧的“高级系统设置”，然后就会出现如下图所示的界面。勾选自定义设置选项，如果你不知道怎么选，就按下图的来，这样可以保证在性能的情况下视觉效果还能接受。勾选如图所示的所有选项。 3.打游戏时，将mac系统下不相关的app都关掉 打游戏时，其他不相关的进程都关掉，比如qq、浏览器、爱奇艺等，能够最大限度的释放内存。 4.清理电脑灰尘 上面几步电脑软件上能调整的都调整后，如果还有卡顿现象，则需要清理电脑灰尘。电脑灰尘经常是不被大家重视的一点，但是实际上，长期的电脑灰尘积压会严重降低电脑的散热能力，电脑散热能力差会使电脑的运行温度过高，减低电脑的运行性能，致使游戏出现不顺畅。 定期清理灰尘，不仅能够解决游戏流畅度的问题，也能延长电脑的使用寿命。清理方法如果你能自己卸掉后盖，可以自行清理，或者去电脑城花一点钱请专人帮忙清理即可。 5.风扇帮助散热 如果电脑持续过热的话，高温会导致降频，电脑打游戏就会卡顿。因此要注意散热，可以买个电脑散热小风扇，对着键盘吹，或者电脑散热座，借助外力加快电脑散热。之前有种解决方法是安装mac电脑调整转速的软件，但是多方查找资料后，我发现这类强行调整mac风扇转速的软件还是最好不安装，卸载时如果没设置好，转速就无法调整了，之后对电脑可能产生不好的影响，因此不建议安装软件来加快风扇转速。 好了，以上是苹果电脑打lol/新倩女幽魂等游戏流畅不卡顿的解决方案，同样试过4G内存的air打梦幻西游、剑三等等没问题。像WOW、天下这种对显卡要求比较高的游戏，就需要Pro才能hold住了。 解决方案总结： 1.游戏内视频效果、画质设置调低。 2.电脑系统及控制面板设置。 3.打游戏时，将mac系统下不相关的app都关掉 4.清理电脑灰尘 5.风扇帮助散热","link":"/2021/08/22/2f9774a9e066.html"},{"title":"常用linux命令","text":"md5summd5sum命令采用MD5报文摘要算法（128位）计算和检查文件的校验和。一般来说，安装了Linux后，就会有md5sum这个工具，直接在命令行终端直接运行。MD5算法常常被用来验证网络文件传输的完整性，防止文件被人篡改。 MD5 全称是报文摘要算法（Message-Digest Algorithm 5），此算法对任意长度的信息逐位进行计算，产生一个二进制长度为128位（十六进制长度就是32位）的“指纹”（或称“报文摘要”），不同的文件产生相同的报文摘要的可能性是非常非常之小的。 语法 md5sum(选项)(参数) 选项 -b：二进制模式读取文件； -t或–text：把输入的文件作为文本文件看待； -c：从指定文件中读取MD5校验和，并进行校验； –status：验证成功时不输出任何信息； -w：当校验不正确时给出警告信息。 参数 文件：指定保存着文件名和校验和的文本文件。 来自 tee可以保存一份数据到文件，然后再将数据重定向给其它命令。如： ls -al | tee local_file.txt | grep &quot;hello&quot; xargs可以让非重定向命令实现类似重定向命令的功能。如ls命令。 ls | xargs rm -rf 博客 查看系统信息lsb_release -a,uname -a, getconf -a 1234567891011121314151617181920➜ ~ lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 16.04.3 LTSRelease: 16.04Codename: xenial➜ ~ uname -aLinux jdu4e00u53f7 4.4.0-93-generic #116-Ubuntu SMP Fri Aug 11 21:17:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux➜ ~ getconf LONG_BIT64➜ ~ lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 16.04.3 LTSRelease: 16.04Codename: xenial➜ ~ uname -aLinux jdu4e00u53f7 4.4.0-93-generic #116-Ubuntu SMP Fri Aug 11 21:17:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux➜ ~ getconf LONG_BIT64 zsh主题与大仓库git速度慢的问题使用oh-my-zsh中的主题后，因为其中含有对git信息的获取，在一个很大的git项目中可能会导致卡顿。因此可以调用者两条命令，来禁止主题获取相应的信息，以提高响应的响应速度。 git config --add oh-my-zsh.hide-dirty 1 隐藏git status信息。 git config --add oh-my-zsh.hide-status 1 隐藏所有的git信息。相应的使用0是显示。","link":"/2017/10/15/afb4674306a0.html"},{"title":"对颜色空间YUV、RGB的理解","text":"接触到了一些yuv相关的信息。从Camera中拿到的每一帧，它的默认格式是NV21，它是一种yuv格式，然后转成OpenCV所需的BGR。Camera的每一帧的数据格式还可以指定成别的格式。因此开始关注了yuv这个名词，后面还有yuv的各种衍生，因此仔细地梳理一下自己的理解，以及与RGB对比。 什么是RGB对RGB，并不陌生，从初中开始接触的色光的三原色，告诉我们我们可以看到的光可以由这三种颜色按一定的比例去混合得到；后来在HTML以及Android开发中设置元素/控件的颜色时，可以通过一串数字，得到某个特定的颜色。这就是RGB的应用。 RGB 模型是目前常用的一种彩色信息表达方式，它使用红、绿、蓝三原色的亮度来定量表示颜色。该模型也称为加色混色模型，是以RGB三色光互相叠加来实现混色的方法，因而适合于显示器等发光体的显示。 RGB 颜色模型可以看做三维直角坐标颜色系统中的一个单位正方体。任何一种颜色在RGB 颜色空间中都可以用三维空间中的一个点来表示。在RGB 颜色空间上，当任何一个基色的亮度值为零时，即在原点处，就显示为黑色。当三种基色都达到最高亮度时，就表现为白色。在连接黑色与白色的对角线上，是亮度等量的三基色混合而成的灰色，该线称为灰色线。 什么是BGR与RGB类似，只是存储时B位与R位的位置进行调换。 什么是YCbCrY表示亮度，CbCr表示颜色。怎么表示颜色，可以看下面这幅坐标图： Y要如何表示亮度呢，下面是Y在不同的情况下的表现： 因此可以这样理解，同样是使用三个数来表示某个像素点的颜色，但是这三个数的意义变了，与RGB相比。然后接下来是各种yuv的衍生物。 The scope of the terms Y′UV, YUV, YCbCr, YPbPr, etc., is sometimes ambiguous and overlapping. Historically, the terms YUV and Y′UV were used for a specific analog encoding of color information in television systems, while YCbCr was used for digital encoding of color information suited for video and still-image compression and transmission such as MPEG and JPEG. Today, the term YUV is commonly used in the computer industry to describe file-formats that are encoded using YCbCr. 上面的意思是，这些术语有时真的很难区分，因为定义也是模糊不清。不过重要的是最后面那一句话：现在的YUV是通常用于计算机领域用来表示使用YCbCr编码的文件。 所以可以粗浅地视YUV为YCbCr。 不过我在Camera预览中的每一帧中，除默认格式NV21外，还发现了其它的格式如YV12。去搜一些关于他们的资料时，发现都是yuv420系列的。具体有什么差异呢？ 膜拜一下大佬的博客（稍作编辑与修改）： YUV分类与意义planar和packed对于planar的YUV格式，先连续存储所有像素点的Y，紧接着存储所有像素点的U，随后是所有像素点的V。 对于packed的YUV格式，每个像素点的Y,U,V是连续交*存储的。 YUV，分为三个分量，“Y”表示明亮度（Luminance或Luma），也就是灰度值；而“U”和“V” 表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。 与我们熟知的RGB类似，YUV也是一种颜色编码方法，主要用于电视系统以及模拟视频领域，它将亮度信息（Y）与色彩信息（UV）分离，没有UV信息一样可以显示完整的图像（是不是写错了），只不过是黑白的，这样的设计很好地解决了彩色电视机与黑白电视的兼容问题。并且，YUV不像RGB那样要求三个独立的视频信号同时传输，所以用YUV方式传送占用极少的频宽。 YUV码流的存储格式其实与其采样的方式密切相关，主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0，关于其详细原理，可以通过网上其它文章了解，这里我想强调的是如何根据其采样格式来从码流中还原每个像素点的YUV值，因为只有正确地还原了每个像素点的YUV值，才能通过YUV与RGB的转换公式提取出每个像素点的RGB值，然后显示出来。 存储方式用三个图来直观地表示采集的方式吧，以黑点表示采样该像素点的Y分量，以空心圆圈表示采用该像素点的UV分量。 先记住下面这段话，以后提取每个像素的YUV分量会用到。 YUV 4:4:4采样，每一个Y对应一组UV分量。 YUV 4:2:2采样，每两个Y共用一组UV分量。 YUV 4:2:0采样，每四个Y共用一组UV分量。 下面我用图的形式给出常见的YUV码流的存储方式，并在存储方式后面附有取样每个像素点的YUV数据的方法，其中，Cb、Cr的含义等同于U、V。 YUVY 格式 （属于YUV422） YUYV为YUV422采样的存储格式中的一种，相邻的两个Y共用其相邻的两个Cb、Cr，分析，对于像素点Y’00、Y’01 而言，其Cb、Cr的值均为 Cb00、Cr00，其他的像素点的YUV取值依次类推。 UYVY 格式 （属于YUV422） UYVY格式也是YUV422采样的存储格式中的一种，只不过与YUYV不同的是UV的排列顺序不一样而已，还原其每个像素点的YUV值的方法与上面一样。 YUV422P（属于YUV422） YUV422P也属于YUV422的一种，它是一种Plane模式，即平面模式，并不是将YUV数据交错存储，而是先存放所有的Y分量，然后存储所有的U（Cb）分量，最后存储所有的V（Cr）分量，如上图所示。其每一个像素点的YUV值提取方法也是遵循YUV422格式的最基本提取方法，即两个Y共用一个UV。比如，对于像素点Y’00、Y’01 而言，其Cb、Cr的值均为 Cb00、Cr00。 YV12，YU12格式（属于YUV420） YU12和YV12属于YUV420格式，也是一种Plane模式，将Y、U、V分量分别打包，依次存储。其每一个像素点的YUV数据提取遵循YUV420格式的提取方式，即4个Y分量共用一组UV。注意，上图中，Y’00、Y’01、Y’10、Y’11共用Cr00、Cb00，其他依次类推。 NV12、NV21（属于YUV420） NV12和NV21属于YUV420格式，是一种two-plane模式，即Y和UV分为两个Plane，但是UV（CbCr）为交错存储，而不是分为三个plane。其提取方式与上一种类似，即Y’00、Y’01、Y’10、Y’11共用Cr00、Cb00 YUV文件大小计算以720×488大小图象YUV420 planar为例，其存储格式是： 共大小为(720×480×3&gt;&gt;1)字节， 分为三个部分:Y,U和V Y分量： (720×480)个字节U(Cb)分量：(720×480&gt;&gt;2)个字节V(Cr)分量：(720×480&gt;&gt;2)个字节 三个部分内部均是行优先存储，三个部分之间是Y,U,V 顺序存储。即0－－720×480字节是Y分量值，720×480－－720×480×5/4字节是U分量720×480×5/4 －－720×480×3/2字节是V分量。 4 ：2： 2 和4：2：0 转换最简单的方式： YUV4:2:2 —&gt; YUV4:2:0 Y不变，将U和V信号值在行(垂直方向)在进行一次隔行抽样。 YUV4:2:0 —&gt; YUV4:2:2 Y不变，将U和V信号值的每一行分别拷贝一份形成连续两行数据。 在YUV420中，一个像素点对应一个Y，一个4X4的小方块对应一个U和V。对于所有YUV420图像，它们的Y值排列是完全相同的，因为只有Y的图像就是灰度图像。 YUV420sp与YUV420p的数据格式它们的UV排列在原理上是完全不同的。 420p它是先把U存放完后，再存放V，也就是说UV它们是连续的；而420sp它是UV、UV这样交替存放的。 (见下图) 有了上面的理论，我就可以准确的计算出一个YUV420在内存中存放的大小。 width * hight =Y（总和） U = Y / 4 V = Y / 4 所以YUV420 数据在内存中的长度是 width * hight * 3 / 2， 假设一个分辨率为8X4的YUV图像，它们的格式如下图： YUV420p数据格式如下图 旋转90度的算法:123456789101112131415161718public static void rotateYUV240SP(byte[] src,byte[] des,int width,int height){ int wh = width * height; //旋转Y int k = 0; for(int i=0;i&lt;width;i++) { for(int j=0;j&lt;height;j++) { des[k] = src[width*j + i]; k++; } } for(int i=0;i&lt;width;i+=2) { for(int j=0;j&lt;height/2;j++) { des[k] = src[wh+ width*j + i]; des[k+1]=src[wh + width*j + i+1]; k+=2; } }} YV12和I420的区别一般来说，直接采集到的视频数据是RGB24的格式，RGB24一帧的大小size＝width×heigth×3 Bit，RGB32的size＝width×heigth×4，如果是I420（即YUV标准格式4：2：0）的数据量是 size＝width×heigth×1.5 Bit。 在采集到RGB24数据后，需要对这个格式的数据进行第一次压缩。即将图像的颜色空间由RGB2YUV。因为，X264在进行编码的时候需要标准的YUV（4：2：0）。 但是这里需要注意的是，虽然YV12也是（4：2：0），但是YV12和I420的却是不同的，在存储空间上面有些区别。如下： YV12 ： 亮度（行×列） ＋ U（行×列/4) + V（行×列/4） I420 ： 亮度（行×列） ＋ V（行×列/4) + U（行×列/4） 可以看出，YV12和I420基本上是一样的，就是UV的顺序不同。 继续我们的话题，经过第一次数据压缩后RGB24－&gt;YUV（I420）。这样，数据量将减少一半，为什么呢？ 呵呵，这个就太基础了，我就不多写了。 同样，如果是RGB24－&gt;YUV（YV12），也是减少一半。但是，虽然都是一半，如果是YV12的话效果就有很大损失。然后，经过X264编码后，数据量将大大减少。将编码后的数据打包，通过RTP实时传送。到达目的地后，将数据取出，进行解码。完成解码后，数据仍然是YUV格式的，所以，还需要一次转换，这样windows的驱动才可以处理，就是YUV2RGB24。 YUV420P和 YUV420SP的区别YUV420P，Y，U，V三个分量都是平面格式，分为I420和YV12。I420格式和YV12格式的不同处在U平面和V平面的位置不同。在I420格式中，U平面紧跟在Y平面之后，然后才是V平面（即：YUV）；但YV12则是相反（即：YVU）。 YUV420SP, Y分量平面格式，UV打包格式, 即NV12。 NV12与NV21类似，U 和 V 交错排列,不同在于UV顺序。 I420: YYYYYYYY UU VV =&gt;YUV420P YV12: YYYYYYYY VV UU =&gt;YUV420P NV12: YYYYYYYY UVUV =&gt;YUV420SP NV21: YYYYYYYY VUVU =&gt;YUV420SP Y′UV420p (and Y′V12 or YV12) to RGB888 conversionY′UV420p is a planar format, meaning that the Y′, U, and V values are grouped together instead of interspersed. The reason for this is that by grouping the U and V values together, the image becomes much more compressible. When given an array of an image in the Y′UV420p format, all the Y′ values come first, followed by all the U values, followed finally by all the V values. The Y′V12 format is essentially the same as Y′UV420p, but it has the U and V data switched: the Y′ values are followed by the V values, with the U values last. As long as care is taken to extract U and V values from the proper locations, both Y′UV420p and Y′V12 can be processed using the same algorithm. As with most Y′UV formats, there are as many Y′ values as there are pixels. Where X equals the height multiplied by the width, the first X indices in the array are Y′ values that correspond to each individual pixel. However, there are only one fourth as many U and V values. The U and V values correspond to each 2 by 2 block of the image, meaning each U and V entry applies to four pixels. After the Y′ values, the next X/4 indices are the U values for each 2 by 2 block, and the next X/4 indices after that are the V values that also apply to each 2 by 2 block. Translating Y′UV420p to RGB is a more involved process compared to the previous formats. Lookup of the Y′, U and V values can be done using the following method: 12345size.total = size.width * size.height;y = yuv[position.y * size.width + position.x];u = yuv[(position.y / 2) * (size.width / 2) + (position.x / 2) + size.total];v = yuv[(position.y / 2) * (size.width / 2) + (position.x / 2) + size.total + (size.total / 4)];rgb = Y′UV420toRGB888(y, u, v); As shown in the above image, the Y′, U and V components in Y′UV420 are encoded separately in sequential blocks. A Y′ value is stored for every pixel, followed by a U value for each 2×2 square block of pixels, and finally a V value for each 2×2 block. Corresponding Y′, U and V values are shown using the same color in the diagram above. Read line-by-line as a byte stream from a device, the Y′ block would be found at position 0, the U block at position x×y (6×4 = 24 in this example) and the V block at position x×y + (x×y)/4 (here, 6×4 + (6×4)/4 = 30). Y′UV420sp (NV21) to RGB conversion (Android)This format (NV21) is the standard picture format on Android camera preview. YUV 4:2:0 planar image, with 8 bit Y samples, followed by interleaved V/U plane with 8bit 2x2 subsampled chroma samples.C++ code used on Android to convert pixels of YUVImage: 123456789void YUVImage::yuv2rgb(uint8_t yValue, uint8_t uValue, uint8_t vValue, uint8_t *r, uint8_t *g, uint8_t *b) const { int rTmp = yValue + (1.370705 * (vValue-128)); int gTmp = yValue - (0.698001 * (vValue-128)) - (0.337633 * (uValue-128)); int bTmp = yValue + (1.732446 * (uValue-128)); *r = clamp(rTmp, 0, 255); *g = clamp(gTmp, 0, 255); *b = clamp(bTmp, 0, 255);} 参考： http://www.cnblogs.com/azraelly/archive/2013/01/01/2841269.html https://www.jianshu.com/p/a91502c00fb0 https://en.wikipedia.org/wiki/YUV","link":"/2018/06/09/2e624799f3a3.html"},{"title":"常用排序算法","text":"慢慢再温习一遍之前学习过的排序算法吧，一点点地积累。 插入排序插入排序的基本思想是在遍历数组的过程中，假设在序号 i （i&gt;=1）之前的元素即 [0..i-1] 都已经排好序，本趟需要找到 i 对应的元素 x 的正确位置 k ，并且在寻找这个位置 k 的过程中逐个将比较过的元素往后移一位，为元素 x “腾位置”，最后将 k 对应的元素值赋为 x ，一般情况下，插入排序的时间复杂度和空间复杂度分别为O(n2) 和 O(1)。（通俗说法：把数组后面那些没排序的元素换到数组前面已经排好序的部分里对应的位置） 例如：45 80 48 40 22 78第一轮：45 80 48 40 22 78 —&gt; 45 80 48 40 22 78 i=1第二轮：45 80 48 40 22 78 —&gt; 45 48 80 40 22 78 i=2第三轮：45 48 80 40 22 78 —&gt; 40 45 48 80 22 78 i=3第四轮：40 45 48 80 22 78 —&gt; 22 40 45 48 80 78 i=4第五轮：22 40 45 48 80 78 —&gt; 22 40 45 48 78 80 i=5(红色代表此轮要插入的元素，红色左边是已经排好序的，右边是待排序的) 12345678910111213141516/*** @param int[] 未排序数组* @return int[] 排完序数组*/public static int[] InsertSort(int[] array){ for(int i =1;i&lt;array.length;i++){ int temp = array[i]; int j = i-1; while(j&gt;=0 &amp;&amp; temp &lt; array[j] ){ array[j+1] = array[j]; j--; } array[j+1] = temp; } return array;} 选择排序选择排序的基本思想是遍历数组的过程中，以 i 代表当前需要排序的序号，则需要在剩余的 [i+1,…n-1] 中找出其中的最小值，然后将找到的最小值与 i 指向的值进行交换。因为每一趟确定元素的过程中都会有一个选择最大值/最小值的子流程，所以人们形象地称之为选择排序。选择排序的时间复杂度和空间复杂度分别为O(n2)和O(1)。（通俗说法：每次把剩余数组里最小的选出来放在数组的前面。所以第一次选出来的就是数组里面最小的，第二次选出来的就是数组里面第二小的，依次。。。。。） 例如：45 80 48 40 22 78第一轮：45 80 48 40 22 78 —&gt; 22 80 48 40 45 78 i=0第二轮：22 80 48 40 45 78 —&gt; 22 40 48 80 45 78 i=1第三轮：22 40 48 80 45 78 —&gt; 22 40 45 80 48 78 i=2第四轮：22 40 45 80 48 78 —&gt; 22 40 45 48 80 78 i=3第五轮：22 40 45 48 80 78 —&gt; 22 40 45 48 78 80 i=4(红色代表此轮需要排序的序号的元素，红色左边是已经排好序的，右边是待排序的) 12345678910111213141516171819/*** @param int[] 未排序数组* @return int[] 排完序数组*/public int[] sortSelect(int[] arr){ for (int i = 0; i &lt; arr.length-1; i++) { int miniPost = i; for (int m = i + 1; m &lt; arr.length; m++) { if (arr[m] &lt; arr[miniPost]) miniPost = m; } if (arr[i] &gt; arr[miniPost]) { int temp = arr[i]; arr[i] = arr[miniPost]; arr[miniPost] = temp; } } return arr;} 归并排序来自：https://www.cnblogs.com/chengxiao/p/6194356.html，图非常简洁明了。 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 分而治之可以看到这种结构很像一棵完全二叉树，本文的归并排序我们采用递归去实现（也可采用迭代的方式去实现）。分阶段可以理解为就是递归拆分子序列的过程，递归深度为log2n。 合并相邻有序子序列再来看看治阶段，我们需要将两个已经有序的子序列合并成一个有序序列，比如上图中的最后一次合并，要将[4,5,7,8]和[1,2,3,6]两个已经有序的子序列，合并为最终序列[1,2,3,4,5,6,7,8]，来看下实现步骤。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package sortdemo;import java.util.Arrays;/** * Created by chengxiao on 2016/12/8. */public class MergeSort { public static void main(String []args){ int []arr = {9,8,7,6,5,4,3,2,1}; sort(arr); System.out.println(Arrays.toString(arr)); } public static void sort(int []arr){ int []temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间 sort(arr,0,arr.length-1,temp); } private static void sort(int[] arr,int left,int right,int []temp){ if(left&lt;right){ int mid = (left+right)/2; sort(arr,left,mid,temp);//左边归并排序，使得左子序列有序 sort(arr,mid+1,right,temp);//右边归并排序，使得右子序列有序 merge(arr,left,mid,right,temp);//将两个有序子数组合并操作 } } private static void merge(int[] arr,int left,int mid,int right,int[] temp){ int i = left;//左序列指针 int j = mid+1;//右序列指针 int t = 0;//临时数组指针 while (i&lt;=mid &amp;&amp; j&lt;=right){ if(arr[i]&lt;=arr[j]){ temp[t++] = arr[i++]; }else { temp[t++] = arr[j++]; } } while(i&lt;=mid){//将左边剩余元素填充进temp中 temp[t++] = arr[i++]; } while(j&lt;=right){//将右序列剩余元素填充进temp中 temp[t++] = arr[j++]; } t = 0; //将temp中的元素全部拷贝到原数组中 while(left &lt;= right){ arr[left++] = temp[t++]; } }}/**执行结果[1, 2, 3, 4, 5, 6, 7, 8, 9]**/ 归并排序是稳定排序，它也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。从上文的图中可看出，每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。 快速排序大概的思想是（假设为升序），先以一个数为参照，然后将所有的大于它的数移到它的后面，小于它的数移到前面，再以此数的位置，将数组分成两部分，再对这两部分做相同的操作…如此递归，直至完毕。 12345678910111213141516171819202122232425262728293031public static void main(String[] args) { int[] arr = new int[]{6,2,4,99,22,56,11,5,7,4,1}; QuickSort(arr, 0, arr.length - 1); printArray(arr);}static void QuickSort(int[] arr, int left, int right){ if (left &gt; right) return; int pivot_index = partition1(arr, left, right); QuickSort(arr, left, pivot_index - 1); QuickSort(arr, pivot_index + 1, right);}static int partition1(int[] arr, int left, int right){ int pivot = arr[left]; while(left &lt; right){ while(left &lt; right &amp;&amp; arr[right] &gt;= pivot){ right--; } arr[left] = arr[right]; while(left &lt; right &amp;&amp; arr[left] &lt;= pivot){ left++; } arr[right] = arr[left]; } arr[left] = pivot; return left;}","link":"/2018/01/22/2c683704c99a.html"},{"title":"当你在浏览器中输入 google.com 并且按下回车之后发生了什么？","text":"来源：https://github.com/skyline75489/what-happens-when-zh_CN/blob/master/README.rst 当···时发生了什么？这个仓库试图回答一个古老的面试问题：当你在浏览器中输入 google.com 并且按下回车之后发生了什么？ 不过我们不再局限于平常的回答，而是想办法回答地尽可能具体，不遗漏任何细节。 这将是一个协作的过程，所以深入挖掘吧，并且帮助我们一起完善它。仍然有大量的细节等待着你来添加，欢迎向我们发送 Pull Requset！ 这些内容使用 Creative Commons Zero_ 协议发布。 目录.. contents:: :backlinks: none :local: 按下”g”键接下来的内容介绍了物理键盘和系统中断的工作原理，但是有一部分内容却没有涉及。当你按下“g”键，浏览器接收到这个消息之后，会触发自动完成机制。浏览器根据自己的算法，以及你是否处于隐私浏览模式，会在浏览器的地址框下方给出输入建议。大部分算法会优先考虑根据你的搜索历史和书签等内容给出建议。你打算输入 “google.com”，因此给出的建议并不匹配。但是输入过程中仍然有大量的代码在后台运行，你的每一次按键都会使得给出的建议更加准确。甚至有可能在你输入之前，浏览器就将 “google.com” 建议给你。 回车键按下为了从零开始，我们选择键盘上的回车键被按到最低处作为起点。在这个时刻，一个专用于回车键的电流回路被直接地或者通过电容器间接地闭合了，使得少量的电流进入了键盘的逻辑电路系统。这个系统会扫描每个键的状态，对于按键开关的电位弹跳变化进行噪音消除(debounce)，并将其转化为键盘码值。在这里，回车的码值是13。键盘控制器在得到码值之后，将其编码，用于之后的传输。现在这个传输过程几乎都是通过通用串行总线(USB)或者蓝牙(Bluetooth)来进行的，以前是通过PS/2或者ADB连接进行。 USB键盘： 键盘的USB元件通过计算机上的USB接口与USB控制器相连接，USB接口中的第一号针为它提供了5V的电压 键码值存储在键盘内部电路一个叫做”endpoint”的寄存器内 USB控制器大概每隔10ms便查询一次”endpoint”以得到存储的键码值数据，这个最短时间间隔由键盘提供 键值码值通过USB串行接口引擎被转换成一个或者多个遵循低层USB协议的USB数据包 这些数据包通过D+针或者D-针(中间的两个针)，以最高1.5Mb/s的速度从键盘传输至计算机。速度限制是因为人机交互设备总是被声明成”低速设备”（USB 2.0 compliance） 这个串行信号在计算机的USB控制器处被解码，然后被人机交互设备通用键盘驱动进行进一步解释。之后按键的码值被传输到操作系统的硬件抽象层 虚拟键盘（触屏设备）： 在现代电容屏上，当用户把手指放在屏幕上时，一小部分电流从传导层的静电域经过手指传导，形成了一个回路，使得屏幕上触控的那一点电压下降，屏幕控制器产生一个中断，报告这次“点击”的坐标 然后移动操作系统通知当前活跃的应用，有一个点击事件发生在它的某个GUI部件上了，现在这个部件是虚拟键盘的按钮 虚拟键盘引发一个软中断，返回给OS一个“按键按下”消息 这个消息又返回来向当前活跃的应用通知一个“按键按下”事件 产生中断[非USB键盘]键盘在它的中断请求线(IRQ)上发送信号，信号会被中断控制器映射到一个中断向量，实际上就是一个整型数 。CPU使用中断描述符表(IDT)把中断向量映射到对应函数，这些函数被称为中断处理器，它们由操作系统内核提供。当一个中断到达时，CPU根据IDT和中断向量索引到对应的中断处理器，然后操作系统内核出场了。 (Windows)一个 WM_KEYDOWN 消息被发往应用程序HID把键盘按下的事件传送给 KBDHID.sys 驱动，把HID的信号转换成一个扫描码(Scancode)，这里回车的扫描码是 VK_RETURN(0x0d)。 KBDHID.sys 驱动和 KBDCLASS.sys (键盘类驱动,keyboard class driver)进行交互，这个驱动负责安全地处理所有键盘和小键盘的输入事件。之后它又去调用 Win32K.sys ，在这之前有可能把消息传递给安装的第三方键盘过滤器。这些都是发生在内核模式。 Win32K.sys 通过 GetForegroundWindow() API函数找到当前哪个窗口是活跃的。这个API函数提供了当前浏览器的地址栏的句柄。Windows系统的”message pump”机制调用 SendMessage(hWnd, WM_KEYDOWN, VK_RETURN, lParam) 函数， lParam 是一个用来指示这个按键的更多信息的掩码，这些信息包括按键重复次数（这里是0），实际扫描码（可能依赖于OEM厂商，不过通常不会是 VK_RETURN ），功能键（alt, shift, ctrl）是否被按下（在这里没有），以及一些其他状态。 Windows的 SendMessage API直接将消息添加到特定窗口句柄 hWnd 的消息队列中，之后赋给 hWnd 的主要消息处理函数 WindowProc 将会被调用，用于处理队列中的消息。 当前活跃的句柄 hWnd 实际上是一个edit control控件，这种情况下，WindowProc 有一个用于处理 WM_KEYDOWN 消息的处理器，这段代码会查看 SendMessage 传入的第三个参数 wParam ，因为这个参数是 VK_RETURN ，于是它知道用户按下了回车键。 (Mac OS X)一个 KeyDown NSEvent被发往应用程序中断信号引发了I/O Kit Kext键盘驱动的中断处理事件，驱动把信号翻译成键码值，然后传给OS X的 WindowServer 进程。然后， WindowServer 将这个事件通过Mach端口分发给合适的（活跃的，或者正在监听的）应用程序，这个信号会被放到应用程序的消息队列里。队列中的消息可以被拥有足够高权限的线程使用 mach_ipc_dispatch 函数读取到。这个过程通常是由 NSApplication 主事件循环产生并且处理的，通过 NSEventType 为 KeyDown 的 NSEvent 。 (GNU/Linux)Xorg 服务器监听键码值当使用图形化的 X Server 时，X Server 会按照特定的规则把键码值再一次映射，映射成扫描码。当这个映射过程完成之后， X Server 把这个按键字符发送给窗口管理器(DWM，metacity, i3等等)，窗口管理器再把字符发送给当前窗口。当前窗口使用有关图形API把文字打印在输入框内。 解析URL 浏览器通过 URL 能够知道下面的信息： Protocol “http” 使用HTTP协议 Resource “/“ 请求的资源是主页(index) 输入的是 URL 还是搜索的关键字？当协议或主机名不合法时，浏览器会将地址栏中输入的文字传给默认的搜索引擎。大部分情况下，在把文字传递给搜索引擎的时候，URL会带有特定的一串字符，用来告诉搜索引擎这次搜索来自这个特定浏览器。 转换非 ASCII 的 Unicode 字符 浏览器检查输入是否含有不是 a-z， A-Z，0-9， - 或者 . 的字符 这里主机名是 google.com ，所以没有非ASCII的字符；如果有的话，浏览器会对主机名部分使用 Punycode_ 编码 检查 HSTS 列表 浏览器检查自带的“预加载 HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站 如果网站在这个列表里，浏览器会使用 HTTPS 而不是 HTTP 协议，否则，最初的请求会使用HTTP协议发送 注意，一个网站哪怕不在 HSTS 列表里，也可以要求浏览器对自己使用 HSTS 政策进行访问。浏览器向网站发出第一个 HTTP 请求之后，网站会返回浏览器一个响应，请求浏览器只使用 HTTPS 发送请求。然而，就是这第一个 HTTP 请求，却可能会使用户受到 downgrade attack_ 的威胁，这也是为什么现代浏览器都预置了 HSTS 列表。 DNS 查询 浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开 chrome://net-internals/#dns &lt;chrome://net-internals/#dns&gt;_）。 如果缓存中没有，就去调用 gethostbyname 库函数（操作系统不同函数也不同）进行查询。 gethostbyname 函数在试图进行DNS解析之前首先检查域名是否在本地 Hosts 里，Hosts 的位置 不同的操作系统有所不同_ 如果 gethostbyname 没有这个域名的缓存记录，也没有在 hosts 里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS 服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。 查询本地 DNS 服务器 如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询 如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询 ARP 过程要想发送 ARP（地址解析协议）广播，我们需要有一个目标 IP 地址，同时还需要知道用于发送 ARP 广播的接口的 MAC 地址。 首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC 如果缓存没有命中： 查看路由表，看看目标 IP 地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。 查询选择的网络接口的 MAC 地址 我们发送一个二层（ OSI 模型_ 中的数据链路层）ARP 请求： ARP Request:: Sender MAC: interface:mac:address:here Sender IP: interface.ip.goes.here Target MAC: FF:FF:FF:FF:FF:FF (Broadcast) Target IP: target.ip.goes.here 根据连接主机和路由器的硬件类型不同，可以分为以下几种情况： 直连： 如果我们和路由器是直接连接的，路由器会返回一个 ARP Reply （见下面）。 集线器： 如果我们连接到一个集线器，集线器会把 ARP 请求向所有其它端口广播，如果路由器也“连接”在其中，它会返回一个 ARP Reply 。 交换机： 如果我们连接到了一个交换机，交换机会检查本地 CAM/MAC 表，看看哪个端口有我们要找的那个 MAC 地址，如果没有找到，交换机会向所有其它端口广播这个 ARP 请求。 如果交换机的 MAC/CAM 表中有对应的条目，交换机会向有我们想要查询的 MAC 地址的那个端口发送 ARP 请求 如果路由器也“连接”在其中，它会返回一个 ARP Reply ARP Reply:: Sender MAC: target:mac:address:here Sender IP: target.ip.goes.here Target MAC: interface:mac:address:here Target IP: interface.ip.goes.here 现在我们有了 DNS 服务器或者默认网关的 IP 地址，我们可以继续 DNS 请求了： 使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议 如果本地/ISP DNS 服务器没有找到结果，它会发送一个递归查询请求，一层一层向高层 DNS 服务器做查询，直到查询到起始授权机构，如果找到会把结果返回 使用套接字当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数 socket ，请求一个TCP流套接字，对应的参数是 AF_INET/AF_INET6 和 SOCK_STREAM 。 这个请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range) TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet。 这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame 头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。 到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输： 以太网_ WiFi_ 蜂窝数据网络_ 对于大部分家庭网络和小型企业网络来说，封包会从本地计算机出发，经过本地网络，再通过调制解调器把数字信号转换成模拟信号，使其适于在电话线路，有线电视光缆和无线电话线路上传输。在传输线路的另一端，是另外一个调制解调器，它把模拟信号转换回数字信号，交由下一个 网络节点_ 处理。节点的目标地址和源地址将在后面讨论。 大型企业和比较新的住宅通常使用光纤或直接以太网连接，这种情况下信号一直是数字的，会被直接传到下一个 网络节点_ 进行处理。 最终封包会到达管理本地子网的路由器。在那里出发，它会继续经过自治区域(autonomous system, 缩写 AS)的边界路由器，其他自治区域，最终到达目标服务器。一路上经过的这些路由器会从IP数据报头部里提取出目标地址，并将封包正确地路由到下一个目的地。IP数据报头部 time to live (TTL) 域的值每经过一个路由器就减1，如果封包的TTL变为0，或者路由器由于网络拥堵等原因封包队列满了，那么这个包会被路由器丢弃。 上面的发送和接受过程在 TCP 连接期间会发生很多次： 客户端选择一个初始序列号(ISN)，将设置了 SYN 位的封包发送给服务器端，表明自己要建立连接并设置了初始序列号 服务器端接收到 SYN 包，如果它可以建立连接： 服务器端选择它自己的初始序列号 服务器端设置 SYN 位，表明自己选择了一个初始序列号 服务器端把 (客户端ISN + 1) 复制到 ACK 域，并且设置 ACK 位，表明自己接收到了客户端的第一个封包 客户端通过发送下面一个封包来确认这次连接： 自己的序列号+1 接收端 ACK+1 设置 ACK 位 数据通过下面的方式传输： 当一方发送了N个 Bytes 的数据之后，将自己的 SEQ 序列号也增加N 另一方确认接收到这个数据包（或者一系列数据包）之后，它发送一个 ACK 包，ACK 的值设置为接收到的数据包的最后一个序列号 关闭连接时： 要关闭连接的一方发送一个 FIN 包 另一方确认这个 FIN 包，并且发送自己的 FIN 包 要关闭的一方使用 ACK 包来确认接收到了 FIN TLS 握手 客户端发送一个 ClientHello 消息到服务器端，消息中同时包含了它的 Transport Layer Security (TLS) 版本，可用的加密算法和压缩算法。 服务器端向客户端返回一个 ServerHello 消息，消息中包含了服务器端的TLS版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（Certificate Authority，缩写 CA）签发的服务器公开证书，证书中包含了公钥。客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥 客户端根据自己的信任CA列表，验证服务器端的证书是否可信。如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它。这串随机数会被用于生成新的对称密钥 服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥 客户端发送一个 Finished 消息给服务器端，使用对称密钥加密这次通讯的一个散列值 服务器端生成自己的 hash 值，然后解密客户端发送来的信息，检查这两个值是否对应。如果对应，就向客户端发送一个 Finished 消息，也使用协商好的对称密钥加密 从现在开始，接下来整个 TLS 会话都使用对称秘钥进行加密，传输应用层（HTTP）内容 HTTP 协议如果浏览器是 Google 出品的，它不会使用 HTTP 协议来获取页面信息，而是会与服务器端发送请求，商讨使用 SPDY 协议。 如果浏览器使用 HTTP 协议而不支持 SPDY 协议，它会向服务器发送这样的一个请求:: GET / HTTP/1.1 Host: google.com Connection: close [其他头部] “其他头部”包含了一系列的由冒号分割开的键值对，它们的格式符合HTTP协议标准，它们之间由一个换行符分割开来。（这里我们假设浏览器没有违反HTTP协议标准的bug，同时假设浏览器使用 HTTP/1.1 协议，不然的话头部可能不包含 Host 字段，同时 GET 请求中的版本号会变成 HTTP/1.0 或者 HTTP/0.9 。） HTTP/1.1 定义了“关闭连接”的选项 “close”，发送者使用这个选项指示这次连接在响应结束之后会断开。例如： Connection:close 不支持持久连接的 HTTP/1.1 应用必须在每条消息中都包含 “close” 选项。 在发送完这些请求和头部之后，浏览器发送一个换行符，表示要发送的内容已经结束了。 服务器端返回一个响应码，指示这次请求的状态，响应的形式是这样的:: 200 OK [响应头部] 然后是一个换行，接下来有效载荷(payload)，也就是 www.google.com 的HTML内容。服务器下面可能会关闭连接，如果客户端请求保持连接的话，服务器端会保持连接打开，以供之后的请求重用。 如果浏览器发送的HTTP头部包含了足够多的信息（例如包含了 Etag 头部），以至于服务器可以判断出，浏览器缓存的文件版本自从上次获取之后没有再更改过，服务器可能会返回这样的响应:: 304 Not Modified [响应头部] 这个响应没有有效载荷，浏览器会从自己的缓存中取出想要的内容。 在解析完 HTML 之后，浏览器和客户端会重复上面的过程，直到HTML页面引入的所有资源（图片，CSS，favicon.ico等等）全部都获取完毕，区别只是头部的 GET / HTTP/1.1 会变成 GET /$(相对www.google.com的URL) HTTP/1.1 。 如果HTML引入了 www.google.com 域名之外的资源，浏览器会回到上面解析域名那一步，按照下面的步骤往下一步一步执行，请求中的 Host 头部会变成另外的域名。 HTTP 服务器请求处理HTTPD(HTTP Daemon)在服务器端处理请求/响应。最常见的 HTTPD 有 Linux 上常用的 Apache 和 nginx，以及 Windows 上的 IIS。 HTTPD 接收请求 服务器把请求拆分为以下几个参数： HTTP 请求方法(GET, POST, HEAD, PUT, DELETE, CONNECT, OPTIONS, 或者 TRACE)。直接在地址栏中输入 URL 这种情况下，使用的是 GET 方法 域名：google.com 请求路径/页面：/ (我们没有请求google.com下的指定的页面，因此 / 是默认的路径) 服务器验证其上已经配置了 google.com 的虚拟主机 服务器验证 google.com 接受 GET 方法 服务器验证该用户可以使用 GET 方法(根据 IP 地址，身份信息等) 如果服务器安装了 URL 重写模块（例如 Apache 的 mod_rewrite 和 IIS 的 URL Rewrite），服务器会尝试匹配重写规则，如果匹配上的话，服务器会按照规则重写这个请求 服务器根据请求信息获取相应的响应内容，这种情况下由于访问路径是 “/“ ,会访问首页文件（你可以重写这个规则，但是这个是最常用的）。 服务器会使用指定的处理程序分析处理这个文件，假如 Google 使用 PHP，服务器会使用 PHP 解析 index 文件，并捕获输出，把 PHP 的输出结果返回给请求者 浏览器背后的故事当服务器提供了资源之后（HTML，CSS，JS，图片等），浏览器会执行下面的操作： 解析 —— HTML，CSS，JS 渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制 浏览器浏览器的功能是从服务器上取回你想要的资源，然后展示在浏览器窗口当中。资源通常是 HTML 文件，也可能是 PDF，图片，或者其他类型的内容。资源的位置通过用户提供的 URI(Uniform Resource Identifier) 来确定。 浏览器解释和展示 HTML 文件的方法，在 HTML 和 CSS 的标准中有详细介绍。这些标准由 Web 标准组织 W3C(World Wide Web Consortium) 维护。 不同浏览器的用户界面大都十分接近，有很多共同的 UI 元素： 一个地址栏 后退和前进按钮 书签选项 刷新和停止按钮 主页按钮 浏览器高层架构 组成浏览器的组件有： 用户界面 用户界面包含了地址栏，前进后退按钮，书签菜单等等，除了请求页面之外所有你看到的内容都是用户界面的一部分 浏览器引擎 浏览器引擎负责让 UI 和渲染引擎协调工作 渲染引擎 渲染引擎负责展示请求内容。如果请求的内容是 HTML，渲染引擎会解析 HTML 和 CSS，然后将内容展示在屏幕上 网络组件 网络组件负责网络调用，例如 HTTP 请求等，使用一个平台无关接口，下层是针对不同平台的具体实现 UI后端 UI 后端用于绘制基本 UI 组件，例如下拉列表框和窗口。UI 后端暴露一个统一的平台无关的接口，下层使用操作系统的 UI 方法实现 Javascript 引擎 Javascript 引擎用于解析和执行 Javascript 代码 数据存储 数据存储组件是一个持久层。浏览器可能需要在本地存储各种各样的数据，例如 Cookie 等。浏览器也需要支持诸如 localStorage，IndexedDB，WebSQL 和 FileSystem 之类的存储机制 HTML 解析浏览器渲染引擎从网络层取得请求的文档，一般情况下文档会分成8kB大小的分块传输。 HTML 解析器的主要工作是对 HTML 文档进行解析，生成解析树。 解析树是以 DOM 元素以及属性为节点的树。DOM是文档对象模型(Document Object Model)的缩写，它是 HTML 文档的对象表示，同时也是 HTML 元素面向外部(如Javascript)的接口。树的根部是”Document”对象。整个 DOM 和 HTML 文档几乎是一对一的关系。 解析算法 HTML不能使用常见的自顶向下或自底向上方法来进行分析。主要原因有以下几点: 语言本身的“宽容”特性 HTML 本身可能是残缺的，对于常见的残缺，浏览器需要有传统的容错机制来支持它们 解析过程需要反复。对于其他语言来说，源码不会在解析过程中发生变化，但是对于 HTML 来说，动态代码，例如脚本元素中包含的 document.write() 方法会在源码中添加内容，也就是说，解析过程实际上会改变输入的内容 由于不能使用常用的解析技术，浏览器创造了专门用于解析 HTML 的解析器。解析算法在 HTML5 标准规范中有详细介绍，算法主要包含了两个阶段：标记化（tokenization）和树的构建。 解析结束之后 浏览器开始加载网页的外部资源（CSS，图像，Javascript 文件等）。 此时浏览器把文档标记为可交互的（interactive），浏览器开始解析处于“推迟（deferred）”模式的脚本，也就是那些需要在文档解析完毕之后再执行的脚本。之后文档的状态会变为“完成（complete）”，浏览器会触发“加载（load）”事件。 注意解析 HTML 网页时永远不会出现“无效语法（Invalid Syntax）”错误，浏览器会修复所有错误内容，然后继续解析。 CSS 解析 根据 CSS词法和句法_ 分析CSS文件和 &lt;style&gt; 标签包含的内容以及 style 属性的值 每个CSS文件都被解析成一个样式表对象（StyleSheet object），这个对象里包含了带有选择器的CSS规则，和对应CSS语法的对象 CSS解析器可能是自顶向下的，也可能是使用解析器生成器生成的自底向上的解析器 页面渲染 通过遍历DOM节点树创建一个“Frame 树”或“渲染树”，并计算每个节点的各个CSS样式值 通过累加子节点的宽度，该节点的水平内边距(padding)、边框(border)和外边距(margin)，自底向上的计算”Frame 树”中每个节点的首选(preferred)宽度 通过自顶向下的给每个节点的子节点分配可行宽度，计算每个节点的实际宽度 通过应用文字折行、累加子节点的高度和此节点的内边距(padding)、边框(border)和外边距(margin)，自底向上的计算每个节点的高度 使用上面的计算结果构建每个节点的坐标 当存在元素使用 floated，位置有 absolutely 或 relatively 属性的时候，会有更多复杂的计算，详见http://dev.w3.org/csswg/css2/ 和 http://www.w3.org/Style/CSS/current-work 创建layer(层)来表示页面中的哪些部分可以成组的被绘制，而不用被重新栅格化处理。每个帧对象都被分配给一个层 页面上的每个层都被分配了纹理(?) 每个层的帧对象都会被遍历，计算机执行绘图命令绘制各个层，此过程可能由CPU执行栅格化处理，或者直接通过D2D/SkiaGL在GPU上绘制 上面所有步骤都可能利用到最近一次页面渲染时计算出来的各个值，这样可以减少不少计算量 计算出各个层的最终位置，一组命令由 Direct3D/OpenGL发出，GPU命令缓冲区清空，命令传至GPU并异步渲染，帧被送到Window Server。 GPU 渲染 在渲染过程中，图形处理层可能使用通用用途的 CPU，也可能使用图形处理器 GPU 当使用 GPU 用于图形渲染时，图形驱动软件会把任务分成多个部分，这样可以充分利用 GPU 强大的并行计算能力，用于在渲染过程中进行大量的浮点计算。 Window Server后期渲染与用户引发的处理渲染结束后，浏览器根据某些时间机制运行JavaScript代码(比如Google Doodle动画)或与用户交互(在搜索栏输入关键字获得搜索建议)。类似Flash和Java的插件也会运行，尽管Google主页里没有。这些脚本可以触发网络请求，也可能改变网页的内容和布局，产生又一轮渲染与绘制。 .. _Creative Commons Zero: https://creativecommons.org/publicdomain/zero/1.0/.. _CSS词法和句法: http://www.w3.org/TR/CSS2/grammar.html.. _Punycode: https://en.wikipedia.org/wiki/Punycode.. _以太网: http://en.wikipedia.org/wiki/IEEE_802.3.. _WiFi: https://en.wikipedia.org/wiki/IEEE_802.11.. _蜂窝数据网络: https://en.wikipedia.org/wiki/Cellular_data_communication_protocol.. _analog-to-digital converter: https://en.wikipedia.org/wiki/Analog-to-digital_converter.. _网络节点: https://en.wikipedia.org/wiki/Computer_network#Network_nodes.. 不同的操作系统有所不同 : https://en.wikipedia.org/wiki/Hosts%28file%29#Location_in_the_file_system.. _downgrade attack: http://en.wikipedia.org/wiki/SSL_stripping.. _OSI 模型: https://en.wikipedia.org/wiki/OSI_model","link":"/2022/04/25/d09dcd3af22a.html"},{"title":"我敢打赌这不是你所认识的kubectl apply！","text":"介绍与 kubectl apply 相关的几个概念、相关操作的主要逻辑，主要包括 Server Side Apply、Client Side Apply。 一句话概述kubectl apply 执行时，先读取资源，再将资源更新到 apiserver。 读取资源流程 这里有被谭浩强i+++++i支配的恐惧（虽然这种用法没有太大的实际意义） 1234cat staging/src/k8s.io/kubectl/testdata/apply/cm.yaml | kubectl apply \\-f - \\-f staging/src/k8s.io/kubectl/testdata/apply/service.yaml \\-f https://k8s.io/examples/controllers/nginx-deployment.yaml 上面从 3 种不同类型的“文件”读取资源，对应源码实现中 3 中不同的 Vistor，这 3 种不同的 Visitor 都可以抽象成一种流，所以他们底层都是依赖于 StreamVisitor。 如果 -f dir，有多少个文件，就会有多少个 FileVisitor。 还有一种方式是从 kustomize 目录中读取资源，kustomize 目录类似于 helm，需要先构建后才能获取到 Manifest。使用方式如下： 1kubectl apply -k ../kustomize/examples/helloWorld 对一个 kustomize 类型的资源，会添加一个 KustomizeVistor。它会构建一个默认的 kustomize 命令，然后执行该 kustomize 命令。效果等同于执行了 kustomize build。得到结果后，最终还是会引入一个 StreamVisitor 来读取构建的结果。 流程中其他 Visitor 的作用举例： 当有多个资源加载时，一个资源读取报错，不会影响其他资源。 至此，读取到的资源会存放在列表中。 1infos, err := o.GetObjects() 更新资源在读取到所有的资源之后，会对每个资源进行单独操作，每个资源的操作结果是独立的。 12345for _, info := range infos { if err := o.applyOneObject(info); err != nil { errs = append(errs, err) }} 至此，apply 流程已经执行完毕，上述代码片段后面是对错误的聚合处理。 现象与问题 用 Lens 工具查看资源 yaml 时，老长的一串 managedFields 是啥？用来干啥？💻 可演示 =&gt; one.yaml 1k get deployment nginx-dep-one --show-managed-fields 跑完 kubectl apply 之后，annotation 中的 kubectl.kubernetes.io/last-applied-configuration 是什么？有什么作用？ 这段 Warning 是什么意思？是否有副作用？💻 可演示 =&gt; two.yaml 12Warning: resource deployments/nginx-dep-two is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.deployment.apps/nginx-dep-two configured 有副作用。当 apply 的数据中，有删除字段时，会出现删不掉的问题。 kubectl create -f data/two.yaml 删除 two.yaml 中的一个 pod kubectl apply -f data/two.yaml 什么是冲突？💻 可演示 =&gt; three.yaml 123456789101112error: Operation cannot be fulfilled on pods &quot;nginx-dep-7486b598d5-k794w&quot;: the object has been modified; please apply your changes to the latest version and try againPlease review the fields above--they currently have other managers. Hereare the ways you can resolve this warning:* If you intend to manage all of these fields, please re-run the apply command with the `--force-conflicts` flag.* If you do not intend to manage all of the fields, please edit your manifest to remove references to the fields that should keep their current managers.* You may co-own fields by updating your manifest to match the existing value; in this case, you'll become the manager if the other manager(s) stop managing the field (remove it from their configuration).See https://kubernetes.io/docs/reference/using-api/server-side-apply/#conflicts 先以 a manager 创建 svc kubectl apply -f data/three.yaml --server-side --field-manager=a 修改 svc 的字段 再以 b manager 修改 svc kubectl apply -f data/three.yaml --server-side --field-manager=b Apply 操作分类 Client Side Apply （默认） 第一次 apply 操作时的请求如下： 123456I0726 14:41:20.148843 73549 loader.go:372] Config loaded from file: /Users/yangyu/.kube/configI0726 14:41:20.149611 73549 cert_rotation.go:137] Starting client certificate rotation controllerI0726 14:41:20.165326 73549 round_trippers.go:553] GET https://192.168.59.100:8443/openapi/v2?timeout=32s 200 OK in 15 millisecondsI0726 14:41:20.217376 73549 round_trippers.go:553] GET https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-dep 404 Not Found in 1 millisecondsI0726 14:41:20.224037 73549 round_trippers.go:553] POST https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments?fieldManager=kubectl-client-side-apply&amp;fieldValidation=Strict 201 Created in 6 millisecondsdeployment.apps/nginx-dep created 再次 apply 操作时（无任何修改）的请求如下： 12345I0726 14:42:15.636114 73739 loader.go:372] Config loaded from file: /Users/yangyu/.kube/configI0726 14:42:15.641428 73739 cert_rotation.go:137] Starting client certificate rotation controllerI0726 14:42:15.676334 73739 round_trippers.go:553] GET https://192.168.59.100:8443/openapi/v2?timeout=32s 200 OK in 32 millisecondsI0726 14:42:15.780602 73739 round_trippers.go:553] GET https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-dep 200 OK in 6 millisecondsdeployment.apps/nginx-dep unchanged 再次 apply 操作时（无任何修改）的请求如下： 123456I0726 14:43:12.579529 73954 loader.go:372] Config loaded from file: /Users/yangyu/.kube/configI0726 14:43:12.582585 73954 cert_rotation.go:137] Starting client certificate rotation controllerI0726 14:43:12.605987 73954 round_trippers.go:553] GET https://192.168.59.100:8443/openapi/v2?timeout=32s 200 OK in 21 millisecondsI0726 14:43:12.663763 73954 round_trippers.go:553] GET https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-dep 200 OK in 2 millisecondsI0726 14:43:12.671397 73954 round_trippers.go:553] PATCH https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-dep?fieldManager=kubectl-client-side-apply&amp;fieldValidation=Strict 200 OK in 6 millisecondsdeployment.apps/nginx-dep configured Server Side Apply （通过 --server-side=true 开启） 请求如下： 1234I0726 14:38:39.703841 72954 loader.go:372] Config loaded from file: /Users/yangyu/.kube/configI0726 14:38:39.704461 72954 cert_rotation.go:137] Starting client certificate rotation controllerI0726 14:38:39.726918 72954 round_trippers.go:553] GET https://192.168.59.100:8443/openapi/v2?timeout=32s 200 OK in 22 millisecondsI0726 14:38:39.796641 72954 round_trippers.go:553] PATCH https://192.168.59.100:8443/api/v1/namespaces/default/pods/nginx-dep-7486b598d5-k794w?fieldManager=kubectl&amp;fieldValidation=Strict&amp;force=false 409 Conflict in 8 milliseconds 当读取到资源后，apply 操作后续的代码逻辑流程示意图如下： 对 client side apply，当 patch 处理失败时，会进行 5 次重试。 server side apply 的特点： 资源中的每个字段都会有一个归属 manager，当不同的 manager 来操作同一个字段时，会提示冲突； 逻辑都在服务端，与客户端的网络无关； 先看 kubectl patch 怎么执行1234567891011121314I0726 15:02:01.540175 77947 loader.go:372] Config loaded from file: /Users/yangyu/.kube/configI0726 15:02:01.543797 77947 cert_rotation.go:137] Starting client certificate rotation controllerI0726 15:02:01.550931 77947 round_trippers.go:463] GET https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-depI0726 15:02:01.550946 77947 round_trippers.go:469] Request Headers:I0726 15:02:01.550973 77947 round_trippers.go:473] Accept: application/jsonI0726 15:02:01.550979 77947 round_trippers.go:473] User-Agent: kubectl/v1.24.1 (darwin/amd64) kubernetes/3ddd0f4I0726 15:02:01.562444 77947 round_trippers.go:574] Response Status: 200 OK in 11 millisecondsI0726 15:02:01.563361 77947 round_trippers.go:463] PATCH https://192.168.59.100:8443/apis/apps/v1/namespaces/default/deployments/nginx-dep?fieldManager=kubectl-patchI0726 15:02:01.563372 77947 round_trippers.go:469] Request Headers:I0726 15:02:01.563379 77947 round_trippers.go:473] Accept: application/jsonI0726 15:02:01.563384 77947 round_trippers.go:473] Content-Type: application/strategic-merge-patch+jsonI0726 15:02:01.563389 77947 round_trippers.go:473] User-Agent: kubectl/v1.24.1 (darwin/amd64) kubernetes/3ddd0f4I0726 15:02:01.568949 77947 round_trippers.go:574] Response Status: 200 OK in 5 millisecondsdeployment.apps/nginx-dep patched (no change) GET 请求用来获取原资源，主要有以下两个作用： 和 PATCH 请求完了之后得到的修改了之后的对象做对比，看是否有 patch 发生； 用来做 client 端 dry-run。 这里相当于只发了一个 PATCH 请求。 kubectl patch 中支持的 patch 方式 Strategic Merge Patch(SMP) --type=strategic 默认 JSON Merge Patch --type=merge JSON Patch --type=json 其他 三者的使用姿势和区别 =》 JSON Patch and JSON Merge Patch SMP 效果演示 💻可演示 =》 four.yaml kubectl apply -f data/four.yaml kubectl patch deployment nginx-dep-four --type strategic --patch-file data/four-patch.yaml 看现象 原因： kubernetes/types.go at master · kubernetes/kubernetes (github.com) 回到 apply 操作 对第二次及后续 apply 操作 既然 apply 操作最终会调用 PATCH 接口，那么 “patch.yaml“ 该怎么来？在获取 ThreeWayMergePatch通过 3WayMergePatch 计算出变更的内容，然后再调用 PATCH 接口，默认使用 Strategic Merge Patch（对找不到 schema 的资源，使用 JSON Merge Patch）。它的定义如下： 1func CreateThreeWayMergePatch(original, modified, current []byte,,,) ([]byte, error) 其中 original, modified, current 的含义如下所示： current 当前资源在 k8s 中的状态，即通过 GET 请求从 k8s 中获取到的内容； original 是 current annotation 中 kubectl.kubernetes.io/last-applied-configuration 中的值，即之前 apply 操作时塞进去的内容； modified 是本次 apply 操作时，从“文件”中读取到的内容，再加上一个键为 kubectl.kubernetes.io/last-applied-configuration 的 annotation。 接下来会计算 3 组数据，分别为 deltaMap: current 与 modified 之间的差异（除去 deletion 操作），找出值发生变化的字段； 12345deltaMapDiffOptions := DiffOptions{ IgnoreDeletions: true, SetElementOrder: true,}deltaMap, err := diffMaps(currentMap, modifiedMap, schema, deltaMapDiffOptions) deletionsMap: original 与 modified 之间的 deletions 操作，找出删除的字段； 12345deletionsMapDiffOptions := DiffOptions{ SetElementOrder: true, IgnoreChangesAndAdditions: true,}deletionsMap, err := diffMaps(originalMap, modifiedMap, schema, deletionsMapDiffOptions) 为什么只能是 original 与 modified ? current 中可能存在自动添加的默认值字段，如果与 modified 进行对比的话，会导致自动添加的字段被标记为删除字段。 此时再回过头看前面的问题。 patchMap: deltaMap 和 deletionsMap 执行 merge 操作后得到 patchMap。 12mergeOptions := MergeOptions{}patchMap, err := mergeMap(deletionsMap, deltaMap, schema, mergeOptions) 最终返回 json.Marshal(patchMap)。至此计算 patch 结束。 调用 PATCH 接口得到 patch 数据后，调用 PATCH 接口，完成 apply 操作。 一个小问题在 Update API Objects in Place Using kubectl patch | Kubernetes 这篇文档中，最后一句 Note 说： Patch 时使用的 SMP 操作不支持 CR。 原因是什么？ 附录 one.yaml123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-dep-one labels: app: nginx-dep-onespec: replicas: 1 selector: matchLabels: app: nginx-one template: metadata: labels: app: nginx-one spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 800 two.yaml12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-dep-two labels: app: nginx-twospec: replicas: 1 selector: matchLabels: app: nginx-two template: metadata: labels: app: nginx-two spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 - name: tomcat image: tomcat:latest ports: - containerPort: 8080 three.yaml1234567891011apiVersion: v1kind: Servicemetadata: name: three-svc labels: name: three-svcspec: ports: - port: 80 selector: name: test-rc four.yaml12345678910111213141516171819202122232425262728293031323334apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-dep-four labels: app: nginx-fourspec: replicas: 1 selector: matchLabels: app: nginx-four template: metadata: labels: app: nginx-four spec: tolerations: - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot; - key: &quot;key2&quot; operator: &quot;Equal&quot; value: &quot;value2&quot; effect: &quot;NoSchedule&quot; containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 800 - name: tomcat image: tomcat:latest ports: - containerPort: 8080 four-patch.yaml12345678910111213spec: template: spec: tolerations: - key: &quot;key3&quot; operator: &quot;Equal&quot; value: &quot;value3&quot; effect: &quot;NoSchedule&quot; containers: - name: redis image: redis:latest ports: - containerPort: 6379","link":"/2022/07/30/9ab7547c8903.html"},{"title":"手动安装K8s记录","text":"必要的工具安装 cfssl cfssljson kubectl 证书与CA 配置和生成kubeconfig kubelet 配置文件 worker-n.kubeconfig，分发到所有 worker 节点上。 kube-proxy 配置文件 kube-proxy.kubeconfig，分发到所有 worker 节点上。 kube-controller-manager 配置文件 kube-controller-manager.kubeconfig，分发到所有 控制节点 上。 kube-scheduler 配置文件 kube-scheduler.kubeconfig，分发到所有 控制节点 上。 Admin 配置文件 admin.kubeconfig，分发到所有 控制节点 上。 配置加密k8s secrets的秘钥encryption-config.yaml，分发到所有 控制节点 上。 配置&amp;部署etcd前置要求：etcd &amp; etcdctl 二进制将 ca.pem、kubernetes-key.pem、kubernetes.pem 拷贝到 etcd 所在节点上，其中 kubernetes-key.pem、kubernetes.pem 作为 etcd https 服务的 TLS 证书。 配置&amp;部署控制节点服务前置要求：kube-apiserver &amp; kube-controller-manager &amp; kube-scheduler &amp; kubectl 二进制 api-server在其启动参数中，需要 指定 CA 为 ca.pem 指定 etcd 的 CA 证书 ca.pem，公私钥为 kubernetes-key.pem、kubernetes.pem、及 etcd 的访问地址 指定 k8s secrets 的秘钥为 encryption-config.yaml 指定 kubelet 的 CA 证书 ca.pem，公私钥为 kubernetes-key.pem、kubernetes.pem 指定 api-server https 服务所用的 TLS 证书为 kubernetes-key.pem、kubernetes.pem 指定 service account 的证书为 service-account.pem controller-manager在其启动参数中，需要 指定 cluster 所使用的 CA 的公私钥为 ca.pem、ca-key.pem 指定 kubeconfig 使用 kube-controller-manager.kubeconfig 指定 root CA 为 ca.pem 指定 service account 的私钥为 service-account-key.pem scheduler在启动参数中，指定配置文件 kube-scheduler.yaml，然后在 kube-scheduler.yaml 中指定 kubeconfig 为 kube-scheduler.kubeconfig。 启动控制面服务 &amp; 验证 给 kubelet 添加数据处理权限创建 system:kube-apiserver-to-kubelet ClusterRole 及 system:kube-apiserver ClusterRoleBinding 以允许请求 Kubelet API 和执行大部分来管理 Pods 的任务 配置&amp;部署worker节点 安装 OS 依赖的组件：socat conntrack ipset 安装 CRI 安装 worker 节点所需的二进制：kubectl、kube-proxy、kubelet、默认提供的 CNI plugins 配置kubelet创建 kubelet-config.yaml 文件，在该文件中指定 CA 证书 TLS 公私钥分别使用 worker-1.pem、worker-1-key.pem。好家伙，kubelet 又是一个 https 服务。 并在 kubelet.service 指定 配置文件使用文件 指定 kubelet 所使用的 kubeconfig 为 worker-n.kubeconfig 配置kube-proxy创建 kube-proxy-config.yaml 文件，在该文件中指定所用的 kubeconfig 为 kube-proxy.kubeconfig；再在 kubelet.service 指定使用此配置文件。 启动控制面服务 配置 kubectl 所使用的 kubeconfig使用 admin.pem 和 admin-key.pem 生成 kubeconfig。 验证12kubectl get componentstatuseskubectl get nodes 安装其他重要的组件 安装 CNI DNS 验证123kubectl run busybox --image=busybox:1.28.3 --command -- sleep 3600kubectl get pods -l run=busyboxkubectl exec -ti $POD_NAME -- nslookup kubernetes 烟雾测试 数据加密 Deployment 创建 端口转发 容器日志 在容器中执行命令 Service 创建 访问","link":"/2023/06/12/51cba5e1e272.html"},{"title":"折腾我的新家用锄头","text":"当前 macOS 版本：Big Sur 11.5.2 配置 组件 品牌 备注 主板 ASRock Z490M ITX/AC 依据是网上 EFI 数量 CPU i7-10700K 感觉没必要上i9,甚至i7都多余了 GPU Radeon RX560 无需供电、性能不强，奈何显卡太贵 iGPU Intel® UHD 630 内存 威刚(AData) 16GBx2 DDR4 2666 MHz 没信仰，随便上 WiFi 蓝牙 BCM94352z 没感觉出不完美 NVMe SSD 英睿达 CT500P5SSD8 500 GB macOS NVMe SSD KIOXIA-EXCERIA PLUS G2 SSD 500 GB Windows SATA HDD 希捷 2 TB 备份&amp;数据 SATA SSD 铠侠 500 GB 虚拟机 BIOS 设置 将 BIOS 设置重置。Exit - Load UEFI Defaults Advanced CPU Configuration Intel Hyper Threading Technology - Enabled Software Guard Extensions(SGX) - Disabled CFG Lock - Disabled Chipset Configuration VT-d - Disabled Above 4G Decoding - Enabled Primary Graphics Adapter - Auto Storage Configuration SATA Controllers - Enabled SATA Mode Selection - AHCI Super IO Configuration PS2 Y-Cable - Enabled ACPI Configuration Suspend to RAM - Auto USB Configuration Legacy USB Support - Enabled XHCI Hand-off - Enabled Trusted Computing Security Device Support - Enabled Security Secure Boot Secure Boot - Disabled Boot Fast Boot - Disabled CSM(Compatibility Support Module) CSM - Disabled 安装使用黑果小兵制作的镜像，刻录到 U 盘后，用它默认的 EFI 来完成安装。这里使用别人的制作好的 EFI 可能会启动不了，导致直接无法安装。 装机后无法启动、开机按了开机键之后，风扇转一下，水冷动一下，然后就没动静了，怎么按开机键都没有动静了。排查了电源问题、主板供电线问题、CPU 供电线问题，最后发现内存条插入插槽之后，冒出来的高度不一致，确实是内存条没插好。 BCM94352z 蓝牙网卡驱动Windows 下无法找到对应WiFi设备、驱动也安装不上，但蓝牙是可以正常工作的。经过大量时间的排查，结果发现是 BIOS 里面将 WiFi 设备关了。 这个配置项是开始装黑苹果时参考某个文章配置的，当时并未知晓其中的含义。发现此问题是由于看到了此文。 如果遇到类似问题，可检查的相关配置项为： WAN Radio/Onboard WAN Device。同时，也可以尝试 Exit - Load UEFI Defaults 后，重新设置 BIOS。 在 OC/kexts 中添加如下驱动： AirportBrcmFixup BrcmBluetoothInjector BrcmFirmwareData BrcmPatchRAM3 按如下配置添加到 config.plist 中 启用 - AirportBrcmFixup.kext 禁用 - AirportBrcmFixup.kext/Contents/PlugIns/AirPortBrcm4360_Injector.kext 启用 - AirportBrcmFixup.kext/Contents/PlugIns/AirPortBrcmNIC_Injector.kext 启用 - BrcmBluetoothInjector.kext 启用 - BrcmFirmwareData.kext 启用 - BrcmPatchRAM3.kext 添加启动参数(boot-arg) 1-brcmfx-driver=2 更新 OpenCore 版本到 OpenCore 项目的 release 中下载最新的版本到本地，然后解压，进入 X64 文件夹，如下（部分可选更新项已省略） 1234567891011~/Downloads/OpenCore-0.7.2-RELEASE/X64 &gt; tree ..└── EFI ├── BOOT │ └── BOOTx64.efi └── OC ├── Drivers │ ├── AudioDxe.efi │ ├── OpenCanopy.efi │ └── OpenRuntime.efi └── OpenCore.efi /EFI/BOOT/BOOTx64.efi：OpenCore 的引导文件，必须替换 /EFI/OC/OpenCore.efi：必须替换 /EFI/OC/Driver/OpenRuntime：OpenCore 的功能库，必须替换 /EFI/OC/Bootstrap/Bootstrap.efi：如果使用了 Bootstrap，则需要 「提示」OpenCore 自 0.6.6 版本开始删除了 Bootstrap，如果之前你使用了 Bootstrap，需要先在 config 中关闭，重启计算机并重置 NVRAM，最后再升级 OC 文件 /EFI/OC/Driver/AudioDxe.efi：如果使用了开机声音，则需要替换 /EFI/OC/Driver/OpenCanopy：如果使用了官方主题服务，则需要替换 「再次提示」OpenCore 部分版本升级后依然提示没有升级，一般常见于 0.6.5、0.6.6、0.6.7 这三个版本，需要通过在引导界面重置 NVRAM 解决，如果你的引导界面没有 ResetNVRAM 的选项，打开以下设置：config → Misc → Security → AllowResetNvram 勾选/True Q：opencore升级版本后，Hackintool上的引导依旧显示原来的版本号。 A：使用opencore configure工具打开EFI引导分区OC目录下config.plist文件，Misc—Security—AllowNvramReset选项勾选上，然后保存重启，进入菜单栏页面选择rest nvram选项，系统会自动重启，重启后在去Hackintool上看引导的OC版本号，已经显示为最新版本。 Reference (EFI) Lorys89 (EFI) Old-Black-Dog (EFI) ruibeard (EFI) luckyyyyy (EFI) 小明和他的女朋友 (EFI) doubleman2020 (EFI) tonymacx86-thread 黑苹果BigSur：BCM94352Z驱动方法 黑苹果无线网卡购买&amp;安装&amp;使用指南2021年版 Tonymacx86 wifi not work xjn Arsock Deskmini H310 更新 OpenCore 版本","link":"/2021/08/22/344d045172ce.html"},{"title":"折腾自建博客系列","text":"从CSDN迁移到Github Pages 打算将CSDN上的博客迁移到GitHub Pages上去，怕有一天所有的博客都不见了的时候，自己会有一个备份. 其中，上传到CSDN网站上的图片，是必须要自己有一个备份的。所以，便有了这一篇记录博客。 了解ScrapyScrapy是一个Python包，是一个爬取网页的框架。顾名思义，可以理解成Java中的抽象类。它负责流程性的逻辑，我们自己编写具体的处理逻辑。经过此次的使用，发现它确实是一个比较厉害的框架。首先，在爬取网页的过程中，你可能会遇到的问题，网上都有相应的解答；其次，我们只需要编写处理网页的逻辑和小的流程逻辑，这样我们可以更加专注爬取这件事本身，而不用关注使用什么技术来怎么爬。 简易使用 网上的使用方法很多，这里只写一些关键性的步骤以及自己遇到的问题、解决办法。 初始化项目：scrapy startproject CSDNBlogMover 各个文件及目录的作用： items.py 1234567891011# 定义所需数据的属性，比如说，想爬取每一篇文章，此文件中则定义一些文章属性，如下：class CsdnblogmoverItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() link = scrapy.Field() title = scrapy.Field() time = scrapy.Field() tags = scrapy.Field() categories = scrapy.Field() content = scrapy.Field() comments = scrapy.Field() pipelines.py 1234567891011121314151617# 此文件可以理解成在某些关键时候，所要执行的操作，比如打开、关闭、处理爬虫这3个关键时候，与Android中Activity的生命周期类似class CsdnblogmoverPipeline(object): def open_spider(self, spider): self.myconn = mysql_connection() def close_spider(self, spider): self.myconn.conn.close() def process_item(self, item, spider): self.myconn.reconnect() sql = 'INSERT INTO wp_posts(post_author, post_excerpt, to_ping, pinged, post_content_filtered, post_date, post_date_gmt, post_content, post_title, post_modified, post_modified_gmt) VALUES (1, &quot; &quot;,&quot; &quot;, &quot; &quot;, &quot;&quot;, %s, %s, %s, %s, %s, %s)' vars = (get_uniformed_datetime(item['time'], DATE_FORMAT_CN), get_gmt_datetime(item['time'], DATE_FORMAT_CN), '&lt;!-- wp:html --&gt;\\n'+item['content'] + item['comments'] + '\\n&lt;!-- /wp:html --&gt;', item['title'], get_now_datetime(), get_gmt_datetime(get_now_datetime())) self.myconn.cursor.execute(sql, vars) self.myconn.conn.commit() print(item) return item middlewares.py 这个文件的作用在此次爬取博客中未使用到，但是也了解了部分内容，其实就是可以在这里面加上selenium，来处理动态加载的数据。 settings.py 这是一个配置类，里面有很多项，并且都有相应的注释，可以仔细看看。 1234567891011BOT_NAME = 'CSDNBlogMover'SPIDER_MODULES = ['CSDNBlogMover.spiders']NEWSPIDER_MODULE = 'CSDNBlogMover.spiders'FEED_EXPORT_ENCODING = 'utf-8'ROBOTSTXT_OBEY = TrueITEM_PIPELINES = { 'CSDNBlogMover.pipelines.CsdnblogmoverPipeline': 300,} 爬取的关键：spiders/CSDNBlogSpider.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144import jsonimport mathimport scrapy# 需要更换相应的Cookie，来确定你对此博客的拥有权，否则会抓取失败。# 直接从浏览器的开发者工具中，打开编辑器时，所发出的请求的Cookie即可raw_cookie = 'xxx'items = raw_cookie.split('; ')cookies = {}for item in items: kv = item.split('=') cookies[kv[0]] = kv[1]print(cookies)class CSDNBlogSpider(scrapy.Spider): # 名字，用来使用scrapy crawl csdn_spider来调用此爬虫 name = 'csdn_spider' # 限定爬取的域名，如果域名不为此，则会爬取失败 allowed_domains = ['blog.csdn.net', 'mp.csdn.net'] author = '' def __init__(self): # self.browser = webdriver.Chrome() # self.browser.set_page_load_timeout(30) pass def closed(self, spider): print(&quot;spider closed&quot;) # 爬虫入口 def start_requests(self): urls = [ 'https://blog.csdn.net/asahinokawa' ] for url in urls: self.author = url.split('/')[-1] # 返回一个Request，并指明：当请求发送成功，收到响应后，执行self.parse()回调 yield scrapy.Request(url=url, callback=self.parse) # 只负责爬取页数 def parse(self, response): # 获取总博客数 total_blog_cnt = response.xpath( '//*[@id=&quot;mainBox&quot;]/aside/div[@id=&quot;asideProfile&quot;]/div[2]/dl[1]/dd/a/span/text()').get() if total_blog_cnt is None or total_blog_cnt == '': raise Exception('total blog number parse error') else: total_blog_cnt = int(total_blog_cnt) # 获取第1页的博客总数 if response.status == 200: links = response.xpath('//*[@id=&quot;mainBox&quot;]/main/div[2]/div[@data-articleid]/h4/a/@href') raw_links = [] for link in links: if link.get().__contains__(self.author): # yield scrapy.Request(link.get(), callback=self.parse_content) raw_links.append(link.get()) else: print('%s not belong to author %s' % (link, self.author)) # 获取第1页博客数量 first_page_blog_cnt = len(raw_links) if first_page_blog_cnt &lt;= total_blog_cnt: # 不止一页 # 通过总页数与第一页页数，来计算总共有多少页 pages = int(math.ceil(total_blog_cnt / first_page_blog_cnt)) + 1 for idx in range(1, int(pages)): page_url = '%s/article/list/%d' % (response.url, idx) print(page_url) # 返回爬取某页页面的请求 yield scrapy.Request(url=page_url, callback=self.parse_page) else: self.parse_page(self, response) else: print('对CSDN主页访问的响应异常，请检查URL') # 爬取某页页面的请求 def parse_page(self, response): if response.status == 200: links = response.xpath('//*[@id=&quot;mainBox&quot;]/main/div[2]/div[@data-articleid]/h4/a/@href') # 依次遍历所有的博客请求，并第每一个博客链接（即所有文章），进行文章页面爬取 for link in links: # 包含作者 if link.get().__contains__(self.author): yield scrapy.Request(url=link.get(), callback=self.parse_content) else: print('%s not belong to author %s, skipped' % (link.get(), self.author)) else: print('对CSDN中某页访问出错') # 爬取页面 @staticmethod def parse_content(self, response): if response.status == 200: data = { 'link': response.url, 'title': response.xpath( '//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;blog-content-box&quot;]/div[@class=&quot;article-header-box&quot;]/div[@class=&quot;article-header&quot;]/div[@class=&quot;article-title-box&quot;]/h1/text()').get(), # //*[@id=&quot;mainBox&quot;]/main/div[1]/div/div/div[2]/div[1]/span[1] 'time': response.xpath( '//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;blog-content-box&quot;]/div[@class=&quot;article-header-box&quot;]/div[@class=&quot;article-header&quot;]/div[@class=&quot;article-info-box&quot;]/div[@class=&quot;article-bar-top&quot;]/span[@class=&quot;time&quot;]/text()').get(), # //*[@id=&quot;mainBox&quot;]/main/div[1]/div/div/div[2]/div[1]/span[3]/a 'tags': response.xpath( '//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;blog-content-box&quot;]/div[@class=&quot;article-header-box&quot;]/div[@class=&quot;article-header&quot;]/div[@class=&quot;article-info-box&quot;]/div[@class=&quot;article-bar-top&quot;]/span[@class=&quot;tags-box artic-tag-box&quot;]/a/text()').get(), # //*[@id=&quot;mainBox&quot;]/main/div[1]/div/div/div[2]/div[1]/div/a 'categories': response.xpath( '//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;blog-content-box&quot;]/div[@class=&quot;article-header-box&quot;]/div[@class=&quot;article-header&quot;]/div[@class=&quot;article-info-box&quot;]/div[@class=&quot;article-bar-top&quot;]/div[@class=&quot;tags-box space&quot;]/a/text()').get(), # //*[@id=&quot;mainBox&quot;]/main/div[1]/article # class=&quot;blog-content-box&quot; 'content': response.xpath('//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;blog-content-box&quot;]/article').get(), # //*[@id=&quot;mainBox&quot;]/main/div[3]/div[2] 'comments': response.xpath( '//*[@id=&quot;mainBox&quot;]/main/div[@class=&quot;comment-box&quot;]/div[@class=&quot;comment-list-container&quot;]').get() } # 获取markdown文档 mark_down_url = 'https://mp.csdn.net/mdeditor/getArticle?id=' + str(response.url.split('/')[-1]) yield scrapy.Request(url=mark_down_url, callback=self.get_markdown_content, meta=data, # Headers模拟浏览器的头部 headers={ 'accept-encoding': 'gzip, deflate, br', 'accept': '*/*', 'accept-language': 'zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5', 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36', }, # 需要更换相应的Cookie，来确定你对此博客的拥有权，否则会抓取失败 cookies=cookies) else: print('对CSDN中某篇文章访问出错') # 接收markdown内容，并作为Item的属性 @staticmethod def get_markdown_content(response): content = json.loads(response.body_as_unicode()) data = content['data'] if 'markdowncontent' in data: content = data['markdowncontent'] # print('$$$$ == ' + content) response.meta['content'] = content response.meta['tags'] = data['tags'] response.meta['categories'] = data['categories'] # 此处返回的是一个完整的Item return response.meta else: print('获取失败 : '+response.meta['link']) 关键性的API获取在上面的处理中，对于Hexo来说，最为关键的API是获取markdown的API，这里记录一下发现的过程。此处要求原文是markdown格式，否则得到的markdown数据为空。 第一步、在登录状态下，点开编辑 观察API 链接：https://mp.csdn.net/mdeditor/getArticle?id=89402970 入参为一个id加一些Headers（这里选择与浏览器保持一致），返回的参数为一个JSON串，里面的数据如下： 12345678910111213141516171819{ &quot;data&quot;: { &quot;id&quot;: &quot;89402970&quot;, &quot;title&quot;: &quot;Flask如何使用logging.FileHandler将日志保存到文件&quot;, &quot;articleedittype&quot;: 1, &quot;description&quot;: &quot;需求\\n将日志尽可能往文件中输，自带的默认只输出到屏幕上。\\n代码\\n获取文件名\\ndef get_custom_file_name():\\n def make_dir(make_dir_path):\\n path = make_dir_path.strip()\\n if not os.path.exists(path):\\n os.makedirs(pat...&quot;, &quot;content&quot;: &quot;&lt;h2&gt;&lt;a id=\\&quot;_0\\&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;\\n&lt;p&gt;将日志尽可能往文件中输，自带的默认只输出到屏幕上。&lt;/p&gt;\\n&lt;h2&gt;&lt;a id=\\&quot;_3\\&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;\\n&lt;p&gt;获取文件名&lt;/p&gt;\\n....&quot;, &quot;markdowncontent&quot;: &quot;## 需求\\n将日志尽可能往文件中输，自带的默认只输出到屏幕上。\\n\\n## 代码\\n获取文件名\\n```python\\ndef get_custom_file_name():\\n def make_dir(make_dir_path):\\n path = make_dir_path.strip()\\n if not os.path.exists(path):\\n os.makedirs(path)\\n return path\\n log_dir = \\&quot;ac_logs\\&quot;\\n file_name = 'logger-' + time.strftime('%Y-%m-%d', time.localtime(time.time())) + '.log'\\n file_folder = os.path.abspath(os.path.dirname(__file__)) + os.sep + log_dir\\n make_dir(file_folder)\\n return file_folder + os.sep + file_name\\n```\\n配置logging\\n\\n```python\\ndictConfig({\\n 'version': 1,\\n 'formatters': {'default': {\\n 'format': '%(asctime)s - %(levelname)s - %(filename)s - %(funcName)s - %(lineno)s - %(message)s',\\n }},\\n 'handlers': {\\n 'default': {\\n 'class': 'logging.StreamHandler',\\n 'stream': 'ext://flask.logging.wsgi_errors_stream',\\n 'formatter': 'default'\\n },\\n 'custom': {\\n 'class' : 'logging.FileHandler',\\n 'formatter': 'default',\\n 'filename' : get_custom_file_name(),\\n 'encoding' : 'utf-8'\\n },\\n },\\n 'root': {\\n 'level': 'INFO',\\n 'handlers': ['custom']\\n }\\n})\\n```\\n## 代码分析...&quot;, &quot;private&quot;: 0, &quot;tags&quot;: &quot;Flask,日志&quot;, &quot;categories&quot;: &quot;Python&quot;, &quot;channel&quot;: &quot;31&quot;, &quot;type&quot;: &quot;original&quot;, &quot;status&quot;: 1, &quot;read_need_vip&quot;: 0 }, &quot;error&quot;: &quot;&quot;, &quot;status&quot;: true} 对图片的处理至此，所有格式为markdown的CSDN博客都被抓取下来，接下来就是对其中图片的处理。对于图片，初步的想法是，先把markdown中的图片下载下来，再随机命名，然后把原来markdown中的图片链接修改成改名之后的，图片的baseUrl使用gitee前缀，也就是说，把所有下载下来的图片都存到一个仓库中，（也算是作为一种备份吧）然后通过如下形式的地址，来访问该图片：/images/pics/xxx.jpg。处理代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import osimport randomimport reimport stringimport filetype as filetypedir = &quot;C:\\\\Users\\\\yangyu\\\\sasuraiu.github.io\\\\source\\\\_posts&quot;img_dir = &quot;C:\\\\Users\\\\yangyu\\\\sasuraiu.github.io\\\\source\\\\_posts\\\\images&quot;mds = os.listdir(dir)pattern = re.compile('!\\[.*\\]\\(([^\\)]+)\\)')# 读取markdown内容def get_file_content(path): content = '' if not os.path.isdir(path): with open(path, 'r', encoding='utf-8') as f: for line in f: content = content + line return content else: return None# 修改markdown中的图片原地址def parse_content(content): changed = False for pic in pattern.findall(content): # print(pic) new_pic_link = download_pic(pic, img_dir, random_name()) if new_pic_link is not None: content = content.replace(pic, '/images/pics/' + new_pic_link) changed = True return changed, content# 随机名称def random_name(): return ''.join(random.sample(string.ascii_letters + string.digits, 32)).upper()# 下载图片并重命名def download_pic(url, path, name): import requests r = requests.get(url) if r.status_code == 200: filepath = path + '\\\\' + name # 下载 with open(filepath, 'wb') as f: f.write(r.content) # 重命名，通过文件魔数确定图片类型 # 这里进行类型判断是为了避免格式错误导致的图片无法展示 kind = filetype.guess(filepath) if kind is None: print('Cannot guess file type!') os.remove(filepath) return None else: os.rename(filepath, filepath+'.'+kind.extension) return name+'.'+kind.extension else: print(url) print('下载图片失败，请手动确认\\n\\n') return None# 修改后保存回文件def write_back_file(filepath, content): with open(filepath, 'w', encoding='utf-8') as f: f.write(content)if __name__ == '__main__': for md in mds: print('当前正在处理的文件为：' + md) filepath = dir + &quot;\\\\&quot; + md # 获取文件内容 content = get_file_content(filepath) # 解析文件中是否含有图片链接 if content is not None and content != '': changed, content = parse_content(content) # 替换回原文件 if changed: write_back_file(filepath, content) print('replaced original file with the latest link') 后记至此，大部分重复性质的工作已经完成了，剩下就是对每一个篇文章进行格式检查。此爬虫的代码地址为（欢迎fork）：https://github.com/sasuraiu/CSDNBlogMover wordpress添加https访问 docker中的wordpress 申请证书可以从freessl.cn免费申请。免费的SSL证书时间长度为1年，但是只能对单个域名，不支持多域名通配符，选择的话以个人需求为准。 选择浏览器生成 点击确认创建后，得到如下信息： 接下来到域名管理里面，按上述信息配置域名的信息，可以参考上面的验证配置指南，如下： 配置完了之后，不一定会立马生效，取决于配置改解析项的TTL。 apache配置 将容器里面的443端口映射到宿主机的443端口。如果已启动了容器，可能需要重新创建。 将申请好的证书和私钥上传到宿主机中，并将其挂载到容器中。 123456789docker run --name wp \\-p 80:80 \\-p 443:443 \\-e WORDPRESS_DB_HOST=host \\-e WORDPRESS_DB_USER=user \\-e WORDPRESS_DB_PASSWORD=&quot;&quot; \\-v /root/wordpress:/var/www/html \\-v /root/ssl:/ssl \\-d wordpress 先进入容器中 1docker container exec -it wp bash 加载apache的ssl模块 1a2enmod ssl 修改证书和私钥路径 1vim /etc/apache2/sites-available/default-ssl.conf 找到SSLCertificateFile和SSLCertificateKeyFile这两个配置项，改成把私钥和证书挂载进容器里面后的路径，这里都在/ssl/目录下。修改后为： 让ssl配置被apache加载 1ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/default-ssl.conf 退出容器，并重启容器。docker container restart wp 强制http请求转到https编辑 /etc/apache2/sites-available/000-default.conf，找到&lt;VirtualHost *:80&gt; &lt;/VirtualHost&gt;标签中增加下面的配置： 1234567&lt;Directory &quot;/var/www/html&quot;&gt; RewriteEngine on RewriteBase / # FORCE HTTPS RewriteCond %{HTTPS} !=on RewriteRule ^/?(.*) https://%{SERVER_NAME}/$1 [R,L]&lt;/Directory&gt; 如下： 退出容器，并重启容器。docker container restart wp 检验如果不能访问，可以往如下两方面考虑： 查看容器的日志，看报什么错误信息： 1docker container logs -f wp 看宿主机的443端口是否开放 参考：https://blog.csdn.net/yori_chen/article/details/88577249 从hexo批量迁移到wordpress 感觉”业务”有扩展，hexo不能动态添加文章有点不太适应 wordpress添加markdown支持选择了WP Editor.md这个插件，新增post，测试markdown能够生效。 获取hexo博客的md文档在source/_posts下有所有的markdown文件，全都是博客的内容，并且是有一定的格式规律的。这里我需要的关于博客的数据有标题、发布日期、标签以及目录，当然还有博客正文。非常好解析。 读取所有md文件的代码如下： 123456789101112131415dir = &quot;/xxxxx/blog-source/source/_posts&quot;files = os.listdir(dir)count = 0if __name__ == '__main__': files = os.listdir(dir) can_go_on = False for file in files: full_path = dir + '/' + file print(full_path) parse_md_file(full_path) # if count &gt;= 10: # break; count = count + 1 print(&quot;Count: &quot;, count) print(count) 解析每个md文档首先，是文件最开始有两个---，在这两个---之间的全部是文章的属性，之外的全是文章的内容。解析文章属性的时候，需要对文章的标签、目录做可能存在多个处理，所以用list存储。其中post_meta_data_status的各值的含义如下： post_meta_data_status 含义 0 初始状态，刚开始解析md文件 1 正在解析文章属性状态 2 文章属性解析完成，正在解析文章内容 解析md文件的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def get_property(line, splitter=':'): items = line.split(splitter) item = items[len(items) - 1].strip() return itemdef parse_md_file(file_path, print_content=False): title = &quot;&quot; tag = [] category = [] last_item = [] date = &quot;&quot; post_content = &quot;&quot; with open(file_path, encoding='utf8') as f: post_meta_data_status = 0 for line in f: if post_meta_data_status == 2: post_content += line # print(line, end='') else: if line.__contains__(&quot;---&quot;): if post_meta_data_status == 0: post_meta_data_status = 1 else: post_meta_data_status = 2 else: if line.__contains__(&quot;title&quot;): title = get_property(line).strip() elif line.__contains__(&quot;date&quot;): date = get_property(line, ': ').strip() elif line.__contains__(&quot;tags&quot;): item = get_property(line) if item!='': tag.append(item) last_item = tag elif line.__contains__(&quot;categories&quot;): item = get_property(line) if item != '': category.append(item) last_item = category elif line.__contains__('-'): item = get_property(line, '-') if item != '': last_item.append(item) print(&quot;title: &quot;, title) print(&quot;date: &quot;, date) print(&quot;tags: &quot;, tag) print(&quot;categories: &quot;, category) date=datetime.datetime.strptime(date, &quot;%Y-%m-%d %H:%M:%S&quot;) 将解析后的数据上传到wordpress上传主要用到了wordpress-xmlrpc。其基本操作可参看该官网上的用例。 安装方式：pip install python-wordpress-xmlrpc 12345678910111213141516171819from wordpress_xmlrpc import Client, WordPressPostfrom wordpress_xmlrpc.methods.posts import GetPosts, NewPostfrom wordpress_xmlrpc.methods.users import GetUserInfowp = Client('http://www.wordpress.site/xmlrpc.php', 'username', 'password')def add_post(title, date, content, tag, category): post = WordPressPost() post.title = title post.content = content post.post_status = 'publish' # date为python的datetime类型 post.date = date post.terms_names = { 'post_tag': tag, 'category': category, } post_id = wp.call(NewPost(post)) print(post_id) 如果需要更新更多的post相关的信息，可参看WordPressPost文档。 从halo迁移到hexo 今年年初由 wordpress 迁移到 halo，主要是觉得懂点 Java，有什么定制化的需求，自己改代码会方便一些。但是也没有什么特别的需求需要定制，反而被这种东西折腾得忘记了写博客的初心。技术博客就应该简简单单，只写技术，博客怎么好看、怎么炫酷，都不重要。 配置说明&amp;前置条件 在 Halo 中，数据库使用的是 MySQL 5.7，并将 halo 服务所用数据库，内容导入到本地的数据库中，这样速度会快一些。 hexo 所用主题是 Icarus 编码总体思路：将 halo 的数据，导出成 hexo 所需要的格式。总体分为下面几个步骤： halo 字段与 hexo 字段对比参考 hexo 文档，与之一一对应即可。后续根据 Icarus 的几个配置，又在 front-matter 里面添加了几个属性。 参数 描述 默认值 layout 布局 title 标题 文章的文件名 date 建立日期 文件建立日期 updated 更新日期 文件更新日期 comments 开启文章的评论功能 true tags 标签（不适用于分页） categories 分类（不适用于分页） permalink 覆盖文章网址 将 halo 的 tags、categories 转化成 hexo 里面的 tags、categoriescategory 与 tag 类似，都是通过一个关联表，与 post 建立关联关系。转换的逻辑自然变成了：根据 post_id 查 post_tags 表中的关联关系，得到 tag_id，再从 tag 表中获取 tag 的名称。 转化文章预览这部分不太好转，直接用 markdown 有些 markdown 的语法符号，没办法过滤掉、或者过滤起来很难受。这里的做法是这样的： 在 front-matter 中添加 excerpt 属性 如果原文章(halo)中存在 summary，直接赋值给 excerpt 没有 summary，则先将 markdown 转化成 HTML，然后获取 HTML 中的前几个 dom 元素。 文章属性 123456789101112type Post struct { Title string Content string Password string Date string Updated string Thumbnail string Tags []string Categories []string Summary string Priority string} 主流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package mainimport ( &quot;fmt&quot; _ &quot;github.com/go-sql-driver/mysql&quot; &quot;github.com/gomarkdown/markdown&quot; &quot;html&quot; &quot;io/ioutil&quot; &quot;path&quot; &quot;regexp&quot; &quot;strings&quot; &quot;xorm.io/xorm&quot;)func main() { basePath := &quot;/Users/akina/hexo-blog/source/_posts&quot; db, _ := xorm.NewEngine(&quot;mysql&quot;, &quot;root:root@tcp(localhost:3306)/halodb-tmp&quot;) db.ShowSQL(true) queriedPosts, _ := db.Query(&quot;select * from posts&quot;) for _, qp := range queriedPosts { pid := qp[&quot;id&quot;] post := Post{ Title: string(qp[&quot;title&quot;]), Content: html.UnescapeString(string(qp[&quot;original_content&quot;])), Password: string(qp[&quot;password&quot;]), Date: string(qp[&quot;create_time&quot;]), Updated: string(qp[&quot;update_time&quot;]), Thumbnail: string(qp[&quot;thumbnail&quot;]), Summary: string(qp[&quot;summary&quot;]), Priority: string(qp[&quot;top_priority&quot;]), } // 处理标签 queriedTagIds, _ := db.Query(&quot;select tag_id from post_tags where post_id = &quot; + string(pid)) if len(queriedTagIds) &gt; 0 { tagIds := make([]string, 0) for _, tagId := range queriedTagIds { tagIds = append(tagIds, string(tagId[&quot;tag_id&quot;])) } queriedTagNames, _ := db.Query(fmt.Sprintf(&quot;select name from tags where id in (%s)&quot;, strings.Join(tagIds, &quot;,&quot;))) tagNames := make([]string, 0) for _, tagName := range queriedTagNames { tagNames = append(tagNames, string(tagName[&quot;name&quot;])) } post.Tags = tagNames } // 处理分类 queriedCategoryIds, _ := db.Query(&quot;select category_id from post_categories where post_id = &quot; + string(pid)) if len(queriedCategoryIds) &gt; 0 { categoryIds := make([]string, 0) for _, categoryId := range queriedCategoryIds { categoryIds = append(categoryIds, string(categoryId[&quot;category_id&quot;])) } queriedCategoryNames, _ := db.Query(fmt.Sprintf(&quot;select name from categories where id in (%s)&quot;, strings.Join(categoryIds, &quot;,&quot;))) categoryNames := make([]string, 0) for _, categoryName := range queriedCategoryNames { categoryNames = append(categoryNames, &quot;- [&quot;+string(categoryName[&quot;name&quot;])+&quot;]&quot;) } post.Categories = categoryNames } // 写文件 postHexoData := strings.Join([]string{ &quot;---&quot;, &quot;title: \\&quot;&quot; + post.Title + &quot;\\&quot;&quot;, &quot;date: &quot; + post.Date, &quot;updated: &quot; + post.Updated, &quot;tags: [&quot; + strings.Join(post.Tags, &quot;,&quot;) + &quot;]&quot;, &quot;categories: \\n&quot; + strings.Join(post.Categories, &quot;\\n&quot;), &quot;thumbnail: &quot; + post.Thumbnail, &quot;password: &quot; + post.Password, &quot;excerpt: \\&quot;&quot; + getPostSummary(post) + &quot;\\&quot;&quot;, &quot;top: &quot; + post.Priority, &quot;toc: true&quot;, &quot;---&quot;, post.Content, }, &quot;\\n&quot;) ioutil.WriteFile(path.Join(basePath, post.Title+&quot;.md&quot;), []byte(postHexoData), 0666) }} 获取文章的预览 1234567891011121314151617181920212223242526272829303132333435func getPostSummary(post Post) string { var res string if post.Summary != &quot;&quot; { res = post.Summary } else { htmlContent := string(markdown.ToHTML([]byte(post.Content), nil, nil)) for i := 1; i &lt;= 4; i++ { re := regexp.MustCompile(&quot;&lt;.*?&gt;.*?&lt;/.*?&gt;&quot;) label := string(re.Find([]byte(htmlContent))) if label == &quot;&quot; { break } res = res + label htmlContent = strings.ReplaceAll(htmlContent, label, &quot;&quot;) if htmlContent == &quot;&quot; { break } } } for _, ch := range []string{ &quot;\\n&quot;, } { res = strings.ReplaceAll(res, ch, &quot; &quot;) } res = strings.ReplaceAll(res, &quot;\\&quot;&quot;, &quot;'&quot;) res = strings.TrimPrefix(res, &quot; &quot;) res = strings.TrimSuffix(res, &quot; &quot;) fmt.Println(res) return res} Conclusion后续有几个需要改一下预览的内容，貌似不能通过 hexo g，原因是转义符的问题、单、双引号的问题等，只有少量，手动改了改，还算可以接受。","link":"/2020/09/05/795d32ee2085.html"},{"title":"折腾黑苹果","text":"不知道从什么时候开始，喜欢上了苹果，成为了一个不折不扣的果粉。2017年毕业的时候，刚买小屏的iPhone SE，在此之前已经还买过一个iPhone 6s。真的是贵啊。刚工作没几个月，就去澳门买了一个MacBook Pro 2017。当时主要是觉得台式机麻烦，搬家不方便，才选择笔记本。刚开始如获至宝，后面慢慢发现它的性能很弱。然后便有了两年后的这一台黑苹果主机。 硬件选择按照网上的资料，我选择了一套黑果小兵自用的EFI所对应的机型，EFI链接。当时没有考虑主板的大小，现在感觉MSI Z370 A PRO确实有点大。整体清单如下： 配件 型号 价格 主板 MSI Z370 A PRO ￥741 CPU i5-8500(散片) ￥1169 显卡 Sapphire RX580 ￥1179 SSD(M.2) Intel 760P 256GB ￥319 SSD(SATA) Toshiba TR200 960GB ￥688 内存 Kinston DDR4 2666频 8G X 2 ￥550 散热器 九州风神 玄冰400 ￥85 机箱 SAMA 黑洞7 ￥229 电源 振华(Super Flower) 450W ￥299 蓝牙&amp;WiFi Fenvi FV-T919 BCM94360CD ￥293 主板+CPU+显卡选择要慎重，尽量按照已有的解决方案来买，这样装MacOS的时候麻烦就会少一些。免驱的显卡可以网上多搜搜看，RX580只有满血版才是免驱的。蓝牙+WiFi只需要购买免驱（型号为BCM943602CS）、安装即可（网上的说法为此型号，但目前还未购买，因为之前买了一个20块钱的USB无线网卡）。 装机差不多是第一次装机，装挡板的时候，很害怕把它弄坏了，其实是大力出奇迹。接线方面，只要看着主板的说明书，一步一步接就没啥问题。硅脂的涂法网上各有不同，有五点式、画8式等，但是都不能放太多，免得硅脂滴到主板上。 CPU 主板 显卡 系统安装大致分为下面3个步骤，分别为BIOS设置，macOS启动盘刻录，系统安装。如果进行得比较顺利，那么会比较流畅；如果遇到各种问题，只要慢慢各个击破就行啦！ 准备工作大致流程参考了tonymacx86上面的通用教程，链接。 需要准备的软件有： macOS Mojave(直接在App Store中下载) Clover Configurator UniBeast MultiBeast Kext Utility 黑果小兵的Z370主板EFI BIOS设置上面链接中的第三步，STEP 3: Recommended BIOS Settings里面有推荐的BIOS设置，但是后面发现同主板的一些其他成功安装黑苹果的帖子，还有更多设置，在Google中输入hackintosh msi z370 a pro，如下图所示： 印象中有按照下图进行BIOS的设置： 其他的教程都有参考： https://hackintosher.com/builds/guide-hackintoshing-msi-z370-pro/ https://www.tonymacx86.com/threads/i7-8700k-msi-z370-a-pro-gtx-1050ti-successful-installation.247652/ https://www.reddit.com/r/hackintosh/comments/8cpokx/success_i7_8700k_msi_z370apro_gtx1080ti/ 系统盘刻录按照上面tonymac的通用流程，可以刻录出一个可启动的系统，但是我由于各种原因，并没有启动成功（可能是我在选择启动盘是，选择错误❌），后面改用从App Store里面下载的macOS Mojave的刻录命令进行刻录。 后面将黑果小兵的Z370主板EFI，拷贝到U盘的EFI目录，然后就能启动了到macOS的界面了。 安装由于刚开始装的时候，AMD的RX580还没到，所以开始的时候，启动到系统失败。貌似是因为黑果小兵的EFI适配的系统硬件，应该是AMD RX570，也就是独立显卡，但是我目前没有独显，只有集显。经过搜索资料发现，只需要使用Clover Configurator注入集显相关信息，就可以成功进入安装界面。 其他问题机箱上面的耳机孔的声音非常小，即使在系统中把声音调到最大。不过据黑果小兵的回复，HDMI或DP口上的声音是正常的。 买了一个USB转音频的线，声音就好了。 Update(2021-4-5):在我手里后续折腾了若干台黑苹果，感慨白苹果真香！","link":"/2019/08/20/b6c53e6e2f6c.html"},{"title":"插入耳机时安全音量提示","text":"插入耳机的状态下，当音量达到某个值得时候，会弹出一个“继续提高音量将损害听力”的提示框。这只是一普通的对话框而已，但是这与需求不太一样，需要做一些微微的调整。 源码的目录：Android 8.0中，位于：frameworks/base/packages/SystemUI/src/com/android/systemui/volume/SafetyWarningDialog.java 大致分析正如之前想的那样，它确实只是一个普通的Dialog，但是继承自SystemUIDialog，它只是对AlertDialog做了一些封装。 12345678910111213141516171819202122232425262728@Overridepublic boolean onKeyDown(int keyCode, KeyEvent event) { if (keyCode == KeyEvent.KEYCODE_VOLUME_UP &amp;&amp; event.getRepeatCount() == 0) { mNewVolumeUp = true; } return super.onKeyDown(keyCode, event);}// 这是另外一种继续调节音量上去的方法，它的逻辑也很有趣：// 如果对话框显示的时间超过了某个值，它就默认你看到了这个安全提示，// 便可以继续调节音量了。@Overridepublic boolean onKeyUp(int keyCode, KeyEvent event) { // 如果再按一次音量+,并且不是第一次按，那么对话框的时间有1s // 就可以继续调节音量 if (keyCode == KeyEvent.KEYCODE_VOLUME_UP &amp;&amp; mNewVolumeUp &amp;&amp; (System.currentTimeMillis() - mShowTime) &gt; KEY_CONFIRM_ALLOWED_AFTER) { if (D.BUG) Log.d(TAG, &quot;Confirmed warning via VOLUME_UP&quot;); mAudioManager.disableSafeMediaVolume(); dismiss(); } return super.onKeyUp(keyCode, event);}// 这个被设置成了对话框的确认按钮的点击事件，// 所以不难解释为什么点击了确认之后，就可以继续往上调节音量了。@Overridepublic void onClick(DialogInterface dialog, int which) { mAudioManager.disableSafeMediaVolume();} 在什么情况下弹出提醒框待补充ing 确认后做了哪些具体的事情12345678910111213141516171819// AudioManager.javapublic void disableSafeMediaVolume() { try { getService().disableSafeMediaVolume( mApplicationContext.getOpPackageName()); } catch (RemoteException e) { throw e.rethrowFromSystemServer(); }}// 这是一个很典型的AIDL的应用，获取与远程服务的连接；// 然后调用远程服务的disableSafeMediaVolume()方法。private static IAudioService getService(){ if (sService != null) { return sService; } IBinder b = ServiceManager.getService(Context.AUDIO_SERVICE); sService = IAudioService.Stub.asInterface(b); return sService;} 现在我们知道它是通过AIDL来调用远程Service中的disableSafeMediaVolume()方法，所以现在应该要找到它的具体实现方法在哪里。想要实现该AIDL所定义的功能，肯定要创建一个类继承IAudioService.Stub，然后实现该方法。因此我们可以看到一个继承了IAudioService.Stub的类，它的路径如下：base/services/core/java/com/android/server/audio/AudioService.java，因此可以直接打开这个文件，具体的实现方法就在里面。如下： 重点看setSafeMediaVolumeEnabled(false, callingPackage);因为它的名字看起来与我们想要看的功能十分接近。 mSafeMediaVolumeState已经被置为SAFE_MEDIA_VOLUME_INACTIVE。 略囧，看到这里，后面的一些代码看了很久，着实没看懂了，其实主要纠结的一点在于：点击确认按钮后，以后再调到临界音量的时候，它并不会弹窗，我很自然地想，这个应该是保存到了SharedPreference里面，但是保存该项状态的语句之后一处，然后由那一处，一直往上找，看它是什么时候保存的，结果找到了一个死胡同，出不去了。感觉自己对音量调节这一块知道的还是有点少，需要进一步学习这方面的东西，才看得懂。虽然网上有一些已经对这个做过分析的文章，也仔细阅读过，但是无奈源码的版本不一样，本着思想应该大致不会变的想法，我还是继续去寻找。","link":"/2018/03/11/66fd5b4ee73f.html"},{"title":"整合Spring+SpringMVC+MyBatis(SSM)中所遇到的问题","text":"最近公司的事情太多了，周一、二晚上跑通了MyBatis的简单例子，周末架起了Spring+SpringMVC+MyBatis的基本骨架，简单例子成功跑了起来。后续的一些深入理解，在这个的基础上才能进行吧。 其实跑一个简单的Sample问题是不大的，遇到的错误，需要仔细阅读错误提示信息，然后根据提示一步一步去解决；遇到一些莫名其妙的错误时，可以考虑一下是否为包的版本问题。 问题1：导入MyBatis-Spring、MyBatis以及Spring版本所对应的关系参考：http://www.mybatis.org/spring/ MyBatis-Spring MyBatis Spring 1.0.0 and 1.0.1 3.0.1 to 3.0.5 3.0.0 or higher 1.0.2 3.0.6 3.0.0 or higher 1.1.0 or higher 3.1.0 or higher 3.0.0 or higher 1.3.0 or higher 3.4.0 or higher 3.0.0 or higher 问题2：java.lang.IllegalAccessError: org.apache.commons.dbcp.DelegatingPreparedStatement.isClosed()Z出现这个错误的时候，MyBatis的版本是3.4.6，只需要将其版本降下去，此错误即可消失。这个错误确实有点无语。已换成了3.2.6。 问题3：运行项目MyEclipse提示端口8080被占用Mac下可使用lsof命令，如下lsof是一个显示系统中所有已打开文件的一个命令，即ls open file 问题4：MyEclipse不进行代码提示JetBrain系列IDE使用多了，在MyEclipse上不能进行代码提示，有点难受。网上也是有解决方案的，如下： 进入Preference-&gt;Java-&gt;Editor-&gt;Content Assist-&gt;Auto Activation，在Auto activation trigger for Java中我们可以看到有一个’.’，所以这就是为什么我们输入.的时候，就会出来代码提示，而其它情况下就不会。所以只需要在其后面加上a-zA-Z0-9就好了。即：abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 问题5：Cannot find class [org.springframework.http.converter.json.MappingJacksonHttpMessageConverter]这是一个典型的因为包的版本不兼容而引起的错误。MappingJacksonHttpMessageConverter这个类是很久以前的一个类了，目前最新的包内是不含有此类的，取而代之的是MappingJackson2HttpMessageConverter参考：https://blog.csdn.net/vili_sky/article/details/73105550 问题6：Class not found： AnnotationMethodHandlerAdapter同上。 Spring Framework 3.1 introduces a new set of support classes for processing requests with annotated controllers: RequestMappingHandlerMapping RequestMappingHandlerAdapter ExceptionHandlerExceptionResolver These classes are a replacement for the existing: DefaultAnnotationHandlerMapping AnnotationMethodHandlerAdapter AnnotationMethodHandlerExceptionResolver 参考 https://blog.csdn.net/zhshulin/article/details/37956105 https://blog.csdn.net/qq598535550/article/details/51703190 https://blog.csdn.net/yfisaboy/article/details/31755631 https://blog.csdn.net/yfisaboy/article/details/31755631","link":"/2018/05/13/9ab9bb506726.html"},{"title":"无U盘安装Linux openSUSE（通过硬盘安装Linux）","text":"无U盘安装Linux openSUSE（通过硬盘安装Linux） 一、说明为什么会想着用硬盘安装Linux？只是因为我陆陆续续买了两个U盘，然后它们都丢了，就没再买了。然而现在又想装个openSUSE，没有U盘，只能想办法通过硬盘安装。 记录自己走过的弯路，同时也为大家提供一个无U盘或硬盘安装Linux系统的提供一个思路。 如果发现错误，请大家指正，祝大家折腾成功！ 二、环境一开始，电脑上面只有一个Windows 10，磁盘的分区是GPT，启动方式为UEFI，华硕X450JB 四、无U盘安装openSUSE（UEFI+GPT）1、在硬盘中格式化出来10G（大小只要够用就行）的盘，格式为FAT32。 2、将系统镜像（.iso结尾的文件）解压到刚刚格式化出来的FAT32盘中。 3、添加启动项：作为启动的是grub.efi ​ 1）可以通过BIOS中自带的添加启动项。具体的过程视不同型号的BIOS而定吧。 ​ 2）可以通过EasyUEFI（我的尝试失败了，但是还不知道为啥，还是可以再尝试一下） 4、重启 -&gt; 进入相应的启动项 5、开始安装 三、动手尝试这是尝试的过程，记录自己走过的弯路，教程在动手尝试之后 之前有过一次从硬盘安装Ubuntu的经历，所以我觉得这是有可能的。但是当时的磁盘分区是MBR，系统是win 7。现在找到的教程基本上是和这个类似的。这时就只能自力更生啦。 在此之前，我对于UEFI和刻录U盘的了解仅限于此。 1.UEFI“执行”的是以.efi结尾的文件，并以此来启动整个安装程序。 2.通过以前的观察，将系统刻录到U盘上面感觉只是将.iso文件里面的内容解压并复制到U盘。 在Legacy BIOS + MBR中有个一个EasyBCD的软件，在UEFI+GPT中也有一款类似的叫做EasyUEFI。我开始想着只要能够加上一个启动项，应该就可以启动了呀。因此马上行动。打开EasyUEFI后我就傻眼了，选择添加类型是“Linux及其他系统”的时候，它首先要我选择一个目标分区，其实当时傻眼了呢，这是要干啥呢？点又点不了，不过最终发现有一个盘长得不一样，如下图所示： 然后我点了一下它，嗯，它变色了。Nice。然后下面有一个栏，叫浏览文件。这是干啥的？点进去一看，是一个根目录的图标，嗯，接着点下去。然后这里面的内容好像有点似曾相识 这不就是ESP盘里面的内容吗？在UEFI+GPT模式中，有一个专门的分区，叫ESP，如下图所示（其中的openSUSE文件夹是我自己接下来加上去的，暂时先忽略它）。 UEFI是从这个分区里面读取.efi文件，然后启动系统的。我记得Linux的安装文件****.iso里面有个EFI文件夹，我觉得貌似看到了一点希望。下面是openSUSE-Leap-42.2-DVD-x86_64.iso里面的文件 这个时候，我觉得那不是只要将这里面的东西复制到ESP这个磁盘的相应地方就Okay了？因此我通过DiskGenius，将EFI文件夹下面的内容按照相应的样式添加了进ESP下的EFI文件夹下。如下： 然后就可以通过EasyUEFI添加相应的启动项了。嗯，好像是可以了。加上去了之后，然后兴冲冲地重启。结果开机重启后，按了ESC，调出“选择启动项”的框，发现竟然没有我刚才加的。我不信。进了BIOS的Boot项下面，真的没有。不过我看到了ADD BOOT的那一栏。心想，通过EasyUEFI添加不成功，那我通过BIOS来添加总可以了吧。输入了启动项的名字，找到了我想作为启动项的那一个之后（我不知道是grub.efi还是MokManager.efi，其实还有一个bootx64.efi文件，但是安装成功后不见了，所以我添加了三个启动项，分别启动grub.efi,bootx64.efi,MokManager.efi），然后手残的我按了Ctrl + Alt + Delete，重启了，恩，没保存。所以再次调出“选择启动项”之后还是啥都没有，没事，我又来了一遍。然后确保保存了之后才退出的。恩，出现了三个，选择它，然后，出现的情况也然我有点失望。当然都没有成功。我也在想，它凭啥要成功呢？我只是通过如此添加而已，它怎么找得到启动系统安装的其它文件？不过它在屏幕上的错误提示给了我一个提示： 大致是“找到/boot/下的啥啥啥文件”。 看到这个，是呀，没有找到这个，因为它根本就不存在。此时，看看这幅图： 心中便有了另外一个想法。那就是要是把这个openSUSE-Leap-42.2-DVD-x86_64.iso文件全部解压到ESP下面就好了。可是ESP只有200M左右的样子，不太现实。因此我在想这，只岂不是只要将openSUSE-Leap-42.2-DVD-x86_64.iso文件解压到一个盘，然后在BIOS里面找到相应的.efi文件并添加启动项不就可以了？马上又行动起来了，可是还是失败了。UEFI能够直接读取FAT32格式磁盘里面的内容。刚才的是NTFS格式的，所以读不了其它的内容吧。并且刻录完系统到U盘的后，这个时候U盘的文件系统格式貌似也是为FAT32。因此有了这样的一个想法，只要腾出一个磁盘，将其格式化成FAT32格式，然后将openSUSE-Leap-42.2-DVD-x86_64.iso里面的内容解压到其中，再从BIOS里面添加相应的启动，这次完美进入安装程序。 这里贴一张完美启动的启动项的配置： 安装好了之后，openSUSE的启动项的配置是这样的：","link":"/2017/01/14/58ca6a062977.html"},{"title":"换行符问题","text":"问题Linux 环境执行一些脚本出错，查找原因，发现是文件在Windows环境修改并上传，格式被转换为MS-Dos格式（换行符不同），这样的文件在Linux中运行会出错（shell 解释器把换行符作为一个命令的提交）。 背景很久以前，老式的电传打字机使用两个字符来另起新行。回车符(CR，carriage return)把滑动架移回行首 ，换行符(LF，newline)把纸上移一行 。 当计算机问世以后，存储器曾经非常昂贵。有些人就认定没必要用两个字符来表示行尾。UNIX 用 一个字符来表示行尾。Apple 的MacOS 9 及以前用 &lt;CR&gt; ，MacOS 10跟Unix一样。MS-DOS (以及Windows) 沿用老式的&lt;CR&gt;&lt;LF&gt;，即敲一下回车键，相当于同时执行了 “回车+换行“。总结一下： 系统 中文描述 英文描述 简写 转义符 十六进制 Windows 回车换行 Carriage Return and Line Feed CRLF \\\\r\\\\n 0x0d0a (1310) Unix/Linux/Mac OS 换行 Line Feed LF \\\\n 0x0a (10) 如果你把一个文件从一种系统移到另一种系统，那么你就有换行符方面的麻烦。Windows10的记事本（notepad）能够自动识别Linux文件，但是在Linux中查看MS-DOS格式文件会发现每一行的末尾有个 ^M 字符。(^M 就是 &lt;CR&gt;，即回车符)。 单个文件解决办法Linux 环境下 vim 直接编辑修改文件。 1:set fileformat=unix 或者 1:set ff=unix 保存退出就解决了。 批量文件解决方案一这是通用方案，核心逻辑是 找出文件：用file命令查看文件是否有特殊换行符 修改文件：dos2unix命令直接改。（也可以vi 文件修改，后面在举例） 具体例子 1. 检查文件12$ file ./test.yml ./test.yml: ASCII text, with CRLF line terminators 输出中看到了CRLF，这是Dos文件格式的标志。 2. 下一步，文件格式转换12$ dos2unix ./test.yml dos2unix: converting file ./test.yml to Unix format ... 3. 检查文件是否真的修改了格式12$ file ./test.yml ./test.yml: ASCII text 发现没有CRLF 标志，修改完成。 4. 把上面的命令合并，查找并修改Dos格式文件12345$ find . -type f -exec file {} \\; | grep CRLF | awk -F: '{print $1}' | xargs dos2unix dos2unix: converting file ./ansible/README.md to Unix format ... ... or$ find . -type f -exec file {} \\; | grep CRLF | cut -d : -f 1 | xargs dos2unix 批量文件解决方案二从 7.1 版本后，dos2unix 有-i,–info参数，能够直接获取文件换行符的信息，我们能直接用这个命令来查找和替换。-ic参数表示只是打印需要转换的文件。（MacOS 通过brew 可以安装 dos2unix version 7.4，而centos 7 和 ubuntu 16 默认只能安装版本6.0，更高版本需要自己单独下载安装包。） 1234$ dos2unix -i ./roy_test.yml 11 0 0 no_bom text ./roy_test.yml $ dos2unix -ic ./roy_test.yml ./roy_test.yml 上面的输出数字 11 表示有11个dos换行符。查找并修改dos文件： 123$ find . -type f -exec dos2unix -ic {} \\; | xargs dos2unix dos2unix: converting file ./bin/Readme.txt to Unix format... ... 如果文件数量大，用xargs 替换 exec 更有效率，所以更好的命令是 1$ find . -type f | xargs dos2unix -ic | xargs dos2unix Windows开发中避免换行问题使用编辑器Visual Studio Code这个工具的右下角的文件格式确保是LF。如果不是，就点击重新选择。 git bash 中设置默认检入检出换行符为linux（\\n）风格（为了团队更好的协作） 开启自动换行1234git config --global core.autocrlf true git config --global core.autocrlf true 签出时将换行符转换成CRLF，签入时转换回 LF git config --global core.autocrlf input 签出时不转换换行符，签入时转换回 LF git config --global core.autocrlf false 签出签入均不转换 开启安全换行1git config --global core.safecrlf true 解释：如果你把换行符搞乱了，在一个文件中既包含windows风格的换行符也包含unix风格换行符，那么 safecrlf 就可以发挥作用了： 123git config --global core.safecrlf true 拒绝提交包含混合换行符的文件 git config --global core.safecrlf false 允许提交包含混合换行符的文件 git config --global core.safecrlf warn 提交包含混合换行符的文件时候给出警示 参考文档不同平台windows、linux、mac 上换行符的问题vim下unix和dos格式转换NewLine Wikipedia 链接：https://www.jianshu.com/p/fe8ec5f5792d","link":"/2023/06/12/e54d04dcd0b8.html"},{"title":"汇编语言DEBUG的使用","text":"【汇编语言】DEBUG的使用 在masm for windows中，需要先生存exe文件，然后再点调试按钮。 常用的命令有： R命令：查看、改变CPU寄存器的内容；如果要修改某个寄存器的内容，可以在r的后面接上空格和寄存器名。如：-r ax，然后再输入需要修改的值。如下 T命令：执行一条机器指令； D命令：查看内存中的内容； E命令：改写内存中的内容； U命令：将内存中的机器指令翻译为汇编指令； A命令: 以汇编指令的格式在内存中写入一条机器指令； Q命令：退出汇编；","link":"/2016/12/18/db0f64dc3208.html"},{"title":"汇编语言新手第一步——HelloWorld &amp; A+B","text":"汇编语言新手第一步——HelloWorld &amp; A+B国际惯例，HelloWorld。 这个程序是masm for windows里面的样例程序。按照我自己的理解，对其加上了注释。 123456789101112131415161718192021222324252627;完整段的Hello World程序DATAS SEGMENT STRING DB 'Hello World!',13,10,'$' ;定义了一个字符串,标号是STRING，其值是字符串首字符的地址。 ;DB表示的是字符串中每个字符的都是一个字节，每往后加1的时候，地址偏移量加1. ;13 CR 回车 ;10 LF 换行 ;$作为字符串的结束符DATAS ENDSCODES SEGMENT ASSUME CS:CODES,DS:DATAS START: MOV AX,DATAS MOV DS,AX LEA DX,STRING;LEA 获取偏移量,并将其存入DX MOV AH,9 INT 21H ;INT 21H是DOS中断的调用，其执行的操作根据AH里面的值来确定。 ;9，表示的是输出字符串，其地址为DS:DX ;4CH带返回码结束 MOV AH,4CH INT 21HCODES ENDS END START 然后改写了其中的两个数相加的样例。这是从控制台输入，但是只能输入一位。多位数相加正在学习中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849DATAS SEGMENT ;此处输入数据段代码 TIP1 DB 'PLEASE INPUT A:',13,10,'$' TIP2 DB 13,10,'PLEASE INPUT B:',13,10,'$' TIP3 DB 13,10,'A + B = $'DATAS ENDSSTACKS SEGMENT ;此处输入堆栈段代码STACKS ENDSCODES SEGMENT ASSUME CS:CODES,DS:DATAS,SS:STACKSSTART: MOV AX,DATAS MOV DS,AX ;TIP ONE LEA DX,TIP1 MOV AH,09 INT 21H ;GET A MOV AH,01 INT 21H SUB AL,30H MOV CL,AL ;TIP TWO LEA DX,TIP2 MOV AH,09H INT 21H ;GET B MOV AH,01 INT 21H SUB AL,30H ADD CL,AL ADD CL,30H ;TIP 3 LEA DX,TIP3 MOV AH,09 INT 21H ;RESULT MOV DL,CL MOV AH,02 INT 21H ;TAO LU MOV AH,4CH INT 21HCODES ENDS END START","link":"/2016/12/18/e18a94d8b0fa.html"},{"title":"深入理解Kubernetes中Service的实现","text":"iptables 是 Kubernetes 中 Service 的默认实现，了解 iptables 是理解 Service 工作原理不可缺少的一步。 iptables 的构成在对包处理的过程中，内核添加了对包自定义处理的操作，这些自定义操作以链的形式存在，而链由表组成； 每条链由不同的表组成，每个表由若干条规则构成； 每条链中同名的表相互独立，表名用来区分规则的作用。 5 条链 PREROUTING 接收包时执行的第一个链，执行完后进行路由选择 INPUT 路由选择后发现是本机的包时，会执行该链 FORWARD 接收到数据包，经 PREROUTING 处理并进行路由选择后，发现非本机数据包，进行转发处理时，执行此链 OUTPUT 发送数据包，进行路由选择之后，遇到的第一个链 POSTROUTING 紧跟 OUTPUT 链执行 4 张表 raw目的：将命中规则的包，跳过其它表的处理，它的优先级最高。位置：由于其目的是跳过其它表，所以只需要在接收和发送两大过程的最开头处把关，所以只需要用到 PREROUTING 和 OUTPUT 两个钩子。 mangle目的：根据规则修改数据包的一些标志位，比如 TTL位置：有可能会在任意位置都有可能会修改网络包，所以它是用到了全部的钩子位置。 nat目的：实现网络地址转换位置：分为 SNAT（Source NAT）和 DNAT（Destination NAT）两种，可能会工作在 PREROUTING、INPUT、OUTPUT、POSTROUTING 四个位置。 filter目的：过滤某些包，这是防火墙工作的基础位置：只在 INPUT、OUTPUT 和 FORWARD 这三步中工作就够了 链表之间的关系 iptables 的工作场景 接收网络包 PREROUTING链 -&gt; 路由判断（是本机）-&gt; INPUT链 -&gt; … 转发网络包 PREROUTING链 -&gt; 路由判断（不是本设备，找到下一跳） -&gt; FORWARD链 -&gt; POSTROUTING链 -&gt; … 发送网络包 路由选择 -&gt; OUTPUT链 -&gt; POSTROUTING链 -&gt; … iptables 的工作流程与契机简化的包处理流程 数据接收过程走的是 1 和 2 发送过程走的是 4 、5 转发过程是 1、3、5 完整的包处理流程 包处理的流程图 iptables 的常用命令常用参数 源地址：-s 192.168.1.0/24 目标地址：-d 192.168.1.11 协议：-p tcp|udp|icmp 从哪个网卡进来：-i eth0|lo 从哪个网卡出去：-o eth0|lo 目标端口（必须制定协议）：-p tcp|udp --dport 8080 源端口（必须制定协议）：-p tcp|udp --sport 8080 iptables1iptables -t ${表名} ${Commands} ${链名} ${链中的规则号} ${匹配条件} ${目标动作} 表名：4张表，filter、nat、mangle、raw Commands：尾部追加-A、检查-C、删除-D、头部插入-I、替换-R、查看全部-L、清空-F、新建-N、默认规则-P(默认为ACCEPT) 链名：5条链，PREROUTING、INPUT、FORWOARD、OUTPUT、POSTROUTING 匹配条件：-p协议、-4 IPv4协议包 、-6 IPv6 协议包、-s 源地址、-d 目标地址、-i/-o 进/出网络接口名、--dport/--sport 目标/源端口 目标动作：拒绝访问-j REJECT、允许通过-j ACCEPT、丢弃-j DROP、记录日志 -j LOG、源地址转换-j snat、目标地址转换-j dnat、还有RETURN、QUEUE 示例： iptables -t nat -A POSTROUTING -s 192.168.0.0/24 ! -o br0 -j MASQUERADE SNAT 源地址替换 iptables -t nat -A PREROUTING ! -i br0 -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.0.2:80 DNAT 目的地址转换 iptables -I INPUT -s 121.0.0.0/8 -j DROP 封禁 iptables -I INPUT -s 121.0.0.0/8 -j DROP 解封 iptables -t filter -I INPUT -s 1.2.3.4 -p tcp --dport 22 -j ACCEPT iptables -t filter -I INPUT -p tcp --dport 22 -j DROP Kubernetes Service 的原理相关网段分别为 Pod CIDR：10.244.0.0/16 Service CIDR：10.96.0.0/12 创建一个测试 Deployment 和 Service， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 镜像为 ARM 架构cat &lt;&lt; EOF | kubectl apply -f -apiVersion: apps/v1kind: Deploymentmetadata: labels: app: http-server name: http-serverspec: replicas: 3 selector: matchLabels: app: http-server template: metadata: labels: app: http-server spec: containers: - image: ghcr.io/joengjyu/simple-http-server:20221009 name: simple-http-server ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: labels: app: http-server name: http-svcspec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: http-server---apiVersion: v1kind: Servicemetadata: labels: app: http-server name: http-svc-node-portspec: type: NodePort ports: - port: 80 protocol: TCP targetPort: 80 selector: app: http-serverEOF 结果如下 123456789$ kubectl get pod,svcNAME READY STATUS RESTARTS AGE IPpod/http-server-7b59bbfffc-bxcvs 1/1 Running 0 3m12s 10.244.2.9pod/http-server-7b59bbfffc-f7cgt 1/1 Running 0 3m12s 10.244.1.7pod/http-server-7b59bbfffc-wpfb2 1/1 Running 0 3m12s 10.244.2.8NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S)service/http-svc ClusterIP 10.107.38.142 &lt;none&gt; 80/TCPservice/http-svc-node-port NodePort 10.108.51.223 &lt;none&gt; 80:32054/TCP 然后通过 iptables-save 命令得到所有链、表上的规则，相关规则可概括为： KUBE-SERVICES 或者 KUBE-NODEPORTS 规则对应的 Service 的⼊⼝链，这个规则应该与 VIP 和 Service 端⼝⼀⼀对应； KUBE-SEP-(hash) 规则对应的 DNAT 链，这些规则应该与 Endpoints ⼀⼀对应； KUBE-SVC-(hash) 规则对应的负载均衡链，这些规则的数⽬应该与 Endpoints 数⽬⼀致； 如果是 NodePort 模式的话，还有 POSTROUTING 处的 SNAT 链。 Cluster IP 类型其中与 Service 相关的规则如下： PREROUTING 和 OUTPUT 链中的 NAT 表中其他规则处理完之后，跳转到自定义链 KUBE-SERVICES 上； 12-A PREROUTING -m comment --comment &quot;kubernetes service portals&quot; -j KUBE-SERVICES-A OUTPUT -m comment --comment &quot;kubernetes service portals&quot; -j KUBE-SERVICES 自定义链 KUBE-SERVICES 上有对 Service http-svc 的 Cluster IP 做处理，如果目标 IP 是 10.107.38.142/32 且端口为80，则交给自定义链 KUBE-SVC-GM62ZXCOIF6ZCRWU 处理； 12-A KUBE-SERVICES -d 10.107.38.142/32 -p tcp -m comment --comment &quot;default/http-svc cluster IP&quot; -m tcp --dport 80 -j KUBE-SVC-GM62ZXCOIF6ZCRWU-A KUBE-SERVICES -d 10.108.51.223/32 -p tcp -m comment --comment &quot;default/http-svc-node-port cluster IP&quot; -m tcp --dport 80 -j KUBE-SVC-C3VEVZBK3X2BH5IZ 由于存在两个 Pod，因此在负载均衡链 KUBE-SVC-ZV76JU53N5UCJJE6 上可以看到两条主要的规则，其中第一条以30%的概率执行，第二条是50%的概率执行，第三条100%执行（由于这两条 iptables 规则存在先后顺序，且如果第一条执行后，第二条就不会执行，依次类推）。 1234-A KUBE-SVC-GM62ZXCOIF6ZCRWU ! -s 10.244.0.0/16 -d 10.107.38.142/32 -p tcp -m comment --comment &quot;default/http-svc cluster IP&quot; -m tcp --dport 80 -j KUBE-MARK-MASQ-A KUBE-SVC-GM62ZXCOIF6ZCRWU -m comment --comment &quot;default/http-svc -&gt; 10.244.1.7:80&quot; -m statistic --mode random --probability 0.33333333349 -j KUBE-SEP-C6IB5RPVIEGEDGUL-A KUBE-SVC-GM62ZXCOIF6ZCRWU -m comment --comment &quot;default/http-svc -&gt; 10.244.2.8:80&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-NVFETS636V4CPTUN-A KUBE-SVC-GM62ZXCOIF6ZCRWU -m comment --comment &quot;default/http-svc -&gt; 10.244.2.9:80&quot; -j KUBE-SEP-IHI45R5HV5QHYZU6 在 DNAT 链上，可以看到将目标地址换成了对应 Pod 的 IP 地址。 12345678-A KUBE-SEP-C6IB5RPVIEGEDGUL -s 10.244.1.7/32 -m comment --comment &quot;default/http-svc&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-C6IB5RPVIEGEDGUL -p tcp -m comment --comment &quot;default/http-svc&quot; -m tcp -j DNAT --to-destination 10.244.1.7:80-A KUBE-SEP-NVFETS636V4CPTUN -s 10.244.2.8/32 -m comment --comment &quot;default/http-svc&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-NVFETS636V4CPTUN -p tcp -m comment --comment &quot;default/http-svc&quot; -m tcp -j DNAT --to-destination 10.244.2.8:80-A KUBE-SEP-IHI45R5HV5QHYZU6 -s 10.244.2.9/32 -m comment --comment &quot;default/http-svc&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-IHI45R5HV5QHYZU6 -p tcp -m comment --comment &quot;default/http-svc&quot; -m tcp -j DNAT --to-destination 10.244.2.9:80 NodePort 类型跳转到 NodePort 链 KUBE-NODEPORTS 的时机： 本机从网卡中接受数据包 做为 KUBE-SERVICES 链条的守门员 12-A INPUT -m comment --comment &quot;kubernetes health check service ports&quot; -j KUBE-NODEPORTS-A KUBE-SERVICES -m comment --comment &quot;kubernetes service nodeports; NOTE: this must be the last rule in this chain&quot; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS KUBE-NODEPORTS 链条详情 1234-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/http-svc-node-port&quot; -m tcp --dport 32054 -j KUBE-EXT-C3VEVZBK3X2BH5IZ-A KUBE-EXT-C3VEVZBK3X2BH5IZ -m comment --comment &quot;masquerade traffic for default/http-svc-node-port external destinations&quot; -j KUBE-MARK-MASQ-A KUBE-EXT-C3VEVZBK3X2BH5IZ -j KUBE-SVC-C3VEVZBK3X2BH5IZ 跳转到 KUBE-SVC-C3VEVZBK3X2BH5IZ 链后，接下来的处理方式与 http-svc-node-port 的 ClusterIP 方式一致。 Reference https://mp.weixin.qq.com/s/O084fYzUFk7jAzJ2DDeADg https://mp.weixin.qq.com/s/SP51KH_K8JjUPuaj3ihdfA Structure of Iptables A Deep Dive into Iptables and Netfilter Architecture iptables - Wikipedia Service | Kubernetes","link":"/2022/10/10/673ef43cdb68.html"},{"title":"理解Servlet与Filter的关系与设计思路","text":"什么是Servlet对一个HTTP请求的正常的处理流程是： 发送HTTP请求 服务端的HTTP服务器收到请求 调用业务逻辑 返回HTTP响应 产生了下面3个问题： HTTP 服务器怎么知道要调用哪个业务逻辑，也就是 Java 类的哪个方法呢？ HTTP服务器可以被设计成收到请求后，接续寻找该请求的处理逻辑，但是这样就会使得HTTP 服务器的代码跟业务逻辑耦合在一起。 如果问题1交给HTTP服务器，如何解决HTTP 服务器的代码跟业务逻辑耦合在一起？ 根据职责单一原则，HTTP服务器的功能就应当设计成接收请求、发送响应，具体的处理逻辑可以交给一个第三方，由第三方去寻找处理逻辑所在的Java类。这个第三方就是Servlet容器。 Servlet容器是否需要知道具体的业务逻辑？ 不需要，只需要给到基本的数据（ServletRequest 、ServletResponse）给到业务逻辑处理单位即可，不用关注业务逻辑的具体实现。 所以Servlet被设计成了一个接口： 12345678910111213public interface Servlet { // Servlet容器在加载Servlet类的时候会调用 void init(ServletConfig config) throws ServletException; // 在web.xml给改Servlet配置的参数 ServletConfig getServletConfig(); // 业务逻辑处理入口 void service(ServletRequest req, ServletResponse res）throws ServletException, IOException; String getServletInfo(); // 在卸载的时候会调用 void destroy();} 其处理的流程： HTTP 服务器不直接调用业务类，而是把请求交给容器来处理，容器通过 Servlet 接口调用业务类。因此 Servlet 接口和 Servlet 容器的出现，达到了 HTTP 服务器与业务类解耦的目的。 Servlet 接口和 Servlet 容器这一整套规范叫作 Servlet 规范。Tomcat按照 Servlet 规范的要求实现了 Servlet 容器，同时它们也具有 HTTP 服务器的功能。 什么是Filter过滤器。这个接口允许你对请求和响应做一些统一的定制化处理，比如你可以根据请求的频率来限制访问，或者根据国家地区的不同来修改响应内容。过滤器的工作原理是这样的：Web 应用部署完成后，Servlet 容器需要实例化 Filter 并把 Filter 链接成一个 FilterChain。当请求进来时，获取第一个 Filter 并调用 doFilter 方法，doFilter 方法负责调用这个 FilterChain 中的下一个 Filter。 它在Java中的变现为一个接口： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * A filter is an object that performs filtering tasks on either the request to * a resource (a servlet or static content), or on the response from a resource, * or both. * * Filters perform filtering in the &lt;code&gt;doFilter&lt;/code&gt; method. Every Filter * has access to a FilterConfig object from which it can obtain its * initialization parameters, a reference to the ServletContext which it can * use, for example, to load resources needed for filtering tasks. */public interface Filter { /** * Called by the web container to indicate to a filter that it is being * placed into service. The servlet container calls the init method exactly * once after instantiating the filter. The init method must complete * successfully before the filter is asked to do any filtering work. */ public default void init(FilterConfig filterConfig) throws ServletException {} /** * The &lt;code&gt;doFilter&lt;/code&gt; method of the Filter is called by the container * each time a request/response pair is passed through the chain due to a * client request for a resource at the end of the chain. The FilterChain * passed in to this method allows the Filter to pass on the request and * response to the next entity in the chain. * &lt;p&gt; * A typical implementation of this method would follow the following * pattern:- &lt;br&gt; * 1. Examine the request&lt;br&gt; * 2. Optionally wrap the request object with a custom implementation to * filter content or headers for input filtering &lt;br&gt; * 3. Optionally wrap the response object with a custom implementation to * filter content or headers for output filtering &lt;br&gt; * 4. a) &lt;strong&gt;Either&lt;/strong&gt; invoke the next entity in the chain using * the FilterChain object (&lt;code&gt;chain.doFilter()&lt;/code&gt;), &lt;br&gt; * 4. b) &lt;strong&gt;or&lt;/strong&gt; not pass on the request/response pair to the * next entity in the filter chain to block the request processing&lt;br&gt; * 5. Directly set headers on the response after invocation of the next * entity in the filter chain. */ public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException; /** * Called by the web container to indicate to a filter that it is being * taken out of service. This method is only called once all threads within * the filter's doFilter method have exited or after a timeout period has * passed. After the web container calls this method, it will not call the * doFilter method again on this instance of the filter. * * This method gives the filter an opportunity to clean up any resources * that are being held (for example, memory, file handles, threads) and make * sure that any persistent state is synchronized with the filter's current * state in memory. */ public default void destroy() {}} 什么是FilterChain1234567891011121314151617/** * A FilterChain is an object provided by the servlet container to the developer * giving a view into the invocation chain of a filtered request for a resource. * Filters use the FilterChain to invoke the next filter in the chain, or if the * calling filter is the last filter in the chain, to invoke the resource at the * end of the chain. **/public interface FilterChain { /** * Causes the next filter in the chain to be invoked, or if the calling * filter is the last filter in the chain, causes the resource at the end of * the chain to be invoked. */ // doFilter方法负责调用这个FilterChain中的下一个Filter public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException;} FilterChain是一个接口，Tomcat里面有个一实现该接口的final类ApplicationFilterChain.java。 其中含有一个ApplicationFilterConfig.java 123456789private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0];/** * The int which is used to maintain the current position in the filter chain. */private int pos = 0;/** * The int which gives the current number of filters in the chain. */private int n = 0; 实现了FilterChain的doFilter(ServletRequest request, ServletResponse response)方法，其实就是调用了该类中的internalDoFilter(ServletRequest request, ServletResponse response)。调用完毕后，pos++。如果下次使用该FilterChain的doFilter()方法，会调用下一个Filter（如果存在） 1234567891011121314151617181920212223242526272829303132333435private void internalDoFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { // Call the next filter if there is oneif (pos &lt; n) { // 注意pos++ ApplicationFilterConfig filterConfig = filters[pos++]; try { Filter filter = filterConfig.getFilter(); if (request.isAsyncSupported() &amp;&amp; &quot;false&quot;.equalsIgnoreCase( filterConfig.getFilterDef().getAsyncSupported())) { request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE); } if( Globals.IS_SECURITY_ENABLED ) { final ServletRequest req = request; final ServletResponse res = response; Principal principal = ((HttpServletRequest) req).getUserPrincipal(); Object[] args = new Object[]{req, res, this}; SecurityUtil.doAsPrivilege (&quot;doFilter&quot;, filter, classType, args, principal); } else { // 实际调用Filter的doFilter()方法 filter.doFilter(request, response, this); } } catch (IOException | ServletException | RuntimeException e) { throw e; } catch (Throwable e) { e = ExceptionUtils.unwrapInvocationTargetException(e); ExceptionUtils.handleThrowable(e); throw new ServletException(sm.getString(&quot;filterChain.filter&quot;), e); } return;} 其中有一个对Filter的包装类ApplicationFilterConfig，其中持有一个Filter对象，可通过getFilter()方法去获取。上述类之间的UML图关系如下： 所以如果在Filter的doFilte()方法中，调用filterChain.doFilter(servletRequest, servletResponse);的话，会将流程交给chainFilter。因此也不难理解项目中Filter的使用如下： 1234567891011121314151617181920212223242526272829303132@Order(1)@WebFilter(urlPatterns = &quot;/*&quot;, filterName = &quot;requestWrapperFilter&quot;)public class RequestWrapperFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { // 添加traceId String traceId = ((HttpServletRequest) servletRequest).getHeader(Constants.REQUEST_HEADER_TRACEID); if (StringUtils.isBlank(traceId)) { traceId = StringUtils.replace(UUID.randomUUID().toString(), &quot;-&quot;, &quot;&quot;); } MDC.put(Constants.REQUEST_HEADER_TRACEID, traceId); try { // multipart/form-data请求不添加traceId if (ServletFileUpload.isMultipartContent((HttpServletRequest) servletRequest)) { filterChain.doFilter(servletRequest, servletResponse); } else { filterChain.doFilter(new RequestWrapper((HttpServletRequest) servletRequest), servletResponse); } } finally { // 清除 traceId MDC.remove(Constants.REQUEST_HEADER_TRACEID); } } @Override public void destroy() {}}","link":"/2019/12/18/16aa9f74bf70.html"},{"title":"百度地图墨卡托坐标转高德经纬度坐标（偏移小）","text":"参考：http://www.site-digger.com/tools/mct2latlng.html 这里的转换是直接调用百度地图SDK中的API，通过对其中JavaScript源代码的执行跟踪，提取出其中的墨卡托坐标转百度经纬度坐标的代码如下： Java版本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Datapublic static class Point { private double lng, lat; public Point(double lng, double lat) { this.lng = lng; this.lat = lat; } @Override public String toString() { return lng + &quot;,&quot; + lat; }}private static double xPi = 3.14159265358979324 * 3000.0 / 180.0;// 以下参数来自百度地图的SDKprivate static double[] MCBAND = {12890594.86, 8362377.87, 5591021, 3481989.83, 1678043.12, 0};private static double[][] MC2LL = { {1.410526172116255e-8, 0.00000898305509648872, -1.9939833816331, 200.9824383106796, -187.2403703815547, 91.6087516669843, -23.38765649603339, 2.57121317296198, -0.03801003308653, 17337981.2}, {-7.435856389565537e-9, 0.000008983055097726239, -0.78625201886289, 96.32687599759846, -1.85204757529826, -59.36935905485877, 47.40033549296737, -16.50741931063887, 2.28786674699375, 10260144.86}, {-3.030883460898826e-8, 0.00000898305509983578, 0.30071316287616, 59.74293618442277, 7.357984074871, -25.38371002664745, 13.45380521110908, -3.29883767235584, 0.32710905363475, 6856817.37}, {-1.981981304930552e-8, 0.000008983055099779535, 0.03278182852591, 40.31678527705744, 0.65659298677277, -4.44255534477492, 0.85341911805263, 0.12923347998204, -0.04625736007561, 4482777.06}, {3.09191371068437e-9, 0.000008983055096812155, 0.00006995724062, 23.10934304144901, -0.00023663490511, -0.6321817810242, -0.00663494467273, 0.03430082397953, -0.00466043876332, 2555164.4}, {2.890871144776878e-9, 0.000008983055095805407, -3.068298e-8, 7.47137025468032, -0.00000353937994, -0.02145144861037, -0.00001234426596, 0.00010322952773, -0.00000323890364, 826088.5}};/** * 参考：http://www.site-digger.com/tools/mct2latlng.html * 对上述链接中的操作，找到百度地图的SDK的源代码，然后转换成Java */private static Point convertMC2LL(Point mp) { Point absPoint = new Point(abs(mp.getLng()), abs(mp.getLat())); double[] paramArr = null; for (int i = 0; i &lt; MCBAND.length; i++) { if (absPoint.getLat() &gt;= MCBAND[i]) { paramArr = MC2LL[i]; break; } } if (mp == null || paramArr == null) throw new RuntimeException(&quot;转换出错&quot;); double lng = paramArr[0] + paramArr[1] * abs(mp.getLng()); double tlat = abs(mp.getLat()) / paramArr[9]; double lat = paramArr[2] + paramArr[3] * tlat + paramArr[4] * tlat * tlat + paramArr[5] * tlat * tlat * tlat + paramArr[6] * tlat * tlat * tlat * tlat + paramArr[7] * tlat * tlat * tlat * tlat * tlat + paramArr[8] * tlat * tlat * tlat * tlat * tlat * tlat; lng *= mp.getLng() &lt; 0 ? -1 : 1; lat *= mp.getLat() &lt; 0 ? -1 : 1; return new Point(lng, lat);}/*** 百度经纬度坐标转高德经纬度坐标。网上很常见的一种方式。*/private static Point BD09ToGCJ02(Point bdp) { double x = bdp.getLng() - 0.0065, y = bdp.getLat() - 0.006; double z = sqrt(x * x + y * y) - 0.00002 * sin(y * xPi); double theta = atan2(y, x) - 0.000003 * cos(x * xPi); return new Point(z * cos(theta), z * sin(theta));} Python版本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647xPi = 3.14159265358979324 * 3000.0 / 180.0# 以下参数来自百度地图的SDKMCBAND = [12890594.86, 8362377.87, 5591021, 3481989.83, 1678043.12, 0]MC2LL = [ [1.410526172116255e-8, 0.00000898305509648872, -1.9939833816331, 200.9824383106796, -187.2403703815547, 91.6087516669843, -23.38765649603339, 2.57121317296198, -0.03801003308653, 17337981.2], [-7.435856389565537e-9, 0.000008983055097726239, -0.78625201886289, 96.32687599759846, -1.85204757529826, -59.36935905485877, 47.40033549296737, -16.50741931063887, 2.28786674699375, 10260144.86], [-3.030883460898826e-8, 0.00000898305509983578, 0.30071316287616, 59.74293618442277, 7.357984074871, -25.38371002664745, 13.45380521110908, -3.29883767235584, 0.32710905363475, 6856817.37], [-1.981981304930552e-8, 0.000008983055099779535, 0.03278182852591, 40.31678527705744, 0.65659298677277, -4.44255534477492, 0.85341911805263, 0.12923347998204, -0.04625736007561, 4482777.06], [3.09191371068437e-9, 0.000008983055096812155, 0.00006995724062, 23.10934304144901, -0.00023663490511, -0.6321817810242, -0.00663494467273, 0.03430082397953, -0.00466043876332, 2555164.4], [2.890871144776878e-9, 0.000008983055095805407, -3.068298e-8, 7.47137025468032, -0.00000353937994, -0.02145144861037, -0.00001234426596, 0.00010322952773, -0.00000323890364, 826088.5]]# 百度经纬度坐标转高德经纬度坐标。网上很常见的一种方式。def bd09togcj02(bd_lon, bd_lat): &quot;&quot;&quot; 百度坐标系(BD-09)转火星坐标系(GCJ-02) 百度——&gt;谷歌、高德 :param bd_lat:百度坐标纬度 :param bd_lon:百度坐标经度 :return:转换后的坐标列表形式 &quot;&quot;&quot; x, y = bd_lon - 0.0065, bd_lat - 0.006 z = math.sqrt(x * x + y * y) - 0.00002 * math.sin(y * xPi) theta = math.atan2(y, x) - 0.000003 * math.cos(x * xPi) return z * math.cos(theta), z * math.sin(theta) # 参考：http://www.site-digger.com/tools/mct2latlng.html # 对上述链接中的操作，找到百度地图的SDK的源代码，然后转换成Javadef convertMC2LL(ox, oy) : x, y = abs(ox), abs(oy) for i in range(0, len(MCBAND)) : if y &gt;= MCBAND[i] : paramArr = MC2LL[i] break if paramArr == None: raise Exception('转换坐标失败') lng = paramArr[0] + paramArr[1] * abs(ox) tlat = abs(oy) / paramArr[9] lat = paramArr[2] + paramArr[3] * tlat + paramArr[4] * tlat * tlat + paramArr[5] * tlat * tlat * tlat + paramArr[6] * tlat * tlat * tlat * tlat + paramArr[7] * tlat * tlat * tlat * tlat * tlat + paramArr[8] * tlat * tlat * tlat * tlat * tlat * tlat lng *= (-1 if ox &lt; 0 else 1) lat *= (-1 if oy &lt; 0 else 1) return lng, lat 效果展示： 123456789101112131415161718// 测试代码String kejiyuan = &quot;12682891.3894,2559542.0538,12682896.5467,2559793.62794,12682844.7433,2560206.11494,12682734.4366,2561087.88431,12682681.159,2562074.67985,12682831.1964,2562218.1177,12683623.9092,2562188.56753,12683732.2141,2562243.30281,12683877.4858,2562398.46172,12683916.3509,2562839.59511,12683912.6528,2563051.56215,12683997.6458,2563129.82525,12684148.9608,2563136.64739,12684423.9572,2563249.60486,12684687.41,2563412.50587,12685216.0839,2563387.9877,12686427.857,2563282.11338,12687017.2378,2563194.53233,12687547.0621,2563146.47597,12687711.6126,2563191.93924,12688072.3621,2563098.80984,12688551.9725,2562924.51818,12688595.2954,2562866.34103,12688581.4473,2562769.94654,12688592.8397,2562733.23579,12689180.0331,2562464.27042,12689211.9588,2562420.55064,12689195.8798,2562314.3281,12689168.3537,2562313.76442,12688839.1722,2562275.22138,12688521.5892,2562344.85031,12688215.549,2562370.2208,12687875.1633,2562296.16518,12687304.0261,2562224.77222,12686776.2826,2562209.27294,12686464.1449,2562201.14685,12686253.3935,2562183.17902,12686147.8737,2562159.13696,12686097.5228,2562114.03074,12686174.2562,2560903.22104,12686144.5094,2560727.85702,12686162.7094,2560701.00483,12686702.0782,2560744.58401,12686715.7214,2560727.54607,12686694.5355,2560518.79091,12686469.0556,2560122.34138,12686281.1211,2559770.33875,12686231.908,2559542.23454,12686214.5986,2559162.03758,12686197.169,2559118.19258,12685318.8834,2559094.19446,12685143.0646,2559094.6559,12684986.7893,2559013.13744,12684889.126,2558895.30627,12684835.3891,2558858.28003,12684600.8812,2558847.14735,12684139.8292,2558854.49449,12683748.6599,2558894.79101,12683582.3085,2558936.30384,12683435.5368,2559030.43944,12683260.9697,2559068.85924,12682852.8989,2559166.22101,12682834.3698,2559181.22174,12682891.3894,2559542.0538&quot;;String pss = kejiyuan;String[] points = pss.split(&quot;,&quot;);if (points.length % 2 == 0) { for (int i = 0; i &lt; points.length; i += 2) { System.out.println( &quot;[&quot; + BD09ToGCJ02(convertMC2LL( new Point( Double.parseDouble(points[i]), Double.parseDouble(points[i + 1]) ) )) + &quot;],&quot; ); }} 打开高德地图多边形绘制DEMO示例，然后将上述代码的对应执行结果，以正确的形式粘贴到DEMO代码的相应地方：然后点击运行，查看结果：百度墨卡托坐标转成百度经纬度坐标后，在高德地图上展示情况将百度坐标转换成高德地图坐标后在高德地图中的展示情况百度地图原始数据 后面经过尝试、发现差距并不是特别大，已使用这种方法进行坐标转换","link":"/2019/07/09/37cf8e6d6448.html"},{"title":"真实记录一次对项目中代码的重构过程","text":"这份记录来自对项目中下单接口重构，详细记录了每一步操作、以及运用到的一些方法。力求能够最大程度将当时的过程展现出来。 准备重构中的每次修改都需要进行测试，用来验证修改是否正确，因此单元测试是一个非常好的选择。 单元测试单元测试中可以进行mock操作，从烦人的token中摆脱出来，做到在任何人的IDE里面都能跑起来，从而任何人都能进行重构。当然前期可能工作量会稍微大一些。 接口处理逻辑 下单的入参校验。 乘客校验。 根据订单类型判断是否满足下单条件，例如是否已有在进行中的订单。 根据订单类型塞入想要的值到订单表相应字段。 其他根据订单类型进行的操作。 返回。 存在的问题 神秘的命名（Mysterious Name） 重复代码（Duplicated Code） 过长函数（Long Function） 重复的Switch（Repeated Switches） 主流程重构抛开Controller里面的代码，直接从Service代码开始。 消除重复代码最开头有一个判断用户是否存在的代码。首先，这个代码相信只要是与用户相关的接口，肯定是需要做这样的判断；再者，这是一个相对独立的功能，可以提成一个函数，用恰当的命名，可以让代码更容易理解。 创建新的函数，然后将带提炼的代码拷贝得到新的函数中，确保对其逻辑没有实质的改动。提炼之后的代码位置为：fbb4117030c143d86b0b7f58adff4ea910c39d15，效果如下： 运行单元测试，检测是否改出了新的问题。 消除变量的神秘命名对变量、函数的命名是一门玄学，是个仁者见仁智者见智的问题。就像一千个人眼中有一千个哈姆雷特，每个人眼中正确的命名可能都有不同。 但是评判的标准都应该是：是否容易理解，是否能够一眼看出它的含义，诸如int a,b,c之类的肯定就不可取了。 JetBrains IDEA有很方便的重命名的方法，基本可以保证要改的地方都改了，不该改的不会动。如果实在不放心IDE的修改结果，可以用git diff逐项排查。 还有另外一处函数的局部变量也进行了重命名操作，如下： 重构之后的代码位置为：6fc2330d0ead0429bb8be683c847f40bc338683c，效果如下： 运行单元测试，检测是否改出了新的问题。一定要运行，虽然我也觉得改个名并不会有什么影响。 消除重复的switch语句在检验当前用户是否可以下单的时候，发现里面有一堆if-else的判断，并且在后续的填充订单数据等也有正对订单类型的if-else判断逻辑。 首先要声明的是，在代码中并没有真实的switch语句，但是有嵌套的if-else语句，这个与switch语句在逻辑上是一样的。重复的switch语句做的判断是与订单类型相关，并且这样的判断出现了很多次。想象一下出现这种情况的场景：对某些类型的订单，做了特殊要求的时候，按照尿性，我们都会顺手写个if-else，如果两个if还不够，两个不够那就多来几个if就完事了，但是这样显然是不友好、不优雅的、不利于阅读代码。 用多态取代条件表达式。 新增了OrderAction抽象类，包含一个待子类实现的verify()方法。 新增四种分别表示订单类型的类，继承自OrderAction，实现verify()方法。 因此，对订单的校验变成了下面这种情况： 具体的校验策略均拷贝自原来的校验函数中，暂时不做逻辑上的修改。 重构之后的代码位置为：2329017ba0f420306eae4b443139785c05bc525b。新增实时拼车单、预约不拼车单的单元测试，运行单元测试，检测是否改出了新的问题。 重复运用提炼代码对于刚消除了switch之后的代码，继续对其进行重构。梳理其业务逻辑如下： 查询是否有进行中的订单。 根据需求判断是否可继续下单。 首先从实时单下单前校验开始： 虽然这个if没有bug，但是总是感觉很难受，直接删掉了后面那个判断条件。接着看获取进行中订单列表的函数。 这里又进行了一次判断该用户是否存在的逻辑，然而在下单最开始的时候已经做了该判断，所以，这个if判断是不需要的。但是 调用的地方只有两处，并且另外一处就是预约单下单前校验的时候调用了该函数。虽然后面代码中，还用到了memberInfo的手机号码，去订单表里查询该用户的订单，但是订单表里的每一笔订单后面都加上了user_id（也就是memberId）。因此后面也不需要通过memberInfo去拿手机号码，所以这一次数据库查询完全可以去掉，可以节约一点接口处理时间。 在处理完上面的SQL查询后，对于这种局部变量，可以直接用IDEA的提示进行Inline variable操作，去掉不必要的局部变量。 所以重构后的代码如下： 另外，在Java中基本类型(primitive)优先于装箱基本类型(boxed primitive)。 对变量重命名、并删掉局部变量： 运行单元测试，检测是否改出了新的问题，发现单元测测试过不了。单元测试终于派上用场了，报错是因为StringUtils.join()得到的字符串并不符合SQL语法，如下： 修改成base-support下面的StringUtil.join2SqlInStr即可修改好改问题。 可见，单元测试在保证每步重构的正确性上面，是有一定的帮助的。 实时单下单前校验重构后，代码的位置为：4dcd17826ddd67f711151e28d569970e00ff0327。 预约单下单前校验与实时单类似，这里不再展示。 重构数据填充先去掉重复的switch将原有的dealWithByOrderType()函数放到OrderAction的fillOrderData()中， 并在该类中新建fillOrderDetail()抽象函数，用来分别处理不同订单类型的数据填充方式，在4个子类中分别实现该函数，将相应的填充代码拷贝进相应的函数中，先不做逻辑修改，暂时先对所需的函数、变量进行调整，让它能正常运行即可。 运行单元测试，检测是否改出了新的问题。代码位置为：b0fc69718184ffa543a57df0210e2086225172dd。 对各子类中的fillOrderDetail()进行重构后续发现，在填充数据的函数里面，充斥了大量的校验，这个时候函数做的事情与函数名称是不相符合的，这时候就应该使用提炼函数方法，将不同的工作提到另外一个函数中。因为是拷贝过来的，所以这就是之前代码中的问题。 但是考虑到后面的流程中还有一个填充数据的流程，所以对这部分的重构，等将整体流程重构完成之后，再一起重构。 发送消息完成初步填充数据后，后面还有一个填充数据的流程，这个if-else里面都有unifiedCreateOrderProcess()这个函数，所以可以直接提出来，放到OrderAction里面。这个if-else实质上只做了一件事情，那就是根据不同的订单发送不同的消息。 这个if-else真的是有点辣眼睛啊，最起码也得放到orderList初始化那一行。但是下单接口改的人确实是多，也可以理解。 在OrderAction里面，新建一个发送消息的方法，并将上面if中的代码拷贝进去。根据原代码，得出的结论是只有孩子单没有发送消息的必要，所以只需要在表示孩子单的那个子类中覆盖这个方法，然后函数里面什么都不做，就可以了。但是这里好像把预约单忘了，不过也没关系，目前并没有与预约单相关的业务。 所以修改后的代码如下： 下单流程代码： OrderAction代码： 其函数中的具体重构事项，暂时不管，留着后续再次做重构。此次重构后的代码位置为：30b45bdef6dd69f1737b7d6bde747030a69da5cd。 运行单元测试，检测是否改出了新的问题。 存储上下车站点位置存储上下车站点位置的这段代码看着好像没有啥问题，理解起来也没什么问题，但是始终还是觉得有点辣眼睛。 因为这个needRecordSites()函数还是依据订单类型来做判断，返回是true或者false。 这里可以考虑让每个子类返回一个参数，表示是否需要进行上下车站点的记录。形式可以是将主要的代码移到OrderAction中，构建一个模板方法；或者直接用运行时的多态即可。这里我选择了后面这种，主代码不移走，仍然放在下单的主流程里面。 删掉之前的neeadRecordSites(short orderType)，运行单元测试，检测是否改出了新的问题。代码位置为：2f05795039824d0ddd1d4cfd912069a8bbdf4c79。 主流程扫尾重构①变量命名：OrderIds。改名。 ②这段小代码里面明显存在公用的代码。去掉公用的代码。 ③是网约车平台监控推送代码提炼成一个函数。 ④去掉orderIds这个变量。 当前代码位置为：5b6bac8da。运行单元测试，检测是否改出了新的问题。 各函数重构目前的主流程中如下： ①有一个非常刺眼的orderType在其中 ②并且记录上下车站点的函数名也很是奇怪 ③然后就是校验这一块可以细分成入参校验+用户状态是否可下单校验。因为多种类型的订单，公用一个接口进行下单，在Form表单里面不能一概而论的使用框架提供的参数校验。 ④在createOrder()中调用insertTravellingOrder()函数看起来很多余，因为前者只是做一个转发作用，这是可以将后者内联回前者中。 修改后的主流程代码如下，整体比较清楚明白，但是仍然有点瑕疵，那就是fillOrderData()与unifiedCreateOrderProcess()这个函数是不是可以合并？这个可以待后续观察。 当前代码位置为：5b6bac8da。运行单元测试，检测是否改出了新的问题。 当前的下单逻辑已经分成几块明显的模块，其中verifyMemberStatus()是由之前的verify()改名而来，之前已做过重构。接下来就对fillOrderData()模块进行重构。 fillOrderData()模块这部分的修改主要集中在孩子单的处理上，孩子单的填写参数模块中夹杂着校验参数和填写订单信息、校验乘客状态着三部分的代码，使得每个函数的分工不再明确，因此需要将相应的逻辑，移到相应的函数中去。 在调用这个方法之前有一个查询用户是否存在的函数，如果用户存在，但是在这里参数校验过不了，那么在查询用户是否存在的代码中进行的SQL查询就白费了。因此将参数判断放在最开始的地方是有好处的。 当前代码位置为：698cb047d。运行单元测试，检测是否改出了新的问题。 unifiedCreateOrderProcess()①这个函数参数很奇怪。 这个appointmentTimeList到底来自哪里？ 到头来还是来自orderCreateForm，可是这个参数已经被传进来了。所以这个appointmentTimeList可以直接被干掉。 ②这个函数里面大部分是执行set操作。只有后面有一个对孩子单生成多日订单的代码，不然整个代码使用于所有的订单类型。因此只需要将公共的代码放入fillOrderDataCommon()中即可，生成订单列表的部分，可以交给不同的子类来实现。 当前的代码位置：f30ec83f7a427bd299b40ed7a0cfe4816faef15d。运行单元测试，检测是否改出了新的问题。 发送消息在发送消息模块，有一个VIP通道，意思大致是：后端自己去找合适的车辆，找到了就不用传给算法进行计算，没找到再传给算法计算。这段代码可以提炼。是否需要发送给算法，可以交给子类。 当前的代码位置：3ea9c14331d260a6de8fd7966ec8b84af43744bf。运行单元测试，检测是否改出了新的问题。 到目前为止，下单接口的代码已经重构完成了。可以等发布开发环境后，再次用司机端、客户端再次进行测试。 后记最终还是翻车了，出错的代码在孩子单生成多日订单的时候。 这个是因为for循环里面的order原来也叫orderCreateForm，然后函数的入参变量名也被我改成了orderCreateForm，所以这两个一开始的没开始搬家之前，就已经相同了，然后通过IDEA的Refactor-rename修改时，两个都被改成了一样的名称，但是主流程还是没有报错。","link":"/2020/02/01/3831abf370d2.html"},{"title":"系统应用闹钟之TabLayout的使用","text":"此篇文章记录一些关于安卓原生应用闹钟里面TabLayout的使用，没见过用这个组件的源代码，想从它里面学习学习。就当是见见世面，顺便写个笔记。 先从印象到布局原生闹钟给我的印象非常好，有种说不出的美感。在改工作上的问题时，顺便看它的样式，大致就是一个TabLayout加上四个fragment。 首先是头部的四个图标，是一个嵌在了Toolbar中的TabLayout。Toolbar也是一个ViewGroup，在它的里面放一个其他的控件也是理所当然，只是以前没试过。第一次看到这个写法，感觉非常好。 12345678910111213141516171819202122&lt;android.support.design.widget.AppBarLayoutandroid:layout_width=&quot;match_parent&quot;android:layout_height=&quot;wrap_content&quot;android:background=&quot;@null&quot;app:elevation=&quot;0dp&quot;&gt;&lt;android.support.v7.widget.Toolbar android:id=&quot;@+id/toolbar&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; app:contentInsetStart=&quot;0dp&quot; tools:ignore=&quot;RtlSymmetry&quot;&gt; &lt;android.support.design.widget.TabLayout android:id=&quot;@+id/tabs&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; app:tabGravity=&quot;fill&quot; app:tabIndicatorColor=&quot;@android:color/transparent&quot; app:tabMaxWidth=&quot;0dp&quot; app:tabMode=&quot;fixed&quot; app:tabPaddingEnd=&quot;0dp&quot; app:tabPaddingStart=&quot;0dp&quot; /&gt;&lt;/android.support.v7.widget.Toolbar&gt; 然后在Toolbar下面就是一个ViewPager，存放在一个FrameLayout中。 123456789101112131415&lt;FrameLayout android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; app:layout_behavior=&quot;@string/appbar_scrolling_view_behavior&quot;&gt; &lt;android.support.v4.view.ViewPager android:id=&quot;@+id/desk_clock_pager&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; android:importantForAccessibility=&quot;no&quot; android:saveEnabled=&quot;false&quot; /&gt; &lt;include layout=&quot;@layout/drop_shadow&quot; /&gt;&lt;/FrameLayout&gt; 这样基本上大致的框架就出来了。接着看对它的初始化：基本步骤和网上的教程是差不多的，只是其中的UiDataModel感觉非常有意思，感觉它几乎无所不能，用到的任何东西都可以往里面取。 123456789101112131415161718192021222324252627282930313233// Create the tabs that make up the user interface.mTabLayout = (TabLayout) findViewById(R.id.tabs);final int tabCount = UiDataModel.getUiDataModel().getTabCount();final boolean showTabLabel = getResources().getBoolean(R.bool.showTabLabel);final boolean showTabHorizontally = getResources().getBoolean(R.bool.showTabHorizontally);for (int i = 0; i &lt; tabCount; i++) { final UiDataModel.Tab tabModel = UiDataModel.getUiDataModel().getTab(i); final @StringRes int labelResId = tabModel.getLabelResId(); final TabLayout.Tab tab = mTabLayout.newTab() .setTag(tabModel) .setIcon(tabModel.getIconResId()) .setContentDescription(labelResId); if (showTabLabel) { tab.setText(labelResId); tab.setCustomView(R.layout.tab_item); @SuppressWarnings(&quot;ConstantConditions&quot;) final TextView text = (TextView) tab.getCustomView() .findViewById(android.R.id.text1); text.setTextColor(mTabLayout.getTabTextColors()); // Bind the icon to the TextView. final Drawable icon = tab.getIcon(); if (showTabHorizontally) { // Remove the icon so it doesn't affect the minimum TabLayout height. tab.setIcon(null); text.setCompoundDrawablesRelativeWithIntrinsicBounds(icon, null, null, null); } else { text.setCompoundDrawablesRelativeWithIntrinsicBounds(null, icon, null, null); } } 打开UiDataModel，第一个引起我的关注的是一个枚举型，在其中保存了有关Tab的基本信息，如文本、图标资源id以及该Tab所对应的fragment等。第一次见到这种写法，有点震惊，同时觉得对于这种静态的应用，用枚举型去保存也符合常理，我觉得这种方法可以以后利用在我写的Android项目中，比如说我的应用中，Tab也是固定的，同时这样写可以让那些信息更加集中，修改起来更加方便，让代码的逻辑性更强。看代码： 123456789101112131415161718192021/** Identifies each of the primary tabs within the application. */public enum Tab { ALARMS(AlarmClockFragment.class, R.drawable.ic_tab_alarm, R.string.menu_alarm), CLOCKS(ClockFragment.class, R.drawable.ic_tab_clock, R.string.menu_clock), TIMERS(TimerFragment.class, R.drawable.ic_tab_timer, R.string.menu_timer), STOPWATCH(StopwatchFragment.class, R.drawable.ic_tab_stopwatch, R.string.menu_stopwatch); private final String mFragmentClassName; private final @DrawableRes int mIconResId; private final @StringRes int mLabelResId; Tab(Class fragmentClass, @DrawableRes int iconResId, @StringRes int labelResId) { mFragmentClassName = fragmentClass.getName(); mIconResId = iconResId; mLabelResId = labelResId; } public String getFragmentClassName() { return mFragmentClassName; } public @DrawableRes int getIconResId() { return mIconResId; } public @StringRes int getLabelResId() { return mLabelResId; }} 感觉自己简直被这源代码所陶醉。后面继续看关于TabLayout的初始化。这其中，对其的适配器的写法，我也是比较感兴趣的。因为自己在写应用的时候，遇到过关于PagerAdapter的问题，所以比较期待它是如何去实现的。 123456789101112131415161718192021222324252627// Customize the view pager.mFragmentTabPagerAdapter = new FragmentTabPagerAdapter(this);mFragmentTabPager = (ViewPager) findViewById(R.id.desk_clock_pager);// Keep all four tabs to minimize jank.mFragmentTabPager.setOffscreenPageLimit(3);// Set Accessibility Delegate to null so view pager doesn't intercept movements and// prevent the fab from being selected.mFragmentTabPager.setAccessibilityDelegate(null);// Mirror changes made to the selected page of the view pager into UiDataModel.mFragmentTabPager.addOnPageChangeListener(new PageChangeWatcher());mFragmentTabPager.setAdapter(mFragmentTabPagerAdapter);// Mirror changes made to the selected tab into UiDataModel.mTabLayout.addOnTabSelectedListener(new TabLayout.OnTabSelectedListener() { @Override public void onTabSelected(TabLayout.Tab tab) { UiDataModel.getUiDataModel().setSelectedTab((UiDataModel.Tab) tab.getTag()); } @Override public void onTabUnselected(TabLayout.Tab tab) { } @Override public void onTabReselected(TabLayout.Tab tab) { }}); 适配器的源代码不完全贴出来，感觉都对不起这源代码。它继承自ViewPager，自己实现了其中的方法，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * This adapter produces the DeskClockFragments that are the content of the DeskClock tabs. The * adapter presents the tabs in LTR and RTL order depending on the text layout direction for the * current locale. To prevent issues when switching between LTR and RTL, fragments are registered * with the manager using position-independent tags, which is an important departure from * FragmentPagerAdapter. */final class FragmentTabPagerAdapter extends PagerAdapter { private final DeskClock mDeskClock; /** The manager into which fragments are added. */ private final FragmentManager mFragmentManager; /** A fragment cache that can be accessed before {@link #instantiateItem} is called. */ private final Map&lt;UiDataModel.Tab, DeskClockFragment&gt; mFragmentCache; /** The active fragment transaction if one exists. */ private FragmentTransaction mCurrentTransaction; /** The current fragment displayed to the user. */ private Fragment mCurrentPrimaryItem; FragmentTabPagerAdapter(DeskClock deskClock) { mDeskClock = deskClock; mFragmentCache = new ArrayMap&lt;&gt;(getCount()); mFragmentManager = deskClock.getFragmentManager(); } @Override public int getCount() { return UiDataModel.getUiDataModel().getTabCount(); } /** * @param position the left-to-right index of the fragment to be returned * @return the fragment displayed at the given {@code position} */ DeskClockFragment getDeskClockFragment(int position) { // Fetch the tab the UiDataModel reports for the position. final UiDataModel.Tab tab = UiDataModel.getUiDataModel().getTabAt(position); // First check the local cache for the fragment. DeskClockFragment fragment = mFragmentCache.get(tab); if (fragment != null) { return fragment; } // Next check the fragment manager; relevant when app is rebuilt after locale changes // because this adapter will be new and mFragmentCache will be empty, but the fragment // manager will retain the Fragments built on original application launch. fragment = (DeskClockFragment) mFragmentManager.findFragmentByTag(tab.name()); if (fragment != null) { fragment.setFabContainer(mDeskClock); mFragmentCache.put(tab, fragment); return fragment; } // Otherwise, build the fragment from scratch. final String fragmentClassName = tab.getFragmentClassName(); fragment = (DeskClockFragment) Fragment.instantiate(mDeskClock, fragmentClassName); fragment.setFabContainer(mDeskClock); mFragmentCache.put(tab, fragment); return fragment; } @Override public void startUpdate(ViewGroup container) { if (container.getId() == View.NO_ID) { throw new IllegalStateException(&quot;ViewPager with adapter &quot; + this + &quot; has no id&quot;); } } @Override public Object instantiateItem(ViewGroup container, int position) { if (mCurrentTransaction == null) { mCurrentTransaction = mFragmentManager.beginTransaction(); } // Use the fragment located in the fragment manager if one exists. final UiDataModel.Tab tab = UiDataModel.getUiDataModel().getTabAt(position); Fragment fragment = mFragmentManager.findFragmentByTag(tab.name()); if (fragment != null) { mCurrentTransaction.attach(fragment); } else { fragment = getDeskClockFragment(position); mCurrentTransaction.add(container.getId(), fragment, tab.name()); } if (fragment != mCurrentPrimaryItem) { FragmentCompat.setMenuVisibility(fragment, false); FragmentCompat.setUserVisibleHint(fragment, false); } return fragment; } @Override public void destroyItem(ViewGroup container, int position, Object object) { if (mCurrentTransaction == null) { mCurrentTransaction = mFragmentManager.beginTransaction(); } final DeskClockFragment fragment = (DeskClockFragment) object; fragment.setFabContainer(null); mCurrentTransaction.detach(fragment); } @Override public void setPrimaryItem(ViewGroup container, int position, Object object) { final Fragment fragment = (Fragment) object; if (fragment != mCurrentPrimaryItem) { if (mCurrentPrimaryItem != null) { FragmentCompat.setMenuVisibility(mCurrentPrimaryItem, false); FragmentCompat.setUserVisibleHint(mCurrentPrimaryItem, false); } if (fragment != null) { FragmentCompat.setMenuVisibility(fragment, true); FragmentCompat.setUserVisibleHint(fragment, true); } mCurrentPrimaryItem = fragment; } } @Override public void finishUpdate(ViewGroup container) { if (mCurrentTransaction != null) { mCurrentTransaction.commitAllowingStateLoss(); mCurrentTransaction = null; mFragmentManager.executePendingTransactions(); } } @Override public boolean isViewFromObject(View view, Object object) { return ((Fragment) object).getView() == view; }}","link":"/2018/03/14/175b2912dc35.html"},{"title":"给Ubuntu22.04的根目录扩容的全过程","text":"构建多次镜像后，就把容量占满了，导致一些 Pod 被 Evicted。有的镜像也不太好删，宿主机上却有很多空余的空间，所以可以直接扩容来处理。 操作环境： Ubuntu 22.04.1 LTS VMware Fusion 13 涉及到的命令： parted fdisk df pvresize/pvdisplay lvdisplay/lvextend resize2fs 现状 由于之前已经扩成功了，这里只是再做一遍，所以空余的空间还挺大。 为了将根目录扩容到 150G，现在只有 97G。 1234567$ sudo df -hFilesystem Size Used Avail Use% Mounted ontmpfs 892M 3.1M 889M 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 97G 38G 55G 41% /tmpfs 4.4G 0 4.4G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/lock/dev/sda2 2.0G 247M 1.6G 14% /boot 步骤扩展物理磁盘容量关闭虚拟机，然后在虚拟机软件中，为硬盘扩容。调整好容量后，点击应用。 开机，进入虚拟机，查看磁盘大小。 1234567891011121314151617181920$ sudo fdisk -l...Disk /dev/sda: 150 GiB, 161061273600 bytes, 314572800 sectorsDisk model: VMware Virtual SUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: B314ED9A-5F2F-4EB9-80C8-380D8FBB8F80Device Start End Sectors Size Type/dev/sda1 2048 4095 2048 1M BIOS boot/dev/sda2 4096 4198399 4194304 2G Linux filesystem/dev/sda3 4198400 209715166 205516767 98G Linux filesystemDisk /dev/mapper/ubuntu--vg-ubuntu--lv: 98 GiB, 105222504448 bytes, 205512704 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到磁盘以及扩容到 150G 了，但是新增的容量还处于 Free 状态，并未被系统识别并使用起来。 1234567891011121314151617181920$ sudo fdisk /dev/sdaWelcome to fdisk (util-linux 2.37.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.GPT PMBR size mismatch (209715199 != 314572799) will be corrected by write.This disk is currently in use - repartitioning is probably a bad idea.It's recommended to umount all file systems, and swapoff all swappartitions on this disk.Command (m for help): FUnpartitioned space /dev/sda: 50 GiB, 53687074304 bytes, 104857567 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytes Start End Sectors Size209715200 314572766 104857567 50G 让新增容量追加到对应磁盘设备上使用 parted 将新增的容量追加到 /dev/sda3 上 12sudo parted /dev/sdaunit s 查看空闲空间 p free 12345678910111213(parted) p freeModel: VMware, VMware Virtual S (scsi)Disk /dev/sda: 314572800sSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 34s 2047s 2014s Free Space 1 2048s 4095s 2048s bios_grub 2 4096s 4198399s 4194304s ext4 3 4198400s 209715166s 205516767s 209715167s 314572766s 104857600s Free Space 将空闲空间追加到 3 分区上 resizepart 3，输入空闲空间的 End 数值，然后再查看空闲空间。 123456789101112131415(parted) resizepart 3End? [209715166s]? 314572766s(parted) p freeModel: VMware, VMware Virtual S (scsi)Disk /dev/sda: 314572800sSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 34s 2047s 2014s Free Space 1 2048s 4095s 2048s bios_grub 2 4096s 4198399s 4194304s ext4 3 4198400s 314572766s 310374367s 可以看到 /dev/sda3 以及扩容完毕，按 q 退出 parted。 让LVM识别到新增的磁盘容量更新LVM中pv物理卷 123$ sudo pvresize /dev/sda3 Physical volume &quot;/dev/sda3&quot; changed 1 physical volume(s) resized or updated / 0 physical volume(s) not resized 查看LVM中pv状态 1234567891011$ sudo pvdisplay --- Physical volume --- PV Name /dev/sda3 VG Name ubuntu-vg PV Size &lt;148.00 GiB / not usable 16.50 KiB Allocatable yes PE Size 4.00 MiB Total PE 37887 Free PE 12800 Allocated PE 25087 PV UUID eKN8FR-r6VU-127T-AoNO-tjvm-AYHb-68zSSY 查看LVM逻辑卷状态 1234567891011121314151617$ sudo lvdisplay --- Logical volume --- LV Path /dev/ubuntu-vg/ubuntu-lv LV Name ubuntu-lv VG Name ubuntu-vg LV UUID 276mRA-dCfi-PKNd-MLKM-4lWp-SFNR-a0hAee LV Write Access read/write LV Creation host, time ubuntu-server, 2022-08-29 21:59:13 +0800 LV Status available # open 1 LV Size &lt;98.00 GiB Current LE 25087 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 给LVM逻辑卷扩容 123$ sudo lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv Size of logical volume ubuntu-vg/ubuntu-lv changed from &lt;98.00 GiB (25087 extents) to &lt;148.00 GiB (37887 extents). Logical volume ubuntu-vg/ubuntu-lv successfully resized. 刷新逻辑卷 12345$ sudo resize2fs /dev/ubuntu-vg/ubuntu-lvresize2fs 1.46.5 (30-Dec-2021)Filesystem at /dev/ubuntu-vg/ubuntu-lv is mounted on /; on-line resizing requiredold_desc_blocks = 13, new_desc_blocks = 19The filesystem on /dev/ubuntu-vg/ubuntu-lv is now 38796288 (4k) blocks long. 查看容量是否变更 1234567$ df -hFilesystem Size Used Avail Use% Mounted ontmpfs 892M 3.1M 889M 1% /run/dev/mapper/ubuntu--vg-ubuntu--lv 146G 38G 102G 27% /tmpfs 4.4G 0 4.4G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/lock/dev/sda2 2.0G 247M 1.6G 14% /boot Reference VM虚拟机Ubuntu 20.04 LVM磁盘扩容 - 简书 (jianshu.com) LVM : 简介 - sparkdev - 博客园 (cnblogs.com)","link":"/2023/01/05/c8da1b351035.html"},{"title":"解决web端登录时等待过久并偶尔抛出事务相关异常","text":"问题描述 分析登录函数中有一个事务，如下：事务里面有一个有可能操作比较耗时的过程：在新增登录日志的时候，获取用户的ip。具体干了啥不重要，重要的是发了一个http请求，并且是串行的，所以这个请求比较耗时的可能是很大的，并且具备不确定性因素。 反思TransactionRollbackException的文档注释为： This exception indicates that the transaction associated with processing of the request has been rolled back, or marked to roll back. Thus the requested operation either could not be performed or was not performed because further computation on behalf of the transaction would be fruitless 可能的过程为：线程1进入事务、然后进行了一次update操作，获得了一个排他锁，然后被卡在了获取ip的那个地方，即此事务持有着排他锁，然后还长时间不结束（50s+），然后线程2也进入了事务，此时在进行update的时候，需要等待线程1释放排它锁，在50秒过后，仍未获取到锁，此时获取锁时间超过了预设，抛出上述异常。 解决规避潜在的耗时操作。但是由于此服务没人维护，因此通过本地编译，然后拉包替换相应class文件，再上传到服务器的方式进行修改。 复现查看获取锁的超时阀值： 1SHOW VARIABLES LIKE '%timeout%'; 输出如下： 123456789101112131415161718+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| connect_timeout | 10 || delayed_insert_timeout | 300 || have_statement_timeout | YES || innodb_flush_log_at_timeout | 1 || innodb_lock_wait_timeout | 50 || innodb_rollback_on_timeout | OFF || interactive_timeout | 28800 || lock_wait_timeout | 31536000 || net_read_timeout | 30 || net_write_timeout | 60 || rpl_stop_slave_timeout | 31536000 || slave_net_timeout | 60 || wait_timeout | 28800 |+-----------------------------+----------+13 rows in set (0.01 sec) 代码如下： 12345678910111213141516171819202122232425// --------------------------Controller------------ /** * 测试web端登录锁表 */ @GetMapping(&quot;/hotline/test&quot;) public void testSomeThing() throws InterruptedException { testService.doSomething(); }// ----------------------------Service----------------@Servicepublic class TestService { @Autowired private BizConfMapper confMapper; @Transactional(rollbackFor = Exception.class) public void doSomething() throws InterruptedException { // 共享锁 BizConf conf = confMapper.selectByPrimaryKey(0); // 排它锁 confMapper.updateByPrimaryKey(conf); // 等待让下个线程超时，最起码要大于50 Thread.sleep(60000); }} 日志输出与项目中出现的错误信息基本一致，如下：在@Transactional注解中加入timeout后，报错不一样，但是阔以理解为spring框架为我们抛出了异常。如下： 后记其中对我理解这种现象有很大帮助的资料为这一张图，它让我明白了锁与事务之间的关系。参考：https://segmentfault.com/a/1190000014133576","link":"/2019/03/20/5156767b418e.html"},{"title":"解决使用MyBatis处理含有$的变量时报IllegalArgumentException Illegal group reference","text":"现象在一个GET请求中，输入参数包含$符号，然后后台报错。 复现123456789curl 'http://localhost:9999/xxxx/drivers?page=1&amp;size=20&amp;realname=$' \\-H 'Accept-Encoding: gzip, deflate' \\-H 'Accept-Language: zh,en;q=0.9,ja;q=0.8,zh-TW;q=0.7,fr;q=0.6,zh-CN;q=0.5' \\-H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36' \\-H 'Accept: application/json, text/plain, */*' \\-H 'userId: 453' \\-H 'Connection: keep-alive' \\-H 'token: 1e6966ec2fafdbbd53ef53124cc3e5ae' \\--compressed 报错截图 原因这个现象与mybatis无关，因为mybatis对$符号的操作主要集中在GenericTokenParser.java中，而这些操作都是以\\${出现，因此可以认为mybatis不处理单独的$符号。如下：在interceptor中，有一段打印将要执行的sql语句相关信息，根据调试结果，锁定了这个方法出问题所在，如下： 12Object obj = boundSql.getAdditionalParameter(propertyName);sql = sql.replaceFirst(&quot;\\\\?&quot;, getParameterValue(obj)); 因此问题转化成了下面的问题： 123456// 有问题的语句String sql = &quot;er WHERE realname like ? AND deleted = ?&quot;;sql = sql.replaceFirst(&quot;\\\\?&quot;, &quot;\\\\%$%&quot;);System.out.println(sql);// 修改sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(&quot;\\\\%$%&quot;)); $在replaceFirst(String regex, String replacement)中的使用网上关于这个方法的使用，普遍停留在regex，对replacement的解释少之又少，基本上没有。因为$符号在replacement中导致操作报错，因此，这个$肯定是有某种特殊的意义的。打开源代码，一直跟踪到抛出错误的地方。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * Processes replacement string to replace group references with * groups. */private StringBuilder appendExpandedReplacement(String replacement, StringBuilder result) { int cursor = 0; while (cursor &lt; replacement.length()) { char nextChar = replacement.charAt(cursor); // 可以看出，转义符号使用起来也需要小心。如果在最后面，又会报错。 if (nextChar == '\\\\') { cursor++; if (cursor == replacement.length()) throw new IllegalArgumentException( &quot;character to be escaped is missing&quot;); // 对转义符的操作比较简单，只是先跳过转义符，然后将下一个字符拷贝 nextChar = replacement.charAt(cursor); result.append(nextChar); cursor++; // 如果是$，那么后面要么是数字，要么是{ } else if (nextChar == '$') { // Skip past $ cursor++; // Throw IAE if this &quot;$&quot; is the last character in replacement if (cursor == replacement.length()) throw new IllegalArgumentException( &quot;Illegal group reference: group index is missing&quot;); nextChar = replacement.charAt(cursor); int refNum = -1; if (nextChar == '{') { cursor++; StringBuilder gsb = new StringBuilder(); // 先读出{}中的内容 while (cursor &lt; replacement.length()) { nextChar = replacement.charAt(cursor); if (ASCII.isLower(nextChar) || ASCII.isUpper(nextChar) || ASCII.isDigit(nextChar)) { gsb.append(nextChar); cursor++; } else { break; } } if (gsb.length() == 0) throw new IllegalArgumentException( &quot;named capturing group has 0 length name&quot;); if (nextChar != '}') throw new IllegalArgumentException( &quot;named capturing group is missing trailing '}'&quot;); String gname = gsb.toString(); if (ASCII.isDigit(gname.charAt(0))) throw new IllegalArgumentException( &quot;capturing group name {&quot; + gname + &quot;} starts with digit character&quot;); //{}中包含的内容，是分组的名字，分组存在，直接拿来分组的值，不存在则报错 if (!parentPattern.namedGroups().containsKey(gname)) throw new IllegalArgumentException( &quot;No group with name {&quot; + gname + &quot;}&quot;); refNum = parentPattern.namedGroups().get(gname); cursor++; } else { // The first number is always a group refNum = nextChar - '0'; // 只接受0-9的数字，也就是分组的序号 if ((refNum &lt; 0) || (refNum &gt; 9)) throw new IllegalArgumentException( &quot;Illegal group reference&quot;); cursor++; // Capture the largest legal group string boolean done = false; while (!done) { if (cursor &gt;= replacement.length()) { break; } int nextDigit = replacement.charAt(cursor) - '0'; if ((nextDigit &lt; 0) || (nextDigit &gt; 9)) { // not a number break; } int newRefNum = (refNum * 10) + nextDigit; if (groupCount() &lt; newRefNum) { done = true; } else { refNum = newRefNum; cursor++; } } } // Append group if (start(refNum) != -1 &amp;&amp; end(refNum) != -1) result.append(text, start(refNum), end(refNum)); } else { result.append(nextChar); cursor++; } } return result;} 可以看出，转义符号使用起来也需要小心。如果在最后面，又会报错，对转义符的操作比较简单，只是先跳过转义符，然后将下一个字符拷贝；如果是$，那么后面要么是数字，要么是{。对$符号的处理，如果后面是{，则先读出{}中的内容，也就是分组的名字，然后查询分组是否存在，存在则直接拿来分组的值，不存在则报错，如果后面是数字，就去拿第n个分组的值。 过程如上，但是网上基本上没有上述内容的示例，根据上面的简要分析，做出了下面简要的demo： 12345String Str = new String(&quot;Welcome to Tutoririalspoint.combb&quot;);System.out.print(&quot;Return Value :&quot; );System.out.println(Str.replaceFirst(&quot;Tuto(.*)als(?&lt;hi&gt;.*)(bb)&quot;, &quot;$1AMROOD}$2--$3--${hi}--xx&quot;));// 输出：// Return Value :Welcome to ririAMROOD}point.com--bb--point.com--xx 给分组命名确实以前没尝试过，参考：https://stackoverflow.com/questions/415580/regex-named-groups-in-java。 解决办法替换后的方法如下所示： 12345678910111213141516171819202122232425private String showSql(Configuration configuration, BoundSql boundSql) { Object parameterObject = boundSql.getParameterObject(); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); String sql = boundSql.getSql().replaceAll(&quot;[\\\\s]+&quot;, &quot; &quot;); if (parameterMappings.size() &gt; 0 &amp;&amp; parameterObject != null) { TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry(); if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(parameterObject))); } else { MetaObject metaObject = configuration.newMetaObject(parameterObject); for (ParameterMapping parameterMapping : parameterMappings) { String propertyName = parameterMapping.getProperty(); if (metaObject.hasGetter(propertyName)) { Object obj = metaObject.getValue(propertyName); sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(obj))); } else if (boundSql.hasAdditionalParameter(propertyName)) { Object obj = boundSql.getAdditionalParameter(propertyName); sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(obj))); } } } } return sql;} 参考：https://github.com/abel533/Mapper/issues/30","link":"/2019/03/26/945fdb518121.html"},{"title":"解决宿主机Mac不能访问虚拟机中CentOS的Tomcat服务器","text":"情况描述虚拟机中的系统为CentOS，充当服务器，但是开启Tomcat后，在宿主机Mac中无法访问，显示请求被拒接，如下：除此之外，但是可以使用ssh，也可以ping通。 分析初步认为就是防火墙的问题，但是参考iptables的一些停用方法，直接显示没有iptables这个服务；后面想验证到底是宿主机还是虚拟机的问题，在5000端口，跑了一个简单的Flask服务器（在虚拟机中可通过本机ip地址+端口号进行访问），在宿主机中仍然无法访问，同时也通过其他的一些设备来访问相应的服务器，都无法访问，从这里看来，问题还是出在了虚拟机中；后面又在宿主机mac中开启了一个服务器，在虚拟机和其它局域网设备中都可以访问，因此断定还是虚拟机的问题。那么，没有安装iptables的CentOS，究竟是出了什么问题呢？ 解决办法因为我使用的是CentOS 7，使用iptables的版本是7以前的，CentOS 7使用firewall作为防火墙。 查看已经开放的端口：firewall-cmd --list-ports开启端口：firewall-cmd --zone=public --add-port=80/tcp --permanent 命令含义： 123–zone #作用域–add-port=80/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 重启、停止、禁用、查看防火墙 1234firewall-cmd --reload #重启firewallsystemctl stop firewalld.service #停止firewallsystemctl disable firewalld.service #禁止firewall开机启动firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running） 因此结合上述命令来看，需要将8080端口添加到防火墙的开放端口中，然后重新载入防火墙的配置即可。如下： 123sudo firewall-cmd --zone=public --add-port=8080/tcp --permanentsudo firewall-cmd --reloadsudo firewall-cmd --list-ports 最后面来一张成功访问的截图： 参考：https://www.cnblogs.com/oskyhg/p/7293915.html","link":"/2018/09/02/6266a829e215.html"},{"title":"解决自研CSI启动后无法使用且CSINode无驱动信息的问题","text":"环境信息 此处对一些信息做了模糊处理，不想因此导致一些信息泄露。 A环境：跑在kata容器中的 OS； B环境：跑在虚拟机中的Ubuntu系统； X CSI：开发中的 CSI，目标是跑在 A 环境的 Kubernetes 中。 问题描述当 X CSI 的服务在 A 环境中启动后，在宿主机的 /var/lib/kubelet/plugins和 /var/lib/kubelet/plugins_registry目录中，生成对应的 sock 文件后，CSINode 中 driver 栏没有刚启动的 X CSI。结果如下： 问题影响无法使用 X CSI 来挂载 PV WorkAround kill kubelet 进程 1kill `ps -ef | grep -v grep | grep &quot;/usr/bin/kubelet&quot; | awk '{print $2}'` kubelet 重启后，会填充 CSINode 信息，如下 可能的原因 kubelet 命令是否存在对应的配置参数，来对控制扫描 /var/lib/kubelet/plugins_registry目录？ 是否由于文件系统的原因导致？ 排查过程排查 X CSI 的配置问题找了这张图来看 /var/lib/kubelet/plugins_registry 和 /var/lib/kubelet/csi-plugins/xxx.sock 目录有啥命名规范，会不会是命名不规范，导致 PluginWwatcher watch 不到对应的 sock 文件，从而引起 X CSI 无法顺利注册。 修改成上图中的规范之后，问题依然存在。 对比 B 环境中kubelet参数① A 环境中 kubelet 启动参数为： 1234567891011121314/usr/bin/kubelet --hostname-override=&lt;hostname&gt;--bootstrap-kubeconfig=/etc/k8s/cfg/kubelet-bootstrap.kubeconfig --kubeconfig=/etc/k8s/cfg/kubelet.kubeconfig --cert-dir=/etc/k8s/kubelet --config=/etc/k8s/cfg/kubelet.config --container-runtime=remote --runtime-request-timeout=15m --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=k8s.gcr.io/pause:3.2 --feature-gates=RotateKubeletServerCertificate=true --feature-gates=RotateKubeletClientCertificate=true --rotate-certificates=false --v=6 其中 kubelet.config 中的配置信息如下： 12345678910111213141516171819202122kind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS: [x.x.x.x]clusterDomain: cluster.localfailSwapOn: falseserverTLSBootstrap: trueauthentication: anonymous: enabled: true webhook: cacheTTL: 2m0s enabled: trueauthorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30sevictionHard: memory.available: &quot;10%&quot; ② 在 B 环境中用 kubeadm 自建 Kubernetes 集群 kubelet 启动参数： 1234567/usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.8 其中 kubelet.config 配置文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344apiVersion: kubelet.config.k8s.io/v1beta1authentication: anonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crtauthorization: mode: Webhook webhook: cacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0scgroupDriver: systemdclusterDNS:- 10.96.0.10clusterDomain: cluster.localcpuManagerReconcilePeriod: 0sevictionPressureTransitionPeriod: 0sfileCheckFrequency: 0shealthzBindAddress: 127.0.0.1healthzPort: 10248httpCheckFrequency: 0simageMinimumGCAge: 0skind: KubeletConfigurationlogging: flushFrequency: 0 options: json: infoBufferSize: &quot;0&quot; verbosity: 0memorySwap: {}nodeStatusReportFrequency: 0snodeStatusUpdateFrequency: 0sresolvConf: /run/systemd/resolve/resolv.confrotateCertificates: trueruntimeRequestTimeout: 0sshutdownGracePeriod: 0sshutdownGracePeriodCriticalPods: 0sstaticPodPath: /etc/kubernetes/manifestsstreamingConnectionIdleTimeout: 0ssyncFrequency: 0svolumeStatsAggPeriod: 0s 没有明显的配置差异，跳过对这方面的怀疑。 在 A 环境中部署其他CSI将官方的 nfs-csi 部署 A 环境的 K8s 中，发现在部署完成后，无法立即使用； 极大可能是 A 的环境问题 将 X CSI 部署到 B 环境的 K8s 中发现部署完成后，可立即使用（CSIDriver 显示正常，说明被 kubelet 正确加载了）； 排除 X CSI 配置问题 阅读 kubelet 加载 CSI 定义的代码 经过前面的尝试与分析，初步确定是 kubelet 加载 CSI 时，出现了问题，但具体是哪里的问题，需要先了解 kubelet 是如何加载 CSI 的，从其中寻找答案。 初步了解 CSI Driver 注册流程，在关键点添加日志、修改 kubelet 的日志级别，看日志，未发现文件监听相关的日志； 修改 kubelet 源码（添加 &amp; 修改 kubelet 中相关的日志级别）后，发现当 /var/lib/kubelet/plugins_registry目录下新增 sock 文件、删除 sock 文件后，没有相应日志打印，即监听文件系统的事件出现异常。 定位到问题为 kubelet 监听本地文件变更存在问题后，单独将 kubelet 使用的相关库提出，并单独验证。 将 kubelet 中用于监听文件变更的库单拎出来，写一个监听某文件夹下文件变更的二进制。 经过测试发现，在 A 环境的 /var/lib/kubelet/plugins_registry 目录下，就是极大概率无法监听到文件变更；更换目录，一些已存在的目录可以、一些新增的目录不行，讲道理，这不是一个正常的表现。 将二进制移到 B 环境中，监听相同目录，表现正常，进一步判定为 A 环境问题。 查看挂载信息1234root@&lt;hostname&gt;:/# df -h | grep -i katasharedkataShared 392G 314G 78G 81% /Filesystem 1K-blocks Used Available Use% Mounted onkataShared 410239272 329066648 81172624 81% / 所以问题是否会跟这个 kataSahred 文件系统有关？ 问题的原因kata 容器中默认的文件系统为 kataShare，在这种文件系统下，监听某个目录下的文件变更时，会有一定的概率收不到 CREATE、DELETE、UPDATE 事件。因为收不到变更事件，从而无法触发 kubelet 注册 CSI Driver 的后续流程，导致部署完 CSI 后，不能立即使用。 解决方案将 /var/lib/kubelet 目录挂载成其他文件系统后，安装 CSI 后，可立即使用，即可纵享丝滑。 12root@&lt;hostname&gt;:/# df -h | grep -i /var/lib/kubelet/dev/loop1 2.0G 6.5M 1.8G 1% /var/lib/kubelet One More Question 为什么重启 kubelet 能 workaround？ kubelet 启动时，会主动扫描 plugins_registry 目录下所有的文件，当扫描到文件后，会立即手动触发 CREATE 事件，从而完成 CSI Driver 的注册，达到 CSI 可用的目的。 Reference 一图看懂CSI插件如何注册至Kubernetes - 掘金 (juejin.cn)","link":"/2023/02/27/acd4740af8a6.html"},{"title":"记录一个与容器1号进程有关的问题","text":"浏览器访问服务 502 发现服务挂了 但是 docker 状态看起来还正常着服务跑在 Docker 容器里面启动方式为：shell (pid -&gt; 1) -&gt; java ( pid != 1) docker ps 能看见xxx的 STATUS 为 Up 4 days docker top xxx 显示出来无进程 docker exec -it xxx bash 显示 cannot exec in a stopped state: unknown docker logs 能看见日志 可以看见最后一行日志为 killeddocker stop 需要等待一段时间才能结束 Docker 版本：Docker Engine - Community 20.10.1 123456789101112131415161718192021222324252627282930# ubuntu @ ucloud-hk in ~ [10:55:49]$ docker versionClient: Docker Engine - CommunityVersion: 20.10.1API version: 1.41Go version: go1.13.15Git commit: 831ebeaBuilt: Tue Dec 15 04:34:58 2020OS/Arch: linux/amd64Context: defaultExperimental: trueServer: Docker Engine - CommunityEngine:Version: 20.10.1API version: 1.41 (minimum version 1.12)Go version: go1.13.15Git commit: f001486Built: Tue Dec 15 04:32:52 2020OS/Arch: linux/amd64Experimental: falsecontainerd:Version: 1.4.3GitCommit: 269548fa27e0089a8b8278fc4fc781d7f65a939brunc:Version: 1.0.0-rc92GitCommit: ff819c7e9184c13b7c2607fe6c30ae19403a7affdocker-init:Version: 0.19.0GitCommit: de40ad0 https://blog.csdn.net/zhangjikuan/article/details/114702299","link":"/2023/06/12/38afcaa3bc3c.html"},{"title":"设计模式之代理模式","text":"何为代理模式？代理，顾名思义可联想到代理人，代理人是干啥子的，帮别人做某件事的，且可能会根据一些具体的情况，做一些具体的处理。大概如此吧。 定义与作用它提供了对目标对象另外的访问方式;即通过代理对象访问目标对象。代理对象是对目标对象的扩展,并会调用目标对象。 好处：可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能. 实现静态代理简而言之，就是代理对象与被代理对象都实现同一接口，在代理对象中，调用被代理对象的相应方法，并加上一些自定义的其它操作，要使用被代理对象的方法时，只需要调用代理对象的相应方法即可。 缺点：如果增加接口中的方法，那么代理对象以及被代理对象都需要进行相应的修改，难以维护。 动态代理不需要实现接口，利用JDK的API，在内存中动态地创建代理对象。代理对象不需要实现接口,但是被代理对象一定要实现接口,否则不能用动态代理。 代理类所在包:java.lang.reflect.ProxyJDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是: static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h )其中三个参数的含义依次为: ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入 代码示例: 接口类IUserDao.java以及接口实现类,目标对象UserDao是一样的,没有做修改.在这个基础上,增加一个代理工厂类(ProxyFactory.java),将代理类写在这个地方,然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系,然后代用代理对象的中同名方法 代理工厂类:ProxyFactory.java 12345678910111213141516171819202122232425262728293031/** * 创建动态代理对象 * 动态代理不需要实现接口,但是需要指定接口类型 */public class ProxyFactory{ //维护一个目标对象 private Object target; public ProxyFactory(Object target){ this.target=target; } //给目标对象生成代理对象 public Object getProxyInstance(){ return Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;开始事务2&quot;); //执行被代理对象方法 Object returnValue = method.invoke(target, args); System.out.println(&quot;提交事务2&quot;); return returnValue; } } ); }} 测试类:App.java 12345678910111213141516171819/** * 测试类 */public class App { public static void main(String[] args) { // 目标对象 IUserDao target = new UserDao(); // 【原始的类型 class cn.itcast.b_dynamic.UserDao】 System.out.println(target.getClass()); // 给目标对象，创建代理对象 IUserDao proxy = (IUserDao) new ProxyFactory(target).getProxyInstance(); // class $Proxy0 内存中动态生成的代理对象 System.out.println(proxy.getClass()); // 执行方法 【代理对象】 proxy.save(); }} 其实对于上面的写法，有一个小小的疑问，如果接口中存在多个函数，那么这种做法是会为很一个函数都执行相同的附加操作，如果对每个函数做不同的操作呢？利用Method的属性加以区别，然后对每个函数做分别处理？这样处理可以不。。 参考：https://www.cnblogs.com/cenyu/p/6289209.html","link":"/2018/04/08/e7c7075ec95d.html"},{"title":"通过HTTP包来再次理解重定向与转发","text":"之所以去看它们之间数据包的差异并不是好奇。我理解它们之间的差异，但是我不知道该如何证明它们之间的差异。想了很久，我觉得去抓包，看它们之间数据包之间的差异，就是一个有力的证据。 预设总共有三个servlet，即/ddgg_ssm/loginre/、/ddgg_ssm/loginzf、/ddgg_ssm/user/，它们的作用依次为重定向到/ddgg_ssm/user/、转发到/ddgg_ssm/user/、显示一串字符。简要代码如下：重定向 12345678910111213@Controller@RequestMapping(&quot;/loginre&quot;)public class LoginController { @RequestMapping(&quot;/*&quot;) @ResponseBody public void printMsg(HttpServletRequest request, HttpServletResponse response) { try { response.sendRedirect(&quot;/ddgg_ssm/user/&quot;); } catch (IOException e) { e.printStackTrace(); } }} 转发 123protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { request.getRequestDispatcher(&quot;/user/&quot;).forward(request, response);} 先进行的是重定向，再接着的是转发。 数据包抓取结果以及简要的分析重定向与转发的数据包如下： 首先是第一个数据包，请求loginre。 12345678910GET /ddgg_ssm/loginre/ HTTP/1.1Host: 172.10.1.39:8080Connection: keep-aliveUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Linux; U; Android 7.0; zh-cn; Redmi Note 4X Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/61.0.3163.128 Mobile Safari/537.36 XiaoMi/MiuiBrowser/9.7.2x-miorigin: bAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8Accept-Encoding: gzip, deflateAccept-Language: zh-CN,en-US;q=0.8Cookie: JSESSIONID=3AFB73B954FEA21EA30E9F1D5ECF63A4 得到服务器的302重定向响应 1234HTTP/1.1 302 Location: /ddgg_ssm/user/Content-Length: 0Date: Tue, 05 Jun 2018 09:04:57 GMT 浏览器得到重定向的响应后，再请求Location中的Servlet。 12345678910GET /ddgg_ssm/user/ HTTP/1.1Host: 172.10.1.39:8080Connection: keep-aliveUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Linux; U; Android 7.0; zh-cn; Redmi Note 4X Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/61.0.3163.128 Mobile Safari/537.36 XiaoMi/MiuiBrowser/9.7.2x-miorigin: bAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8Accept-Encoding: gzip, deflateAccept-Language: zh-CN,en-US;q=0.8Cookie: JSESSIONID=3AFB73B954FEA21EA30E9F1D5ECF63A4 最后再得到服务器的响应： 123456HTTP/1.1 200 Content-Type: text/html;charset=ISO-8859-1Content-Length: 12Date: Tue, 05 Jun 2018 09:04:57 GMTHello World! 此时浏览器的地址栏已经变成了/ddgg_ssm/user/。 而后续的转发，只有两个数据包，一个请求与一个响应。 12345678910GET /ddgg_ssm/loginzf HTTP/1.1Host: 172.10.1.39:8080Connection: keep-aliveUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Linux; U; Android 7.0; zh-cn; Redmi Note 4X Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/61.0.3163.128 Mobile Safari/537.36 XiaoMi/MiuiBrowser/9.7.2x-miorigin: bAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8Accept-Encoding: gzip, deflateAccept-Language: zh-CN,en-US;q=0.8Cookie: JSESSIONID=3AFB73B954FEA21EA30E9F1D5ECF63A4 得到的响应是/ddgg_ssm/user/所写入的内容Hello world!。 123456HTTP/1.1 200 Content-Type: text/html;charset=ISO-8859-1Content-Length: 12Date: Tue, 05 Jun 2018 09:05:28 GMTHello World! 再贴一个结论吧 转发在服务器端完成的；重定向在客户端完成 转发的是同一次请求；重定向是两次不同请求 转发地址栏没有变化；重定向地址栏有变化","link":"/2018/06/06/cafe1207008b.html"},{"title":"通过反射来获取Intent中的Key","text":"在项目中遇到一种情况，我想通过了解某个Intent里面到底存了哪些数据来解决这个问题。但是我们知道，Intent里面的数据需要知道key才能调用相应的函数取出来，所以如何才能找出这些key呢？ 通过对Intent代码里面对存数据的观察，我们可以看到，通过putExtra()存的数据，都放在一个叫做mExtras的Bundle中。而Bundle继承自BaseBundle，并且其中申明了一个变量叫做ArrayMap&lt;String, Object&gt; mMap = null;。 12345678910111213// Intent.javapublic @NonNull Intent putExtra(String name, String value) { if (mExtras == null) { mExtras = new Bundle(); } mExtras.putString(name, value); return this;}// BaseBundle.javapublic void putString(@Nullable String key, @Nullable String value) { unparcel(); mMap.put(key, value);} 也不难理解它将数据以Object的方式存放在一个Map中，然后通过相应的get，将Object强转成相应的数据类型。 12345678910111213141516// Intent.javapublic String getStringExtra(String name) { return mExtras == null ? null : mExtras.getString(name);}// BaseBundle.javapublic String getString(@Nullable String key) { unparcel(); final Object o = mMap.get(key); try { return (String) o;//强转成String } catch (ClassCastException e) { typeWarning(key, o, &quot;String&quot;, e); return null; }} 所以我们只需要获取到这个mMap，就可以获取到所有的key和数据。如何才能获取到它呢？Intent以及Bundle中都没有相应的获取方法，然后在BaseBundle中，mMap的申明和获取都是默认包访问权限。所以通过常规方法是无法获取到的。 123456789// BaseBundle.javaArrayMap&lt;String, Object&gt; mMap = null;//默认包访问权限/** @hide */ArrayMap&lt;String, Object&gt; getMap() {//默认包访问权限 unparcel(); return mMap;} 听说反射可以做一些比较牛逼的事情，包括可以调用被@hide修饰的方法以及所有的方法、变量。在这里我们可以通过调用上面的那个get方法，也可以直接获取它的变量。在这里，我通过反射，来获取这个get方法，然后执行相应Bundle的该方法，成功获取到了mMap，并打印出其中的key。 这个代码运行在一个普通的Android应用中，没有需要其他的权限。 123456789101112131415private void showBundleContent(){ try { Class&lt;BaseBundle&gt; c = BaseBundle.class; Method method = c.getDeclaredMethod(&quot;getMap&quot;); method.setAccessible(true); Object obj = method.invoke(getIntent().getExtras()); obj = (ArrayMap&lt;String, Object&gt;) obj; Iterator it = ((ArrayMap&lt;String, Object&gt;) obj).keySet().iterator(); while (it.hasNext()){ Log.e(&quot;TAG&quot;, &quot;set : &quot;+(String)it.next()); } } catch (Exception e) { e.printStackTrace(); }}","link":"/2018/03/27/4a74bf2e6eac.html"},{"title":"通过hierarchyview探寻flowlayout","text":"前言在开发过程中遇到了一个很熟悉的控件，但是我不知道它叫啥名字，并且也不知道该用什么样的语言去描述它。然而，我却在很多的应用中看到了它的身影，QQ音乐，YouTube等，如下图所示： 为了一探究竟，我猜想它属于RecyclerView，是RecyclerView的一种定制化。通过勾选开发者选项中的显示布局边界，得到QQ音乐的截图如下： 看起来也挺像是一个高度定制了之后的RecyclerView，然后去搜索各种关于定制RecyclerView的博客，虽然没有得到很准确的答案，但是我收获到的东西有如下两件： RecyclerView可以通过设置LinearLayoutManager.setOritention()方法，来实现横向滑动，这种样式在很多其它的应用中也有发现。 对于一个应用，如果不知道它使用的是什么控件，可以通过Hierarchy View来进行查看。 关于Hierarchy View的使用曲折Hierarchy View一般在Android Studio的Tools-&gt;Android-&gt;Android Device Monitor中，打开后，选择添加，然后再选择Hierarchy View即可。一开始拿着自己的小米手机，连上电脑，结果发现没有任何东西。网上查询了之后才知道，为了安全考虑，不是所有的Android手机都允许连接上Hierarchy View，一般是模拟器和开发版本的手机可以。当然也有使用真机连接Hierarchy View的教程，但是得不偿失，还是选择使用模拟器吧~使用模拟器还有一个问题，如果安装QQ音乐这种类型的应用，会安装失败，而且返回一条错误提示： 12The APK failed to install.Error: INSTALL_FAILED_NO_MATCHING_ABIS: Failed to extract native libraries, res=-113 借用StackOverflow上面一个得票最高的一个回答： INSTALL_FAILED_NO_MATCHING_ABIS is when you are trying to install an app that has native libraries and it doesn’t have a native library for your cpu architecture. For example if you compiled an app for armv7 and are trying to install it on an emulator that uses the Intel architecture instead it will not work. Android手机的处理器架构一般是ARM，模拟器的大多数推荐使用的架构的是X86，因为支持X86的模拟器在X86处理器的PC上运行更快。虽然网上还是有在X86模拟器上面安装并运行此类应用的办法，但是我觉得那是属于玩机类型的事物，玩玩可以，实用可能还差一点。所以接下来就下载一个ARM架构的模拟器，在它上面装QQ音乐就?了。但是，Android自带的模拟器运行速度实在是太慢了，结果出不来啊。不得不换成BlueStacks，最可笑的事情来了，在BlueStacks中，找了半天没找到开发者选项，心想完了，网上百度也没个说法，结果我随手点了一下运行，结果APK在BlueStacks中跑起来了！！！所以，BlueStacks默认就是开启了开发者选项的啊！！不需要找到那个开发者选项，然后把它打开。不需要这样啊！各位别再百度了。 结果在模拟器中打开到QQ音乐搜索的那个界面，然后再使用Hierarchy View来打开应用，黑黑的界面突然变亮了！这就是当前应用的当前所在界面的控件结构图，上面有每一个控件的名称。抱着试一试的心态，终于找到了一个控件，叫做FlowLayout，双击它之后，便打开了一张图片，上面显示的内容正是我所探寻是何控件构成的那个界面！如图： 为了这个FlowLayout，真是一路坎坷，但是在路上就是最好的！","link":"/2017/10/10/09fad02370c0.html"},{"title":"项目架构解释说明","text":"模块概览base-service1234567891011121314151617181920212223242526272829303132333435363738394041base-service├── pom.xml└── src └── main └── java └── com └── haylion └── realTimeBus ├── advice │ └── SystemAdvice.java # 分页注解实现 ├── annotation │ └── PageAble.java # 分页注解 ├── bean │ ├── BaseModel.java # 含有id熟悉的基础bean │ ├── Condition.java # 条件查询时的条件 │ ├── ResultPageView.java # 被分页注解标记后，改函数返回的对象，将被包装成该对象(一个普通的bean类) │ ├── SMSConf.java # 将yaml文件中sms相关配置信息写入此类对象中 │ └── Sort.java # 查询时排序方式 ├── handler │ └── MySqlJsonHandler.java # MyBatis如何存储JSONObject、如何读取JSONObject ├── http │ └── HttpInvoker.java # RestTemplate单例容器 ├── interceptor │ └── sql │ ├── MyPageHelper.java # 覆盖afterAll后的PageHelper，在MyPageInterceptor中进行调用 │ ├── MyPageInterceptor.java # PageHelper中拦截器PageInterceptor的源码，有自定义修改 │ └── SqlLogHandler.java # 把将要执行的SQL打印出来，集成在MyPageInterceptor中 ├── mappers │ └── BaseMapper.java # 定义了访问数据库的一些基本接口 ├── msg │ └── RetStubMsg.java # 自定义ApplicationException接收的参数 └── service ├── BaseCacheService.java # 定义了一些基本的Redis访问接口 ├── BaseService.java # 实现了service基础数据库操作的抽象类 ├── CacheService.java # BaseCacheService的具体封装实现 ├── DistributedLock.java # 通过redis实现的一种分布式锁 ├── MQService.java # 阿里MQ操作封装 ├── SMSService.java # 阿里短信操作封装 ├── SysThreadPool.java # 自定义线程池 ├── UploadService.java # 文件上传，有文件头部信息校验 └── WXPayService.java # 微信支付相关操作封装 common-service123456789101112131415base-support/common-service├── pom.xml└── src └── main └── java └── com └── haylion └── realTimeBus └── common ├── code │ ├── RetStub.java # ApplicationException所依赖的对象，定义了业务逻辑错误的访问方法 │ └── SysStubInfo.java # 系统默认的错误码信息 ├── exception └── ApplicationException.java # 自定义异常，用来处理业务逻辑中出现的异常，其中依赖RetStub对象，来描述错误码、错误信息 facade-service12345678910111213141516171819202122232425262728base-support/facade-service├── pom.xml└── src └── main └── java └── com └── haylion └── realTimeBus └── facade ├── BaseInitializer.java # 自定义Server初始化类，其中加入了拦截器ActionInterceptor，并指定拦截所有的请求 ├── advice │ └── ResponseAdvice.java # 将所有返回的body中的数据，转换成JsonView的形式 ├── annotation │ └── AnonymousSupport.java # 跳过ActionInterceptor中的校验、塞入userId ├── exception │ └── ExceptionHandle.java # 在请求的处理过程中，出现任何异常，都会调用该类中的处理方法，将错误信息，以JsonView的形式返回。 ├── filter │ ├── RequestWrapper.java # 将请求相关的数据，如headers、queryparams、requestbody、method、url保存到本线程的LogTrace中 │ └── TraceCopyFilter.java # 拦截器，拦截所有的请求，并将请求转换成RequestWrapper ├── intercepter │ └── ActionInterceptor.java # 所有的请求都会经过该类处理，可以在此类中对类进行自定义操作，如按需鉴定权限、添加userId到header中 ├── log │ ├── HttpTraceLog.java # HTTP请求log类 │ └── LogTrace.java # 利用ThreadLocal获取、设置HttpTraceLog ├── validator │ └── ValidatorConfiguration.java # └── view └── JsonView.java # API统一响应模板 主要功能拦截鉴权— ActionInterceptor本项目中鉴定登录状态的方式为：在请求头部加入token，然后在拦截器ActionInterceptor.java中，从请求头部中取出token，并依据token来获取userId，然后将userId插入到头部中；如果上述过程，出现token是null、userId是null，那么该请求将被视为非登录状态，将不会传递到Controller层。 如何跳过校验？ 在Controller的方法上，加上@AnonymousSupport注解，在ActionInterceptor.java中，会通过Method方法，获取@AnonymousSupport，如果存在就不进行后面的登录状态校验。 12345HandlerMethod handlerMethod = (HandlerMethod) o;AnonymousSupport annotation = handlerMethod.getMethod().getAnnotation(AnonymousSupport.class);if (annotation != null) { return true;} 如何将userId添加到请求的headers中？ 通过token在Redis中获取到userId后，如何在headers中添加userId键值对，略微繁杂，但是目的很单纯。设置值的代码如下所示： 1234567MimeHeaders mimeHeaders = (MimeHeaders) headers.get(coyoteRequest);//in case of do not cover the specify keyString header = mimeHeaders.getHeader(key);logger.info(&quot;Original value of &lt;&quot; + key + &quot;&gt; is &quot; + header);mimeHeaders.removeHeader(key);// key = &quot;userId&quot;, value即token值mimeHeaders.addValue(key).setString(value); 在前面，有一个对request类型进行判断的语句，主要目的是为了避免NullPointerException，因为后面通过反射获取属性的时候，可能会由于request类型不同，而获取不到对应的Field，从而导致出现异常。 1234567891011if (request instanceof StandardMultipartHttpServletRequest) { // 文件上传时的类型是这个 StandardMultipartHttpServletRequest standardMultipartHttpServletRequest = (StandardMultipartHttpServletRequest) request; RequestWrapper requestWrapper = (RequestWrapper) standardMultipartHttpServletRequest .getRequest(); request = (HttpServletRequest) requestWrapper.getRequest();} else if (request instanceof RequestWrapper) { // 通常情况下是这个,因为我们在Filter中对request进行过包装，详情见下面请求日志部分 RequestWrapper requestWrapper = (RequestWrapper) request; request = (HttpServletRequest) requestWrapper.getRequest();} 请求日志主要的任务是将请求所有的参数(如：url中的参数、方法、headers、requestBody等)都以直观的方式打印出来。它的主要流程有两处： 拦截器TraceCopyFilter初始化RequestWrapper时，将请求所有的信息都保存到HttpTraceLog中，并通过LogTrace保存在当前线程中(利用ThreadLocal)。 1234567LogTrace.get().setStartTime(System.currentTimeMillis());LogTrace.get().setHttpMethod(request.getMethod());LogTrace.get().setUrl(requestURI);LogTrace.get().setReqParams(request.getQueryString());LogTrace.get().setReqHeader(getHeaderMap(request));// ...LogTrace.get().setRequestBody(sb.toString()); 在ResponseAdvice包装完返回信息之后，会在finally中将所有的请求信息，通过log的形式打印出来。打印完成后，会通过LogTrace将请求的信息从本线程中移除掉(利用ThreadLocal)。 123456789try { LogTrace.get().setSpendTime(System.currentTimeMillis() - LogTrace.get().getStartTime()); LogTrace.get().setRespParams(objectMapper.writeValueAsString(result)); log.info(&quot;Trace log is ====&gt; &quot; + objectMapper.writeValueAsString(LogTrace.get()));} catch (Exception e) { log.error(&quot;Trace log error : &quot;, e);} finally { LogTrace.clearAll();} 其中获取body时，直接使用IO流，把数据保存到变量requestBody中，代码如下： 123456789101112131415// request == null 是一个标志位this.request = null;// IO读取try (InputStream inputStream = request.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream))){ char[] charBuffer = new char[128]; int bytesRead; while ((bytesRead = bufferedReader.read(charBuffer)) &gt; 0) { sb.append(charBuffer, 0, bytesRead); }} catch (IOException ex) { ex.printStackTrace();}// 保存到内存中requestBody = sb.toString(); 但是收到POST请求时（参考链接），会产生两个TCP数据包（并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次），即浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。所以在拿POST请求中body时，如果直接读出来，可能导致后面框架再去读的时候，出现读不了的情况，所以在RequestWrapper中，重写了getInputStream方法，在request不为空，即没有读取过body(这种情况就是在上传文件的情况)，直接以requestBody作为输入流，提供给框架读取，上述问题便解决了。代码如下： 123456789101112131415161718192021222324252627282930@Overridepublic ServletInputStream getInputStream() throws IOException { if (this.request != null) { // 不为空，说明没有读取过body，即为文件上传请求，此时直接返回request.getInputStream() return request.getInputStream(); } // 以requestBody作为输入流 final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(requestBody.getBytes()); return new ServletInputStream() { @Override public boolean isFinished() { return false; } @Override public boolean isReady() { return false; } @Override public void setReadListener(ReadListener readListener) { } @Override public int read() throws IOException { // 以requestBody作为输入流 return byteArrayInputStream.read(); } };} SQL日志SqlLogHandler在SQL拦截中进行调用，它主要做的工作是把SQL中的?替换成实际的值，并打印出执行时间。 API统一的返回数据在ResponseAdvice中，会将数据都转化成JsonView的形式。 其中有一个问题，就是当返回的类型是String的时候，不能包装String类型，只能以String的形式返回。这是由于整个SpringMVC框架的设计问题。假设有如下业务代码： 12345@GetMapping(&quot;test&quot;)@AnonymousSupportpublic String test() { return &quot;test&quot;;} 这时候的返回值如下： 因为是以String的类型直接返回了，上述的返回格式也是理所当然。但是如果将String包装成JsonView，然后返回会怎么样？修改ResponseAdvice如下： 123456789if (o instanceof JsonView ) { result = o; return result;}if (o == null) { o = EMPTY_DATA;}result = new JsonView&lt;&gt;(SysStubInfo.DEFAULT_SUCCESS, o);return result; 这时候如果再次访问，程序会报错如下： 报错的堆栈信息如下： 123456789101112131415161718192021222324java.lang.ClassCastException: com.haylion.realTimeBus.facade.view.JsonView cannot be cast to java.base/java.lang.String at org.springframework.http.converter.StringHttpMessageConverter.getContentLength(StringHttpMessageConverter.java:43) at org.springframework.http.converter.AbstractHttpMessageConverter.addDefaultHeaders(AbstractHttpMessageConverter.java:259) at org.springframework.http.converter.AbstractHttpMessageConverter.write(AbstractHttpMessageConverter.java:210) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:275) at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.handleReturnValue(RequestResponseBodyMethodProcessor.java:180) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:82) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:119) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:877) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:783) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:866) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at com.haylion.realTimeBus.facade.filter.TraceCopyFilter.doFilter(TraceCopyFilter.java:52) 上面的错误简单理解，类型转换错误，也就是需要一个String，但是却收到了一个JsonView。需要的String是我们在Controller中返回的类型，然而实际收到的JsonView是在ResponseAdvice中包装后返回的。为什么这样的原因是：与ResponseAdvice执行的时机有关。在AbstractMessageConverterMethodProcessor.java文件的writeWithMessageConverters()方法中，调试数据如下： 确定返回类型： 确定可用的转换器，然后执行ResponseAdvice： 在ResponseAdvice执行前，SpringMVC会根据Controller的返回类型，确定一个AbstractHttpMessageConverter，由于在Controller中返回类型为String，所以这里为StringHttpMessageConverter，也就是说，它是用来转换一个String类型的转换器。等转换器确定好了之后，会执行ResponseAdvice中的处理方法，将String转换成JsonView。 写入返回数据： 忽略掉其他代码，直接进入出现错误的代码，在AbstractHttpMessageConverter中的addDefaultHeaders()方法中，需要在头部获取整个请求的大小，即调用getContentLength()方法。 它是一个期望被子类覆盖的方法，默认的实现如下： 123protected Long getContentLength(T t, @Nullable MediaType contentType) throws IOException { return null;} 这时候应该直接看StringHttpMessageConverter中的getContentLength()方法如下： 12345@Overrideprotected Long getContentLength(String str, @Nullable MediaType contentType) { Charset charset = getContentTypeCharset(contentType); return (long) str.getBytes(charset).length;} 然后再将转换后的JsonView作为抽象函数getContentLength()(这时就是StringHttpMessageConverter的该函数)的第一个参数，如下： 1234protected Long getContentLength(String str, @Nullable MediaType contentType) { Charset charset = getContentTypeCharset(contentType); return (long) str.getBytes(charset).length;} 第一个参数为String，但是实际上是JsonView。因此，ClassCastException在所难免。在ResponseAdvice中，将String直接返回，可以避免出现这种不太好修复的错误。 替代办法： 但是如果非要返回String类型，并且需要包装成JsonView形式，可以考虑直接在Controller中将String包装成JsonView，然后返回，如下： 12345@GetMapping(&quot;test&quot;)@AnonymousSupportpublic Object test() { return new JsonView&lt;&gt;(SysStubInfo.DEFAULT_SUCCESS, &quot;test&quot;);} 结果： 异常处理参看ExceptionHandle具体实现及写法、以及相关源码注释。 分页–PageHelper用法直接在方法上加上@PageAble注解，并在该方法中传入两个参数，分别为page和size，在该方法返回后，会得到一个ResultPageView封装对象，其中包含分页相关信息。 工作流程 SystemAdvice定义一个切面，切点是@annotation(com.haylion.realTimeBus.annotation.PageAble)。也就是说，每个被@PageAble注解过的方法，都将执行下面的代码： 1234567891011121314151617181920private static final String PAGE_ABLE = &quot;@annotation(com.haylion.realTimeBus.annotation.PageAble)&quot;;@Around(PAGE_ABLE)public Object doAroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { logger.info(&quot;execute method : &quot; + proceedingJoinPoint.getSignature().getName()); try { // 进入被@PageAble注解的方法前的准备工作 prepare(proceedingJoinPoint); // 执行被@PageAble注解的方法 Object obj = proceedingJoinPoint.proceed(); // 执行被@PageAble注解的方法后，执行扫尾工作 Object result = after(obj); return result; } catch (Throwable throwable) { logger.error(&quot;aspect execute error : &quot;, throwable); throw throwable; } finally { PageHelper.clearPage(); }} 准备工作：主要是获取page和size的值，然后调用PageHelper的startPage方法，初始化分页信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// PageAble中page和size的默认值分别是1和20@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface PageAble { String pageSizeName() default &quot;size&quot;; String pageNumName() default &quot;page&quot;; int pageSize() default 20; int pageNum() default 1;}// 准备分页private void prepare(ProceedingJoinPoint point) throws Exception { Signature signature = point.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method targetMethod = methodSignature.getMethod(); PageAble pageAble = targetMethod.getAnnotation(PageAble.class); String numName = pageAble.pageNumName(); String sizeName = pageAble.pageSizeName(); // 先获取默认的page和size值 int pageNo = pageAble.pageNum(); int pageSize = pageAble.pageSize(); Object[] paramValues = point.getArgs(); String[] paramNames = methodSignature.getParameterNames(); int length = paramNames.length; // 遍历该方法中的所有参数，如果有page和size信息，那么就覆盖默认值为用户传入的值 for (int i = 0; i &lt; length; i++) { if (paramNames[i].equals(numName)) { pageNo = (Integer) paramValues[i]; } else if (paramNames[i].equals(sizeName)) { pageSize = (Integer) paramValues[i]; } } // 该方法利用ThreadLocal在本线程中插入一个分页信息的对象Page PageHelper.startPage(pageNo, pageSize);}// startPage()方法的最终实现public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count, Boolean reasonable, Boolean pageSizeZero) { Page&lt;E&gt; page = new Page&lt;E&gt;(pageNum, pageSize, count); page.setReasonable(reasonable); page.setPageSizeZero(pageSizeZero); //当已经执行过orderBy的时候 Page&lt;E&gt; oldPage = getLocalPage(); if (oldPage != null &amp;&amp; oldPage.isOrderByOnly()) { page.setOrderBy(oldPage.getOrderBy()); } setLocalPage(page); return page;}protected static void setLocalPage(Page page) { LOCAL_PAGE.set(page);}protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal&lt;Page&gt;(); 进入SQL拦截器（即MyPageInterceptor）：这个拦截器中主要是PageHelper执行分页的步骤，相关步骤可分为： 判断是否需要进行分页。判断的条件为!dialect.skip(ms, parameter, rowBounds)，其实现为： 1234567891011121314151617@Overridepublic boolean skip(MappedStatement ms, Object parameterObject, RowBounds rowBounds) { if(ms.getId().endsWith(MSUtils.COUNT)){ throw new RuntimeException(&quot;在系统中发现了多个分页插件，请检查系统配置!&quot;); } Page page = pageParams.getPage(parameterObject, rowBounds); if (page == null) { return true; } else { //设置默认的 count 列 if(StringUtil.isEmpty(page.getCountColumn())){ page.setCountColumn(pageParams.getCountColumn()); } autoDialect.initDelegateDialect(ms); return false; }} 也就是说，通过判断Page是否为空来决定是否进行分页，Page则从本线程中获取，如下： 1234567891011121314// PageHelper.javaPage page = pageParams.getPage(parameterObject, rowBounds);//PageParams.javapublic Page getPage(Object parameterObject, RowBounds rowBounds) { Page page = PageHelper.getLocalPage(); ...}// PageMethod.javapublic static &lt;T&gt; Page&lt;T&gt; getLocalPage() { return LOCAL_PAGE.get();}protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal&lt;Page&gt;(); 获取数据的总条数。在进入此项前，会进行判断是否需要进行总数查询。这里假设进行总数查询。从源SQL解析出获取数据总条数的代码调试如下： log如下所示： 123456789101112132019-06-14 09:37:31.475 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Preparing: SELECT count(0) FROM advertising 2019-06-14 09:37:31.490 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Parameters: 2019-06-14 09:37:31.507 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - &lt;== Total: 12019-06-14 09:37:31.508 INFO [http-nio-8880-exec-1] c.h.r.i.s.SqlLogHandler - com.haylion.realTimeBus.dao.AdvertisingMapper.getByConditionList_COUNT:select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising&lt;cost time is :45 ms &gt;2019-06-14 09:37:31.512 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Preparing: select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising LIMIT ? 2019-06-14 09:37:31.512 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - ==&gt; Parameters: 1(Integer)2019-06-14 09:37:31.519 DEBUG [http-nio-8880-exec-1] o.a.i.l.j.BaseJdbcLogger - &lt;== Total: 12019-06-14 09:37:31.520 INFO [http-nio-8880-exec-1] c.h.r.i.s.SqlLogHandler - com.haylion.realTimeBus.dao.AdvertisingMapper.getByConditionList:select id, advertising_name, advertising_start_time, advertising_end_time, advertising_position, images_url, advertiser_url, advertiser_name, advertiser_id, settlement_type, settlement_price, create_time, create_user, audit_status, audit_opinion, audit_time, advertising_type from advertising LIMIT 1 &lt;cost time is :8 ms &gt;2019-06-14 09:37:31.591 INFO [http-nio-8880-exec-1] c.h.r.f.a.ResponseAdvice - Trace log is ====&gt; {&quot;url&quot;:&quot;/advertising/getAdvertisingList&quot;,&quot;httpMethod&quot;:&quot;GET&quot;,&quot;reqHeader&quot;:{&quot;host&quot;:&quot;192.168.12.39:8880&quot;,&quot;content-type&quot;:&quot;application/json&quot;,&quot;user-agent&quot;:&quot;curl/7.54.0&quot;,&quot;accept&quot;:&quot;*/*&quot;,&quot;token&quot;:&quot;fe20027352f8250571436f471a988b4d&quot;},&quot;reqParams&quot;:&quot;page=1&amp;size=1&quot;,&quot;requestBody&quot;:&quot;&quot;,&quot;respParams&quot;:&quot;{\\&quot;code\\&quot;:200,\\&quot;message\\&quot;:\\&quot;success\\&quot;,\\&quot;data\\&quot;:{\\&quot;total\\&quot;:9,\\&quot;current\\&quot;:1,\\&quot;pageCount\\&quot;:9,\\&quot;list\\&quot;:[{\\&quot;settlementType\\&quot;:0,\\&quot;imagesUrl\\&quot;:\\&quot;xxxxxxx\\&quot;,\\&quot;advertisingName\\&quot;:\\&quot;hello kitty 111\\&quot;,\\&quot;advertiserName\\&quot;:\\&quot;暁\\&quot;,\\&quot;advertiserId\\&quot;:0,\\&quot;createTimeymdhm_Str\\&quot;:\\&quot;2019-06-10 17:27\\&quot;,\\&quot;advertisingType\\&quot;:0,\\&quot;createTime\\&quot;:1560158854000,\\&quot;advertisingPosition\\&quot;:0,\\&quot;auditStatus\\&quot;:4,\\&quot;createUser\\&quot;:1,\\&quot;id\\&quot;:0,\\&quot;advertiserUrl\\&quot;:\\&quot;xxxxx\\&quot;,\\&quot;createTimeStr\\&quot;:\\&quot;2019-06-10 17:27:34\\&quot;}]}}&quot;,&quot;startTime&quot;:1560476250978,&quot;spendTime&quot;:592} 获取完总数后，会进行判断是否有分页的必要。 分页查询。这里假设有分页的必要。 12345678910111213141516171819//调用方言获取分页 sqlString pageSql = dialect.getPageSql(ms, boundSql, parameter, rowBounds, pageKey);@Overridepublic String getPageSql(MappedStatement ms, BoundSql boundSql, Object parameterObject, RowBounds rowBounds, CacheKey pageKey) { String sql = boundSql.getSql(); Page page = getLocalPage(); //支持 order by String orderBy = page.getOrderBy(); if (StringUtil.isNotEmpty(orderBy)) { pageKey.update(orderBy); sql = OrderByParser.converToOrderBySql(sql, orderBy); } if (page.isOrderByOnly()) { return sql; } // 这是一个抽象方法，会根据具体的数据库，调用不同的实现方法，来在原SQL语句上，加上对应的分页语句 return getPageSql(sql, page, pageKey);} 具体支持的数据库如下： Oracle的分页实现如下： 1234567891011//@Overridepublic String getPageSql(String sql, Page page, CacheKey pageKey) { StringBuilder sqlBuilder = new StringBuilder(sql.length() + 120); sqlBuilder.append(&quot;SELECT * FROM ( &quot;); sqlBuilder.append(&quot; SELECT TMP_PAGE.*, ROWNUM ROW_ID FROM ( &quot;); sqlBuilder.append(sql); sqlBuilder.append(&quot; ) TMP_PAGE WHERE ROWNUM &lt;= ? &quot;); sqlBuilder.append(&quot; ) WHERE ROW_ID &gt; ? &quot;); return sqlBuilder.toString();} MySQL的分页实现如下： 123456789101112@Overridepublic String getPageSql(String sql, Page page, CacheKey pageKey) { StringBuilder sqlBuilder = new StringBuilder(sql.length() + 14); sqlBuilder.append(sql); if (page.getStartRow() == 0) { sqlBuilder.append(&quot; LIMIT ? &quot;); } else { sqlBuilder.append(&quot; LIMIT ?, ? &quot;); } pageKey.update(page.getPageSize()); return sqlBuilder.toString();} 保存分页查询后的结果。 1234567891011121314151617181920212223242526272829303132// resultList是分页查询后的数据列表// afterPage的返回值是有两种情况，但是都可以被转成Listreturn dialect.afterPage(resultList, parameter, rowBounds);// dialect.afterPage()方法@Overridepublic Object afterPage(List pageList, Object parameterObject, RowBounds rowBounds) { //这个方法即使不分页也会被执行，所以要判断 null AbstractHelperDialect delegate = autoDialect.getDelegate(); if(delegate != null){ return delegate.afterPage(pageList, parameterObject, rowBounds); } return pageList;}// delegate.afterPage()方法@Overridepublic Object afterPage(List pageList, Object parameterObject, RowBounds rowBounds) { Page page = getLocalPage(); if (page == null) { return pageList; } page.addAll(pageList); if (!page.isCount()) { page.setTotal(-1); } else if ((page.getPageSizeZero() != null &amp;&amp; page.getPageSizeZero()) &amp;&amp; page.getPageSize() == 0) { page.setTotal(pageList.size()); } else if(page.isOrderByOnly()){ page.setTotal(pageList.size()); } return page;} 其实这里有一个问题是，如果delegate不为空，那么返回的是Page，但是我们在调用xxxxxMapper的查询方法之后，返回值基本上是List，与我们的常识并不符合。那Page是什么呢？它不只是包含分页信息的基本类，它继承自ArrayList。 123public class Page&lt;E&gt; extends ArrayList&lt;E&gt; implements Closeable { // ...} 在return后，还会执行finally中的处理代码，即com.haylion.realTimeBus.interceptor.sql.MyPageHelper的afterAll()方法。其中实现如下： 123456789101112131415161718192021222324252627// com.haylion.realTimeBus.interceptor.sql.MyPageHelper.afterAll()// 这个方法是我们自定义的方法，用来处理执行完前面所述的切点后，保留分页信息，进行再次封装@Overridepublic void afterAll() { Page&lt;Object&gt; localPage = getLocalPage(); // 删除分页信息 super.afterAll(); // 设置回本线程中 setLocalPage(localPage);}// super.afterAll()。这个方法可以简单理解成，清楚掉本线程中的分页信息@Overridepublic void afterAll() { //这个方法即使不分页也会被执行，所以要判断 null AbstractHelperDialect delegate = autoDialect.getDelegate(); if (delegate != null) { delegate.afterAll(); autoDialect.clearDelegate(); } clearPage();}// 移除本地变量public static void clearPage() { LOCAL_PAGE.remove();} 经过上述的过程，MyPageInterceptor执行完毕，分页信息存储在本线程中，然后回到切面处理。 切面收尾工作（回到SystemAdvice）： 12345678910111213private Object after(Object obj) { // ... PageInfo&lt;?&gt; pageInfo; Page&lt;Object&gt; localPage = PageHelper.getLocalPage(); long total = localPage.getTotal(); int pageNum = localPage.getPageNum(); int pages = localPage.getPages(); List&lt;?&gt; list = (List&lt;?&gt;) obj; // ... pageInfo = new PageInfo((list)); ResultPageView&lt;?&gt; resultPageView = new ResultPageView&lt;&gt;(total, pageNum, pages, pageInfo.getList()); return resultPageView;} 至此，还有最重要的一个步骤，是在切面处理完成后，将分页信息从本线程中删除，没有此操作，后续操作会出现莫名其妙的错误。也就是finally语句中的PageHelper.clearPage();。 1234567891011try { prepare(proceedingJoinPoint); Object obj = proceedingJoinPoint.proceed(); Object result = after(obj); return result;} catch (Throwable throwable) { logger.error(&quot;aspect execute error : &quot;, throwable); throw throwable;} finally { PageHelper.clearPage();} 局限这就限定了在一个被PageAble注解了的方法上，只能执行一条查询。如果对于一个到来的请求，需要进行两次或以上的查询，并且某一条查询需要分页的情况，如果所有的查询都放在被PageAble注解的方法下，执行会出现问题（出现不必要的分页操作）。但是可以通过组装的形式，完成该项需求。","link":"/2019/06/18/a16a8d6e1474.html"},{"title":"01.AI概览","text":"Top 10 AI Frameworks for 2024Here are the top 10 Artificial Intelligence Framework to Explore in 2024: TensorFlow PyTorch Theano Microsoft CNTK Scikit-learn Apache Mahout Amazon Machine Learning PaddlePaddle Jax Caffe","link":"/2024/12/09/b0874d97f2ec.html"},{"title":"0 | Golang：基础构建工具使用","text":"Golang 里面有一堆看起来很高大上的名词，以及一些自带的工具链。 1brew install golang 安装完之后，有一堆默认的配置信息，可以通过 go env 来进行查看： 12345678910111213141516171819202122232425262728293031323334╰─$ go envGO111MODULE=&quot;&quot;GOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOCACHE=&quot;/Users/akina/Library/Caches/go-build&quot;GOENV=&quot;/Users/akina/Library/Application Support/go/env&quot;GOEXE=&quot;&quot;GOFLAGS=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOINSECURE=&quot;&quot;GONOPROXY=&quot;&quot;GONOSUMDB=&quot;&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;/Users/akina/go&quot;GOPRIVATE=&quot;&quot;GOPROXY=&quot;https://proxy.golang.org,direct&quot;GOROOT=&quot;/usr/local/Cellar/go/1.14.6/libexec&quot;GOSUMDB=&quot;sum.golang.org&quot;GOTMPDIR=&quot;&quot;GOTOOLDIR=&quot;/usr/local/Cellar/go/1.14.6/libexec/pkg/tool/darwin_amd64&quot;GCCGO=&quot;gccgo&quot;AR=&quot;ar&quot;CC=&quot;clang&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot;GOMOD=&quot;&quot;CGO_CFLAGS=&quot;-g -O2&quot;CGO_CPPFLAGS=&quot;&quot;CGO_CXXFLAGS=&quot;-g -O2&quot;CGO_FFLAGS=&quot;-g -O2&quot;CGO_LDFLAGS=&quot;-g -O2&quot;PKG_CONFIG=&quot;pkg-config&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/km/t6kk56y13ns2yf91lwq58gbh0000gn/T/go-build924722399=/tmp/go-build -gno-record-gcc-switches -fno-common&quot; 其中有几个比较重要的变量，需要注意。 GOROOTGolang 的安装目录。本机上的 GOROOT 为：/usr/local/Cellar/go/1.14.6/libexec，它的目录结构如下： 1234567891011121314151617╰─$ tree -L 1 /usr/local/Cellar/go/1.14.6/libexec/usr/local/Cellar/go/1.14.6/libexec├── CONTRIBUTING.md├── CONTRIBUTORS├── PATENTS├── SECURITY.md├── VERSION├── api├── bin├── doc├── favicon.ico├── lib├── misc├── pkg├── robots.txt├── src└── test GOPATH同样是一个变量，且变量值的内容是一个目录，那 Golang 拿着这个变量来做什么呢？它的作用用文字说明可能比较苍白无力、甚至有点抽象，用亲手实践来看看它到底有什么用处。在本机中，GOPATH 的值（默认值：$HOME/go）为：/Users/akina/go。 12345╰─$ tree -L 1 /Users/akina/go/Users/akina/go├── bin├── pkg└── src 其中会自动生成三个文件夹，它们的作用分别为： 文件夹 作用 bin golang 编译可执行文件存放路径，可自动生成。 pkg golang编译的.a中间文件存放路径，可自动生成。 src 源码路径。按照golang默认约定，go run，go install等命令的当前工作路径（即在此路径下执行上述命令） 暂时将其视为一个普通的目录，拥有三个普通的文件夹。先看后面的 go build、go install、go run。 GOBINgo install 编译存放路径。为空时则遵循“约定优于配置”原则，可执行文件放在各自 GOPATH 目录的 bin 文件夹中，即 $GOPATH/bin。 有两种情况下，bin 目录会变得没有意义。 当设置了有效的 GOBIN 环境变量以后，bin 目录就变得没有意义。 如果 GOPATH 里面包含多个工作区路径的时候，必须设置 GOBIN 环境变量，否则就无法安装 Go 程序的可执行文件。 GOPROXY如果遇到下载不下来包的情况，可以考虑尝试设置 GOPROXY 。如下（&gt;=1.13）： 12345678go env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.io,direct# 设置不走 proxy 的私有仓库，多个用逗号相隔（可选）go env -w GOPRIVATE=*.corp.example.com# 设置不走 proxy 的私有组织（可选）go env -w GOPRIVATE=example.com/org_name go buildusage: go build [-o output] [-i] [build flags] [packages] Build compiles the packages named by the import paths, along with their dependencies, but it does not install the results. If the arguments to build are a list of .go files from a single directory, build treats them as a list of source files specifying a single package. When compiling packages, build ignores files that end in ‘_test.go’. When compiling a single main package, build writes the resulting executable to an output file named after the first source file (‘go build ed.go rx.go’ writes ‘ed’ or ‘ed.exe’) or the source code directory (‘go build unix/sam’ writes ‘sam’ or ‘sam.exe’). The ‘.exe’ suffix is added when writing a Windows executable. When compiling multiple packages or a single non-main package, build compiles the packages but discards the resulting object, serving only as a check that the packages can be built. go build 命令默认编译当前目录下的所有 go 文件 go build a.go 只编译 a.go 文件如果将编译对象换成不含有 main 函数的代码，没有任何输出 go build IMPORT-PATH 编译在 $GOPATH/src 下面的 IMPORT-PATH 包，并在当前目录 （pwd）下，生成可执行文件（对含有 main 函数的代码来说） go install它在 go build 的基础上，将编译后的可执行文件或中间文件，移动到 $GOPATH 的 bin 或 pkg 目录下。 go run类似于 go build，可以在其它目录，仅指定在 $GOPATH 下的包名，即可运行该包内容；也可以指定一个含有 main 函数的文件。如下： go get用于从远程代码仓库（比如 Github 等 ）上下载并安装代码包。下载源码包的go工具会自动根据不同的域名调用不同的源码工具，对应关系如下： 仓库 源码工具 BitBucket Mercurial Git GitHub Git Google Code Project Hosting Git, Mercurial, Subversion Launchpad Bazaar 它会把当前的代码包下载到 $GOPATH 中的第一个工作区的 src 目录中，并安装。 -d：只下载不安装 -u：更新已下载的代码包 GoLand 中打开的 terminal 会自动将 $GOPATH/bin 添加到 PATH 变量中，导致在 GoLand 的 terminal 上可以使用通过 go get 安装的命令，在 iTerm2 上面就不行。只要在 .bashrc/.zshrc 中，将 $GOPATH/bin 添加到 PATH 变量中就可以在 iTerm2 中使用。 go fmt将代码整理成 Golang 风格。 usage: go fmt [-n] [-x] [packages] Fmt runs the command ‘gofmt -l -w’ on the packages named by the import paths. It prints the names of the files that are modified. For more about gofmt, see ‘go doc cmd/gofmt’.For more about specifying packages, see ‘go help packages’. The -n flag prints commands that would be executed.The -x flag prints commands as they are executed. The -mod flag’s value sets which module download mode to use: readonly or vendor. See ‘go help modules’ for more. To run gofmt with specific options, run gofmt itself. go fmt 实际调用的是 gofmt -l -w，而 gofmt 的使用如下： 12345678910usage: gofmt [flags] [path ...] -cpuprofile string write cpu profile to this file -d display diffs instead of rewriting files -e report all errors (not just the first 10 on different lines) -l list files whose formatting differs from gofmt's -r string rewrite rule (e.g., 'a[b:len(a)] -&gt; a[b:]') -s simplify code -w write result to (source) file instead of stdout gofmt 与 go 在同一级目录，都在 $GOROOT/bin 下：看看效果： 初始样式 执行 go fmt，可以明显看出，代码变整齐了。 go testReference https://halfrost.com/go_command/ https://astaxie.gitbooks.io/build-web-application-with-golang/content/zh/01.3.html https://goproxy.io/zh/","link":"/2020/08/20/6ec2646852dc.html"},{"title":"Calico证书学习笔记","text":"准备工作安装测试集群 1234curl https://raw.githubusercontent.com/tigera/ccol1/main/control-init.yaml | multipass launch -n control -m 2048M 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/node1-init.yaml | multipass launch -n node1 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/node2-init.yaml | multipass launch -n node2 20.04 --cloud-init -curl https://raw.githubusercontent.com/tigera/ccol1/main/host1-init.yaml | multipass launch -n host1 20.04 --cloud-init - calico 的四种安装方式 Manifest Operator Managed Kubernetes Service(EKS、GKE、AKS) Kubernetes Distro(MicroK8s) 以Operator的方式来安装calico 123456789101112131415multipass shell host1kubectl create -f https://docs.projectcalico.org/archive/v3.21/manifests/tigera-operator.yamlcat &lt;&lt;EOF | kubectl apply -f -apiVersion: operator.tigera.io/v1kind: Installationmetadata: name: defaultspec: calicoNetwork: containerIPForwarding: Enabled ipPools: - cidr: 198.19.16.0/21 natOutgoing: Enabled encapsulation: NoneEOF 安装测试所需的模拟业务 12multipass shell host1kubectl apply -f https://raw.githubusercontent.com/tigera/ccol1/main/yaobank.yaml 网络策略原生网络策略 要想 NetworkPolicy 生效，必须使用实现了此的 CNI 插件，如 calico。 ingress 进 pod 流量 默认全部打开，当被应用规则后，pod 所在 node 上、ingress 规则列表中允许的流量可以进入 pod； egress 出 pod 流量，默认全部可以出，当被应用规则后，只有规则中允许的流量可以出 pod； 白名单机制，即在 rules 中配置了，才能通行（包括进和出），规则可以叠加，但能做到只要配置了就能通行； 默认配置 命名空间中没有 policy 时，全部开放； 拒绝/允许所有流量 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-deny-allspec: podSelector: {} policyTypes: - Ingress - Egress---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-all-ingressspec: podSelector: {} ingress: - {} policyTypes: - Ingress---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: default-deny-egressspec: podSelector: {} policyTypes: - Egress---apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: allow-all-egressspec: podSelector: {} egress: - {} policyTypes: - Egress 选择流量的3种方式 podSelector namespaceSelector ipBlock DNS 记录 Service shs-8080.tcp.shs-svc.default.svc.cluster.local shs-svc.default.svc.cluster.local Pod 10-244-0-8.default.pod.cluster.local Calico Network Policy 比原生网络策略的优势 原生策略为白名单机制，即只有 allow 这一个动作，calico 还有 deny，log 等操作。 原生策略资源是ns级别的，calico 即支持ns级别、也支持cluster级别。","link":"/2024/12/09/4948e86c1262.html"},{"title":"如何在YAML文件中进行优雅地换行","text":"样式对比 123456789101112131415161718a: &gt; hiello jasdfb: &gt;- hiello jasdfc: &gt;+ hiello jasdfA: | hiello jasdfB: |- hiello jasdfC: |+ hiello jasdf Reference syntax - How do I break a string in YAML over multiple lines? - Stack Overflow 「译文」如何在YAML中输入多行字符串? - 腾讯云开发者社区-腾讯云 (tencent.com)","link":"/2024/12/09/6dae87e31dc3.html"},{"title":"CKS证书学习资料汇编","text":"真题①基于1.22版本前言CKA 和 CKS 是 LINUX 基金会联合 CNCF社区组织的云原生技术领域权威认证，考试采用实操方式进行。CKS全称是Kubernetes安全专家认证，它在一个模拟真实的环境中测试考生对Kubernetes和云安全的知识。在参加CKS考试之前，必须已经通过CKA(Kubernetes管理员认证)，在获得CKA认证之后才可以预约CKS考试。CKS 的考试难度相对于 CKA 提高了很多，2个小时的考试时间很紧张，因为考试是在外网上进行，这两个考试又是实操考试，网络条件不好，很影响效率，如果不抓紧的话，很可能做不完所有实操题。提醒备考的同学善用考试软件提供的 notepad 功能，先把 yaml 文件或命令写到notepad里，再粘贴到 terminal里。 我因为上次 CKA 考试还是比较顺利，94 高分通过，所以这次的 CKS 考试有点疏忽了，搞忘带身份证和护照，CKA/CKS 考试需要身份证+护照/信用卡，因此跟监考老师沟通了很久时间，最后修改了考试人姓名为中文，是用驾驶证完成的考试。意外之喜是 CKS 给我的证书是中文名的。 我这次考试的 kubernetes 版本是 1.22，特意记录了一下考试会考到的知识点，分享给需要的同学。 1. NetworkPolicy通常使用标签选择器来选择pod，控制流量。所以要对 kubectl label的使用方法熟悉起来。 12kubectl label [--overwrite] (-f FILENAME | TYPE NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--resource-version=version] [options] 网络策略的实用方法见注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: test-network-policy namespace: defaultspec: # podSelector: {} 表示选择所有 pod 应用 NetworkPolicy podSelector: # 表示选择包含标签 role=db 的 pod 应用下面的 NetworkPolicy matchLabels: role: db policyTypes: # 表示 NetworkPolicy 包含 ingress 和 egress 流量规则 - Ingress - Egress ingress: # ingress 规则白名单列表，每条规则允许同时匹配 from 和 ports 流，可以有条个规则。 # 第1条白名单，允许以下pod访问（限 tcp 6379 端口），包含 # 1. from + ports 的组合规则，允许来自172.17网段(172.17.1除外)； # 2. 标签 project=myproject 的命名空间的所有 pod； # 3. default 命名空间下标签 role=frontend 的 pod； - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 # 第二条白名单，只包含 from 规则，允许 # 1. 来自所有命名空间包含 environment=testing 标签的 pod 访问（不限端口） - from: - namespaceSelector: {} podSelector: matchLabels: environment: testing egress: # egress 规则白名单列表，同 ingress 规则一样，每条规则包含 to+ports，可以有多条规则。 - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 2. Apparmor查看当前节点加载的 apparmor profile ，如果没有加载，要手工加载 12apparmor_status | grep nginxapparmor_parser /etc/apparmor.d/nginx_apparmor cks 考试的 apparmor profile 文件内容： 12345678#include &lt;tunables/global&gt;#nginx-profile-3 profile nginx-profile-3 flags=(attach_disconnected) { #include &lt;abstractions/base&gt; file, # Deny all file writes. deny /** w,} 注意： nginx-profile-3 这一行要确保注释掉，考试环境提供的可能没有注释，加载配置文件按时会报错 12root@node01:~# apparmor_parser /etc/apparmor.d/nginx_apparmorAppArmor parser error for /etc/apparmor.d/nginx_apparmor in /etc/apparmor.d/ninx_apparmor at line 2: Found unexpected character: '-' 修改 pod yaml 文件，在注释里设置为 podx 加载 apparmor profile 12annotations: container.apparmor.security.beta.kubernetes.io/podx: localhost/nginx-profile-3 yaml 文件内容如下： 12345678910111213141516apiVersion: v1kind: Podmetadata: name: podx annotations: container.apparmor.security.beta.kubernetes.io/podx: localhost/nginx-profile-3spec: containers: - image: busybox imagePullPolicy: IfNotPresent name: podx command: [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo 'Hello AppArmor!' &amp;&amp; sleep 1h&quot; ] resources: {} nodeName: node01 dnsPolicy: ClusterFirst restartPolicy: Always 3. 修复kube-bench发现的安全问题kube-bench 是一个 CIS 评估工具，扫描 kubernetes 集群存在的安全问题，基本上按照 扫描结果的修复建议进行修复就可以了，系统会给出很具体的修复措施。 12345678910111213141516171819202122232425262728# 修复 kube-apiserver 安全问题vi /etc/kubernetes/manifests/kube-apiserver#修改：--authorization-mode=Node,RBAC#添加--insecure-port=0#删除# --insecure-bind-address=0.0.0.0#修复 kubelet 安全问题vi /var/lib/kubelet/config.yaml# 将authentication.anonymous.enabled 设置为 falseauthentication: anonymous: enabled: false# authorization.mode 设置为 Webhookauthorization: mode: Webhook # 修复 etcd 安全问题vi /etc/kubernetes/manifests/etcd.yaml# 修改为true：- --client-cert-auth=true# 以上修复完成后 重新加载配置文件并重启kubeletsystemctl daemon-reloadsystemctl restart kubelet 4. 解决 pod 的 serviceaccount 设置错误问题这个题要注意 serviceaccount 有个选项 automountServiceAccountToken, 这个选项决定是否自动挂载 secret 到 pod。有这个选项，我们可以控制 pod 创建并绑定 serviceaccount 时，不自动挂载对应的 secret，这样 pod 就没有权限访问 apiserver，提高了业务 pod 的安全性。 可以在 serviceaccount 和 pod 的 spec 里设置，pod的设置优先于 serviceaccount 里的设置。 1234567891011121314151617apiVersion: v1kind: ServiceAccountmetadata: name: backend-sa namespace: qa automountServiceAccountToken: falseapiVersion: v1kind: Podmetadata: name: backend namespace: qaspec: serviceAccountName: backend-sa containers: - image: nginx:1.9 imagePullPolicy: IfNotPresent name: backend 删除未使用的 serviceaccount 5. 设置默认网络策略这道题是送分题，设置默认拒绝所有出站和入站的 pod 流量，基本上可以参考官网的案例直接改一下名字就可以了默认网络策略 6. RBAC这道题也基本是送分题，参考官网文档，根据题目要求，设置 role 的 资源访问权限，绑定到 serviceaccount 就可以了。RBAC 7. 日志审计这道题稍复杂，需要按照要求启动日志审计，包括两个步骤：(1) 编写日志审计策略文件日志审计策略 123456789101112131415161718192021222324apiVersion: audit.k8s.io/v1kind: PolicyomitStages: - &quot;RequestReceived&quot;rules: - level: RequestResponse resources: - group: &quot;&quot; resources: [&quot;namespaces&quot;] - level: Request resources: - group: &quot;&quot; resources: [&quot;persistentvolumes&quot;] namespaces: [&quot;front-apps&quot;] - level: Metadata resources: - group: &quot;&quot; resources: [&quot;secrets&quot;, &quot;configmaps&quot;] - level: Metadata omitStages: - &quot;RequestReceived&quot; (2) 修改 kube-apiserver.yaml配置文件，启用日志审计策略，日志策略配置文件位置、日志文件存储位置、循环周期。启动日志配置 vi /etc/kubernetes/manifests/kube-apiserver.yaml 123456789101112131415161718192021222324252627# 设置日志审计策略文件在 pod 里的 mount 位置- --audit-policy-file=/etc/kubernetes/logpolicy/sample-policy.yaml# 设置日志文件存储位置- --audit-log-path=/var/log/kubernetes/audit-logs.txt# 设置日志文件循环- --audit-log-maxage=10 - --audit-log-maxbackup=2# mount 日志策略和日志文件的volumeMounts: - mountPath: /etc/kubernetes/logpolicy/sample-policy.yaml name: audit readOnly: true - mountPath: /var/log/kubernetes/audit-logs.txt name: audit-log readOnly: falsevolumes: - name: audit hostPath: path: /etc/kubernetes/logpolicy/sample-policy.yaml type: File - name: audit-log hostPath: path: /var/log/kubernetes/audit-logs.txt type: FileOrCreate 重启 kubelet 12systemctl daemon-reloadsystemctl restart kubelet 8. 创建 secret这道题考解码 secret 的 base64 编码信息，创建新的 secret 并 mount 到 pod 的特定位置。解码 secret 12kubectl get secrets -n istio-system db1-test -o jsonpath={.data.username} | base64 -d &gt; /cks/sec/user.txtkubectl get secrets -n istio-system db1-test -o jsonpath={.data.password} | base64 -d &gt; /cks/sec/pass.txt 创建secret 1kubectl create secret generic db2-test -n istio-system --from-literal=username=production-instance --from-literal=password=KvLftKgs4aVH 使用secret 12345678910111213141516apiVersion: v1kind: Podmetadata: name: secret-pod namespace: istio-systemspec: containers: - name: dev-container image: nginx volumeMounts: - name: secret-volume mountPath: /etc/secret volumes: - name: secret: secretName: db2-test 9. 检测 dockerfile 的不安全指令这道题也是送分题，主要是把 dockerfile里两个 使用了 root 用户的指令删除，把添加特定能力的 securityContext 安全上下文注释掉。 123456# 删除两处USER root# 注释 securityContext# securityContext:# {&quot;Capabilities&quot;: {'add':{NET_BIND_SERVICE}, 'drop: []'}, 'privileged': TRUE} 10. 运行沙箱容器给出了 支持安全沙箱容器运行时 handler runsc， 我们需要创建一个 RuntimeClass 并在 pod spec里指定是用该 RuntimeClass参考资料 创建 RuntimeClass 12345apiVersion: node.k8s.io/v1beta1kind: RuntimeClassmetadata: name: untrusted handler: runsc 修改 server 命名空间 所有 pod，设置 runtimeClassName 12345678注意：运行中的 pod 只能修改有限的几个属性，不支持修改 RuntimeClass，需要将所有 pod 的 yaml 解析出来，修改 yaml 后，再重新创建 pod还需要修改deployment spec:。 runtimeClassName: untrusted containers: - image: vicuu/nginx:host imagePullPolicy: IfNotPresent name: nginx-host 11. 删除 不符合最佳实践的 pod参考链接 删除启用了特权的 pod主要是检查 pod 是否含 privileged: truekubectl get po xxx -n production -o yaml| grep -i “privileged: true” 删除有状态 podkubectl get pods XXXX -n production -o jsonpath={.spec.volumes} | jq 12. 扫描镜像安全漏洞并删除使用有安全漏洞镜像的pod这道题考察对于镜像扫描工具 trivy 的使用 12345# 获取镜像名kubect get pod XXXX -n kamino -o yaml | grep image# 扫描镜像trivy image -s HIGH,CRITICAL imagename# kubectl delete po xxx 13. 使用 sysdig 检查容器里里的异常进程本体考察是否掌握 sysdig 的基本用法，记住两个帮助命令： sysdig -h 查看 sysdig 帮助 sysdig -l 查看 sysdig 支持的元数据 另外 sysdig 支持指定 containerid 分析特定容器 123# 查看容器iddocker ps |grep tomcatsysdig -M 30 -p &quot;*%evt.time,%user.uid,%proc.name&quot; container.id=xxxx&gt;opt/DFA/incidents/summary 14. PodSecurityPolicy这道题考察是否掌握 psp 的用法，包括5步骤(1) 创建 psp参考链接 12345678910111213141516apiVersion: policy/v1beta1kind: PodSecurityPolicymetadata: name: restrict-policyspec: privileged: false seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny volumes: - '*' (2) 创建 clusterrole，使用 psp 1kubectl create clusterrole restrict-access-role --verb=use --resource=psp --resource-name=restrict-policy (3) 创建 serviceaccount 1kubectl create sa psp-denial-sa -n staging (4) 绑定 clusterrole 到 serviceaccount 1kubectl create clusterrolebinding dany-access-bind --clusterrole=restrict-access-role --serviceaccount=staging:psp-denial-sa (5) 启用 PodSecurityPolicy 123vi /etc/kubernetes/manifests/kube-apiserver.yaml #确保有以下内容：- --enable-admission-plugins=NodeRestriction,PodSecurityPolicy 15. 启用 API server认证这道题同前面 kube-bench 的考核内容有点重合，题目中是用 kubeamd创建的 kubernetes服务器权限设置有问题，允许未经授权的访问。参考链接需要进行以下修改： 使用 Node,RBAC 授权模式和 NodeRestriction 准入控制器 123456vi /etc/kubernetes/manifests/kube-apiserver.yaml# 确保以下内容- --authorization-mode=Node,RBAC- --enable-admission-plugins=NodeRestriction- --client-ca-file=/etc/kubernetes/pki/ca.crt- --enable-bootstrap-token-auth=true 删除 system:anonymous 的 ClusterRolebinding角色绑定，取消匿名用户的集群管理员权限 1kubectl delete clusterrolebinding system:anonymous 16. ImagePolicyWebhook这道题考察 ImagePolicyWebhook 准入控制器的使用，分4个步骤 修改控制器配置文件，将未找到有效后端时的默认拒绝改为默认不拒绝参考链接 vi /etc/kubernetes/epconfig/admission_configuration.json 12345678910{ &quot;imagePolicy&quot;: { &quot;kubeConfigFile&quot;: &quot;/etc/kubernetes/epconfig/kubeconfig.yaml&quot;, &quot;allowTTL&quot;: 50, &quot;denyTTL&quot;: 50, &quot;retryBackoff&quot;: 500, &quot;defaultAllow&quot;: false }} 修改 控制器访问 webhook server 的 kubeconfig 123456789101112vi /etc/kubernetes/epconfig/kubeconfig.yaml修改如下内容apiVersion: v1kind: Configclusters:- cluster: certificate-authority: /etc/kubernetes/epconfig/webhook.pem server: https://acme.local:8082/image_policy # web hook server 的地址 name: bouncer_webhook# 以下省略 启用ImagePolicyWebhookvi /etc/kubernetes/manifests/kube-apiserver.yaml 12345678910111213# 启用 ImagePolicyWebhook- --enable-admission-plugins=NodeRestriction,ImagePolicyWebhook# 指定准入控制器配置文件- --admission-control-config-file=/etc/kubernetes/epconfig/admission_configuration.json# mount volumeMounts: - mountPath: /etc/kubernetes/epconfig name: epconfig# 映射 volumes volumes: - name: epconfig hostPath: path: /etc/kubernetes/epconfig 测试是否生效 123systemctl daemon-reloadsystemctl restart kubeletkubectl apply -f /cks/img/web1.yaml From: 2022年2月我的CKS备考记录 - scwang18 - 博客园 (cnblogs.com) 真题②基于1.26版本考试内容CKS 考试链接Important Instructions: CKS 考试包括 15-20 项performance-based tasks。 2023.1 实测是16道题 考生有 2 小时的时间完成 CKS 考试。 因为从06/2022开始环境升级（贬义），考试环境更难用了，变的很卡，所以时间变得比较紧张。容易做不完题，建议先把有把握的，花费时间不多的题先做掉 CKS CKA CKAD changed Terminal to Remote Desktop CKS考试67分以上即可通过，考试不通过有一次补考机会。 Certifications- expire 36 months from the date that the Program certification requirements are met by a candidate. Certified Kubernetes Security Specialist (CKS)The following tools and resources are allowed during the exam as long as they are used by candidates to work independently on exam tasks (i.e. not used for 3rd party assistance or research) and are accessed from within the Linux server terminal on which the Exam is delivered.During the exam, candidates may: review the Exam content instructions that are presented in the command line terminal. review Documents installed by the distribution (i.e. /usr/share and its subdirectories) use the search function provided on https://kubernetes.io/docs/ however, they may only open search results that have a domain matching the sites listed below use the browser within the VM to access the following documentation: Kubernetes Documentation: https://kubernetes.io/docs/ and their subdomains https://kubernetes.io/blog/ and their subdomainsThis includes all available language translations of these pages (e.g. https://kubernetes.io/zh/docs/) Tools: Trivy documentation https://aquasecurity.github.io/trivy/ Falco documentation https://falco.org/docs/This includes all available language translations of these pages (e.g. https://falco.org/zh/docs/) App Armor: Documentation https://gitlab.com/apparmor/apparmor/-/wikis/Documentation You’re only allowed to have one other browser tab open with: https://kubernetes.io/docs https://github.com/kubernetes https://kubernetes.io/blog https://github.com/aquasecurity/trivy https://falco.org/docs https://gitlab.com/apparmor/apparmor/-/wikis/Documentation CKS Environment Each task on this exam must be completed on a designated cluster/configuration context. Sixteen clusters comprise the exam environment, one for each task. Each cluster is made up of one master node and one worker node. An infobox at the start of each task provides you with the cluster name/context and the hostname of the master and worker node. You can switch the cluster/configuration context using a command such as the following: kubectl config use-context &lt;cluster/context name&gt; Nodes making up each cluster can be reached via ssh, using a command such as the following: ssh &lt;nodename&gt; You have elevated privileges on any node by default, so there is no need to assume elevated privileges. You must return to the base node (hostname cli) after completing each task. Nested −ssh is not supported. You can use kubectl and the appropriate context to work on any cluster from the base node. When connected to a cluster member via ssh, you will only be able to work on that particular cluster via kubectl. For your convenience, all environments, in other words, the base system and the cluster nodes, have the following additional command-line tools pre-installed and pre-configured: kubectl with kalias and Bash autocompletion yq and jq for YAML/JSON processing tmux for terminal multiplexing curl and wget for testing web services man and man pages for further documentation Further instructions for connecting to cluster nodes will be provided in the appropriate tasks The CKS environment is currently running etcd v3.5 The CKS environment is currently running Kubernetes v1.26 The CKS exam environment will be aligned with the most recent K8s minor version within approximately 4 to 8 weeks of the K8s release date. More items for CKS than CKA and CKAD Pod Security Policies(PSP) - removed from Kubernetes in v1.25 AppArmor Apiserver Apiserver Crash Apiserver NodeRestriction ImagePolicyWebhook kube-bench Trivy CKS 知识点&amp;练习题总结如何备考k8s练习环境(同CKA)CKS练习题有几个练习库，建议将每个题目都自己亲自操作一遍，一定要操作。 CKS在线练习环境：https://killercoda.com/killer-shell-cks CKS Simulator Kubernetes 1.26 Adminission pligin/Pod Security Policies 练习 CKS课程 【需付费】CKS考试-对应官方课程Kubernetes for Developers (LFS260) 感觉没必要买，只看官方文档就足够了。 常用命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 不熟## 输出pod statuskubectl -n default describe pod pod1 | grep -i status:kubectl -n default get pod pod1 -o jsonpath=&quot;{.status.phase}&quot;## Check the pod for errorkubectl describe pod podname | grep -i error... Error: ImagePullBackOff## a fast way to get an overview of the ReplicaSets of a Deployment and their images could be done with:kubectl -n neptune get rs -o wide | grep deploynameNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTORdeployname 3 3 3 9m6s httpd httpd:alpine app=wonderful## 创建jobkubectl -n neptune create job neb-new-job --image=busybox:1.31.0 $do &gt; /opt/course/3/job.yaml -- sh -c &quot;sleep 2 &amp;&amp; echo done&quot;## If a Secret bolongs to a serviceaccount, it'll have the annotation kubernetes.io/service-account.namekubectl get secrets -oyaml | grep annotations -A 1 # shows secrets with first annotation## logkubectl logs podname &gt; /opt/test.log## decode base64base64 -d filename## check service connection using a temporary Pod## k run tmp --restart=Never --rm --image=nginx:alpine -i -- curl http://svcname.namespace:svcportkubectl run tmp --restart=Never --rm --image=nginx:alpine -i -- curl http://svcname.namespace:80## check that both PV and PVC have the status Bound:k -n earth get pv,pvcNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpersistentvolume/earth-project-earthflower-pv 2Gi RWO Retain Bound earth/earth-project-earthflower-pvc 8m4sNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEpersistentvolumeclaim/earth-project-earthflower-pvc Bound earth-project-earthflower-pv 2Gi RWO 7m38s## We can confirm the pod of deployment with PVC mounting correctly:k describe pod project-earthflower-586758cc49-hb87f -n earth | grep -A2 Mount: Mounts: /tmp/project-data from task-pv-storage (rw) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jj2t2 (ro)## Verify everything using kubectl auth can-ikubectl auth can-i create deployments --as system:serviceaccount:app-team1:cicd-token -n app-team1 # YES# 常用## 创建podkubectl run pod1 --image=httpd:2.4.41-alpine $do &gt; 2.yamlkubectl get pod sat-003 -o yaml &gt; 7-sat-003.yaml # exportkubectl delete pod pod1 --force --grace-period=0## 创建servicekubectl expose deployment d1 --name=服务名 --port=服务端口 --target-port=pod运行端口 --type=类型kubectl expose pod pod名 --name=服务名 --port=服务端口 --target-port=pod运行端口 --type=类型# CKS## 创建secretkubectl create secret generic db-credentials --from-literal db-password=passwd## modify a pod yaml to deployment yaml### put the Pod's metadata: and spec: into the Deployment's template: section:## To verify that the token hasn't been mounted run the following commands:kubectl -n one exec -it pod-name -- mount | grep serviceaccountkubectl -n one exec -it pod-name -- cat /var/run/secrets/kubernetes.io/serviceaccount/token### 创建 clusterrole，使用 pspkubectl create clusterrole restrict-access-role --verb=use --resource=psp --resource-name=restrict-policy## after modify /etc/kubernetes/manifests/kube-apiserver.yamlsystemctl restart kubelet### 查询 sa 对应的 role 名称（假设是 role-1）kubectl get rolebinding -n db -oyaml | grep 'service-account-web' -B 10### grepgrep apple -A 10 # apple之后10行grep apple -B 10 # apple之前10行### secret used by podkubectl exec pod1 -- envkubectl exec pod1 -- cat /etc/diver/hosts 经验总结(同CKA) Pre Setup(同CKA) CKS 2023 真题 1.26考题1 - AppArmor 访问控制ContextAppArmor is enabled on the cluster’s worker node. An AppArmor profile is prepared, but not enforced yet.You may use your browser to open one additional tab to access the AppArmor documentation. AppArmor 已在 cluster 的工作节点上被启用。一个 AppArmor 配置文件已存在，但尚未被实施。 TaskOn the cluster’s worker node, enforce the prepared AppArmor profile located at /etc/apparmor.d/nginx_apparmor .Edit the prepared manifest file located at /home/candidate/KSSH00401/nginx-deploy.yaml to apply the AppArmor profile.Finally, apply the manifest file and create the pod specified in it. 在 cluster 的工作节点上，实施位于 /etc/apparmor.d/nginx_apparmor 的现有 AppArmor 配置文件。编辑位于 /home/candidate/KSSH00401/nginx-deploy.yaml 的现有清单文件以应用 AppArmor 配置文件。最后，应用清单文件并创建其中指定的 Pod 。 Solution搜索 apparmor（使用 AppArmor 限制容器对资源的访问），接着再搜索字符串 “parser”https://kubernetes.io/zh/docs/tutorials/security/apparmor/ 12345678910111213141516171819202122232425### 远程登录到指定工作节点ssh cka-node01### 从profile文件查看策略名称cat /etc/apparmor.d/nginx_apparmor profile nginx-profile flags=(attach_disconnected) { ...### 加载 apparmor 配置文件apparmor_parser /etc/apparmor.d/nginx_apparmor### 查看策略名称，结果是 nginx-profileapparmor_status | grep nginx-profile### 回到控制节点，并更新 Pod 的注解exitvim /home/candidate/KSSH00401/nginx-deploy.yaml annotations: ### hello 是 Pod 里容器名称，nginx-profile 则是 apparmor_status 解析出来的结果 container.apparmor.security.beta.kubernetes.io/hello: localhost/nginx-profile### 如果 apply 后报错，则先删除保存并删除旧 Pod，改完后再创建新的kubectl apply -f /home/candidate/KSSH00401/nginx-deploy.yaml 考题2 - Kube-Bench 基准测试ContextA CIS Benchmark tool was run against the kubeadm-created cluster and found multiple issues that must be addressed immediately. 针对 kubeadm 创建的 cluster 运行 CIS 基准测试工具时， 发现了多个必须立即解决的问题。 TaskFix all issues via configuration and restart theaffected components to ensure the new settings take effect.通过配置修复所有问题并重新启动受影响的组件以确保新的设置生效。 Fix all of the following violations that were found against the API server:修复针对 API 服务器发现的所有以下违规行为：Ensure that the 1.2.7 –authorization-mode FAIL argument is not set to AlwaysAllowEnsure that the 1.2.8 –authorization-mode FAIL argument includes NodeEnsure that the 1.2.9 –authorization-mode FAIL argument includes RBACEnsure that the 1.2.18 –insecure-bind-address FAIL argument is not setEnsure that the 1.2.19 –insecure-port FAIL argument is set to 0 Fix all of the following violations that were found against the kubelet:修复针对 kubelet 发现的所有以下违规行为：Ensure that the 4.2.1 –anonymous-auth FAIL argument is set to falseEnsure that the 4.2.2 –authorization-mode FAIL argument is not set to AlwaysAllowUse Webhook authn/authz where possible. 注意：尽可能使用 Webhook authn/authz。 Fix all of the following violations that were found against etcd:修复针对 etcd 发现的所有以下违规行为：Ensure that the 4.2.1 –client-cert-auth FAIL argument is set to true Solution123456789101112131415161718192021222324252627282930313233343536373839$ ssh root@vms65.rhce.cc# kube-bench run --target=master --check=1.2.7kube-bench run --target=master | grep FAIL### 修复针对 APIserver 发现的以下所有问题：### 确保 1.2.7 --authorization-mode 参数不能设置为 AlwaysAllow### 确保 1.2.8 --authorization-mode 参数包含 Node### 确保 1.2.9 --authorization-mode 参数包含 RBAC### 确保 1.2.18 --insecure-bind-address 参数不能设置### 确保 1.2.19 --insecure-port 参数设置为 0### 注意：修改 master 节点！vim /etc/kubernetes/manifests/kube-apiserver.yaml #- --authorization-mode=AlwaysAllow 删除AlwaysAllow，加Node,RBAC - --authorization-mode=Node,RBAC #- --insecure-bind-address=0.0.0.0 - --insecure-port=0### 修复针对 kubelet 发现的以下所有问题：### 确保 4.2.1 anonymous-auth 参数设置为 false### 确保 4.2.2 --authorization-mode 参数不能设置为 AlwaysAllow，尽可能使用 Webhook authn/authz### 注意：master 和 node 节点都要修改！vim /var/lib/kubelet/config.yaml authentication: anonymous: enabled: false authorization: mode: Webhook### 修复针对 etcd 发现的以下所有问题：### 确保 4.2.--client-cert-auth 参数设置为 true### 注意：修改 master 节点！vim /etc/kubernetes/manifests/etcd.yaml - --client-cert-auth=true### 加载并重启 kubelet 服务### 注意：master 和 node 节点都要重启！systemctl daemon-reloadsystemctl restart kubelet 考题3 - Trivy 镜像扫描Task使用 Trivy 开源容器扫描器检测 namespace kamino 中 Pod 使用的具有严重漏洞的镜像。查找具有 High 或 Critical 严重性漏洞的镜像，并删除使用这些镜像的 Pod。注意：Trivy 仅安装在 cluster 的 master 节点上，在工作节点上不可使用。你必须切换到 cluster 的 master 节点才能使用 Trivy 。 Use the Trivy open-source container scanner to detect images with severe vulnerabilities used by Pods in the namespace kamino.Look for images with High or Critical severity vulnerabilities, and delete the Pods that use those images. Trivy is pre-installed on the cluster’s master node only; it is not available on the base system or the worker nodes. You’ll have to connect to the cluster’s master node to use Trivy. Solution搜索 kubectl images（列出集群中所有运行容器的镜像）https://kubernetes.io/zh-cn/docs/tasks/access-application-cluster/list-all-running-container-images/ 123456789101112131415### 需登录到控制节点操作ssh cka-master01### 查询命名空间 kamino 中 pod 使用的镜像kubectl get pod -n kamino -o yaml | grep image:# 或者kubectl get pods -n kamino -o jsonpath='{range .items[*]}{&quot;\\n&quot;}{.metadata.name}{&quot;:\\t&quot;}{range .spec.containers[*]}{.image}{&quot;, &quot;}{end}{end}' | sort### 假设镜像是 registry.aliyuncs.com/google_containers/coredns:1.7.0### 使用 trivy 工具查询具有 HIGH 或 CRITICAL 漏洞的镜像trivy --helptrivy image --severity HIGH,CRITICAL 'registry.aliyuncs.com/google_containers/coredns:1.7.0'### 删除检测到的漏洞镜像对应的 pod（如果有控制器，得删除控制器）kubectl delete pod -n kamino pod名称 考题4 - Sysdig &amp; Falcoyou may use you brower to open one additonal tab to access sysdig’s documentation or Falco’s documentaion TaskUse runtime detection tools to detect anomalous processes spawning and executing frequently in the sigle container belonging to Pod redis. Two tools are avaliable to use:使用运行时检测工具来检测 Pod tomcat 单个容器中频发生成和执行的异常进程。有两种工具可供使用： sysdig falco The tools are pre-installed on the cluster’s worker node only, they are not avaliable on the base system or the master node.Using the tool of you choice (including any non pre-install tool) analyse the container’s behavior for at least 30 seconds, using filers that detect newly spawing and executing processes, store an incident file at /opt/KSR00101/incidents/summary, containing the detected incidents one per line in the follwing format:注：这些工具只预装在 cluster 的工作节点，不在 master 节点。使用工具至少分析 30 秒，使用过滤器检查生成和执行的进程，将事件写到 /opt/KSR00101/incidents/summary 文件中，其中包含检测的事件, 每个单独一行格式如下： 1[timestamp],[uid],[processName] 保持工具的原始时间戳格式不变。注：确保事件文件存储在集群的工作节点上。 12345678910111213141516171819202122232425262728293031323334353637383940414243# 方法一 sysdig### 需登录到工作节点操作ssh cka-node01### 查看 sysdig 帮助sysdig -h### 查看 sysdig 支持的元数据sysdig -l### 查看指定容器IDcrictl ps | grep redis### -M 分析容器30秒，-p 指定事件保存格式，--cri 指定容器运行时，并且保存到指定文件路径中sysdig -M 30 -p &quot;*%evt.time,%user.uid,%proc.name&quot; --cri /run/containerd/containerd.sock container.id=xxxxx &gt; /opt/KSR00101/incidents/summary# 方法二 falco### 需登录到工作节点操作ssh cka-node01### cd /etc/falcols### vim /etc/falco/falco_rules.yaml# Container is supposed to be immutable. Package management should be done in building the image.- rule: Launch Package Management Process in Container desc: Package management process ran inside container condition: &gt; spawned_process and container and user.name != &quot;_apt&quot; and package_mgmt_procs and not package_mgmt_ancestor_procs and not user_known_package_manager_in_container output: &gt; Package management process launched in container %evt.time,%user.uid,%proc.name### 查看指定容器IDcat /var/log/sysdig | grep falco | grep &quot;Package management&quot; -i# vim /opt/KSR00101/incidents/summary 考题5 - ServiceAccountContextA Pod fails to run because of an incorrectly specified ServiceAcccount. Taskcreate a new ServiceAccount named backend-sa in the existing namespace qa, which must not have access to any secrets. Inspect the Pods in the namespace 1qa . Edit the Pod to use the newly created serviceAccount backend-sa. Ensure that the modified specification is applied and the Pod is running. Finally, clean-up and delete the now unused serviceAccount in the namespace qa.在现有 namespace qa 中创建一个名为 backend-sa 的新 ServiceAccount， 确保此 ServiceAccount 不自动挂载secrets。使用 /cks/9/pod9.yaml 中的清单文件来创建一个 Pod。最后，清理 namespace qa 中任何未使用的 ServiceAccount。 Solution搜索 serviceaccount（为Pod配置服务账号），接着再搜索字符串 “automount”https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-service-account/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445### 创建 ServiceAccountkubectl apply -f - &lt;&lt;EOFapiVersion: v1kind: ServiceAccountmetadata: name: backend-sa namespace: qaautomountServiceAccountToken: falseEOF### k get pods -n qa web1-xxx1 web2-xwx2 web3-xwx3k get deployment -n qa web1 web2 web3# 发现这些pod都属于deployment### 编辑 Pod 使用新创建的 serviceaccountk edit deployment/web1 -n qak edit deployment/web2 -n qak edit deployment/web3 -n qa...template: spec: serviceAccountName: backend-sa # add...### 应用清单文件kubectl apply -f /cks/9/pod9.yaml### 把除了 backend-sa, 并且没有被使用的 serviceaccount 都删除kubectl get serviceaccount -n qa backend-sa default contentsakubectl get rolebinding -n qa -o widekubectl get clustorrolebinding -n qa -o widekubectl delete -n qa serviceaccount contentsa 考题6 - 2022真题v1.20 Pod 安全策略-PodSecurityPolicy2023的最新考试已经没有这道题了，替代的是Pod Security Standard Context6A PodsecurityPolicy shall prevent the creation on of privileged Pods in a specific namespace.PodSecurityPolicy 应防止在特定 namespace 中特权 Pod 的创建。 Task6Create a new PodSecurityPolicy named restrict-policy, which prevents the creation of privileged Pods. Create a new ClusterRole named restrict-access-role, which uses the newly created PodSecurityPolicy restrict-policy.Create a new serviceAccount named psp-denial-sa in the existing namespace staging. Finally, create a new clusterRoleBinding named dany-access-bind, which binds the newly created ClusterRole restrict-access-role to the newly created serviceAccount psp-denial-sa. 创建一个名为 restrict-policy 的新的 PodSecurityPolicy，以防止特权 Pod 的创建。创建一个名为 restrict-access-role 并使用新创建的 PodSecurityPolicy restrict-policy 的 ClusterRole。在现有的 namespace staging 中创建一个名为 psp-denial-sa 的新 ServiceAccount 。最后，创建一个名为 dany-access-bind 的 ClusterRoleBinding，将新创建的 ClusterRole restrict-access-role 绑定到新创建的 ServiceAccount psp-denial-sa。你可以在一下位置找到模版清单文件： /cks/psp/psp.yaml Solution6搜索 runasany（Pod Security Policy）https://kubernetes.io/id/docs/concepts/policy/pod-security-policy/搜索 clusterrole（使用RBAC鉴权）https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/rbac/ 1234567891011121314151617181920212223242526272829303132333435### (1)创建 pspvim /cks/psp/psp.yamlapiVersion: policy/v1beta1kind: PodSecurityPolicymetadata: name: restrict-policyspec: privileged: false seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny volumes: - '*'kubectl apply -f /cks/psp/psp.yaml### (2)创建 clusterrole，使用 pspkubectl create clusterrole restrict-access-role --verb=use --resource=psp --resource-name=restrict-policy### (3)创建 serviceaccountkubectl create serviceaccount psp-denial-sa -n staging ### (4)创建 clusterrolebindingkubectl create clusterrolebinding dany-access-bind --clusterrole=restrict-access-role --serviceaccount=staging:psp-denial-sa### (5)启用 PodSecurityPolicy（在控制节点上修改 apiserver 配置）vim /etc/kubernetes/manifests/kube-apiserver.yaml - --enable-admission-plugins=NodeRestriction,PodSecurityPolicysystemctl restart kubelet 考题6 - 2023真题V1.26 Pod Security StandardTask weight: 8%Use context: kubectl config use-context workload-prod There is Deployment container-host-hacker in Namespace team-red which mounts /run/containerd as a hostPath volume on the Node where it’s running. This means that the Pod can access various data about other containers running on the same Node. To prevent this configure Namespace team-red to enforce the baseline Pod Security Standard. Once completed, delete the Pod of the Deployment mentioned above. Check the ReplicaSet events and write the event/log lines containing the reason why the Pod isn’t recreated into /opt/course/4/logs. AnswerMaking Namespaces use Pod Security Standards works via labels. We can simply edit it: 1k edit ns team-red Now we configure the requested label: 123456789# kubectl edit namespace team-redapiVersion: v1kind: Namespacemetadata: labels: kubernetes.io/metadata.name: team-red pod-security.kubernetes.io/enforce: baseline # add name: team-red... This should already be enough for the default Pod Security Admission Controller to pick up on that change. Let’s test it and delete the Pod to see if it’ll be recreated or fails, it should fail! 123456789➜ k -n team-red get podNAME READY STATUS RESTARTS AGEcontainer-host-hacker-dbf989777-wm8fc 1/1 Running 0 115s➜ k -n team-red delete pod container-host-hacker-dbf989777-wm8fc pod &quot;container-host-hacker-dbf989777-wm8fc&quot; deleted➜ k -n team-red get podNo resources found in team-red namespace. Usually the ReplicaSet of a Deployment would recreate the Pod if deleted, here we see this doesn’t happen. Let’s check why: 1234567891011121314➜ k -n team-red get rsNAME DESIRED CURRENT READY AGEcontainer-host-hacker-dbf989777 1 0 0 5m25s➜ k -n team-red describe rs container-host-hacker-dbf989777Name: container-host-hacker-dbf989777Namespace: team-red...Events: Type Reason Age From Message ---- ------ ---- ---- -------... Warning FailedCreate 2m41s replicaset-controller Error creating: pods &quot;container-host-hacker-dbf989777-bjwgv&quot; is forbidden: violates PodSecurity &quot;baseline:latest&quot;: hostPath volumes (volume &quot;containerdata&quot;) Warning FailedCreate 2m2s (x9 over 2m40s) replicaset-controller (combined from similar events): Error creating: pods &quot;container-host-hacker-dbf989777-kjfpn&quot; is forbidden: violates PodSecurity &quot;baseline:latest&quot;: hostPath volumes (volume &quot;containerdata&quot;) There we go! Finally we write the reason into the requested file so that Mr Scoring will be happy too! 12# /opt/course/4/logsWarning FailedCreate 2m2s (x9 over 2m40s) replicaset-controller (combined from similar events): Error creating: pods &quot;container-host-hacker-dbf989777-kjfpn&quot; is forbidden: violates PodSecurity &quot;baseline:latest&quot;: hostPath volumes (volume &quot;containerdata&quot;) Pod Security Standards can give a great base level of security! But when one finds themselves wanting to deeper adjust the levels like baseline or restricted… this isn’t possible and 3rd party solutions like OPA could be looked at. 考题7 - NetworkPolicy - default-denyContextA default-deny NetworkPolicy avoids to accidentally expose a Pod in a namespace that doesn’t have any other NetworkPolicy defined.一个默认拒绝（default-deny）的 NetworkPolicy 可避免在未定义任何其他 NetworkPolicy 的 namespace 中意外公开 Pod。 TaskCreate a new default-deny NetworkPolicy named denynetwork in the namespace development for all traffic of type Ingress.The new NetworkPolicy must deny all ingress traffic in the namespace development. Apply the newly created default-deny NetworkPolicy to all Pods running in namespace development.You can find a skeleton manifest file at /cks/15/p1.yaml 为所有类型为 Ingress+Egress 的流量在 namespace testing 中创建一个名为 denynetwork 的新默认拒绝 NetworkPolicy。 此新的 NetworkPolicy 必须拒绝 namespace testng 中的所有的 Ingress + Egress 流量。将新创建的默认拒绝 NetworkPolicy 应用与在 namespace testing 中运行的所有 Pod。你可以在 /cks/15/p1.yaml 找到一个模板清单文件。 1234567891011121314### 修改模板清单文件vim /cks/15/p1.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: denynetwork namespace: testingspec: podSelector: {} policyTypes: - Ingress### 应用清单文件kubectl apply -f /cks/15/p1.yaml 考题8 - NetworkPolicyTaskcreate a NetworkPolicy named pod-restriction to restrict access to Pod products-service running in namespace dev-team.Only allow the following Pods to connect to Pod products-service: Pods in the namespace qa Pods with label environment: testing, in any namespace Make sure to apply the NetworkPolicy.You can find a skelet on manifest file at /cks/6/p1.yaml 创建一个名为 pod-restriction 的 NetworkPolicy 来限制对在 namespace dev-team 中运行的 Pod products-service 的访问。只允许以下 Pod 连接到 Pod products-service： namespace qa 中的 Pod 位于任何 namespace，带有标签 environment: testing 的 Pod 注意：确保应用 NetworkPolicy。你可以在/cks/net/po.yaml 找到一个模板清单文件。 Solution搜索 networkpolicy（网络策略）https://kubernetes.io/zh-cn/docs/concepts/services-networking/network-policies/ 123456789101112131415161718192021222324252627282930### (1)查看命名空间 qa 具有的标签kubectl get namespace qa --show-labels### (2)查看 pod 具有的标签kubectl get pod products-service -n dev-team --show-labels### 修改模板清单文件vim /cks/net/po.yamlapiVersion: networking.k8s.io/v1kind: NetworkPolicymetadata: name: pod-restriction # name namespace: dev-team # namespacespec: podSelector: matchLabels: run: products-service # (2) policyTypes: - Ingress ingress: - from: - namespaceSelector: matchLabels: name: qa # (1) - podSelector: # 注意带 - ，表示或的关系 matchLabels: environment: testing namespaceSelector: {} ## 任何命名空间, 不带 - ，且的关系### 应用清单文件kubectl apply -f /cks/net/po.yaml 考题9 - RBACContext绑定到 Pod 的 ServiceAccount 的 Role 授予过度宽松的权限。完成以下项目以减少权限集。A Role bound to a Pod’s serviceAccount grants overly permissive permissions.Complete the following tasks to reduce the set of permissions. Task一个名为 web-pod 的现有 Pod 已在 namespace db 中运行。编辑绑定到 Pod 的 ServiceAccount service-account-web 的现有 Role， 仅允许只对 services 类型的资源执行 get 操作。 在 namespace db 中创建一个名为 role-2 ，并仅允许只对 namespaces 类型的资源执行 delete 操作的新 Role。 创建一个名为 role-2-binding 的新 RoleBinding，将新创建的 Role 绑定到 Pod 的 ServiceAccount。注意：请勿删除现有的 RoleBinding。 Given an existing Pod named web-pod running in the namespace db. Edit the existing Role bound to the Pod’s serviceAccount sa-dev-1 to only allow performing list operations, only on resources of type Endpoints. create a new Role named role-2 in the namespace db, which only allows performing update operations, only on resources of type persistentvolumeclaims create a new RoleBinding named role-2-binding binding the newly created Role to the Pod’s serviceAccount. Don’t delete the existing RoleBinding solution搜索 clusterrole（使用RBAC鉴权）https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/rbac/ 12345678910111213141516171819202122232425### 查询 sa 对应的 role 名称（假设是 role-1）kubectl get rolebinding -n db -oyaml | grep 'service-account-web' -B 10### 修改 role 清单文件（仅允许对 services 类型的资源执行 get 操作）kubectl edit role -n db role-1apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: role-1 namespace: db resourceVersion: &quot;9528&quot;rules:- apiGroups: - &quot;&quot; resources: - services verbs: - get### 创建新角色 role-2（仅允许只对 namespaces 类型的资源执行 delete 操作）kubectl create role role-2 -n db --verb=delete --resource=namespaces### 创建 rolebinding，并绑定到 sa 上kubectl create rolebinding role-2-binding --role=role-2 --serviceaccount=db:service-account-web 考题10 - kube-apiserver 审计日志记录和采集TaskEnable audit logs in the cluster.To do so, enable the log backend, and ensure that: logs are stored at /var/log/kubernetes/audit-logs.txt log files are retained for 10 days at maximum, a number of 2 auditlog files are retainedA basic policy is provided at /etc/kubernetes/logpolicy/sample-policy.yaml. it only specifies what not to log. The base policy is located on the cluster’s master node. Edit and extend the basic policy to log: namespaces changes at RequestResponse level the request body of pods changes in the namespace front-apps configMap and secret changes in all namespaces at the Metadata level Also, add a catch-all ruie to log all other requests at the Metadata level. Don’t forget to apply the modifiedpolicy./etc/kubernetes/logpolicy/sample-policy.yaml 在 cluster 中启用审计日志。为此，请启用日志后端，并确保： 日志存储在 /var/log/kubernetes/audit-logs.txt 日志文件能保留 10 天 最多保留 2 个旧审计日志文件/etc/kubernetes/logpolicy/sample-policy.yaml 提供了基本策略。它仅指定不记录的内容。注意：基本策略位于 cluster 的 master 节点上。 编辑和扩展基本策略以记录： RequestResponse 级别的 cronjobs 更改 namespace front-apps 中 deployment 更改的请求体 Metadata 级别的所有 namespace 中的 ConfigMap 和 Secret 的更改 此外，添加一个全方位的规则以在 Metadata 级别记录所有其他请求。注意：不要忘记应用修改后的策略 Solution搜索 audit（审计）https://kubernetes.io/zh-cn/docs/tasks/debug/debug-cluster/audit/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253### 如果没有 /var/log/kubernetes/，则创建目录mkdir /var/log/kubernetes/### 修改 audit 模板文件vim /etc/kubernetes/logpolicy/sample-policy.yamlapiVersion: audit.k8s.io/v1kind: PolicyomitStages: - &quot;RequestReceived&quot;rules: - level: RequestResponse resources: - group: &quot;&quot; resources: [&quot;cronjobs&quot;] - level: Request resources: - group: &quot;&quot; resources: [&quot;deployments&quot;] namespaces: [&quot;front-apps&quot;] - level: Metadata resources: - group: &quot;&quot; resources: [&quot;secrets&quot;, &quot;configmaps&quot;] - level: Metadata omitStages: - &quot;RequestReceived&quot;### 修改 apiserver 配置文件，启用审计日志vim /etc/kubernetes/manifests/kube-apiserver.yaml--audit-policy-file=/etc/kubernetes/logpolicy/sample-policy.yaml--audit-log-path=/var/log/kubernetes/audit-logs.txt--audit-log-maxage=10--audit-log-maxbackup=2### 在 apiserver 的 Pod 上挂载策略文件和日志文件所在的目录（考试时可能已经挂载好）vim /etc/kubernetes/manifests/kube-apiserver.yamlvolumeMounts: - mountPath: /var/log/kubernetes name: kubernetes-logs - mountPath: /etc/kubernetes/logpolicy name: kubernetes-policyvolumes:- name: kubernetes-logs hostPath: path: /var/log/kubernetes- name: kubernetes-policy hostPath: path: /etc/kubernetes/logpolicy### 重载生效配置systemctl daemon-reloadsystemctl restart kubelet 考题11 - SecretTaskRetrieve the content of the existing secret named db1-test in the istio-system namespace.store the username field in a file named /home/candidate/user.txt, and the password field in a file named /home/candidate/pass.txt. You must create both files; they don’t exist yet.Do not use/modify the created files in the following steps, create new temporary files if needed. Create a new secret named db2-test in the istio-system namespace, with the following 12username : production-instancepassword : KvLftKgs4aVH Finally, create a new Pod that has access to the secret db2-test via a volume: Pod name secret-pod Namespace istio-system container name dev-container image nginx volume name secret-volume mount path /etc/secret 在 namespace istio-system 中获取名为 db1-test 的现有 secret 的内容.将 username 字段存储在名为 /cks/sec/user.txt 的文件中，并将 password 字段存储在名为 /cks/sec/pass.txt 的文件中。 注意：你必须创建以上两个文件，他们还不存在。注意：不要在以下步骤中使用/修改先前创建的文件，如果需要，可以创建新的临时文件。 在 istio-system namespace 中创建一个名为 db2-test 的新 secret，内容如下： 12username : production-instancepassword : KvLftKgs4aVH 最后，创建一个新的 Pod，它可以通过卷访问 secret db2-test ： Pod 名称 secret-pod Namespace istio-system 容器名 dev-container 镜像 nginx 卷名 secret-volume 挂载路径 /etc/secret Solution搜索 secret（使用 kubectl 管理 Secret）https://kubernetes.io/zh-cn/docs/tasks/configmap-secret/managing-secret-using-kubectl/搜索 secret（Secret）https://kubernetes.io/zh-cn/docs/concepts/configuration/secret/ 1234567891011121314151617181920212223242526272829303132333435### 检索已存在的 secret，将获取到的用户名和密码字段存储到指定文件kubectl get secrets db2-test -o jsonpath='{.data.username}' | base64 -d &gt; /home/candidate/user.txtkubectl get secrets db2-test -o jsonpath='{.data.password}' | base64 -d &gt; /home/candidate/pass.txt### 创建 secretkubectl -n istio-system create secret generic db2-test --from-literal=username=production-instance --from-literal=password=KvLftKgs4aVH # kubectl create secret generic db2-test -n istio-system --from-literal username=production-instance --from-literal password=KvLftKgs4aVH# error: exactly one NAME is required, got 2### 在 Pod 中以文件形式使用 Secretvim k8s-secret.yamlapiVersion: v1kind: Podmetadata: name: secret-pod namespace: istio-systemspec: containers: - name: dev-container image: nginx volumeMounts: - name: secret-volume mountPath: &quot;/etc/secret&quot; readOnly: true volumes: - name: secret-volume secret: secretName: db2-test optional: false### 应用清单文件kubectl apply -f k8s-secret.yaml### 验证 podkubectl get pods -n istio-system dev-pod 考题12 - dockerfile 和 deployment 安全优化Task Analyze and edit the given Dockerfile (based on the ubuntu:16.04 image) /cks/docker/Dockerfile fixing two instructions present in the file being prominent security/best-practice issues. Analyze and edit the given manifest file /cks/docker/deployment.yaml fixing two fields present in the file being prominent security/best-practice issues. Don’t add or remove configuration settings; only modify the existing configuration settings, so that two configuration settings each are no longer security/best-practice concerns. Should you need an unprivileged user for any of the tasks, use user nobody with user id 65535. 分析和编辑给定的 Dockerfile /cks/docker/Dockerfile（基于 ubuntu:16.04 镜像），并修复在文件中拥有的突出的安全/最佳实践问题的两个指令。 分析和编辑给定的清单文件 /cks/docker/deployment.yaml，并修复在文件中拥有突出的安全/最佳实践问题的两个字段。 注意：请勿添加或删除配置设置；只需修改现有的配置设置让以上两个配置设置都不再有安全/最佳实践问题。注意：如果您需要非特权用户来执行任何项目，请使用用户 ID 65535 的用户 nobody 。答题： 注意，本次的 Dockerfile 和 deployment.yaml 仅修改即可，无需部署。 Solution 121234567891011121314151617181920212223242526272829303132### 修复 dockerfile 文件中存在的两个安全/最佳实践指令### (1)把ubuntu:latest改为ubuntu:16.04 (2)将 root 注释掉；增加 nobodyvim /cks/docker/Dockerfile# FROM ubuntu:latest 1 修改FROM ubuntu:16.04#USER root USER nobody # 2### 修复 deployment 文件中存在的两个安全/最佳实践问题字段### (1)将 privileged 变为 False；(2)将 readOnlyRootFilesystem 变为 True 3 check runAsUser 65535vim /cks/docker/deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: labels: app: dev name: devspec: replicas: 1 selector: matchLabels: app: dev template: metadata: labels: app: dev spec: containers: - image: mysql name: mysql securityContext: {'capabilities':{'add':['NET_ADMIN'],'drop':['all']},'privileged': False,'readOnlyRootFilesystem': True, 'runAsUser': 65535} 考题13 - admission-controllers - ImagePolicyWebhookContextA container image scanner is set up on the cluster, but it’s not yet fully integrated into the cluster’s configuration. When complete, the container image scanner shall scan for and reject the use of vulnerable images. cluster 上设置了容器镜像扫描器，但尚未完全集成到 cluster 的配置中。完成后，容器镜像扫描器应扫描并拒绝易受攻击的镜像的使用。 TaskYou have to complete the entire task on the cluster’s master node, where all services and files have been prepared and placed.Given an incomplete configuration in directory /etc/kubernetes/epconfig and a functional container image scanner with HTTPS endpoint https://acme.local:8082/image_policy: Enable the necessary plugins to create an image policy validate the control configuration and change it to an implicit deny Edit the configuration to point to the provided HTTPS endpoint correctly. Finally , test if the configuration is working by trying to deploy the vulnerable resource /cks/1/web1.yaml You can find the container image scanner’s log file at /var/loglimagepolicyiacme.log 注意：你必须在 cluster 的 master 节点上完成整个考题，所有服务和文件都已被准备好并放置在该节点上。 给定一个目录 /etc/kubernetes/epconfig 中不完整的配置以及具有 HTTPS 端点 https://acme.local:8082/image_policy 的功能性容器镜像扫描器： 启用必要的插件来创建镜像策略 校验控制配置并将其更改为隐式拒绝（implicit deny） 编辑配置以正确指向提供的 HTTPS 端点 最后，通过尝试部署易受攻击的资源 /cks/img/web1.yaml 来测试配置是否有效。 你可以在 /var/log/imagepolicy/roadrunner.log 找到容器镜像扫描仪的日志文件。 Solution搜索 imagepolicywebhook（使用准入控制器），接着再搜索字符串”imagepolicywebhook”https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/admission-controllers/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 0 master nodessh masterNodecd /etc/kubernetes/epconfigls admission_configuration.json kubeconfig.yaml### 查看config-file路径cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep --admission-control-config-file - --admission-control-config-file=/etc/kubernetes/epconfig/admission_configuration.json ### 1 验证控制平面的配置并将其更改为拒绝vim /etc/kubernetes/epconfig/admission_configuration.json{ &quot;apiVersion&quot;: &quot;apiserver.config.k8s.io/v1&quot;, &quot;kind&quot;: &quot;AdmissionConfiguration&quot;, &quot;plugins&quot;: [ { &quot;name&quot;: &quot;ImagePolicyWebhook&quot;, &quot;configuration&quot;: { &quot;imagePolicy&quot;: { &quot;kubeConfigFile&quot;: &quot;/etc/kubernetes/epconfig/kubeconfig.yaml&quot;, // 1.1 kubeconfig &quot;allowTTL&quot;: 100, &quot;denyTTL&quot;: 50, &quot;retryBackoff&quot;: 500, &quot;defaultAllow&quot;: false // 1.2 modify from true to false } } } ]}### 2 编辑配置以正确指向提供的 HTTPS 端点vim kubeconfig.yaml apiVersion: v1 kind: Config clusters: - cluster: certificate-authority: /etc/kubernetes/epconfig/webhook.pem server: https://acme.local:8082/image_policy # 2 配置此步 name: bouncer_webhook### 3 启用必要的插件以创建镜像策略vim /etc/kubernetes/manifests/kube-apiserver.yaml - --enable-admission-plugins=NodeRestriction,ImagePolicyWebhook # 3.1 Add ImagePolicyWebhook - --admission-control-config-file=/etc/kubernetes/epconfig/admission_configuration.json # 3.2 Check config-file path ...... volumeMounts: # 3.3 Check Mount, can search audit log in kubernetes.io - mountPath: /etc/kubernetes/epconfig name: config readyOnly: false volumes: - hostPath: path: /etc/kubernetes/epconfig type: DirectoryOrCreate name: config### 4 加载生效配置systemctl daemon-reloadsystemctl restart kubelet### 5 通过部署易受攻击的资源来测试配置是否有效kubectl apply -f /cks/img/web1.yaml 考题14 - 删除非无状态或非不可变的 podContext: it is best-practice to design containers to be stateless and immutable TaskInspect Pods runnings in namespace production and delete any Pod that is either not stateless or not immutable. Use the following strict interpretation of stateless and immutable: Pod being able to store data inside containers must be treated as not stateless. You don’t have to worry whether data is actually stored inside containers or not already. Pod being configured to be privileged in any way must be treated as potentially not stateless and not immutable. 检查在 namespace production 中运行的 Pod，并删除任何非无状态或非不可变的 Pod。使用以下对无状态和不可变的严格解释： 能够在容器内存储数据的 Pod 的容器必须被视为非无状态的。 被配置为任何形式的特权 Pod 必须被视为可能是非无状态和非不可变的。注意：你不必担心数据是否实际上已经存储在容器中。 123456789101112### 在命名空间 dev 中检查 running 状态的 podkubectl get pods -n production | grep running -i### 查看具有特权的 podkubectl get pods -n production -oyaml | grep -i &quot;privileged: true&quot;### 查看具有 volume 的 pod# jq 用于处理JSON输入，将给定过滤器应用于其JSON文本输入并在标准输出上将过滤器的结果生成为JSON。kubectl get pods -n production -o jsonpath={.spec.volumes} | jq### 将查询到的具有特权和 volume 的 pod 都删除kubectl delete pods -n production pod名称 考题15 - gVisor/runtimeclassContextThis cluster uses containerd as CRI runtime.Containerd’s default runtime handler is runc . Containerd has been prepared to support an additional runtime handler , runsc (gVisor). 该 cluster 使用 containerd 作为 CRI 运行时。containerd 的默认运行时处理程序是 runc。 containerd 已准备好支持额外的运行时处理程序 runsc (gVisor)。 TaskCreate a RuntimeClass named untrusted using the prepared runtime handler named runsc.Update all Pods in the namespace server to run on gvisor, unless they are already running on anon-default runtime handler.You can find a skeleton manifest file at /cks/13/rc.yaml 使用名为 runsc 的现有运行时处理程序，创建一个名为 untrusted 的 RuntimeClass。更新 namespace server 中的所有 Pod 以在 gVisor 上运行。您可以在 /cks/gVisor/rc.yaml 中找到一个模版清单 Solution搜索 runtimeclass（容器运行时类）https://kubernetes.io/zh-cn/docs/concepts/containers/runtime-class/ 123456789101112131415161718192021222324### 修改模板清单文件vim /cks/gVisor/rc.yaml apiVersion: node.k8s.io/v1 kind: RuntimeClass metadata: name: untrusted handler: runsc### 应用清单文件kubectl apply -f /cks/gVisor/rc.yaml### 修改 server 命名空间下的所有 pod（还需要修改deployment）kubectl get pods -n serverkubectl get deployments -n serverkubectl get pods -n server -oyaml &gt; myrc.yamlvim myrc.yamlspec: ...... runtimeClassName: untrusted### 更新清单文件kubectl delete -f myrc.yamlkubectl apply -f myrc.yaml 考题16 - 启用 API Server 认证Context由 kubeadm 创建的 cluster 的 Kubernetes API 服务器，出于测试目的，临时配置允许未经身份验证和未经授权的访问，授予匿名用户 cluster-admin 的访问权限。 Task重新配置 cluster 的 Kubernetes API 服务器，以确保只允许经过身份验证和授权的 REST 请求。使用授权模式 Node,RBAC 和准入控制器 NodeRestriction。删除用户 system:anonymous 的 ClusterRoleBinding 来进行清理。注意：所有 kubectl 配置环境/文件也被配置使用未经身份验证和未经授权的访问。 你不必更改它，但请注意，一旦完成 cluster 的安全加固， kubectl 的配置将无法工作。 您可以使用位于 cluster 的 master 节点上，cluster 原本的 kubectl 配置文件 /etc/kubernetes/admin.conf ，以确保经过身份验证的授权的请求仍然被允许。 123456789101112131415k get nodes### 注意：修改 master 节点！ssh masterNode### (1)使用授权模式 Node,RBAC 和准入控制器 NodeRestrictionvim /etc/kubernetes/manifests/kube-apiserver.yaml - --authorization-mode=Node,RBAC # modify Node,RBAC - --enable-admission-plugins=NodeRestriction # modify NodeRestriction - --client-ca-file=/etc/kubernetes/pki/ca.crt - --enable-bootstrap-token-auth=true### (2)删除 system:anonymous 的 ClusterRolebinding 角色绑定（取消匿名用户的集群管理员权限）k get clusterrolebinding -A | grep system:anonymouskubectl delete clusterrolebinding system:anonymous 参考文章 CKS 真题 2022年11月最新CKS认证题库 2022.10 CKS考试题库v1.24 2022.10 CKS 1.24真题解析 2022.8 kubernets CKS内容及题库 2022.6 CKS认证考题+解析 2022.3 CKS 1.23 真题 2022.1 cks 试题 2021.12 Kubernetes CKS 1.20 - 真题 15道题 2021 Kubernetes CKS 1.20 - 真题 15道题 CKS其他 CKS考试知识点链接 From: http://liyuankun.top/Kubernates-Certified%20Kubernetes%20Security%20Specialist-CKS.html 真题③基于1.22版本1、Pod 指定 ServiceAccount Task 在现有 namespace qa 中创建一个名为 backend-sa 的新 ServiceAccount， 确保此ServiceAccount 不自动挂载 API 凭据。 使用 /cks/sa/pod1.yaml 中的清单文件来创建一个 Pod。 最后，清理 namespace qa 中任何未使用的 ServiceAccount。 2、RBAC - RoleBindingContext 绑定到 Pod 的 ServiceAccount 的 Role 授予过度宽松的权限。完成以下项目以减少权限集。 Task 一个名为 web-pod 的现有 Pod 已在 namespace db 中运行。 编辑绑定到 Pod 的 ServiceAccount service-account-web 的现有 Role， 仅允许只对 services 类型的资源 执行 get 操作。 在namespace db 中创建一个名为 role-2 ，并仅允许只对 namespaces 类型的资源执行 delete 操作的新Role。 创建一个名为 role-2-binding 的新 RoleBinding，将新创建的 Role 绑定到 Pod 的ServiceAccount。 注意：请勿删除现有的 RoleBinding。 3、启用 API server 认证Context 由 kubeadm 创建的 cluster 的 Kubernetes API 服务器，出于测试目的，临时配置允许未经身份验证和未经授权的访问，授予匿名用户 cluster-admin 的访问权限. Task 重新配置 cluster 的Kubernetes APl 服务器，以确保只允许经过身份验证和授权的 REST 请求。 使用授权模式 Node,RBAC 和准入控制器NodeRestriction。 删除用户 system:anonymous 的 ClusterRoleBinding 来进行清理。 注意：所有 kubectl 配置环境/文件也被配置使用未经身份验证和未经授权的访问。 你不必更改它，但请注意，一旦完成 cluster的安全加固， kubectl 的配置将无法工作。 您可以使用位于 cluster 的 master 节点上，cluster 原本的kubectl 配置文件 /etc/kubernetes/admin.conf ，以确保经过身份验证的授权的请求仍然被允许。 4、Sysdig &amp; falcoTask： 使用运行时检测工具来检测 Pod tomcat 单个容器中频发生成和执行的异常进程。 有两种工具可供使用： ⚫ sysdig⚫ falco 注： 这些工具只预装在 cluster 的工作节点，不在 master 节点。 使用工具至少分析 30 秒，使用过滤器检查生成和执行的进程，将事件写到 /opt/KSR00101/incidents/summary 文件中，其中包含检测的事件， 格式如下： [timestamp],[uid],[processName] 保持工具的原始时间戳格式不变。 注：确保事件文件存储在集群的工作节点上。 5、 容器安全，删除特权 PodTask 检查在 namespace production 中运行的 Pod，并删除任何非无状态或非不可变的 Pod。使用以下对无状态和不可变的严格解释： ⚫ 能够在容器内存储数据的 Pod 的容器必须被视为非无状态的。注意：你不必担心数据是否实际上已经存储在容器中。 ⚫ 被配置为任何形式的特权 Pod 必须被视为可能是非无状态和非不可变的。 6、沙箱运行容器 gVisorContext 该 cluster 使用 containerd 作为 CRI 运行时。containerd 的默认运行时处理程序是runc。 containerd 已准备好支持额外的运行时处理程序 runsc (gVisor)。 Task 使用名为 runsc的现有运行时处理程序，创建一个名为 untrusted 的 RuntimeClass。 更新 namespace server 中的所有Pod 以在 gVisor 上运行。 您可以在 /cks/gVisor/rc.yaml 中找到一个模版清单 7、Pod 安全策略-PSPContext PodSecurityPolicy 应防在特定 namespace 中特权 Pod 的创建。 Task 创建一个名为restrict-policy 的新的PodSecurityPolicy，以防止特权 Pod 的创建。 创建一个名为restrict-access-role 并使用新创建的 PodSecurityPolicy restrict-policy 的ClusterRole。 在现有的 namespace staging 中创建一个名为 psp-denial-sa 的新ServiceAccount 。最后，创建一个名为 dany-access-bind 的 ClusterRoleBinding ，将新创建的 ClusterRole restrict-access-role 绑定到新创建的 ServiceAccount psp-denial-sa。 你可以在一下位置找到模版清单文件： /cks/psp/psp.yaml 8、创建 SecretTask 在 namespace istio-system 中获取名为 db1-test 的现有 secret 的内容 将 username字段存储在名为 /cks/sec/user.txt 的文件中，并将 password 字段存储在名为 /cks/sec/pass.txt 的文件 中。注意：你必须创建以上两个文件，他们还不存在。 注意：不要在以下步骤中使用/修改先前创建的文件，如果需要，可以创建新的临时文件。 在 istio-system namespace 中创建一个名为 db2-test 的新 secret，内容如下： username : production-instance password : KvLftKgs4aVH 最后，创建一个新的 Pod，它可以通过卷访问 secret db2-test ： Pod 名称 secret-pod Namespace istio-system 容器名 dev-container 镜像 nginx 卷名 secret-volume 挂载路径 /etc/secret 9、AppArmorContext APPArmor 已在 cluster 的工作节点上被启用。一个 APPArmor 配置文件已存在，但尚未被实施 Task在 cluster 的工作节点上，实施位于 /etc/apparmor.d/nginx_apparmor 的现有 APPArmor配置文件。 编辑位于 /home/candidate/KSSH00401/nginx-deploy.yaml 的现有清单文件以应用 AppArmor 配置文件。 最后，应用清单文件并创建其中指定的 Pod 。 10、kube-bench 修复不安全项Context 针对 kubeadm 创建的 cluster 运行 CIS 基准测试工具时， 发现了多个必须立即解决的问题。 Task通过配置修复所有问题并重新启动受影响的组件以确保新的设置生效。 修复针对 API 服务器发现的所有以下违规行为： 1.2.7 Ensure that the –authorization-mode argument is not set to AlwaysAllow 1.2.8 Ensure that the –authorization-mode argument includes Node 1.2.9 Ensure that the –authorization-mode argument includes RBAC 1.2.18 Ensure that the –insecure-bind-address argument is not set 1.2.19 Ensure that the –insecure-port argument is set to 0 FAIL FAIL FAIL FAIL FAIL 修复针对 kubelet 发现的所有以下违规行为： Fix all of the following violations that were found against the kubelet: 4.2.1 Ensure that the anonymous-auth argument is set to false 4.2.2 Ensure that the –authorization-mode argument is not set to AlwaysAllow FAIL FAIL 注意：尽可能使用 Webhook 身份验证/授权。 修复针对 etcd 发现的所有以下违规行为： Fix all of the following violations that were found against etcd: 2.2 Ensure that the –client-cert-auth argument is set to true FAIL 11、网络策略 NetworkPolicyTask 创建一个名为 pod-restriction 的 NetworkPolicy 来限制对在 namespace dev-team 中运行的 Pod products-service 的访问。 只允许以下 Pod 连接到 Pod products-service ⚫ namespace qa 中的 Pod ⚫ 位于任何 namespace，带有标签 environment: testing 的 Pod 注意：确保应用 NetworkPolicy。 你可以在/cks/net/po.yaml 找到一个模板清单文件。 12、Dockerfile 检测Task 分析和编辑给定的 Dockerfile /cks/docker/Dockerfile（基于 ubuntu:16.04 镜像），并修复在文件中拥有的突出的安全/最佳实践问题的两个指令。 分析和编辑给定的清单文件 /cks/docker/deployment.yaml， 并修复在文件中拥有突出的安全/最佳实践问题的两个字段。注意：请勿添加或删除配置设置；只需修改现有的配置设置让以上两个配置设置都不再有安全/最佳实践问题。注意：如果您需要非特权用户来执行任何项目，请使用用户 ID 65535 的用户 nobody 。 答题： 注意，本次的 Dockerfile和 deployment.yaml 仅修改即可，无需部署。 13、ImagePolicyWebhook 容器镜像扫描Context cluster 上设置了容器镜像扫描器，但尚未完全集成到 cluster 的配置中。完成后，容器镜像扫描器应扫描并拒绝易受攻击的镜像的使用。 Task 注意：你必须在 cluster 的 master 节点上完成整个考题，所有服务和文件都已被准备好并放置在该节点上。 给定一个目录 /etc/kubernetes/epconfig 中不完整的配置以及具有 HTTPS 端点 https://acme.local:8082/image_policy 的功能性容器镜像扫描器： 启用必要的插件来创建镜像策略 校验控制配置并将其更改为隐式拒绝（implicit deny） 编辑配置以正确指向提供的 HTTPS 端点 最后，通过尝试部署易受攻击的资源 /cks/img/web1.yaml 来测试配置是否有效。 你可以在 /var/log/imagepolicy/roadrunner.log 找到容器镜像扫描仪的日志文件。 14、Trivy 扫描镜像安全漏洞Task 使用 Trivy 开源容器扫描器检测 namespace kamino 中 Pod 使用的具有严重漏洞的镜像。 查找具有 High 或 Critical 严重性漏洞的镜像，并删除使用这些镜像的 Pod。 注意：Trivy 仅安装在 cluster 的 master 节点上， 在工作节点上不可使用。 你必须切换到 cluster 的 master 节点才能使用 Trivy 15、默认网络策略Context 一个默认拒绝（default-deny）的 NetworkPolicy 可避免在未定义任何其他 NetworkPolicy 的 namespace 中 意外公开 Pod。 Task 为所有类型为 Ingress+Egress 的流量在 namespace testing 中创建一个名为 denypolicy 的新默认拒绝 NetworkPolicy。 此新的 NetworkPolicy 必须拒绝 namespace testing 中的所有的 Ingress + Egress 流量。 将新创建的默认拒绝 NetworkPolicy 应用与在 namespace testing 中运行的所有 Pod。 你可以在 /cks/net/p1.yaml 找到一个模板清单文件。 16、日志审计 log auditTask 在 cluster 中启用审计日志。为此，请启用日志后端，并确保：⚫ 日志存储在 /var/log/kubernetes/audit-logs.txt⚫ 日志文件能保留 10 天⚫ 最多保留 2 个旧审计日志文件/etc/kubernetes/logpolicy/sample-policy.yaml 提供了基本策略。它仅指定不记录的内容。注意：基本策略位于 cluster 的 master 节点上。 编辑和扩展基本策略以记录：⚫ RequestResponse 级别的cronjobs 更改⚫ namespace front-apps 中 deployment 更改的请求体⚫ Metadata级别的所有 namespace 中的 ConfigMap 和 Secret 的更改 此外，添加一个全方位的规则以在 Metadata级别记录所有其他请求。 注意：不要忘记应用修改后的策略 真题④基于1.22版本云原生|kubernetes|2022年底cks真题解析（1-10）_cks试题_晚风_END的博客-CSDN博客云原生|kubernetes|2022年底cks真题解析（11-16）_晚风_END的博客-CSDN博客","link":"/2024/12/09/25470f32f4bb.html"}],"tags":[{"name":"IO","slug":"IO","link":"/tags/IO/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"spinnaker","slug":"spinnaker","link":"/tags/spinnaker/"},{"name":"源码分析","slug":"源码分析","link":"/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"clouddriver","slug":"clouddriver","link":"/tags/clouddriver/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/tags/SpringBoot/"},{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"拆包","slug":"拆包","link":"/tags/%E6%8B%86%E5%8C%85/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"容器","slug":"容器","link":"/tags/%E5%AE%B9%E5%99%A8/"},{"name":"reactor","slug":"reactor","link":"/tags/reactor/"},{"name":"orca","slug":"orca","link":"/tags/orca/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"CNI","slug":"CNI","link":"/tags/CNI/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"UNIX","slug":"UNIX","link":"/tags/UNIX/"},{"name":"aws","slug":"aws","link":"/tags/aws/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"原生系统","slug":"原生系统","link":"/tags/%E5%8E%9F%E7%94%9F%E7%B3%BB%E7%BB%9F/"},{"name":"打包","slug":"打包","link":"/tags/%E6%89%93%E5%8C%85/"},{"name":"Looper","slug":"Looper","link":"/tags/Looper/"},{"name":"Handler","slug":"Handler","link":"/tags/Handler/"},{"name":"签名","slug":"签名","link":"/tags/%E7%AD%BE%E5%90%8D/"},{"name":"坑","slug":"坑","link":"/tags/%E5%9D%91/"},{"name":"adb","slug":"adb","link":"/tags/adb/"},{"name":"argocd","slug":"argocd","link":"/tags/argocd/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"ArrayList","slug":"ArrayList","link":"/tags/ArrayList/"},{"name":"ButterKnife","slug":"ButterKnife","link":"/tags/ButterKnife/"},{"name":"指针与引用","slug":"指针与引用","link":"/tags/%E6%8C%87%E9%92%88%E4%B8%8E%E5%BC%95%E7%94%A8/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"ftp","slug":"ftp","link":"/tags/ftp/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"服务器环境","slug":"服务器环境","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83/"},{"name":"calico","slug":"calico","link":"/tags/calico/"},{"name":"CKA","slug":"CKA","link":"/tags/CKA/"},{"name":"cmake","slug":"cmake","link":"/tags/cmake/"},{"name":"函数指针","slug":"函数指针","link":"/tags/%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88/"},{"name":"Dockerfile","slug":"Dockerfile","link":"/tags/Dockerfile/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"inode","slug":"inode","link":"/tags/inode/"},{"name":"EventBus","slug":"EventBus","link":"/tags/EventBus/"},{"name":"异常","slug":"异常","link":"/tags/%E5%BC%82%E5%B8%B8/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"Flask","slug":"Flask","link":"/tags/Flask/"},{"name":"日志","slug":"日志","link":"/tags/%E6%97%A5%E5%BF%97/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"google","slug":"google","link":"/tags/google/"},{"name":"groovy","slug":"groovy","link":"/tags/groovy/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"helm","slug":"helm","link":"/tags/helm/"},{"name":"HashMap","slug":"HashMap","link":"/tags/HashMap/"},{"name":"idea","slug":"idea","link":"/tags/idea/"},{"name":"Iterator","slug":"Iterator","link":"/tags/Iterator/"},{"name":"JDBC","slug":"JDBC","link":"/tags/JDBC/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"AQS","slug":"AQS","link":"/tags/AQS/"},{"name":"集合","slug":"集合","link":"/tags/%E9%9B%86%E5%90%88/"},{"name":"Queue","slug":"Queue","link":"/tags/Queue/"},{"name":"Threadlocal","slug":"Threadlocal","link":"/tags/Threadlocal/"},{"name":"值传递与引用传递","slug":"值传递与引用传递","link":"/tags/%E5%80%BC%E4%BC%A0%E9%80%92%E4%B8%8E%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92/"},{"name":"注解","slug":"注解","link":"/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"线程池","slug":"线程池","link":"/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"并发工具","slug":"并发工具","link":"/tags/%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Java进程自动消失","slug":"Java进程自动消失","link":"/tags/Java%E8%BF%9B%E7%A8%8B%E8%87%AA%E5%8A%A8%E6%B6%88%E5%A4%B1/"},{"name":"apiserver","slug":"apiserver","link":"/tags/apiserver/"},{"name":"pod","slug":"pod","link":"/tags/pod/"},{"name":"container","slug":"container","link":"/tags/container/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"oj","slug":"oj","link":"/tags/oj/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"LinkedList","slug":"LinkedList","link":"/tags/LinkedList/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"运行级别","slug":"运行级别","link":"/tags/%E8%BF%90%E8%A1%8C%E7%BA%A7%E5%88%AB/"},{"name":"分区调整","slug":"分区调整","link":"/tags/%E5%88%86%E5%8C%BA%E8%B0%83%E6%95%B4/"},{"name":"manjaro","slug":"manjaro","link":"/tags/manjaro/"},{"name":"Maven","slug":"Maven","link":"/tags/Maven/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"Mongo","slug":"Mongo","link":"/tags/Mongo/"},{"name":"刷机","slug":"刷机","link":"/tags/%E5%88%B7%E6%9C%BA/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"PageHelper","slug":"PageHelper","link":"/tags/PageHelper/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"卡住","slug":"卡住","link":"/tags/%E5%8D%A1%E4%BD%8F/"},{"name":"l2tp","slug":"l2tp","link":"/tags/l2tp/"},{"name":"oracle","slug":"oracle","link":"/tags/oracle/"},{"name":"脚本","slug":"脚本","link":"/tags/%E8%84%9A%E6%9C%AC/"},{"name":"csi","slug":"csi","link":"/tags/csi/"},{"name":"PageAble","slug":"PageAble","link":"/tags/PageAble/"},{"name":"分页","slug":"分页","link":"/tags/%E5%88%86%E9%A1%B5/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"},{"name":"RestTemplate","slug":"RestTemplate","link":"/tags/RestTemplate/"},{"name":"tutorial","slug":"tutorial","link":"/tags/tutorial/"},{"name":"语法","slug":"语法","link":"/tags/%E8%AF%AD%E6%B3%95/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"service","slug":"service","link":"/tags/service/"},{"name":"Set","slug":"Set","link":"/tags/Set/"},{"name":"SmartRefreshLayout","slug":"SmartRefreshLayout","link":"/tags/SmartRefreshLayout/"},{"name":"文件上传","slug":"文件上传","link":"/tags/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/"},{"name":"Spring Data Mongo","slug":"Spring-Data-Mongo","link":"/tags/Spring-Data-Mongo/"},{"name":"全局异常处理","slug":"全局异常处理","link":"/tags/%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"特殊字符","slug":"特殊字符","link":"/tags/%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6/"},{"name":"双数据源","slug":"双数据源","link":"/tags/%E5%8F%8C%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"拦截器","slug":"拦截器","link":"/tags/%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"name":"SpringMVC","slug":"SpringMVC","link":"/tags/SpringMVC/"},{"name":"String","slug":"String","link":"/tags/String/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"JNI","slug":"JNI","link":"/tags/JNI/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"VMware Fusion","slug":"VMware-Fusion","link":"/tags/VMware-Fusion/"},{"name":"WebSocket","slug":"WebSocket","link":"/tags/WebSocket/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"VPN","slug":"VPN","link":"/tags/VPN/"},{"name":"L2TP","slug":"L2TP","link":"/tags/L2TP/"},{"name":"IPSec","slug":"IPSec","link":"/tags/IPSec/"},{"name":"cks","slug":"cks","link":"/tags/cks/"},{"name":"玩具","slug":"玩具","link":"/tags/%E7%8E%A9%E5%85%B7/"},{"name":"curl","slug":"curl","link":"/tags/curl/"},{"name":"grpc","slug":"grpc","link":"/tags/grpc/"},{"name":"crlf","slug":"crlf","link":"/tags/crlf/"},{"name":"lf","slug":"lf","link":"/tags/lf/"},{"name":"jQuery","slug":"jQuery","link":"/tags/jQuery/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"流媒体","slug":"流媒体","link":"/tags/%E6%B5%81%E5%AA%92%E4%BD%93/"},{"name":"libstreaming","slug":"libstreaming","link":"/tags/libstreaming/"},{"name":"回溯法","slug":"回溯法","link":"/tags/%E5%9B%9E%E6%BA%AF%E6%B3%95/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"profile","slug":"profile","link":"/tags/profile/"},{"name":"macos","slug":"macos","link":"/tags/macos/"},{"name":"homebrew","slug":"homebrew","link":"/tags/homebrew/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"netcat","slug":"netcat","link":"/tags/netcat/"},{"name":"tcpdump","slug":"tcpdump","link":"/tags/tcpdump/"},{"name":"try","slug":"try","link":"/tags/try/"},{"name":"free","slug":"free","link":"/tags/free/"},{"name":"windows激活","slug":"windows激活","link":"/tags/windows%E6%BF%80%E6%B4%BB/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"UML","slug":"UML","link":"/tags/UML/"},{"name":"rebase","slug":"rebase","link":"/tags/rebase/"},{"name":"分布式锁","slug":"分布式锁","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"二叉树遍历","slug":"二叉树遍历","link":"/tags/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/"},{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"WiFi直联","slug":"WiFi直联","link":"/tags/WiFi%E7%9B%B4%E8%81%94/"},{"name":"Raft","slug":"Raft","link":"/tags/Raft/"},{"name":"位图","slug":"位图","link":"/tags/%E4%BD%8D%E5%9B%BE/"},{"name":"protected","slug":"protected","link":"/tags/protected/"},{"name":"端口转发","slug":"端口转发","link":"/tags/%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/"},{"name":"RocketMQ","slug":"RocketMQ","link":"/tags/RocketMQ/"},{"name":"framework","slug":"framework","link":"/tags/framework/"},{"name":"编译","slug":"编译","link":"/tags/%E7%BC%96%E8%AF%91/"},{"name":"Bitmap","slug":"Bitmap","link":"/tags/Bitmap/"},{"name":"final","slug":"final","link":"/tags/final/"},{"name":"RequestMapping","slug":"RequestMapping","link":"/tags/RequestMapping/"},{"name":"堆栈","slug":"堆栈","link":"/tags/%E5%A0%86%E6%A0%88/"},{"name":"openwrt","slug":"openwrt","link":"/tags/openwrt/"},{"name":"OOM","slug":"OOM","link":"/tags/OOM/"},{"name":"单例模式","slug":"单例模式","link":"/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"kata","slug":"kata","link":"/tags/kata/"},{"name":"containerd","slug":"containerd","link":"/tags/containerd/"},{"name":"cgo","slug":"cgo","link":"/tags/cgo/"},{"name":"系统源代码导入","slug":"系统源代码导入","link":"/tags/%E7%B3%BB%E7%BB%9F%E6%BA%90%E4%BB%A3%E7%A0%81%E5%AF%BC%E5%85%A5/"},{"name":"nfs","slug":"nfs","link":"/tags/nfs/"},{"name":"buildah","slug":"buildah","link":"/tags/buildah/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"概率","slug":"概率","link":"/tags/%E6%A6%82%E7%8E%87/"},{"name":"jdk","slug":"jdk","link":"/tags/jdk/"},{"name":"tar","slug":"tar","link":"/tags/tar/"},{"name":"signal","slug":"signal","link":"/tags/signal/"},{"name":"tini","slug":"tini","link":"/tags/tini/"},{"name":"开机慢","slug":"开机慢","link":"/tags/%E5%BC%80%E6%9C%BA%E6%85%A2/"},{"name":"关机慢","slug":"关机慢","link":"/tags/%E5%85%B3%E6%9C%BA%E6%85%A2/"},{"name":"macbook","slug":"macbook","link":"/tags/macbook/"},{"name":"command","slug":"command","link":"/tags/command/"},{"name":"颜色空间","slug":"颜色空间","link":"/tags/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/"},{"name":"排序","slug":"排序","link":"/tags/%E6%8E%92%E5%BA%8F/"},{"name":"黑苹果","slug":"黑苹果","link":"/tags/%E9%BB%91%E8%8B%B9%E6%9E%9C/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"halo","slug":"halo","link":"/tags/halo/"},{"name":"音量调节","slug":"音量调节","link":"/tags/%E9%9F%B3%E9%87%8F%E8%B0%83%E8%8A%82/"},{"name":"SSM","slug":"SSM","link":"/tags/SSM/"},{"name":"换行符","slug":"换行符","link":"/tags/%E6%8D%A2%E8%A1%8C%E7%AC%A6/"},{"name":"汇编","slug":"汇编","link":"/tags/%E6%B1%87%E7%BC%96/"},{"name":"GIS","slug":"GIS","link":"/tags/GIS/"},{"name":"重构","slug":"重构","link":"/tags/%E9%87%8D%E6%9E%84/"},{"name":"TabLayout","slug":"TabLayout","link":"/tags/TabLayout/"},{"name":"lvm2","slug":"lvm2","link":"/tags/lvm2/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"超时","slug":"超时","link":"/tags/%E8%B6%85%E6%97%B6/"},{"name":"防火墙","slug":"防火墙","link":"/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"反射","slug":"反射","link":"/tags/%E5%8F%8D%E5%B0%84/"},{"name":"hierarchyview","slug":"hierarchyview","link":"/tags/hierarchyview/"},{"name":"项目架构","slug":"项目架构","link":"/tags/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/"},{"name":"ai","slug":"ai","link":"/tags/ai/"},{"name":"overview","slug":"overview","link":"/tags/overview/"},{"name":"Calico","slug":"Calico","link":"/tags/Calico/"},{"name":"CKS","slug":"CKS","link":"/tags/CKS/"}],"categories":[{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Spring系列","slug":"Spring系列","link":"/categories/Spring%E7%B3%BB%E5%88%97/"},{"name":"Spinnaker","slug":"Spinnaker","link":"/categories/Spinnaker/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/categories/Kubernetes/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"开发工具","slug":"开发工具","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"编程语言","slug":"编程语言","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"macOS","slug":"macOS","link":"/categories/macOS/"},{"name":"大数据","slug":"大数据","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Rust","slug":"Rust","link":"/categories/Rust/"},{"name":"考古文物","slug":"考古文物","link":"/categories/%E8%80%83%E5%8F%A4%E6%96%87%E7%89%A9/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"AI","slug":"AI","link":"/categories/AI/"}],"pages":[{"title":"About","text":"对过往忏悔，对未来充满信心。 悟已往之不谏，知来者之可追。","link":"/about.html"},{"title":"","text":"pics博客用图床","link":"/images/pics/README.html"}]}